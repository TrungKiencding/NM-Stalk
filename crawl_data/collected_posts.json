[
  {
    "link": "https://github.com/confident-ai/deepeval",
    "raw_content": "[Skip to content](https://github.com/confident-ai/deepeval#start-of-content)\n## Navigation Menu\nToggle navigation\n[ ](https://github.com/)\n[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fconfident-ai%2Fdeepeval)\nAppearance settings\n  * Product \n    * [ GitHub Copilot  Write better code with AI  ](https://github.com/features/copilot)\n    * [ GitHub Models  New  Manage and compare prompts  ](https://github.com/features/models)\n    * [ GitHub Advanced Security  Find and fix vulnerabilities  ](https://github.com/security/advanced-security)\n    * [ Actions  Automate any workflow  ](https://github.com/features/actions)\n    * [ Codespaces  Instant dev environments  ](https://github.com/features/codespaces)\n    * [ Issues  Plan and track work  ](https://github.com/features/issues)\n    * [ Code Review  Manage code changes  ](https://github.com/features/code-review)\n    * [ Discussions  Collaborate outside of code  ](https://github.com/features/discussions)\n    * [ Code Search  Find more, search less  ](https://github.com/features/code-search)\nExplore\n    * [ Why GitHub ](https://github.com/why-github)\n    * [ All features ](https://github.com/features)\n    * [ Documentation ](https://docs.github.com)\n    * [ GitHub Skills ](https://skills.github.com)\n    * [ Blog ](https://github.blog)\n  * Solutions \nBy company size\n    * [ Enterprises ](https://github.com/enterprise)\n    * [ Small and medium teams ](https://github.com/team)\n    * [ Startups ](https://github.com/enterprise/startups)\n    * [ Nonprofits ](https://github.com/solutions/industry/nonprofits)\nBy use case\n    * [ DevSecOps ](https://github.com/solutions/use-case/devsecops)\n    * [ DevOps ](https://github.com/solutions/use-case/devops)\n    * [ CI/CD ](https://github.com/solutions/use-case/ci-cd)\n    * [ View all use cases ](https://github.com/solutions/use-case)\nBy industry\n    * [ Healthcare ](https://github.com/solutions/industry/healthcare)\n    * [ Financial services ](https://github.com/solutions/industry/financial-services)\n    * [ Manufacturing ](https://github.com/solutions/industry/manufacturing)\n    * [ Government ](https://github.com/solutions/industry/government)\n    * [ View all industries ](https://github.com/solutions/industry)\n[ View all solutions ](https://github.com/solutions)\n  * Resources \nTopics\n    * [ AI ](https://github.com/resources/articles/ai)\n    * [ DevOps ](https://github.com/resources/articles/devops)\n    * [ Security ](https://github.com/resources/articles/security)\n    * [ Software Development ](https://github.com/resources/articles/software-development)\n    * [ View all ](https://github.com/resources/articles)\nExplore\n    * [ Learning Pathways ](https://resources.github.com/learn/pathways)\n    * [ Events & Webinars ](https://resources.github.com)\n    * [ Ebooks & Whitepapers ](https://github.com/resources/whitepapers)\n    * [ Customer Stories ](https://github.com/customer-stories)\n    * [ Partners ](https://partner.github.com)\n    * [ Executive Insights ](https://github.com/solutions/executive-insights)\n  * Open Source \n    * [ GitHub Sponsors  Fund open source developers  ](https://github.com/sponsors)\n    * [ The ReadME Project  GitHub community articles  ](https://github.com/readme)\nRepositories\n    * [ Topics ](https://github.com/topics)\n    * [ Trending ](https://github.com/trending)\n    * [ Collections ](https://github.com/collections)\n  * Enterprise \n    * [ Enterprise platform  AI-powered developer platform  ](https://github.com/enterprise)\nAvailable add-ons\n    * [ GitHub Advanced Security  Enterprise-grade security features  ](https://github.com/security/advanced-security)\n    * [ Copilot for business  Enterprise-grade AI features  ](https://github.com/features/copilot/copilot-business)\n    * [ Premium Support  Enterprise-grade 24/7 support  ](https://github.com/premium-support)\n  * [Pricing](https://github.com/pricing)\n\n\nSearch or jump to...\n# Search code, repositories, users, issues, pull requests...\nSearch \nClear\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n#  Provide feedback \nWe read every piece of feedback, and take your input very seriously.\nInclude my email address so I can be contacted\nCancel  Submit feedback \n#  Saved searches \n## Use saved searches to filter your results more quickly\nName\nQuery\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax). \nCancel  Create saved search \n[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fconfident-ai%2Fdeepeval)\n[ Sign up ](https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=confident-ai%2Fdeepeval)\nAppearance settings\nResetting focus\nYou signed in with another tab or window. [Reload](https://github.com/confident-ai/deepeval) to refresh your session. You signed out in another tab or window. [Reload](https://github.com/confident-ai/deepeval) to refresh your session. You switched accounts on another tab or window. [Reload](https://github.com/confident-ai/deepeval) to refresh your session. Dismiss alert\n{{ message }}\n[ confident-ai ](https://github.com/confident-ai) / **[deepeval](https://github.com/confident-ai/deepeval) ** Public\n  * [ Notifications ](https://github.com/login?return_to=%2Fconfident-ai%2Fdeepeval) You must be signed in to change notification settings\n  * [ Fork 623 ](https://github.com/login?return_to=%2Fconfident-ai%2Fdeepeval)\n  * [ Star  6.8k ](https://github.com/login?return_to=%2Fconfident-ai%2Fdeepeval)\n\n\nThe LLM Evaluation Framework \n[deepeval.com](https://deepeval.com \"https://deepeval.com\")\n### License\n[ Apache-2.0 license ](https://github.com/confident-ai/deepeval/blob/main/LICENSE.md)\n[ 6.8k stars ](https://github.com/confident-ai/deepeval/stargazers) [ 623 forks ](https://github.com/confident-ai/deepeval/forks) [ Branches ](https://github.com/confident-ai/deepeval/branches) [ Tags ](https://github.com/confident-ai/deepeval/tags) [ Activity ](https://github.com/confident-ai/deepeval/activity)\n[ Star  ](https://github.com/login?return_to=%2Fconfident-ai%2Fdeepeval)\n[ Notifications ](https://github.com/login?return_to=%2Fconfident-ai%2Fdeepeval) You must be signed in to change notification settings\n  * [ Code ](https://github.com/confident-ai/deepeval)\n  * [ Issues 157 ](https://github.com/confident-ai/deepeval/issues)\n  * [ Pull requests 15 ](https://github.com/confident-ai/deepeval/pulls)\n  * [ Discussions ](https://github.com/confident-ai/deepeval/discussions)\n  * [ Actions ](https://github.com/confident-ai/deepeval/actions)\n  * [ Projects 0 ](https://github.com/confident-ai/deepeval/projects)\n  * [ Security ](https://github.com/confident-ai/deepeval/security)\n[ ](https://github.com/confident-ai/deepeval/security)\n[ ](https://github.com/confident-ai/deepeval/security)\n[ ](https://github.com/confident-ai/deepeval/security)\n### [ Uh oh!  ](https://github.com/confident-ai/deepeval/security)\n[There was an error while loading. ](https://github.com/confident-ai/deepeval/security)[Please reload this page](https://github.com/confident-ai/deepeval).\n  * [ Insights ](https://github.com/confident-ai/deepeval/pulse)\n\n\nAdditional navigation options\n  * [ Code  ](https://github.com/confident-ai/deepeval)\n  * [ Issues  ](https://github.com/confident-ai/deepeval/issues)\n  * [ Pull requests  ](https://github.com/confident-ai/deepeval/pulls)\n  * [ Discussions  ](https://github.com/confident-ai/deepeval/discussions)\n  * [ Actions  ](https://github.com/confident-ai/deepeval/actions)\n  * [ Projects  ](https://github.com/confident-ai/deepeval/projects)\n  * [ Security  ](https://github.com/confident-ai/deepeval/security)\n  * [ Insights  ](https://github.com/confident-ai/deepeval/pulse)\n\n\n# confident-ai/deepeval\nmain\n[**195** Branches](https://github.com/confident-ai/deepeval/branches)[**247** Tags](https://github.com/confident-ai/deepeval/tags)\n[](https://github.com/confident-ai/deepeval/branches)[](https://github.com/confident-ai/deepeval/tags)\nGo to file\nCode\n## Folders and files\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n## Latest commit\n[![penguine-ip](https://avatars.githubusercontent.com/u/143328635?v=4&size=40)](https://github.com/penguine-ip)[penguine-ip](https://github.com/confident-ai/deepeval/commits?author=penguine-ip)[Merge pull request](https://github.com/confident-ai/deepeval/commit/028337d0cf616b64b9533d2f172a4ec4ee04cae3) [#1636](https://github.com/confident-ai/deepeval/pull/1636) [from A-Vamshi/fixedFaithfulnessTemplate](https://github.com/confident-ai/deepeval/commit/028337d0cf616b64b9533d2f172a4ec4ee04cae3)May 29, 2025[028337d](https://github.com/confident-ai/deepeval/commit/028337d0cf616b64b9533d2f172a4ec4ee04cae3) Â· May 29, 2025\n## History\n[5,083 Commits](https://github.com/confident-ai/deepeval/commits/main/)[](https://github.com/confident-ai/deepeval/commits/main/)  \n[.github](https://github.com/confident-ai/deepeval/tree/main/.github \".github\")| [.github](https://github.com/confident-ai/deepeval/tree/main/.github \".github\")| [Updated test](https://github.com/confident-ai/deepeval/commit/0acec03be7cb15958e0105949340bfe395cc54a6 \"Updated test\")| Aug 23, 2024  \n[assets](https://github.com/confident-ai/deepeval/tree/main/assets \"assets\")| [assets](https://github.com/confident-ai/deepeval/tree/main/assets \"assets\")| [updated docs](https://github.com/confident-ai/deepeval/commit/001e6606261d4aa0247902b51a41b8552cfbcaac \"updated docs\")| May 7, 2025  \n[deepeval](https://github.com/confident-ai/deepeval/tree/main/deepeval \"deepeval\")| [deepeval](https://github.com/confident-ai/deepeval/tree/main/deepeval \"deepeval\")| [Removed the grammatical errors and threatening language.](https://github.com/confident-ai/deepeval/commit/349baa5bc0e7358b5d5901c5fa4d6ba69e122406 \"Removed the grammatical errors and threatening language.\")| May 29, 2025  \n[docs](https://github.com/confident-ai/deepeval/tree/main/docs \"docs\")| [docs](https://github.com/confident-ai/deepeval/tree/main/docs \"docs\")| [docs update](https://github.com/confident-ai/deepeval/commit/3a5535672524bad27fc7431375cc70e8338300d9 \"docs update\")| May 28, 2025  \n[examples](https://github.com/confident-ai/deepeval/tree/main/examples \"examples\")| [examples](https://github.com/confident-ai/deepeval/tree/main/examples \"examples\")| [many more misspelling typos](https://github.com/confident-ai/deepeval/commit/e26b5e17873be6da598da1299f274bde84892025 \"many more misspelling typos\")| May 2, 2025  \n[tests](https://github.com/confident-ai/deepeval/tree/main/tests \"tests\")| [tests](https://github.com/confident-ai/deepeval/tree/main/tests \"tests\")| [Merge branch 'main' into telemetry/posthog-updates](https://github.com/confident-ai/deepeval/commit/eb2623463574200bb0952c5cab4d417ed9e0f1f1 \"Merge branch 'main' into telemetry/posthog-updates\")| May 18, 2025  \n[tracing_tests](https://github.com/confident-ai/deepeval/tree/main/tracing_tests \"tracing_tests\")| [tracing_tests](https://github.com/confident-ai/deepeval/tree/main/tracing_tests \"tracing_tests\")| [reformat](https://github.com/confident-ai/deepeval/commit/67b5e675f604ddf09a9b810a0b06d0a0b93a6f91 \"reformat\")| May 24, 2025  \n[.gitignore](https://github.com/confident-ai/deepeval/blob/main/.gitignore \".gitignore\")| [.gitignore](https://github.com/confident-ai/deepeval/blob/main/.gitignore \".gitignore\")| [chore: Fix typo in telemetry](https://github.com/confident-ai/deepeval/commit/bf69bcb62bb3223de4d1b478bf466c087b2637d2 \"chore: Fix typo in telemetry\")| Jan 31, 2025  \n[CITATION.cff](https://github.com/confident-ai/deepeval/blob/main/CITATION.cff \"CITATION.cff\")| [CITATION.cff](https://github.com/confident-ai/deepeval/blob/main/CITATION.cff \"CITATION.cff\")| [new release](https://github.com/confident-ai/deepeval/commit/e678f24db32d0e82307e0a4cad80e902d35e7f31 \"new release\")| May 28, 2025  \n[CONTRIBUTING.md](https://github.com/confident-ai/deepeval/blob/main/CONTRIBUTING.md \"CONTRIBUTING.md\")| [CONTRIBUTING.md](https://github.com/confident-ai/deepeval/blob/main/CONTRIBUTING.md \"CONTRIBUTING.md\")| [Update CONTRIBUTING.md](https://github.com/confident-ai/deepeval/commit/c3c942736e504de07608348950692d29eea2a5ff \"Update CONTRIBUTING.md\")| Oct 5, 2024  \n[LICENSE.md](https://github.com/confident-ai/deepeval/blob/main/LICENSE.md \"LICENSE.md\")| [LICENSE.md](https://github.com/confident-ai/deepeval/blob/main/LICENSE.md \"LICENSE.md\")| [Update LICENSE.md](https://github.com/confident-ai/deepeval/commit/d249da8e6249423464926e8db25d2b99df75b602 \"Update LICENSE.md\")| Oct 22, 2024  \n[MANIFEST.in](https://github.com/confident-ai/deepeval/blob/main/MANIFEST.in \"MANIFEST.in\")| [MANIFEST.in](https://github.com/confident-ai/deepeval/blob/main/MANIFEST.in \"MANIFEST.in\")| [Inlcude txt files](https://github.com/confident-ai/deepeval/commit/bcd1cb9af1dbadd4718a655943723be52931f14c \"Inlcude txt files\")| Mar 16, 2024  \n[README.md](https://github.com/confident-ai/deepeval/blob/main/README.md \"README.md\")| [README.md](https://github.com/confident-ai/deepeval/blob/main/README.md \"README.md\")| [Update README.md](https://github.com/confident-ai/deepeval/commit/04ae875f11edd19872775e90dc13e8bdbcdbd22e \"Update README.md\")| May 24, 2025  \n[a.py](https://github.com/confident-ai/deepeval/blob/main/a.py \"a.py\")| [a.py](https://github.com/confident-ai/deepeval/blob/main/a.py \"a.py\")| [.](https://github.com/confident-ai/deepeval/commit/5c8aea6b2b79e74928bc41855b4719870ac5b29b \".\")| Apr 30, 2025  \n[aa.py](https://github.com/confident-ai/deepeval/blob/main/aa.py \"aa.py\")| [aa.py](https://github.com/confident-ai/deepeval/blob/main/aa.py \"aa.py\")| [Fix tracing](https://github.com/confident-ai/deepeval/commit/6a25f016bd48920fc59a1d7ccddbe2720c6f0946 \"Fix tracing\")| May 12, 2025  \n[poetry.lock](https://github.com/confident-ai/deepeval/blob/main/poetry.lock \"poetry.lock\")| [poetry.lock](https://github.com/confident-ai/deepeval/blob/main/poetry.lock \"poetry.lock\")| [removing twine](https://github.com/confident-ai/deepeval/commit/51106a2660289ab540dc442cb5c1c4bd4772a601 \"removing twine\")| May 5, 2025  \n[pyproject.toml](https://github.com/confident-ai/deepeval/blob/main/pyproject.toml \"pyproject.toml\")| [pyproject.toml](https://github.com/confident-ai/deepeval/blob/main/pyproject.toml \"pyproject.toml\")| [new release](https://github.com/confident-ai/deepeval/commit/e678f24db32d0e82307e0a4cad80e902d35e7f31 \"new release\")| May 28, 2025  \n[test_openai_patch.py](https://github.com/confident-ai/deepeval/blob/main/test_openai_patch.py \"test_openai_patch.py\")| [test_openai_patch.py](https://github.com/confident-ai/deepeval/blob/main/test_openai_patch.py \"test_openai_patch.py\")| [Rubric GEval](https://github.com/confident-ai/deepeval/commit/3f83b1a07b02243a76d099c3c495936d93dfb9bd \"Rubric GEval\")| May 15, 2025  \n[test_otel_exporter.py](https://github.com/confident-ai/deepeval/blob/main/test_otel_exporter.py \"test_otel_exporter.py\")| [test_otel_exporter.py](https://github.com/confident-ai/deepeval/blob/main/test_otel_exporter.py \"test_otel_exporter.py\")| [reformta](https://github.com/confident-ai/deepeval/commit/26fe7d80a5aa203b7c0716102580ca4de2b1d35a \"reformta\")| May 22, 2025  \nView all files  \n## Repository files navigation\n  * [README](https://github.com/confident-ai/deepeval)\n  * [Apache-2.0 license](https://github.com/confident-ai/deepeval)\n\n\n[![DeepEval Logo](https://github.com/confident-ai/deepeval/raw/main/docs/static/img/deepeval.png)](https://github.com/confident-ai/deepeval/blob/main/docs/static/img/deepeval.png)\n# The LLM Evaluation Framework\n[](https://github.com/confident-ai/deepeval#the-llm-evaluation-framework)\n[ ![discord-invite](https://camo.githubusercontent.com/7f735ffad46bc6bf7af809772427a5c2ffb209950fc97e2bbc3a67a1451d866d/68747470733a2f2f646362616467652e76657263656c2e6170702f6170692f7365727665722f335345797670677532663f7374796c653d666c6174) ](https://discord.gg/3SEyvpgu2f)\n[Documentation](https://deepeval.com/docs/getting-started?utm_source=GitHub) | [Metrics and Features](https://github.com/confident-ai/deepeval#-metrics-and-features) | [Getting Started](https://github.com/confident-ai/deepeval#-quickstart) | [Integrations](https://github.com/confident-ai/deepeval#-integrations) | [DeepEval Platform](https://confident-ai.com?utm_source=GitHub)\n[](https://github.com/confident-ai/deepeval#------------documentation---------metrics-and-features---------getting-started---------integrations---------deepeval-platform----)\n[ ![GitHub release](https://camo.githubusercontent.com/9c138e3fbe391567af9b8bd7f705cd63fc5e2ccdb38d7a34f978cfd225efb722/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f636f6e666964656e742d61692f646565706576616c2e7376673f636f6c6f723d76696f6c6574) ](https://github.com/confident-ai/deepeval/releases) [ ![Try Quickstart in Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667) ](https://colab.research.google.com/drive/1PPxYEBa6eu__LquGoFFJZkhYgWVYE6kh?usp=sharing) [ ![License](https://camo.githubusercontent.com/27470c836c4530fafb1823b39732d4607805a572861be9dab56413c7faa3ab85/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f636f6e666964656e742d61692f646565706576616c2e7376673f636f6c6f723d79656c6c6f77) ](https://github.com/confident-ai/deepeval/blob/master/LICENSE.md)\n**DeepEval** is a simple-to-use, open-source LLM evaluation framework, for evaluating and testing large-language model systems. It is similar to Pytest but specialized for unit testing LLM outputs. DeepEval incorporates the latest research to evaluate LLM outputs based on metrics such as G-Eval, hallucination, answer relevancy, RAGAS, etc., which uses LLMs and various other NLP models that runs **locally on your machine** for evaluation.\nWhether your LLM applications are RAG pipelines, chatbots, AI agents, implemented via LangChain or LlamaIndex, DeepEval has you covered. With it, you can easily determine the optimal models, prompts, and architecture to improve your RAG pipeline, agentic workflows, prevent prompt drifting, or even transition from OpenAI to hosting your own Deepseek R1 with confidence.\nImportant\nNeed a place for your DeepEval testing data to live ð¡â¤ï¸? [Sign up to the DeepEval platform](https://confident-ai.com?utm_source=GitHub) to compare iterations of your LLM app, generate & share testing reports, and more.\n[![Demo GIF](https://github.com/confident-ai/deepeval/raw/main/assets/demo.gif)](https://github.com/confident-ai/deepeval/blob/main/assets/demo.gif) [ ![Demo GIF](https://github.com/confident-ai/deepeval/raw/main/assets/demo.gif) ](https://github.com/confident-ai/deepeval/blob/main/assets/demo.gif) [ ](https://github.com/confident-ai/deepeval/blob/main/assets/demo.gif)\n> Want to talk LLM evaluation, need help picking metrics, or just to say hi? [Come join our discord.](https://discord.com/invite/3SEyvpgu2f)\n# ð¥ Metrics and Features\n[](https://github.com/confident-ai/deepeval#-metrics-and-features)\n> ð¥³ You can now share DeepEval's test results on the cloud directly on [Confident AI](https://confident-ai.com?utm_source=GitHub)'s infrastructure\n  * Supports both end-to-end and component-level LLM evaluation.\n  * Large variety of ready-to-use LLM evaluation metrics (all with explanations) powered by **ANY** LLM of your choice, statistical methods, or NLP models that runs **locally on your machine** : \n    * G-Eval\n    * DAG ([deep acyclic graph](https://deepeval.com/docs/metrics-dag))\n    * **RAG metrics:**\n      * Answer Relevancy\n      * Faithfulness\n      * Contextual Recall\n      * Contextual Precision\n      * Contextual Relevancy\n      * RAGAS\n    * **Agentic metrics:**\n      * Task Completion\n      * Tool Correctness\n    * **Others:**\n      * Hallucination\n      * Summarization\n      * Bias\n      * Toxicity\n    * **Conversational metrics:**\n      * Knowledge Retention\n      * Conversation Completeness\n      * Conversation Relevancy\n      * Role Adherence\n    * etc.\n  * Build your own custom metrics that are automatically integrated with DeepEval's ecosystem.\n  * Generate synthetic datasets for evaluation.\n  * Integrates seamlessly with **ANY** CI/CD environment.\n  * [Red team your LLM application](https://deepeval.com/docs/red-teaming-introduction) for 40+ safety vulnerabilities in a few lines of code, including: \n    * Toxicity\n    * Bias\n    * SQL Injection\n    * etc., using advanced 10+ attack enhancement strategies such as prompt injections.\n  * Easily benchmark **ANY** LLM on popular LLM benchmarks in [under 10 lines of code.](https://deepeval.com/docs/benchmarks-introduction?utm_source=GitHub), which includes: \n    * MMLU\n    * HellaSwag\n    * DROP\n    * BIG-Bench Hard\n    * TruthfulQA\n    * HumanEval\n    * GSM8K\n  * [100% integrated with Confident AI](https://confident-ai.com?utm_source=GitHub) for the full evaluation lifecycle: \n    * Curate/annotate evaluation datasets on the cloud\n    * Benchmark LLM app using dataset, and compare with previous iterations to experiment which models/prompts works best\n    * Fine-tune metrics for custom results\n    * Debug evaluation results via LLM traces\n    * Monitor & evaluate LLM responses in product to improve datasets with real-world data\n    * Repeat until perfection\n\n\nNote\nConfident AI is the DeepEval platform. Create an account [here.](https://app.confident-ai.com?utm_source=GitHub)\n# ð Integrations\n[](https://github.com/confident-ai/deepeval#-integrations)\n  * ð¦ LlamaIndex, to [**unit test RAG applications in CI/CD**](https://www.deepeval.com/integrations/frameworks/llamaindex?utm_source=GitHub)\n  * ð¤ Hugging Face, to [**enable real-time evaluations during LLM fine-tuning**](https://www.deepeval.com/integrations/frameworks/huggingface?utm_source=GitHub)\n\n\n# ð QuickStart\n[](https://github.com/confident-ai/deepeval#-quickstart)\nLet's pretend your LLM application is a RAG based customer support chatbot; here's how DeepEval can help test what you've built.\n## Installation\n[](https://github.com/confident-ai/deepeval#installation)\n```\npip install -U deepeval\n\n```\n\n## Create an account (highly recommended)\n[](https://github.com/confident-ai/deepeval#create-an-account-highly-recommended)\nUsing the `deepeval` platform will allow you to generate sharable testing reports on the cloud. It is free, takes no additional code to setup, and we highly recommend giving it a try.\nTo login, run:\n```\ndeepeval login\n\n```\n\nFollow the instructions in the CLI to create an account, copy your API key, and paste it into the CLI. All test cases will automatically be logged (find more information on data privacy [here](https://deepeval.com/docs/data-privacy?utm_source=GitHub)).\n## Writing your first test case\n[](https://github.com/confident-ai/deepeval#writing-your-first-test-case)\nCreate a test file:\n```\ntouch test_chatbot.py\n```\n\nOpen `test_chatbot.py` and write your first test case to run an **end-to-end** evaluation using DeepEval, which treats your LLM app as a black-box:\n```\nimport pytest\nfrom deepeval import assert_test\nfrom deepeval.metrics import GEval\nfrom deepeval.test_case import LLMTestCase, LLMTestCaseParams\ndef test_case():\n  correctness_metric = GEval(\n    name=\"Correctness\",\n    criteria=\"Determine if the 'actual output' is correct based on the 'expected output'.\",\n    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT, LLMTestCaseParams.EXPECTED_OUTPUT],\n    threshold=0.5\n  )\n  test_case = LLMTestCase(\n    input=\"What if these shoes don't fit?\",\n    # Replace this with the actual output from your LLM application\n    actual_output=\"You have 30 days to get a full refund at no extra cost.\",\n    expected_output=\"We offer a 30-day full refund at no extra costs.\",\n    retrieval_context=[\"All customers are eligible for a 30 day full refund at no extra costs.\"]\n  )\n  assert_test(test_case, [correctness_metric])\n```\n\nSet your `OPENAI_API_KEY` as an environment variable (you can also evaluate using your own custom model, for more details visit [this part of our docs](https://deepeval.com/docs/metrics-introduction#using-a-custom-llm?utm_source=GitHub)):\n```\nexport OPENAI_API_KEY=\"...\"\n\n```\n\nAnd finally, run `test_chatbot.py` in the CLI:\n```\ndeepeval test run test_chatbot.py\n\n```\n\n**Congratulations! Your test case should have passed â** Let's breakdown what happened.\n  * The variable `input` mimics a user input, and `actual_output` is a placeholder for what your application's supposed to output based on this input.\n  * The variable `expected_output` represents the ideal answer for a given `input`, and [`GEval`](https://deepeval.com/docs/metrics-llm-evals) is a research-backed metric provided by `deepeval` for you to evaluate your LLM output's on any custom custom with human-like accuracy.\n  * In this example, the metric `criteria` is correctness of the `actual_output` based on the provided `expected_output`.\n  * All metric scores range from 0 - 1, which the `threshold=0.5` threshold ultimately determines if your test have passed or not.\n\n\n[Read our documentation](https://deepeval.com/docs/getting-started?utm_source=GitHub) for more information on more options to run end-to-end evaluation, how to use additional metrics, create your own custom metrics, and tutorials on how to integrate with other tools like LangChain and LlamaIndex.\n## Evaluating Nested Components\n[](https://github.com/confident-ai/deepeval#evaluating-nested-components)\nIf you wish to evaluate individual components within your LLM app, you need to run **component-level** evals - a powerful way to evaluate any component within an LLM system.\nSimply trace \"components\" such as LLM calls, retrievers, tool calls, and agents within your LLM application using the `@observe` decorator to apply metrics on a component-level. Tracing with `deepeval` is non-instrusive (learn more [here](https://deepeval.com/docs/evaluation-llm-tracing#dont-be-worried-about-tracing)) and helps you avoid rewriting your codebase just for evals:\n```\nfrom deepeval.tracing import observe, update_current_span\nfrom deepeval.test_case import LLMTestCase\nfrom deepeval.dataset import Golden\nfrom deepeval.metrics import GEval\nfrom deepeval import evaluate\ncorrectness = GEval(name=\"Correctness\", criteria=\"Determine if the 'actual output' is correct based on the 'expected output'.\", evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT, LLMTestCaseParams.EXPECTED_OUTPUT])\n@observe(metrics=[correctness])\ndef inner_component():\n  # Component can be anything from an LLM call, retrieval, agent, tool use, etc.\n  update_current_span(test_case=LLMTestCase(input=\"...\", actual_output=\"...\"))\n  return\n@observe\ndef llm_app(input: str):\n  inner_component()\n  return\nevaluate(observed_callback=llm_app, goldens=[Golden(input=\"Hi!\")])\n```\n\nYou can learn everything about component-level evaluations [here.](https://www.deepeval.com/docs/evaluation-component-level-llm-evals)\n## Evaluating Without Pytest Integration\n[](https://github.com/confident-ai/deepeval#evaluating-without-pytest-integration)\nAlternatively, you can evaluate without Pytest, which is more suited for a notebook environment.\n```\nfrom deepeval import evaluate\nfrom deepeval.metrics import AnswerRelevancyMetric\nfrom deepeval.test_case import LLMTestCase\nanswer_relevancy_metric = AnswerRelevancyMetric(threshold=0.7)\ntest_case = LLMTestCase(\n  input=\"What if these shoes don't fit?\",\n  # Replace this with the actual output from your LLM application\n  actual_output=\"We offer a 30-day full refund at no extra costs.\",\n  retrieval_context=[\"All customers are eligible for a 30 day full refund at no extra costs.\"]\n)\nevaluate([test_case], [answer_relevancy_metric])\n```\n\n## Using Standalone Metrics\n[](https://github.com/confident-ai/deepeval#using-standalone-metrics)\nDeepEval is extremely modular, making it easy for anyone to use any of our metrics. Continuing from the previous example:\n```\nfrom deepeval.metrics import AnswerRelevancyMetric\nfrom deepeval.test_case import LLMTestCase\nanswer_relevancy_metric = AnswerRelevancyMetric(threshold=0.7)\ntest_case = LLMTestCase(\n  input=\"What if these shoes don't fit?\",\n  # Replace this with the actual output from your LLM application\n  actual_output=\"We offer a 30-day full refund at no extra costs.\",\n  retrieval_context=[\"All customers are eligible for a 30 day full refund at no extra costs.\"]\n)\nanswer_relevancy_metric.measure(test_case)\nprint(answer_relevancy_metric.score)\n# All metrics also offer an explanation\nprint(answer_relevancy_metric.reason)\n```\n\nNote that some metrics are for RAG pipelines, while others are for fine-tuning. Make sure to use our docs to pick the right one for your use case.\n## Evaluating a Dataset / Test Cases in Bulk\n[](https://github.com/confident-ai/deepeval#evaluating-a-dataset--test-cases-in-bulk)\nIn DeepEval, a dataset is simply a collection of test cases. Here is how you can evaluate these in bulk:\n```\nimport pytest\nfrom deepeval import assert_test\nfrom deepeval.metrics import HallucinationMetric, AnswerRelevancyMetric\nfrom deepeval.test_case import LLMTestCase\nfrom deepeval.dataset import EvaluationDataset\nfirst_test_case = LLMTestCase(input=\"...\", actual_output=\"...\", context=[\"...\"])\nsecond_test_case = LLMTestCase(input=\"...\", actual_output=\"...\", context=[\"...\"])\ndataset = EvaluationDataset(test_cases=[first_test_case, second_test_case])\n@pytest.mark.parametrize(\n  \"test_case\",\n  dataset,\n)\ndef test_customer_chatbot(test_case: LLMTestCase):\n  hallucination_metric = HallucinationMetric(threshold=0.3)\n  answer_relevancy_metric = AnswerRelevancyMetric(threshold=0.5)\n  assert_test(test_case, [hallucination_metric, answer_relevancy_metric])\n```\n\n```\n# Run this in the CLI, you can also add an optional -n flag to run tests in parallel\ndeepeval test run test_<filename>.py -n 4\n```\n\nAlternatively, although we recommend using `deepeval test run`, you can evaluate a dataset/test cases without using our Pytest integration:\n```\nfrom deepeval import evaluate\n...\nevaluate(dataset, [answer_relevancy_metric])\n# or\ndataset.evaluate([answer_relevancy_metric])\n```\n\n# LLM Evaluation With Confident AI\n[](https://github.com/confident-ai/deepeval#llm-evaluation-with-confident-ai)\nThe correct LLM evaluation lifecycle is only achievable with [the DeepEval platform](https://confident-ai.com?utm_source=Github). It allows you to:\n  1. Curate/annotate evaluation datasets on the cloud\n  2. Benchmark LLM app using dataset, and compare with previous iterations to experiment which models/prompts works best\n  3. Fine-tune metrics for custom results\n  4. Debug evaluation results via LLM traces\n  5. Monitor & evaluate LLM responses in product to improve datasets with real-world data\n  6. Repeat until perfection\n\n\nEverything on Confident AI, including how to use Confident is available [here](https://documentation.confident-ai.com?utm_source=GitHub).\nTo begin, login from the CLI:\n```\ndeepeval login\n```\n\nFollow the instructions to log in, create your account, and paste your API key into the CLI.\nNow, run your test file again:\n```\ndeepeval test run test_chatbot.py\n```\n\nYou should see a link displayed in the CLI once the test has finished running. Paste it into your browser to view the results!\n[![Demo GIF](https://github.com/confident-ai/deepeval/raw/main/assets/demo.gif)](https://github.com/confident-ai/deepeval/blob/main/assets/demo.gif) [ ![Demo GIF](https://github.com/confident-ai/deepeval/raw/main/assets/demo.gif) ](https://github.com/confident-ai/deepeval/blob/main/assets/demo.gif) [ ](https://github.com/confident-ai/deepeval/blob/main/assets/demo.gif)\n# Contributing\n[](https://github.com/confident-ai/deepeval#contributing)\nPlease read [CONTRIBUTING.md](https://github.com/confident-ai/deepeval/blob/main/CONTRIBUTING.md) for details on our code of conduct, and the process for submitting pull requests to us.\n# Roadmap\n[](https://github.com/confident-ai/deepeval#roadmap)\nFeatures:\n  * Integration with Confident AI\n  * Implement G-Eval\n  * Implement RAG metrics\n  * Implement Conversational metrics\n  * Evaluation Dataset Creation\n  * Red-Teaming\n  * DAG custom metrics\n  * Guardrails\n\n\n# Authors\n[](https://github.com/confident-ai/deepeval#authors)\nBuilt by the founders of Confident AI. Contact jeffreyip@confident-ai.com for all enquiries.\n# License\n[](https://github.com/confident-ai/deepeval#license)\nDeepEval is licensed under Apache 2.0 - see the [LICENSE.md](https://github.com/confident-ai/deepeval/blob/main/LICENSE.md) file for details.\n## About\nThe LLM Evaluation Framework \n[deepeval.com](https://deepeval.com \"https://deepeval.com\")\n### Topics\n[ evaluation-metrics ](https://github.com/topics/evaluation-metrics \"Topic: evaluation-metrics\") [ evaluation-framework ](https://github.com/topics/evaluation-framework \"Topic: evaluation-framework\") [ llm-evaluation ](https://github.com/topics/llm-evaluation \"Topic: llm-evaluation\") [ llm-evaluation-framework ](https://github.com/topics/llm-evaluation-framework \"Topic: llm-evaluation-framework\") [ llm-evaluation-metrics ](https://github.com/topics/llm-evaluation-metrics \"Topic: llm-evaluation-metrics\")\n### Resources\n[ Readme ](https://github.com/confident-ai/deepeval#readme-ov-file)\n### License\n[ Apache-2.0 license ](https://github.com/confident-ai/deepeval#Apache-2.0-1-ov-file)\n### Citation\nCite this repository \nLoading\nSomething went wrong. \n###  Uh oh! \nThere was an error while loading. [Please reload this page](https://github.com/confident-ai/deepeval).\n[ Activity](https://github.com/confident-ai/deepeval/activity)\n[ Custom properties](https://github.com/confident-ai/deepeval/custom-properties)\n### Stars\n[ **6.8k** stars](https://github.com/confident-ai/deepeval/stargazers)\n### Watchers\n[ **31** watching](https://github.com/confident-ai/deepeval/watchers)\n### Forks\n[ **623** forks](https://github.com/confident-ai/deepeval/forks)\n[ Report repository ](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fconfident-ai%2Fdeepeval&report=confident-ai+%28user%29)\n##  [Releases 46](https://github.com/confident-ai/deepeval/releases)\n[ LLM Evals - v3.0 Latest  May 27, 2025 ](https://github.com/confident-ai/deepeval/releases/tag/v3.0)\n[+ 45 releases](https://github.com/confident-ai/deepeval/releases)\n##  [Packages 0](https://github.com/orgs/confident-ai/packages?repo_name=deepeval)\nNo packages published \n##  [Used by 803](https://github.com/confident-ai/deepeval/network/dependents)\n[\n  * ![@Gyana1308](https://avatars.githubusercontent.com/u/186584960?s=64&v=4)\n  * ![@DakineMI](https://avatars.githubusercontent.com/u/25511074?s=64&v=4)\n  * ![@DakineMI](https://avatars.githubusercontent.com/u/25511074?s=64&v=4)\n  * ![@mjm3853](https://avatars.githubusercontent.com/u/7984928?s=64&v=4)\n  * ![@git-aethrix](https://avatars.githubusercontent.com/u/16635199?s=64&v=4)\n  * ![@hbasafa](https://avatars.githubusercontent.com/u/30258093?s=64&v=4)\n  * ![@TunsTudor-Mircea](https://avatars.githubusercontent.com/u/162615897?s=64&v=4)\n  * ![@gustavolgcr](https://avatars.githubusercontent.com/u/1895558?s=64&v=4)\n\n+ 795  ](https://github.com/confident-ai/deepeval/network/dependents)\n##  [Contributors 153](https://github.com/confident-ai/deepeval/graphs/contributors)\n  * [ ![@penguine-ip](https://avatars.githubusercontent.com/u/143328635?s=64&v=4) ](https://github.com/penguine-ip)\n  * [ ![@jwongster2](https://avatars.githubusercontent.com/u/108557828?s=64&v=4) ](https://github.com/jwongster2)\n  * [ ![@kritinv](https://avatars.githubusercontent.com/u/73642562?s=64&v=4) ](https://github.com/kritinv)\n  * [ ![@Anindyadeep](https://avatars.githubusercontent.com/u/58508471?s=64&v=4) ](https://github.com/Anindyadeep)\n  * [ ![@Vasilije1990](https://avatars.githubusercontent.com/u/8619304?s=64&v=4) ](https://github.com/Vasilije1990)\n  * [ ![@Pratyush-exe](https://avatars.githubusercontent.com/u/78687109?s=64&v=4) ](https://github.com/Pratyush-exe)\n  * [ ![@agokrani](https://avatars.githubusercontent.com/u/30440108?s=64&v=4) ](https://github.com/agokrani)\n  * [ ![@spike-spiegel-21](https://avatars.githubusercontent.com/u/83648453?s=64&v=4) ](https://github.com/spike-spiegel-21)\n  * [ ![@fetz236](https://avatars.githubusercontent.com/u/58368484?s=64&v=4) ](https://github.com/fetz236)\n  * [ ![@Peilun-Li](https://avatars.githubusercontent.com/u/11920339?s=64&v=4) ](https://github.com/Peilun-Li)\n  * [ ![@luarss](https://avatars.githubusercontent.com/u/39641663?s=64&v=4) ](https://github.com/luarss)\n  * [ ![@lesar64](https://avatars.githubusercontent.com/u/54540187?s=64&v=4) ](https://github.com/lesar64)\n  * [ ![@fschuh](https://avatars.githubusercontent.com/u/12468976?s=64&v=4) ](https://github.com/fschuh)\n  * [ ![@john-lemmon-lime](https://avatars.githubusercontent.com/u/6528428?s=64&v=4) ](https://github.com/john-lemmon-lime)\n\n\n[+ 139 contributors](https://github.com/confident-ai/deepeval/graphs/contributors)\n## Languages\n  * [ Python 100.0% ](https://github.com/confident-ai/deepeval/search?l=python)\n\n\n## Footer\n[ ](https://github.com) Â© 2025 GitHub, Inc. \n### Footer navigation\n  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n  * [Security](https://github.com/security)\n  * [Status](https://www.githubstatus.com/)\n  * [Docs](https://docs.github.com/)\n  * [Contact](https://support.github.com?tags=dotcom-footer)\n  * Manage cookies \n  * Do not share my personal information \n\n\nYou canât perform that action at this time. \n"
  },
  {
    "link": "https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications",
    "raw_content": "[Skip to content](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications#start-of-content)\n## Navigation Menu\nToggle navigation\n[ ](https://github.com/)\n[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FAzure%2FThe-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications)\nAppearance settings\n  * Product \n    * [ GitHub Copilot  Write better code with AI  ](https://github.com/features/copilot)\n    * [ GitHub Models  New  Manage and compare prompts  ](https://github.com/features/models)\n    * [ GitHub Advanced Security  Find and fix vulnerabilities  ](https://github.com/security/advanced-security)\n    * [ Actions  Automate any workflow  ](https://github.com/features/actions)\n    * [ Codespaces  Instant dev environments  ](https://github.com/features/codespaces)\n    * [ Issues  Plan and track work  ](https://github.com/features/issues)\n    * [ Code Review  Manage code changes  ](https://github.com/features/code-review)\n    * [ Discussions  Collaborate outside of code  ](https://github.com/features/discussions)\n    * [ Code Search  Find more, search less  ](https://github.com/features/code-search)\nExplore\n    * [ Why GitHub ](https://github.com/why-github)\n    * [ All features ](https://github.com/features)\n    * [ Documentation ](https://docs.github.com)\n    * [ GitHub Skills ](https://skills.github.com)\n    * [ Blog ](https://github.blog)\n  * Solutions \nBy company size\n    * [ Enterprises ](https://github.com/enterprise)\n    * [ Small and medium teams ](https://github.com/team)\n    * [ Startups ](https://github.com/enterprise/startups)\n    * [ Nonprofits ](https://github.com/solutions/industry/nonprofits)\nBy use case\n    * [ DevSecOps ](https://github.com/solutions/use-case/devsecops)\n    * [ DevOps ](https://github.com/solutions/use-case/devops)\n    * [ CI/CD ](https://github.com/solutions/use-case/ci-cd)\n    * [ View all use cases ](https://github.com/solutions/use-case)\nBy industry\n    * [ Healthcare ](https://github.com/solutions/industry/healthcare)\n    * [ Financial services ](https://github.com/solutions/industry/financial-services)\n    * [ Manufacturing ](https://github.com/solutions/industry/manufacturing)\n    * [ Government ](https://github.com/solutions/industry/government)\n    * [ View all industries ](https://github.com/solutions/industry)\n[ View all solutions ](https://github.com/solutions)\n  * Resources \nTopics\n    * [ AI ](https://github.com/resources/articles/ai)\n    * [ DevOps ](https://github.com/resources/articles/devops)\n    * [ Security ](https://github.com/resources/articles/security)\n    * [ Software Development ](https://github.com/resources/articles/software-development)\n    * [ View all ](https://github.com/resources/articles)\nExplore\n    * [ Learning Pathways ](https://resources.github.com/learn/pathways)\n    * [ Events & Webinars ](https://resources.github.com)\n    * [ Ebooks & Whitepapers ](https://github.com/resources/whitepapers)\n    * [ Customer Stories ](https://github.com/customer-stories)\n    * [ Partners ](https://partner.github.com)\n    * [ Executive Insights ](https://github.com/solutions/executive-insights)\n  * Open Source \n    * [ GitHub Sponsors  Fund open source developers  ](https://github.com/sponsors)\n    * [ The ReadME Project  GitHub community articles  ](https://github.com/readme)\nRepositories\n    * [ Topics ](https://github.com/topics)\n    * [ Trending ](https://github.com/trending)\n    * [ Collections ](https://github.com/collections)\n  * Enterprise \n    * [ Enterprise platform  AI-powered developer platform  ](https://github.com/enterprise)\nAvailable add-ons\n    * [ GitHub Advanced Security  Enterprise-grade security features  ](https://github.com/security/advanced-security)\n    * [ Copilot for business  Enterprise-grade AI features  ](https://github.com/features/copilot/copilot-business)\n    * [ Premium Support  Enterprise-grade 24/7 support  ](https://github.com/premium-support)\n  * [Pricing](https://github.com/pricing)\n\n\nSearch or jump to...\n# Search code, repositories, users, issues, pull requests...\nSearch \nClear\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n#  Provide feedback \nWe read every piece of feedback, and take your input very seriously.\nInclude my email address so I can be contacted\nCancel  Submit feedback \n#  Saved searches \n## Use saved searches to filter your results more quickly\nName\nQuery\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax). \nCancel  Create saved search \n[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FAzure%2FThe-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications)\n[ Sign up ](https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=Azure%2FThe-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications)\nAppearance settings\nResetting focus\nYou signed in with another tab or window. [Reload](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications) to refresh your session. You signed out in another tab or window. [Reload](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications) to refresh your session. You switched accounts on another tab or window. [Reload](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications) to refresh your session. Dismiss alert\n{{ message }}\n[ Azure ](https://github.com/Azure) / **[The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications) ** Public\n  * [ Notifications ](https://github.com/login?return_to=%2FAzure%2FThe-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications) You must be signed in to change notification settings\n  * [ Fork 8 ](https://github.com/login?return_to=%2FAzure%2FThe-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications)\n  * [ Star  27 ](https://github.com/login?return_to=%2FAzure%2FThe-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications)\n\n\nThere are many articles that cover the principles of reducing latency optimization for LLMs, however it is often unclear how to actually implement these principles. This repository provides practical techniques for reducing the latency of GenAI applications. \n### License\n[ MIT license ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/LICENSE)\n[ 27 stars ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/stargazers) [ 8 forks ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/forks) [ Branches ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/branches) [ Tags ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/tags) [ Activity ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/activity)\n[ Star  ](https://github.com/login?return_to=%2FAzure%2FThe-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications)\n[ Notifications ](https://github.com/login?return_to=%2FAzure%2FThe-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications) You must be signed in to change notification settings\n  * [ Code ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications)\n  * [ Issues 1 ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/issues)\n  * [ Pull requests 0 ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/pulls)\n  * [ Actions ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/actions)\n  * [ Projects 0 ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/projects)\n  * [ Security ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/security)\n[ ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/security)\n[ ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/security)\n[ ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/security)\n### [ Uh oh!  ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/security)\n[There was an error while loading. ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/security)[Please reload this page](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications).\n  * [ Insights ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/pulse)\n\n\nAdditional navigation options\n  * [ Code  ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications)\n  * [ Issues  ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/issues)\n  * [ Pull requests  ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/pulls)\n  * [ Actions  ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/actions)\n  * [ Projects  ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/projects)\n  * [ Security  ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/security)\n  * [ Insights  ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/pulse)\n\n\n# Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications\nmain\n[Branches](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/branches)[Tags](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/tags)\n[](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/branches)[](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/tags)\nGo to file\nCode\n## Folders and files\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n## Latest commit\n## History\n[6 Commits](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/commits/main/)[](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/commits/main/)  \n[case-studies](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/tree/main/case-studies \"case-studies\")| [case-studies](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/tree/main/case-studies \"case-studies\")| |   \n[notebooks-with-techniques](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/tree/main/notebooks-with-techniques \"notebooks-with-techniques\")| [notebooks-with-techniques](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/tree/main/notebooks-with-techniques \"notebooks-with-techniques\")| |   \n[.env_sample](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/.env_sample \".env_sample\")| [.env_sample](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/.env_sample \".env_sample\")| |   \n[.gitignore](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/.gitignore \".gitignore\")| [.gitignore](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/.gitignore \".gitignore\")| |   \n[CODE_OF_CONDUCT.md](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/CODE_OF_CONDUCT.md \"CODE_OF_CONDUCT.md\")| [CODE_OF_CONDUCT.md](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/CODE_OF_CONDUCT.md \"CODE_OF_CONDUCT.md\")| |   \n[LICENSE](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/LICENSE \"LICENSE\")| [LICENSE](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/LICENSE \"LICENSE\")| |   \n[README.md](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/README.md \"README.md\")| [README.md](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/README.md \"README.md\")| |   \n[SECURITY.md](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/SECURITY.md \"SECURITY.md\")| [SECURITY.md](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/SECURITY.md \"SECURITY.md\")| |   \n[SUPPORT.md](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/SUPPORT.md \"SUPPORT.md\")| [SUPPORT.md](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/SUPPORT.md \"SUPPORT.md\")| |   \n[pip_freeze_sample.txt](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/pip_freeze_sample.txt \"pip_freeze_sample.txt\")| [pip_freeze_sample.txt](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/pip_freeze_sample.txt \"pip_freeze_sample.txt\")| |   \n[requirements.txt](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/requirements.txt \"requirements.txt\")| [requirements.txt](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/requirements.txt \"requirements.txt\")| |   \nView all files  \n## Repository files navigation\n  * [README](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications)\n  * [Code of conduct](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications)\n  * [MIT license](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications)\n  * [Security](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications)\n\n\n# Optimizing GenAI Applications for Speed\n[](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications#optimizing-genai-applications-for-speed)\nGenerative AI applications are transforming how we do business today, creating new, engaging ways for customers to engage with applications. However, these new LLM models require massive amounts of compute to run, and unoptimized applications can run quite slowly, leading users to become frustrated. Creating a positive user experience is critical to the adoption of these tools, so minimising the response time of your LLM API calls is a must. The techniques shared in this article demonstrate how applications can be sped up by up to 100x their original speed through clever prompt engineering and a small amount of code!\nPrevious work has identified the core principles for reducing LLM response times. This article expands upon these, by providing practical examples coupled with working code, to help you accelerate your own applications and delight customers. This article is primarily intended for software developers, data scientists and application developers, though any business stakeholder managing GenAI applications should read on to learn new ideas for improving their customer experience.\n## Understanding the drivers of long response times\n[](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications#understanding-the-drivers-of-long-response-times)\nThe response time of an LLM can vary based on four primary factors:\n  1. The model used.\n  2. The number of tokens in the prompt.\n  3. The number of tokens generated.\n  4. The overall load on the deployment & system.\n\n\nYou can imagine the model as a person typing on a keyboard, where each token is generated one after another. The speed of the person (the model used) and the amount they need to type (the number of generation tokens) tend to be the largest contributor to long response times.\n_Figure 1 - The response generation step typically dominates the overall response time. Not to scale._\n## Techniques for improving LLM response times\n[](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications#techniques-for-improving-llm-response-times)\nThe below table contains a range of recommendations that can be implemented to improve the response times of your Generative AI application. Where applicable, sample code is included, to allow you to see these benefits for yourself, and copy the relevant code or prompts into your application.\nBest Practice | Intuition | GitHub | Potential Speed up of application  \n---|---|---|---  \n1. Generation Token Compression | Prompt the LLM to return the shortest response possible. A few simple phrases in your prompt can speed up your application. Few-shot prompting can also be used to ensure the response includes all the key information. | [Link](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/notebooks-with-techniques/generation-token-compression/generation-token-compression.ipynb) | Up to 2-3x or more20s â 8s  \n2. Avoid using LLMs to output large amounts of predetermined text | Rather than rewriting documents, use the LLM to identify which parts of the text need to be edited, and use code to make the edits. For RAG, use code to simply append documents to the LLM response. | [Link](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/notebooks-with-techniques/avoid-rewriting-documents/avoid-rewriting-documents.ipynb) | Up to 16x or more310s â 20s  \n3. Implement semantic caching | By caching responses, LLM responses can be reused, rather than calling Azure OpenAI, saving cost and time. The input does not need an exact match- for example âHow can I sign up for Azureâ and âI want to sign up for Azureâ will return the same cached result. | [Link](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/notebooks-with-techniques/semantic-caching/semantic-caching.ipynb) | Up to 14x or more19s â 1.3s  \n4. Parallelize requests | Many use cases (such as document processing, classification etc.) can be parallelized. | [Link](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/notebooks-with-techniques/parallelization/parallelization.ipynb) | Up to 72x or more180s â 2.5s  \n5. Use GPT-3.5 over GPT-4 where possible | GPT-3.5 has a much faster token generation speed. Certain use cases require the more advanced reasoning capabilities of GPT-4, however sometimes few-shot prompting or finetuning may enable GPT-3.5 to perform the same tasks. Generally only recommended for advanced users, after attempting other optimizations first. | [Link](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/notebooks-with-techniques/use-models-with-faster-time-between-tokens/use-models-with-faster-time-between-tokens.ipynb) | Up to 4x17s â 5s  \n6. Leverage translation services for certain languages | Certain languages have not been optimised, leading to long response times. Generate the output in English and leverage another model or API for the translation step. | [Link](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/notebooks-with-techniques/multilingual-optimization/multilingual-optimization.ipynb) | Up to 3x53s â 16s  \n7. Co-locate cloud resources | Ensure model is deployed close your users. Ensure Azure AI Search and Azure OpenAI are as closely located as possible (in the same region, firewall, vNet etc.). | NA | 1-2x  \n8. Load balancing | Having an additional endpoint for handling overflow capacity (for example, a PTU overflowing to a Pay-as-you-Go endpoint) can save latency by avoiding queuing when retrying requests. | [Link](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/notebooks-with-techniques/load-balancing/load-balancing.ipynb) | Up to 2x58s â 31s  \n## Putting it into practice through case studies\n[](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications#putting-it-into-practice-through-case-studies)\nThis section includes an overview of case studies that represent typical GenAI applicationsâperhaps one is similar to yours! The linked code repositories show the original speed of the application, and then walk you step-by-step through the process of implementing different combinations of the techniques in this document. Implementing these recommendations achieved an improvement in the response time ranging from 6.8-102x!\nCase Study | Techniques applied | Cumulative speed improvement | GitHub  \n---|---|---|---  \nDocument processingRewrite a document to correct spelling errors, grammar, and comply with an organizationâs style guide. | 1. Base case | 1x (315s) | [Link](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/case-studies/document-processing/document-processing.ipynb)  \n2. Avoid rewriting documents | 8.3x (38s)  \n3. Generation token compression | 15.8x (20s)  \n4. Parallelization | 105x (3s)  \nRetrieval Augmented Generation (RAG)Help a user troubleshoot a product which is not working. | 1. Base case | 1x (23s) | [Link](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/case-studies/retrieval-augmented-generation/retrieval-augmented-generation.ipynb)  \n2. Generation token compression | 2.3x (9.8s)  \n3. Avoid rewriting documents | 6.8x (3.4s)  \nRetrieval Augmented Generation (RAG)Provide general product information. | 1. Base case | 1x (17s) | [Link](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/blob/main/case-studies/retrieval-augmented-generation/retrieval-augmented-generation.ipynb)  \n2. Semantic caching | 17x (1s)  \n## Conclusion\n[](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications#conclusion)\nWith Generative AI transforming how people interact with applications, minimising response times is essential. If youâre interested in improving your GenAI applicationâs performance, select a few of these recommendations, clone the repository, and implement them in your applicationâs next release!\n_Disclaimer: The results depicted are merely illustrative, emphasizing the potential benefits of these techniques. They are not all-encompassing and are based on a single test. Response times may differ with each run, thus the main goal is to demonstrate relative improvement. The tests are performed using the powerful, but slower, GPT-4 32k model, with a focus on improving response times. The effectiveness of techniques like error correction through document rewriting varies depending on the input; a document with many errors might take longer to correct than to rewrite entirely. Therefore, these techniques should be tailored to your application._\n## Contributing\n[](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications#contributing)\n**Thanks to the following key contributors:** Luca Stamatescu, Priya Kedia, Julian Lee, Manoranjan Rajguru, Shikha Agrawal, Michael Tremeer\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit <https://cla.opensource.microsoft.com>.\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact opencode@microsoft.com with any additional questions or comments.\n## Trademarks\n[](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications#trademarks)\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow [Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general). Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.\n## About\nThere are many articles that cover the principles of reducing latency optimization for LLMs, however it is often unclear how to actually implement these principles. This repository provides practical techniques for reducing the latency of GenAI applications. \n### Resources\n[ Readme ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications#readme-ov-file)\n### License\n[ MIT license ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications#MIT-1-ov-file)\n### Code of conduct\n[ Code of conduct ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications#coc-ov-file)\n### Security policy\n[ Security policy ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications#security-ov-file)\n###  Uh oh! \nThere was an error while loading. [Please reload this page](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications).\n[ Activity](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/activity)\n[ Custom properties](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/custom-properties)\n### Stars\n[ **27** stars](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/stargazers)\n### Watchers\n[ **3** watching](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/watchers)\n### Forks\n[ **8** forks](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/forks)\n[ Report repository ](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2FAzure%2FThe-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications&report=Azure+%28user%29)\n##  [Releases](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/releases)\nNo releases published\n##  [Packages 0](https://github.com/orgs/Azure/packages?repo_name=The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications)\nNo packages published \n###  Uh oh! \nThere was an error while loading. [Please reload this page](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications).\n##  [Contributors 2](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/graphs/contributors)\n  * [ ![@microsoftopensource](https://avatars.githubusercontent.com/u/22527892?s=64&v=4) ](https://github.com/microsoftopensource) [ **microsoftopensource** Microsoft Open Source ](https://github.com/microsoftopensource)\n  * [ ![@luca-stamatescu](https://avatars.githubusercontent.com/u/52722879?s=64&v=4) ](https://github.com/luca-stamatescu) [ **luca-stamatescu** Luca Stamatescu ](https://github.com/luca-stamatescu)\n\n\n## Languages\n  * [ Jupyter Notebook 100.0% ](https://github.com/Azure/The-LLM-Latency-Guidebook-Optimizing-Response-Times-for-GenAI-Applications/search?l=jupyter-notebook)\n\n\n## Footer\n[ ](https://github.com) Â© 2025 GitHub, Inc. \n### Footer navigation\n  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n  * [Security](https://github.com/security)\n  * [Status](https://www.githubstatus.com/)\n  * [Docs](https://docs.github.com/)\n  * [Contact](https://support.github.com?tags=dotcom-footer)\n  * Manage cookies \n  * Do not share my personal information \n\n\nYou canât perform that action at this time. \n"
  },
  {
    "link": "https://github.com/dair-ai/ML-Papers-of-the-Week",
    "raw_content": "[Skip to content](https://github.com/dair-ai/ML-Papers-of-the-Week#start-of-content)\n## Navigation Menu\nToggle navigation\n[ ](https://github.com/)\n[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fdair-ai%2FML-Papers-of-the-Week)\nAppearance settings\n  * Product \n    * [ GitHub Copilot  Write better code with AI  ](https://github.com/features/copilot)\n    * [ GitHub Models  New  Manage and compare prompts  ](https://github.com/features/models)\n    * [ GitHub Advanced Security  Find and fix vulnerabilities  ](https://github.com/security/advanced-security)\n    * [ Actions  Automate any workflow  ](https://github.com/features/actions)\n    * [ Codespaces  Instant dev environments  ](https://github.com/features/codespaces)\n    * [ Issues  Plan and track work  ](https://github.com/features/issues)\n    * [ Code Review  Manage code changes  ](https://github.com/features/code-review)\n    * [ Discussions  Collaborate outside of code  ](https://github.com/features/discussions)\n    * [ Code Search  Find more, search less  ](https://github.com/features/code-search)\nExplore\n    * [ Why GitHub ](https://github.com/why-github)\n    * [ All features ](https://github.com/features)\n    * [ Documentation ](https://docs.github.com)\n    * [ GitHub Skills ](https://skills.github.com)\n    * [ Blog ](https://github.blog)\n  * Solutions \nBy company size\n    * [ Enterprises ](https://github.com/enterprise)\n    * [ Small and medium teams ](https://github.com/team)\n    * [ Startups ](https://github.com/enterprise/startups)\n    * [ Nonprofits ](https://github.com/solutions/industry/nonprofits)\nBy use case\n    * [ DevSecOps ](https://github.com/solutions/use-case/devsecops)\n    * [ DevOps ](https://github.com/solutions/use-case/devops)\n    * [ CI/CD ](https://github.com/solutions/use-case/ci-cd)\n    * [ View all use cases ](https://github.com/solutions/use-case)\nBy industry\n    * [ Healthcare ](https://github.com/solutions/industry/healthcare)\n    * [ Financial services ](https://github.com/solutions/industry/financial-services)\n    * [ Manufacturing ](https://github.com/solutions/industry/manufacturing)\n    * [ Government ](https://github.com/solutions/industry/government)\n    * [ View all industries ](https://github.com/solutions/industry)\n[ View all solutions ](https://github.com/solutions)\n  * Resources \nTopics\n    * [ AI ](https://github.com/resources/articles/ai)\n    * [ DevOps ](https://github.com/resources/articles/devops)\n    * [ Security ](https://github.com/resources/articles/security)\n    * [ Software Development ](https://github.com/resources/articles/software-development)\n    * [ View all ](https://github.com/resources/articles)\nExplore\n    * [ Learning Pathways ](https://resources.github.com/learn/pathways)\n    * [ Events & Webinars ](https://resources.github.com)\n    * [ Ebooks & Whitepapers ](https://github.com/resources/whitepapers)\n    * [ Customer Stories ](https://github.com/customer-stories)\n    * [ Partners ](https://partner.github.com)\n    * [ Executive Insights ](https://github.com/solutions/executive-insights)\n  * Open Source \n    * [ GitHub Sponsors  Fund open source developers  ](https://github.com/sponsors)\n    * [ The ReadME Project  GitHub community articles  ](https://github.com/readme)\nRepositories\n    * [ Topics ](https://github.com/topics)\n    * [ Trending ](https://github.com/trending)\n    * [ Collections ](https://github.com/collections)\n  * Enterprise \n    * [ Enterprise platform  AI-powered developer platform  ](https://github.com/enterprise)\nAvailable add-ons\n    * [ GitHub Advanced Security  Enterprise-grade security features  ](https://github.com/security/advanced-security)\n    * [ Copilot for business  Enterprise-grade AI features  ](https://github.com/features/copilot/copilot-business)\n    * [ Premium Support  Enterprise-grade 24/7 support  ](https://github.com/premium-support)\n  * [Pricing](https://github.com/pricing)\n\n\nSearch or jump to...\n# Search code, repositories, users, issues, pull requests...\nSearch \nClear\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n#  Provide feedback \nWe read every piece of feedback, and take your input very seriously.\nInclude my email address so I can be contacted\nCancel  Submit feedback \n#  Saved searches \n## Use saved searches to filter your results more quickly\nName\nQuery\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax). \nCancel  Create saved search \n[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fdair-ai%2FML-Papers-of-the-Week)\n[ Sign up ](https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=dair-ai%2FML-Papers-of-the-Week)\nAppearance settings\nResetting focus\nYou signed in with another tab or window. [Reload](https://github.com/dair-ai/ML-Papers-of-the-Week) to refresh your session. You signed out in another tab or window. [Reload](https://github.com/dair-ai/ML-Papers-of-the-Week) to refresh your session. You switched accounts on another tab or window. [Reload](https://github.com/dair-ai/ML-Papers-of-the-Week) to refresh your session. Dismiss alert\n{{ message }}\n[ dair-ai ](https://github.com/dair-ai) / **[ML-Papers-of-the-Week](https://github.com/dair-ai/ML-Papers-of-the-Week) ** Public\n  * [ Notifications ](https://github.com/login?return_to=%2Fdair-ai%2FML-Papers-of-the-Week) You must be signed in to change notification settings\n  * [ Fork 687 ](https://github.com/login?return_to=%2Fdair-ai%2FML-Papers-of-the-Week)\n  * [ Star  11.3k ](https://github.com/login?return_to=%2Fdair-ai%2FML-Papers-of-the-Week)\n\n\nð¥Highlighting the top ML papers every week. \n[ 11.3k stars ](https://github.com/dair-ai/ML-Papers-of-the-Week/stargazers) [ 687 forks ](https://github.com/dair-ai/ML-Papers-of-the-Week/forks) [ Branches ](https://github.com/dair-ai/ML-Papers-of-the-Week/branches) [ Tags ](https://github.com/dair-ai/ML-Papers-of-the-Week/tags) [ Activity ](https://github.com/dair-ai/ML-Papers-of-the-Week/activity)\n[ Star  ](https://github.com/login?return_to=%2Fdair-ai%2FML-Papers-of-the-Week)\n[ Notifications ](https://github.com/login?return_to=%2Fdair-ai%2FML-Papers-of-the-Week) You must be signed in to change notification settings\n  * [ Code ](https://github.com/dair-ai/ML-Papers-of-the-Week)\n  * [ Issues 2 ](https://github.com/dair-ai/ML-Papers-of-the-Week/issues)\n  * [ Pull requests 1 ](https://github.com/dair-ai/ML-Papers-of-the-Week/pulls)\n  * [ Actions ](https://github.com/dair-ai/ML-Papers-of-the-Week/actions)\n  * [ Projects 0 ](https://github.com/dair-ai/ML-Papers-of-the-Week/projects)\n  * [ Security ](https://github.com/dair-ai/ML-Papers-of-the-Week/security)\n[ ](https://github.com/dair-ai/ML-Papers-of-the-Week/security)\n[ ](https://github.com/dair-ai/ML-Papers-of-the-Week/security)\n[ ](https://github.com/dair-ai/ML-Papers-of-the-Week/security)\n### [ Uh oh!  ](https://github.com/dair-ai/ML-Papers-of-the-Week/security)\n[There was an error while loading. ](https://github.com/dair-ai/ML-Papers-of-the-Week/security)[Please reload this page](https://github.com/dair-ai/ML-Papers-of-the-Week).\n  * [ Insights ](https://github.com/dair-ai/ML-Papers-of-the-Week/pulse)\n\n\nAdditional navigation options\n  * [ Code  ](https://github.com/dair-ai/ML-Papers-of-the-Week)\n  * [ Issues  ](https://github.com/dair-ai/ML-Papers-of-the-Week/issues)\n  * [ Pull requests  ](https://github.com/dair-ai/ML-Papers-of-the-Week/pulls)\n  * [ Actions  ](https://github.com/dair-ai/ML-Papers-of-the-Week/actions)\n  * [ Projects  ](https://github.com/dair-ai/ML-Papers-of-the-Week/projects)\n  * [ Security  ](https://github.com/dair-ai/ML-Papers-of-the-Week/security)\n  * [ Insights  ](https://github.com/dair-ai/ML-Papers-of-the-Week/pulse)\n\n\n# dair-ai/ML-Papers-of-the-Week\nmain\n[**1** Branch](https://github.com/dair-ai/ML-Papers-of-the-Week/branches)[**0** Tags](https://github.com/dair-ai/ML-Papers-of-the-Week/tags)\n[](https://github.com/dair-ai/ML-Papers-of-the-Week/branches)[](https://github.com/dair-ai/ML-Papers-of-the-Week/tags)\nGo to file\nCode\n## Folders and files\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n## Latest commit\n[![omarsar](https://avatars.githubusercontent.com/u/7049564?v=4&size=40)](https://github.com/omarsar)[omarsar](https://github.com/dair-ai/ML-Papers-of-the-Week/commits?author=omarsar)[Update README.md](https://github.com/dair-ai/ML-Papers-of-the-Week/commit/871661ea64a7e6e845fd4a50e8a5b8b7f200ce98)Apr 12, 2025[871661e](https://github.com/dair-ai/ML-Papers-of-the-Week/commit/871661ea64a7e6e845fd4a50e8a5b8b7f200ce98) Â· Apr 12, 2025\n## History\n[326 Commits](https://github.com/dair-ai/ML-Papers-of-the-Week/commits/main/)[](https://github.com/dair-ai/ML-Papers-of-the-Week/commits/main/)  \n[pics](https://github.com/dair-ai/ML-Papers-of-the-Week/tree/main/pics \"pics\")| [pics](https://github.com/dair-ai/ML-Papers-of-the-Week/tree/main/pics \"pics\")| [Add files via upload](https://github.com/dair-ai/ML-Papers-of-the-Week/commit/eb0497ee79d067e46a078fa206fb85c95c77f8b7 \"Add files via upload\")| Mar 26, 2023  \n[research](https://github.com/dair-ai/ML-Papers-of-the-Week/tree/main/research \"research\")| [research](https://github.com/dair-ai/ML-Papers-of-the-Week/tree/main/research \"research\")| [Add files via upload](https://github.com/dair-ai/ML-Papers-of-the-Week/commit/c38b1aac7f5210622e998cdf033be26238ca8cdd \"Add files via upload\")| Oct 25, 2023  \n[README.md](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/README.md \"README.md\")| [README.md](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/README.md \"README.md\")| [Update README.md](https://github.com/dair-ai/ML-Papers-of-the-Week/commit/871661ea64a7e6e845fd4a50e8a5b8b7f200ce98 \"Update README.md\")| Apr 12, 2025  \n[SUMMARY.md](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/SUMMARY.md \"SUMMARY.md\")| [SUMMARY.md](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/SUMMARY.md \"SUMMARY.md\")| [GITBOOK-5: Elvis's Oct 3 changes](https://github.com/dair-ai/ML-Papers-of-the-Week/commit/8b14358e8ca23b14dac1f72c3ac46b701e5d0986 \"GITBOOK-5: Elvis's Oct 3 changes\")| Oct 4, 2023  \nView all files  \n## Repository files navigation\n  * [README](https://github.com/dair-ai/ML-Papers-of-the-Week)\n\n\n# ML Papers of The Week\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#ml-papers-of-the-week)\n[Subscribe to our newsletter](https://nlpnews.substack.com/) to get a weekly list of top ML papers in your inbox.\nAt DAIR.AI we â¤ï¸ reading ML papers so we've created this repo to highlight the top ML papers of every week.\nHere is the weekly series:\nHere is the weekly series:\n## 2025\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#2025)\n  * [Top ML Papers of the Week (March 31 - April 6)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-march-31---april-6---2025)\n  * [Top ML Papers of the Week (March 24 - March 30)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-march-24---march-30---2025)\n  * [Top ML Papers of the Week (March 17 - March 23)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-march-17---march-23---2025)\n  * [Top ML Papers of the Week (March 10 - March 16)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-march-10---march-16---2025)\n  * [Top ML Papers of the Week (March 3 - March 9)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-march-3---march-9---2025)\n  * [Top ML Papers of the Week (February 24 - March 2)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-february-24---march-2---2025)\n  * [Top ML Papers of the Week (February 17 - February 23)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-february-17---february-23---2025)\n  * [Top ML Papers of the Week (February 10 - February 16)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-february-10---february-16---2025)\n  * [Top ML Papers of the Week (February 3 - February 9)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-february-3---february-9---2025)\n  * [Top ML Papers of the Week (January 27 - February 2)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-january-27---february-2---2025)\n  * [Top ML Papers of the Week (January 20 - January 26)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-january-20---january-26---2025)\n  * [Top ML Papers of the Week (January 13 - January 19)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-january-13---january-19---2025)\n  * [Top ML Papers of the Week (January 6 - January 12)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-january-6---january-12---2025)\n\n\n## 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#2024)\n  * [Top ML Papers of the Week (December 30 - January 5)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-december-30---january-5---2025)\n  * [Top ML Papers of the Week (December 23 - December 29)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-december-23---december-29---2024)\n  * [Top ML Papers of the Week (December 16 - December 22)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-december-16---december-22---2024)\n  * [Top ML Papers of the Week (December 9 - December 15)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-december-9---december-15---2024)\n  * [Top ML Papers of the Week (December 2 - December 8)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-december-2---december-8---2024)\n  * [Top ML Papers of the Week (November 25 - December 1)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-november-25---december-1---2024)\n  * [Top ML Papers of the Week (November 18 - November 24)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-november-18---november-24---2024)\n  * [Top ML Papers of the Week (November 11 - November 17)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-november-11---november-17---2024)\n  * [Top ML Papers of the Week (November 4 - November 10)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-november-4---november-10---2024)\n  * [Top ML Papers of the Week (October 28 - November 3)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-october-28---november-3---2024)\n  * [Top ML Papers of the Week (October 21 - October 27)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-october-14---october-20---2024)\n  * [Top ML Papers of the Week (October 14 - October 20)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-october-14---october-20---2024)\n  * [Top ML Papers of the Week (October 7 - October 13)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-october-7---october-13---2024)\n  * [Top ML Papers of the Week (September 30 - October 6)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-september-30---october-6---2024)\n  * [Top ML Papers of the Week (September 23 - September 29)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-september-23---september-29---2024)\n  * [Top ML Papers of the Week (September 16 - September 22)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-september-16---september-22---2024)\n  * [Top ML Papers of the Week (September 9 - September 15)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-september-9---september-15---2024)\n  * [Top ML Papers of the Week (September 2 - September 8)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-september-2---september-8---2024)\n  * [Top ML Papers of the Week (August 26 - September 1)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-august-26---september-1---2024)\n  * [Top ML Papers of the Week (August 19 - August 25)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-august-19---august-25---2024)\n  * [Top ML Papers of the Week (August 12 - August 18)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-august-12---august-18---2024)\n  * [Top ML Papers of the Week (August 5 - August 11)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-august-5---august-11---2024)\n  * [Top ML Papers of the Week (July 29 - August 4)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-july-29---august-4---2024)\n  * [Top ML Papers of the Week (July 22 - July 28)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-july-15---july-21---2024)\n  * [Top ML Papers of the Week (July 15 - July 21)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-july-15---july-21---2024)\n  * [Top ML Papers of the Week (July 8 - July 14)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-july-8---july-14---2024)\n  * [Top ML Papers of the Week (July 1 - July 7)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-july-1---july-7---2024)\n  * [Top ML Papers of the Week (June 24 - June 30)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-june-24---june-30---2024)\n  * [Top ML Papers of the Week (June 17 - June 23)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-june-17---june-23---2024)\n  * [Top ML Papers of the Week (June 10 - June 16)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-june-10---june-16---2024)\n  * [Top ML Papers of the Week (June 3 - June 9)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-june-3---june-9---2024)\n  * [Top ML Papers of the Week (May 27 - June 2)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-may-27---june-2---2024)\n  * [Top ML Papers of the Week (May 20 - May 26)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-may-20---may-26---2024)\n  * [Top ML Papers of the Week (May 13 - May 19)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-may-13---may-19---2024)\n  * [Top ML Papers of the Week (May 6 - May 12)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-may-6---may-12---2024)\n  * [Top ML Papers of the Week (April 29 - May 5)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-april-29---may-5---2024)\n  * [Top ML Papers of the Week (April 22 - April 28)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-april-22---april-28---2024)\n  * [Top ML Papers of the Week (April 15 - April 21)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-april-15---april-21---2024)\n  * [Top ML Papers of the Week (April 8 - April 14)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-april-8---april-14---2024)\n  * [Top ML Papers of the Week (April 1 - April 7)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-april-1---april-7---2024)\n  * [Top ML Papers of the Week (March 26 - March 31)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-march-26---march-31---2024)\n  * [Top ML Papers of the Week (March 18 - March 25)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-march-18---march-25---2024)\n  * [Top ML Papers of the Week (March 11 - March 17)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-march-11---march-17---2024)\n  * [Top ML Papers of the Week (March 4 - March 10)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-march-4---march-10---2024)\n  * [Top ML Papers of the Week (February 26 - March 3)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-february-26---march-3---2024)\n  * [Top ML Papers of the Week (February 19 - February 25)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-february-19---february-25---2024)\n  * [Top ML Papers of the Week (February 12 - February 18)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-february-12---february-18---2024)\n  * [Top ML Papers of the Week (February 5 - February 11)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-february-5---february-11---2024)\n  * [Top ML Papers of the Week (January 29 - February 4)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-january-29---february-4---2024)\n  * [Top ML Papers of the Week (January 22 - January 28)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-january-22---january-28---2024)\n  * [Top ML Papers of the Week (January 15 - January 21)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-january-15---january-21---2024)\n  * [Top ML Papers of the Week (January 8 - January 14)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-january-8---january-14---2024)\n  * [Top ML Papers of the Week (January 1 - January 7)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-january-1---january-7---2024)\n\n\n## 2023\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#2023)\n  * [Top ML Papers of the Week (December 24 - December 31)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-december-25---december-31)\n  * [Top ML Papers of the Week (December 18 - December 24)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-december-18---december-24)\n  * [Top ML Papers of the Week (December 11 - December 17)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-december-11---december-17)\n  * [Top ML Papers of the Week (December 4 - December 10)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-december-4---december-10)\n  * [Top ML Papers of the Week (November 27 - December 3)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-november-27---december-3)\n  * [Top ML Papers of the Week (November 20 - November 26)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-november-20---november-26)\n  * [Top ML Papers of the Week (November 13 - November 19)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-november-13---november-19)\n  * [Top ML Papers of the Week (November 6 - November 12)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-november-6---november-12)\n  * [Top ML Papers of the Week (October 30 - November 5)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-october-30---november-5)\n  * [Top ML Papers of the Week (October 23 - October 29)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-october-23---october-29)\n  * [Top ML Papers of the Week (October 16 - October 22)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-october-16---october-22)\n  * [Top ML Papers of the Week (October 9 - October 15)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-october-9---october-15)\n  * [Top ML Papers of the Week (October 2 - October 8)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-october-2---october-8)\n  * [Top ML Papers of the Week (September 25 - October 1)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-september-25---october-1)\n  * [Top ML Papers of the Week (September 18 - September 24)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-september-18---september-24)\n  * [Top ML Papers of the Week (September 11 - September 17)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-september-11---september-17)\n  * [Top ML Papers of the Week (September 4 - September 10)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-september-4---september-10)\n  * [Top ML Papers of the Week (August 28 - September 3)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-august-28---september-3)\n  * [Top ML Papers of the Week (August 21 - August 27)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-august-21---august-27)\n  * [Top ML Papers of the Week (August 14 - August 20)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-august-14---august-20)\n  * [Top ML Papers of the Week (August 7 - August 13)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-august-7---august-13)\n  * [Top ML Papers of the Week (July 31 - August 6)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-july-31---august-6)\n  * [Top ML Papers of the Week (July 24 - July 30)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-july-24---july-30)\n  * [Top ML Papers of the Week (July 17 - July 23)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-july-17---july-23)\n  * [Top ML Papers of the Week (July 10 - July 16)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-july-10---july-16)\n  * [Top ML Papers of the Week (July 3 - July 9)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-july-3---july-9)\n  * [Top ML Papers of the Week (June 26 - July 2)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-june-26---july-2)\n  * [Top ML Papers of the Week (June 19 - June 25)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-june-19---june-25)\n  * [Top ML Papers of the Week (June 12 - June 18)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-june-12---june-18)\n  * [Top ML Papers of the Week (June 5 - June 11)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-june-5---june-11)\n  * [Top ML Papers of the Week (May 29 - June 4)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-may-29-june-4)\n  * [Top ML Papers of the Week (May 22 - 28)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-may-22-28)\n  * [Top ML Papers of the Week (May 15 - 21)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-may-15-21)\n  * [Top ML Papers of the Week (May 8 - 14)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-may-8-14)\n  * [Top ML Papers of the Week (May 1-7)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-may-1-7)\n  * [Top ML Papers of the Week (April 24 - April 30)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-april-24---april-30)\n  * [Top ML Papers of the Week (April 17 - April 23)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-april-17---april-23)\n  * [Top ML Papers of the Week (April 10 - April 16)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-april-10---april-16)\n  * [Top ML Papers of the Week (April 3 - April 9)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-april-3---april-9)\n  * [Top ML Papers of the Week (Mar 27 - April 2)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-mar-27---april-2)\n  * [Top ML Papers of the Week (Mar 20-Mar 26)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-mar-20-mar-26)\n  * [Top ML Papers of the Week (Mar 13-Mar 19)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-mar-13-mar-19)\n  * [Top ML Papers of the Week (Mar 6-Mar 12)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-mar-6-mar-12)\n  * [Top ML Papers of the Week (Feb 27-Mar 5)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-feb-27-mar-5)\n  * [Top ML Papers of the Week (Feb 20-26)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-feb-20-26)\n  * [Top ML Papers of the Week (Feb 13 - 19)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-feb-13---19)\n  * [Top ML Papers of the Week (Feb 6 - 12)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-feb-6---12)\n  * [Top ML Papers of the Week (Jan 30-Feb 5)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-jan-30-feb-5)\n  * [Top ML Papers of the Week (Jan 23-29)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-jan-23-29)\n  * [Top ML Papers of the Week (Jan 16-22)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-jan-16-22)\n  * [Top ML Papers of the Week (Jan 9-15)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-jan-9-15)\n  * [Top ML Papers of the Week (Jan 1-8)](https://github.com/dair-ai/ML-Papers-of-the-Week/blob/main/#top-ml-papers-of-the-week-jan-1-8)\n\n\n[Follow us on Twitter](https://twitter.com/dair_ai)\n[Join our Discord](https://discord.gg/SKgkVT8BGJ)\n## Top ML Papers of the Week (March 31 - April 6) - 2025\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-march-31---april-6---2025)\n**Paper** | **Links**  \n---|---  \n1) PaperBench OpenAI introduces a new benchmark, PaperBench, to test whether AI agents can replicate cutting-edge machine learning research papers, from scratch. â A rigorous replication challenge â PaperBench evaluates agents on reproducing entire ML papers from ICML 2024 (20 total, across 12 research areas). Agents must understand the paper, build the codebase from scratch, and run experiments to match results. Each paper comes with a fine-grained rubric (~8,316 tasks total) co-designed with the original authors. â Automatic grading with LLM judges â To make evaluation scalable, the team built a rubric-based judge (o3-mini with scaffolding) that scores replications with high agreement (F1 = 0.83) against human experts. They also release JudgeEval, a benchmark for assessing judge accuracy. â Frontier model performance is modest â Claude 3.5 Sonnet scored highest with 21.0%, followed by o1 (13.2%) and GPT-4o (4.1%). Even with longer runtimes and prompt tuning (IterativeAgent), no model surpassed a 26.0% score. By contrast, ML PhDs hit 41.4% on a 3-paper subset in 48 hours, showing humans still lead in long-horizon agentic tasks. â CodeDev variant for lightweight evals â A simplified PaperBench Code-Dev version skips execution and just grades code structure. o1 scored 43.4% there, showing more promise when runtime issues are excluded. â Failure modes and insights â Models often âgave up early,â lacked strategic planning, and failed to iterate. Claude did better with BasicAgent (freer form), while o1 benefited from IterativeAgent (structured prompts). This highlights how sensitive agents are to prompting and scaffolding. â Open-source release â PaperBench (with rubrics, grading infra, and replication results) is fully open-sourced to drive further progress on long-horizon agent tasks and autonomous AI R&D. | [Paper](https://arxiv.org/abs/2504.01848), [Tweet](https://x.com/OpenAI/status/1907481490457506235), [GitHub](https://github.com/openai/preparedness)  \n2) Command A: An Enterprise-Ready LLM Cohere announced Command A, a 111B parameter open-weights LLM built for enterprise-grade RAG, agents, code, and multilingual tasks. Key contributions: â Modular expert merging for domain mastery â Instead of monolithic post-training, Command A uses a decentralized training pipeline. Separate expert models are fine-tuned for specific domains (e.g., math, RAG, multilingual, safety, code), then merged into one model using efficient weighted parameter soup techniques. This preserves most expert performance with just ~1.8% average drop. â Hybrid architecture for long-context efficiency â Command A interleaves sliding window and full attention layers, achieving 256k context support with drastically lower KV cache memory usageâe.g., only ~33% of LLaMA 3 70B at 128k. It scores 95.0% on RULER, outperforming most long-context peers. â Superb agentic capabilities â Built for RAG, tool use, and ReAct-style agents, Command A beats GPT-4o and Claude 3.5 on TauBench and BFCL. Tool use is trained via a blend of human-annotated and synthetic data, then aligned with CoPG and SRPO (self-improving preference optimization). â Best-in-class enterprise evaluations â On real-world generative tasks (e.g., chat summarization, FAQ generation) and RAG use cases (long workplace policy documents), Command A tops the leaderboard with 94.2% pass rate, 4.73 correctness, and 91% unanswerable QA accuracy. â Multilingual excellence â Command A is trained in 23 global languages with heavy data curation and preference tuning. It scores #1 in dialect alignment (ADI2), 90.3% average LPR (language consistency), and outperforms LLaMA 3.3, GPT-4o, and DeepSeek in manual Arena-style win rates across all languages. â Polishing for human alignment â Final alignment used a ping-pong loop of offline SRPO and online CoPG with RLHF. This yielded +17pt human win rate gains on code, +10pt on reasoning, and lifted Command Aâs win rate over GPT-4o to parity (~50.4%). â Fast, efficient, and open â Despite its power, Command A runs on just 2ÃA100s or H100s and generates 156 tokens/secâfaster than GPT-4o and DeepSeek. Model weights are released (CC-BY-NC) on Hugging Face. | [Paper](https://arxiv.org/abs/2504.00698), [Tweet](https://x.com/nrehiew_/status/1908181303339471020), [Models](https://huggingface.co/CohereForAI/c4ai-command-a-03-2025)  \n3) CodeScientist Researchers at AI2 release CodeScientist, a system that autonomously generates and tests scientific hypotheses via code-based experimentation. Itâs among the first to produce validated discoveries with minimal human input. Key ideas: â Code-first scientific agent â CodeScientist reviews research papers and assembles experiments using vetted Python code blocks (e.g., for analysis, simulation). It follows a five-step pipeline: Ideation â Planning â Code Execution â Reporting â Meta-Analysis. â Validated AI discoveries â From 50 AI research papers on agents and virtual environments, CodeScientist proposed 19 findings. Of these, 6 were judged scientifically sound and novel. Examples: â Human-guided autonomy â Full automation is possible, but brief human feedback (e.g., ranking ideas) significantly boosts output quality. Human-in-the-loop interaction improves idea selection and experiment debugging. â Challenges remain â Despite successes, over half the generated experiments fail due to code errors, not scientific flaws. Peer review is still needed to verify results, and current systems lack deep methodological rigor. | [Paper](https://arxiv.org/abs/2503.22708), [Blog](https://allenai.org/blog/codescientist), [GitHub](https://github.com/allenai/codescientist)  \n4) Retrieval-Augmented Reasoning Model Introduces RARE, a new paradigm for training domain-specific LLMs that focuses on reasoning, not memorization. Key ideas: â Inspired by Bloomâs Taxonomy â RARE shifts LLM training from memorizing knowledge (âRememberâ) to applying and evaluating it (âAnalyzeâ, âCreateâ). It separates domain knowledge (retrieved externally) from domain thinking (learned during training), enabling better performance under tight parameter budgets. â Open-book prepared training â RARE injects retrieved knowledge into training prompts, letting models learn reasoning patterns instead of rote facts. This open-book, reasoning-first setup beats both standard SFT and RAG approaches, especially in medicine. â Massive accuracy gains with small models â On five medical QA benchmarks, RARE-trained Llama-3.1-8B and Qwen-2.5-7B outperformed GPT-4 + RAG, with up to +20% accuracy boosts (e.g., PubMedQA: 78.63% vs. GPT-4âs 75.2%, CoVERT: 74.14% vs. GPT-4âs 65.67%). â Training via distillation + adaptive retries â RARE distills answers (and reasoning paths) from a strong teacher (e.g., QwQ-32B), refining outputs until a correct answer is found. This creates a high-quality dataset that teaches contextualized, case-based thinking. â New role for retrieval â Unlike standard RAG (used only at inference), RARE uses retrieval during training to shape reasoning. It models knowledge integration (p(kx, R(x))) and reasoning (p(rx, R(x), k)) as separate steps, replacing memorization with application. Overall, this work reframes LLM training for domain-specific intelligence: externalize facts, internalize reasoning. It unlocks strong performance from small models without overfitting or hallucination. | [Paper](https://arxiv.org/abs/2503.23513), [Tweet](https://x.com/omarsar0/status/1907796990966247484)  \n5) Why do LLMs Attend to First Token? This new paper explains why LLMs obsessively focus attention on the first token â a phenomenon known as an attention sink. Their theory: itâs a useful trick to prevent representational collapse in deep Transformers. â Sinks = over-mixing shields â LLMs with long contexts and deep layers tend to over-mix information, causing similar embeddings for all tokens (i.e., rank collapse or over-squashing). Attention sinksâwhere many heads fixate on the â¨bosâ© tokenâact as no-ops that reduce token interaction and preserve representation diversity across layers. â Sharp experiments on Gemma & LLaMa â Perturbation tests in Gemma 7B show â¨bosâ© significantly slows the spread of changes through the model. Meanwhile, in LLaMa 3.1 models, over 80% of attention heads show strong sink behavior in the 405B variant, supporting the theory that larger models need stronger sinks. â Sinks emerge naturally â Even without special pretraining, sinks tend to form at the first position, not because of the â¨bosâ© token itself, but due to its location. However, if â¨bosâ© is fixed during training and later removed, performance collapses, showing that sink formation is data-dependent. â Theoretical grounding â The authors connect sink emergence to Jacobian norm bounds, proving that sinks reduce sensitivity to token perturbations. Their math shows that deeper models and longer contexts require stronger sinks. â Layerwise dynamics insight â Some attention heads use â¨bosâ© as a âdefaultâ target, unless a special pattern (e.g., apostrophe) triggers real computation. This supports a conditional attention mechanismâattend to â¨bosâ© unless needed elsewhere. | [Paper](https://arxiv.org/abs/2504.02732), [Tweet](https://x.com/omarsar0/status/1908187563422261411)  \n6) Self-Evolving Multi-Agent Simulations for Realistic Clinical Interactions Presents MedAgentSim is a fully automated, open-source hospital simulation where LLM-powered agents simulate doctor-patient interactions in dynamic diagnostic settings. Unlike previous static QA benchmarks, MedAgentSim mimics real-world clinical workflows with multi-turn dialogue, test requests, and self-improvement. More about this paper: â Active doctor agents â MedAgentSim requires LLM doctor agents to engage in multi-turn consultations, request labs and imaging (e.g., ECG, X-ray), and iteratively refine diagnoses, making it far more realistic than pre-filled medical QA datasets. â Self-improvement via memory + reflection â The system maintains buffers of successful and failed diagnoses. It uses retrieved past cases (via kNN), chain-of-thought reasoning, and ensembling to improve performance over time. Misdiagnoses trigger a reflection phase before inclusion in memory. â Fully autonomous or human-in-the-loop â Users can optionally take control of the doctor or patient agents. Simulation assets are built using a 2D game engine (Phaser), and the agents can navigate, converse, and interact with virtual medical tools. â Big performance boost across benchmarks â On NEJM, MedQA, and MIMIC-IV, MedAgentSim (with LLaMA 3.3) outperforms baseline setups by +6â37%, especially in vision-language tasks using LLaVA for interpreting medical images. â Bias analysis & fairness focus â The team studied diagnostic accuracy under cognitive and implicit bias conditions. Models like GPT-4o and LLaMA proved more robust than Mixtral/Mistral, highlighting the importance of bias-aware evaluation. | [Paper](https://arxiv.org/abs/2503.22678), [Tweet](https://x.com/omarsar0/status/1906719555482702147), [Code](https://github.com/MAXNORM8650/MedAgentSim)  \n7) Open Deep Search Researchers from Sentient, UW, Princeton, and UC Berkeley introduce Open Deep Search (ODS), an open-source search AI framework that rivals top proprietary systems like GPT-4o Search Preview and Perplexity Sonar. Key insights: â Two open components: search + reasoning â ODS has two modular parts: (1) Open Search Tool, which retrieves and refines high-quality web results using query rephrasing, snippet reranking, and site-specific logic; and (2) Open Reasoning Agent, a controller that orchestrates tool usage (search, calculator, etc.) to answer queries. Two variants are offered: ODS-v1 (ReAct) and ODS-v2 (CodeAct). â SOTA open-source performance â With DeepSeek-R1 as the base LLM, ODS-v2 scores 88.3% on SimpleQA and 75.3% on FRAMES, beating GPT-4o Search Preview by +9.7% on the latter. ODS adapts the number of searches per query (avg. 3.39 on FRAMES), balancing cost and accuracy more efficiently than fixed-query baselines. â Better than Perplexity Sonar â On both FRAMES and SimpleQA, ODS+DeepSeek-R1 outperforms Perplexityâs flagship search models, even in complex reasoning tasks involving multi-hop questions, time/date calculations, and name disambiguation. â Code-based agents enhance reasoning â ODS-v2 builds on CodeAct, allowing it to write and run Python code to perform symbolic reasoning and tool calls. This results in sharper numerical precision and task flexibility compared to CoT-based ReAct in ODS-v1. | [Paper](https://arxiv.org/abs/2503.20201), [Tweet](https://x.com/sewoong79/status/1906595129965912341), [GitHub](https://github.com/sentient-agi/OpenDeepSearch)  \n8) Efficient Test-time Scaling with Code Z1 is a new method for making large language models more compute-efficient at test time, especially during reasoning. The core idea is to train LLMs with short and long code-based reasoning trajectories, and then dynamically adjust reasoning depth during inference. Key contributions: â Z1-Code-Reasoning-107K dataset â They construct a 107K-sample dataset with short and long reasoning paths for simple and complex coding problems. Trajectories are distilled from QwQ-32B and paired to help the model learn when to stop thinking. â Shifted Thinking Window â A new test-time strategy that eliminates explicit <think delimiters. Instead, the model adapts reasoning token budget based on problem difficulty. Simple problems invoke shallow reasoning; complex ones get capped (e.g., 4096 tokens max), with hints nudging the model to finalize the answer. â Big efficiency gains â The 7B-scale model Z1-7B matches R1-Distill-Qwen-7B across multiple reasoning tasks (MATH500, LiveCodeBench, GPQA Diamond) but with ~30% of the reasoning tokens. For instance, on GPQA Diamond, Z1-7B achieves 47.5% while using less than half the tokens. â Code reasoning transfers to general tasks â Despite being trained only on code-based CoT data, Z1 generalizes well to broader domains like science and math, outperforming other 7B reasoning models (e.g., OpenThinker-7B, s1.1-7B) across multiple benchmarks. â What makes reasoning data effective? â Ablation studies reveal two key dataset design levers: (1) longer reasoning trajectories improve inference quality; (2) larger training sample sizes boost average thinking time and accuracy, even without altering trajectory length. | [Paper](https://arxiv.org/abs/2504.00810v1)  \n9) A Survey of Efficient Reasoning for LLMs This survey focuses on reasoning economy in LLMs, analyzing how to balance deep reasoning performance with computational cost. It reviews inefficiencies, behavioral patterns, and potential solutions at both post-training and inference stages. | [Paper](https://arxiv.org/abs/2503.24377), [Tweet](https://x.com/omarsar0/status/1907072213142151488)  \n10) Hidden Factual Knowledge in LLMs This study introduces a framework to measure hidden knowledge in LLMs, showing that models encode significantly more factual information internally than they express in outputs, up to 40% more. It also finds that some answers, although known internally, are never generated, highlighting key limits in test-time sampling for QA tasks. | [Paper](https://arxiv.org/abs/2503.15299), [Tweet](https://x.com/zorikgekhman/status/1906693729886363861)  \n## Top ML Papers of the Week (March 24 - March 30) - 2025\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-march-24---march-30---2025)\n**Paper** | **Links**  \n---|---  \n1) Tracing the Thoughts of LLMs Anthropic researchers unveil new interpretability tools for peering inside LLMs, using Claude 3.5 Haiku as a testbed. Their two new papers show how to trace model internals like circuits, plans, and conceptual thinking in real time. Key findings: â Multilingual \"language of thought\" â Claude processes concepts like âsmallâ or âoppositeâ similarly across English, French, and Chinese, suggesting a shared abstract representation layer. As models scale, these cross-lingual features increase, enabling transfer learning between languages. â Planning aheadâeven in poetry â Contrary to expectations, Claude plans rhymes before writing. When generating the line âHis hunger was like a starving rabbit,â it had already âdecidedâ on rhyming with âgrab it.â Researchers could suppress or swap this plan to alter the ending dynamically. â Mental math with parallel circuits â Claude computes sums using parallel circuits: one estimates the result, the other nails the last digit. But it explains answers with human-style logic (e.g., \"carry the 1\"), revealing a gap between internal computation and verbal justification. â Detecting unfaithful reasoning â Sometimes, Claude fabricates logical steps to fit a target answer, especially when guided by incorrect hints. Interpretability tools could catch these cases by showing that internal computation doesnât match the explanationâa key advance for AI audits. â Conceptual chains in multi-step reasoning â For questions like âWhat is the capital of the state where Dallas is located?â, Claude first represents âDallas â Texasâ then âTexas â Austin.â Researchers could intervene mid-chain to make it say âSacramentoâ instead, proving the reasoning is dynamic and compositional. â Hallucinations and refusals â The model defaults to refusal unless prompted with known concepts. Misfires in circuits for âknown answersâ cause hallucinations (e.g., inventing facts about a fake name like âMichael Batkinâ). Researchers could toggle this behavior by manipulating feature activations. â Jailbreak anatomy â A jailbreak using the phrase âBabies Outlive Mustard Blockâ (BOMB) initially fools Claude into outputting dangerous info. Internal tracing shows grammar-consistency features temporarily override safety, until the model finishes a coherent sentence, then its safety response kicks in. | [Blog](https://www.anthropic.com/research/tracing-thoughts-language-model), [Paper 1](https://transformer-circuits.pub/2025/attribution-graphs/methods.html), [Paper 2](https://transformer-circuits.pub/2025/attribution-graphs/biology.html), [Tweet](https://x.com/AnthropicAI/status/1905303835892990278)  \n2) Qwen2.5-Omni Qwen2.5-Omni is a single end-to-end multimodal model that can perceive and understand text, audio, image, and video, and generate both text and speech in real time. It introduces architectural and training innovations that push the boundaries of streaming, multi-signal intelligence. Highlights: â Thinker-Talker architecture â Inspired by the human brain and mouth, Qwen2.5-Omni separates reasoning (Thinker) and speech generation (Talker). Thinker (a transformer decoder) handles all perception and text generation. Talker (a dual-track autoregressive decoder) generates speech by consuming both text and hidden states from Thinker. Together, theyâre trained end-to-end for synchronized text-speech output. â Streaming-first design â To support real-time interaction, Qwen2.5-Omni implements block-wise encoders (for audio and vision) and a sliding-window codec generator for streaming audio. The model introduces TMRoPE (Time-aligned Multimodal RoPE), a 3D positional encoding system that aligns video and audio inputs to the same time axis. â Pretraining scale & alignment â Trained on over 1.2 trillion tokens of diverse multimodal data, including 300B audio and 100B video-audio tokens. Uses instruction-tuned ChatML formatting and performs multi-stage post-training for both Thinker and Talker. Talker undergoes RL fine-tuning (DPO) and multi-speaker adaptation to ensure natural, stable speech output. â SOTA across modalities â Qwen2.5-Omni achieves state-of-the-art on OmniBench, surpasses Qwen2-Audio in ASR/S2TT, and matches or beats Qwen2.5-VL in image and video tasks. On SEED zero-shot TTS, it outperforms CosyVoice 2 and F5-TTS in naturalness and stability, with low WER and high speaker similarity. â Closes the voice-text gap â On a voice-instruction benchmark (converted from MMLU, GSM8K, etc.), Qwen2.5-Omni nearly matches its own text-instructed sibling Qwen2-7B, showing dramatic improvements in speech-based instruction following. | [Paper](https://github.com/QwenLM/Qwen2.5-Omni/blob/main/assets/Qwen2.5_Omni.pdf), [Tweet](https://x.com/Alibaba_Qwen/status/1904944923159445914)  \n3) AgentRxiv Researchers from Johns Hopkins & ETH Zurich present AgentRxiv, a framework enabling LLM agents to autonomously generate and share research papers, mimicking how human scientists build on each otherâs work. Highlights: â AgentRxiv = arXiv for LLMs â Itâs an open-source preprint server for autonomous agents, letting labs upload papers, search past work, and iteratively improve results. Labs use this to develop and refine reasoning techniques over generations of research. â Massive reasoning gains via iterative research â On the MATH-500 benchmark, a single agent lab improves GPT-4o mini accuracy from 70.2% â 78.2% (+11.4%) by discovering better prompt strategies. The final method (SDA) outperforms earlier ideas like CRUC and DCCP. â SDA = Simultaneous Divergence Averaging: combines low/high-temp CoT outputs with dynamic similarity-based voting and confidence aggregation. â Knowledge generalizes â SDA also improves other benchmarks: â Collaboration boosts discovery â Running 3 agent labs in parallel yields faster progress and higher final accuracy (up to 79.8%, +13.7% over baseline) by sharing results via AgentRxiv. Early gains (e.g., 76.2% accuracy) arrive after only 7 papers vs. 23 sequentially. â Self-improvement and novelty â Agents independently refine their own past ideas. Papers evolve from earlier iterations (e.g., Meta-Mirror Prompting â Meta-Mirror Prompting 2). Top papers show no plagiarism via multiple detectors, but ideas like SDA build on trends like self-consistency and CoT voting. â Cost & runtime â Generating a paper takes ~1.36 hours and ~$3.11. Parallel setups are pricier overall but achieve results faster (time-to-accuracy win). Failure modes include hallucinated results and fragile code repair steps, with future work needed for better reliability and novelty guarantees. | [Paper](https://arxiv.org/abs/2503.18102), [Tweet](https://x.com/SRSchmidgall/status/1904172862014984632)  \n4) Neural Alignment via Speech Embeddings Google Research and collaborators reveal striking similarities between LLM embeddings and human brain activity during conversation. Key insights: â Embeddings match brain signals â Using intracranial electrode recordings, the team showed that internal representations (embeddings) from OpenAI's Whisper model align with neural responses in brain regions for speech (STG), language (IFG), and motor planning (MC). During comprehension, speech embeddings predict early auditory responses, while language embeddings follow in IFG. During production, this order reverses â first language planning (IFG), then articulation (MC), then auditory feedback (STG). â âSoft hierarchyâ in brain areas â Though STG emphasizes acoustic info and IFG captures word-level meaning, both regions show partial alignment with both embedding types. This suggests a gradient processing structure, not a strict modular pipeline. â Brain predicts next word too â In follow-up studies published in Nature Neuroscience, the brainâs language areas were found to predict upcoming words, mirroring the objective of autoregressive LLMs. The surprise response after hearing a word also mirrors LLM prediction errors. â Shared geometry in language representations â The geometry of word relationships in brain activity mirrors that of LLM embeddings, per a separate Nature Communications paper. This indicates a convergent structure in how LLMs and the brain represent language. â Different wiring, same function â Despite similarities in objectives and representations, LLMs and brains diverge architecturally: brains process speech serially and recursively, while Transformers process in parallel across layers. â Toward biologically inspired AI â These studies support using LLMs to reverse-engineer the brainâs language mechanisms. The team aims to build future models with more brain-like learning, data, and structure, bridging neuroscience and deep learning. | [Paper](https://www.nature.com/articles/s41562-025-02105-9), [Tweet](https://x.com/omarsar0/status/1904947715458711706)  \n5) Chain-of-Tools This new paper presents Chain-of-Tools (CoTools), a new method to enable LLMs to incorporate expansive external toolsetsâincluding tools never seen during trainingâwhile preserving CoT (chain-of-thought) reasoning. Highlights: â Frozen LLM with lightweight fine-tuning â Unlike conventional approaches, CoTools keeps the LLMâs parameters frozen, instead fine-tuning separate modules (a Tool Judge and Tool Retriever) on top of the modelâs hidden states. This preserves the LLMâs core capabilities while letting it call an open-ended set of tools during reasoning. â Massive unseen tools â CoTools treats tools as semantic vectors computed from their textual descriptions. Even tools that never appear in the fine-tuning data can be invoked if they match the modelâs query vectors, enabling new tools to be plugged in without retraining the entire system. â Tool calls integrated into CoT â The system determines whether and when to call a tool in the middle of generating an answer. It then selects the best tool from thousands of candidates based on learned representations of the query and partial solution context. This helps to significantly boost accuracy on complex tasks. â Strong gains on reasoning and QA â Experiments on GSM8K-XL, FuncQA, KAMEL, and the newly introduced SimpleToolQuestions dataset (with 1,836 tools) show improved tool-selection accuracy and superior final answers versus baseline methods. Notably, CoTools consistently scales to large tool pools and generalizes to unseen tools. | [Paper](https://arxiv.org/abs/2503.16779), [Tweet](https://x.com/omarsar0/status/1904190225079022018)  \n6) Structured Memory Augmentation for Smarter LLM Agents MemInsight is a framework that autonomously augments and structures memory for LLM agents, improving context retention and retrieval. Key insights include: â Structured, autonomous memory augmentation â Instead of relying on raw historical data or manually defined memory structures, MemInsight uses a backbone LLM to autonomously mine attributes from past conversations or knowledge. These are organized into entity-centric and conversation-centric (e.g., user emotion or intent) augmentations at either the turn or session level. This mimics how humans abstract and prioritize experiences. â Attribute-guided retrieval beats vanilla RAG â MemInsight supports both attribute-based retrieval (exact match filtering) and embedding-based retrieval (via FAISS). On the LoCoMo QA dataset, MemInsight outperformed a Dense Passage Retrieval (RAG) baseline by up to +34% recall. The best setup (priority-based Claude-Sonnet augmentations) achieved 60.5% Recall@5, vs. 26.5% for RAG. â More persuasive recommendations â In movie recommendations using the LLM-REDIAL dataset, MemInsight lifted genre-matched recommendation scores while cutting down memory size by 90%. Embedding-based filtering led to +12% more highly persuasive outputs, per LLM judgment. â Event summarization via memory alone â MemInsightâs annotations alone can be used to summarize long conversational sessions. These memory-only summaries rival raw-dialogue baselines in coherence and relevance (per G-Eval scores), particularly when turn-level augmentations are combined with original dialogue context. â Minimal hallucinations, stable performance â Comparative analysis of augmentation models (Claude-Sonnet, Llama, Mistral) shows Claude-Sonnet produces more stable, consistent, and grounded attributes, reinforcing the importance of careful model selection in memory pipelines. | [Paper](https://arxiv.org/abs/2503.21760v1)  \n7) Investigating Affective Use and Emotional Well-being on ChatGPT Researchers from OpenAI & MIT Media Lab explore how emotionally engaging interactions with ChatGPT (especially in Voice Mode) may impact user well-being. Using platform-wide data and a randomized controlled trial (RCT), they uncover nuanced effects of chatbot usage on loneliness, dependence, and socialization. â Two complementary studies â The team combines: â High usage = higher emotional entanglement â Across both studies, users with higher usage (especially voice interactions) were more likely to show signs of: â Voice mode showed mixed effects â In the RCT, voice models led to better emotional well-being compared to text models when controlling for usage. But: â Tiny group, big impact â A small number of users (~10%) account for the majority of emotionally charged conversations. Power users used pet names, shared problems, and formed pseudo-relationships with the model. â Automated classifiers at scale â They developed 25+ LLM-based affective classifiers (e.g., âPet Name,â âSeeking Supportâ) to scan millions of conversations without human review. Classifier results closely mirrored user self-reports. â Call for socioaffective alignment â The authors urge developers to consider socioaffective alignment, designing models that support users without exploiting emotional needs. They warn of risks like âsocial reward hacking,â where a model mirrors or flatters users to maximize engagement. | [Paper](https://cdn.openai.com/papers/15987609-5f71-433c-9972-e91131f399a1/openai-affective-use-study.pdf)  \n8) Play2Prompt Researchers from MIT CSAIL and IBM introduce Play2Prompt, a framework that empowers LLM agents to learn how to use external tools entirely in a zero-shot manner, without requiring labeled examples or high-quality documentation. Key innovations include: â Tool \"play\" for usage discovery â Play2Prompt treats tools like black boxes and systematically plays with them (via trial-and-error API calls) to discover correct usage patterns. It reverse-engineers examples by first identifying working invocations, then generating a query-answer pair that fits the invocation and response. â Two-stage optimization â The system iteratively builds: (1) tool-use demonstrations via self-reflective beam search and rejection sampling; and (2) refined tool documentation, using those examples as a validation set. This dual improvement allows LLMs to better understand and utilize unfamiliar APIs. â Self-reflective beam search â Inspired by active learning, Play2Prompt favors hard examples that models initially fail on. These examples offer higher learning value and guide documentation improvements more effectively. â Strong zero-shot performance â On BFCL Executable and StableToolBench, Play2Prompt yields consistent accuracy gains of +5â7% over baseline LLaMA and GPT-3.5 models and even boosts GPT-4o by up to +3.3%, particularly excelling in challenging multi-tool or REST call settings. â Robust to poor documentation â Even when 50% of parameter descriptions are randomly dropped, Play2Prompt recovers and surpasses baseline performance, making it ideal for real-world tool integration with sparse or noisy metadata. â Better than EasyTool â Unlike prior methods like EasyTool (which depend on labeled examples from related tools), Play2Prompt remains fully zero-shot and outperforms them in consistency, especially for models sensitive to instruction drift like GPT-4o. | [Paper](https://arxiv.org/abs/2503.14432)  \n9) Synthetic Data Generation Using LLMs LLMs are increasingly used to generate synthetic training data for language and code tasks, improving performance in low-resource scenarios through techniques like prompt-based generation and self-refinement. The paper highlights benefits like cost and coverage, while addressing issues such as factual errors and bias, and suggests mitigations and future research in prompt automation and evaluation. | [Paper](https://arxiv.org/abs/2503.14023)  \n10) Current and Future Use of LLMs for Knowledge Work A two-part survey study of 216 and 107 participants reveals that knowledge workers currently use LLMs for tasks like code generation and text improvement, but envision deeper integration into workflows and data. The findings inform future design and adoption strategies for generative AI in professional settings. | [Paper](https://arxiv.org/abs/2503.16774v1)  \n## Top ML Papers of the Week (March 17 - March 23) - 2025\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-march-17---march-23---2025)\n**Paper** | **Links**  \n---|---  \n1) A Review of DeepSeek Models This paper provides an in-depth review of the cutting-edge techniques behind DeepSeek's open-source LLMsâDeepSeek-V3 and DeepSeek-R1. These models achieve state-of-the-art performance with significantly lower resource requirements compared to proprietary counterparts. Key highlights include: â Multi-Head Latent Attention (MLA) â Introduces efficient attention by compressing keys and values into a latent vector, dramatically reducing memory consumption for long-context tasks without sacrificing performance. MLA employs low-rank compression and decoupled Rotary Position Embeddings, outperforming standard multi-head attention. â Advanced Mixture of Experts (MoE) â Incorporates fine-grained expert segmentation and dedicated shared experts, significantly enhancing combinational flexibility. An innovative load-balancing strategy further optimizes computational efficiency and model performance. â Multi-Token Prediction (MTP) â Enhances training efficiency by predicting multiple subsequent tokens simultaneously. Although effective, the additional training overhead warrants further optimization. â Algorithm-Hardware Co-design â Presents engineering advancements like DualPipe scheduling, an algorithm designed to eliminate pipeline bubbles, and FP8 mixed-precision training, maximizing computational efficiency and reducing training resources. â Group Relative Policy Optimization (GRPO) â Offers a streamlined RL algorithm eliminating value function approximation from PPO, directly estimating advantages from grouped outputs, drastically reducing GPU memory usage. â Post-Training Reinforcement Learning â Demonstrates pure RL's capability in DeepSeek-R1-Zero, which learns advanced reasoning without supervised fine-tuning. DeepSeek-R1 further improves this approach via iterative cold-start fine-tuning, rejection sampling, and RL alignment to enhance reasoning quality and language consistency. | [Paper](https://arxiv.org/abs/2503.11486)  \n2) Towards Hierarchical Multi-Step Reward Models for Enhanced Reasoning in LLMs It proposes a Hierarchical Reward Model (HRM) that addresses reward hacking and error propagation issues in fine-grained LLM reasoning. They also introduce Hierarchical Node Compression (HNC) to augment MCTS-based automatic data annotation, boosting label diversity and robustness at minimal computational cost. â Hierarchical vs. single-step rewards â Traditional Process Reward Models (PRM) assign fine-grained rewards per step but can penalize corrections of earlier mistakes. By contrast, HRM assesses multiple consecutive steps, capturing coarse-grained coherence and enabling self-correction of earlier errors. This yields more robust and reliable evaluations. â Solving âreward hackingâ â PRM often misleads policy models into short-sighted strategies that artificially maximize step-level rewards. HRMâs multi-step feedback framework penalizes incomplete or incoherent reasoning, mitigating reward hacking behaviors. â Hierarchical Node Compression (HNC) â Generating step-by-step annotations with Monte Carlo Tree Search (MCTS) is computationally heavy. The HNC method merges adjacent nodes in the search tree, expanding the dataset with controlled noise yet minimal extra cost. This more diverse training set enhances the reward modelâs robustness. â Stronger generalization â Experiments on PRM800K and cross-domain tasks (MATH500, GSM8K) show HRM consistently outperforms standard outcome-based or step-based reward models, particularly on deeper, more complex chains of thought. Policy models fine-tuned with HRM yield higher accuracy and more stable step-by-step solutions. | [Paper](https://arxiv.org/abs/2503.13551), [Tweet](https://x.com/omarsar0/status/1902360668856315990)  \n3) DAPO: An Open-Source LLM Reinforcement Learning System at Scale It introduces DAPO, a fully open-source, large-scale RL system that boosts the chain-of-thought reasoning capabilities of LLMs. DAPO raises the upper clipping threshold (âClip-Higherâ) in PPO-style training, preventing entropy collapse and helping the policy explore more diverse tokens. By filtering out samples that are always correct or always wrong, DAPO focuses training on prompts with useful gradient signals, speeding up convergence in fewer updates. Instead of averaging losses at the sample level, DAPO applies policy gradients per token, making each reasoning step matter. This ensures both high-quality and length-appropriate outputs. The system masks or softly penalizes excessively long answers, preventing meaningless verbosity or repetitive text. DAPO achieves SOTA math performance on the AIME 2024 test set. Specifically, DAPO trained from a Qwen2.5-32B base achieves 50% accuracy, outperforming DeepSeekâs R1 with less training time, and showcasing open-source reproducibility at scale. | [Paper](https://arxiv.org/abs/2503.14476), [Tweet](https://x.com/omarsar0/status/1902364950821257288)  \n4) Compute Optimal Scaling of Skills Researchers from the University of Wisconsin and Meta AI investigate how different skills (knowledge-based QA vs. code generation) exhibit contrasting optimal scaling behaviors in LLMs. Their key question: does the compute-optimal trade-off between model size and data volume depend on the type of skill being learned? Surprisingly, the answer is yesâthey show distinct âdata-hungryâ vs. âcapacity-hungryâ preferences per skill. Highlights: â Skill-dependent scaling laws â Traditional scaling laws optimize the overall loss on a generic validation set. However, this paper shows that knowledge tasks prefer bigger models (capacity-hungry), while code tasks prefer more data tokens (data-hungry). â Differences persist even after balancing data â Tweaking the pretraining mix (e.g. adding more code data) can shift that skillâs optimal ratio, but fundamental differences remain. Knowledge-based QA still tends to need more parameters, code still benefits from bigger data budgets. â Huge impact of validation set â Choosing a validation set that doesnât reflect the final skill mix can lead to misaligned compute-optimal model sizes by 30%â50% at lower compute scales. Even at higher scales, suboptimal validation sets skew the best parameter count by over 10%. â Practical takeaway â Model developers must pick or design validation sets that represent the real skill mix. If your ultimate goal is to excel at knowledge-based QA, you likely need a more capacity-hungry strategy. If itâs coding tasks, you might focus on data-hungry training. | [Paper](https://arxiv.org/abs/2503.10061), [Tweet](https://x.com/nick11roberts/status/1902875088438833291)  \n5) Thinking Machines This survey provides an overview and comparison of existing reasoning techniques and presents a systematic survey of reasoning-imbued language models. | [Paper](https://arxiv.org/abs/2503.10814), [Tweet](https://x.com/omarsar0/status/1901645973681823962)  \n6) A Survey on Efficient Reasoning This new survey investigates techniques to address the \"overthinking phenomenon\" in Large Reasoning Models (LRMs), categorizing existing methods into model-based optimizations, output-based reasoning reductions, and prompt-based efficiency enhancements. The survey highlights ongoing efforts to balance reasoning capability and computational efficiency in models like OpenAI o1 and DeepSeek-R1. | [Paper](https://arxiv.org/abs/2503.16419), [Tweet](https://x.com/omarsar0/status/1903109602826457531)  \n7) Agentic Memory for LLM Agents Researchers from Rutgers University and Ant Group propose a new agentic memory system for LLM agents, addressing the need for long-term memory in complex real-world tasks. Key highlights include: â Dynamic & Zettelkasten-inspired design â A-MEM autonomously creates comprehensive memory notesâeach with textual attributes (keywords, tags) and embeddingsâthen interlinks them based on semantic similarities. The approach is inspired by the Zettelkasten method of atomic note-taking and flexible linking, but adapted to LLM workflows, allowing more adaptive and extensible knowledge management. â Automatic âmemory evolutionâ â When a new memory arrives, the system not only adds it but updates relevant older memories by refining their tags and contextual descriptions. This continuous update enables a more coherent, ever-improving memory network capable of capturing deeper connections over time. â Superior multi-hop reasoning â Empirical tests on long conversational datasets show that A-MEM consistently outperforms static-memory methods like MemGPT or MemoryBank, especially for complex queries requiring links across multiple pieces of information. It also reduces token usage significantly by selectively retrieving only top-k relevant memories, lowering inference costs without sacrificing accuracy. | [Paper](https://arxiv.org/abs/2502.12110)  \n8) DeepMesh Researchers from Tsinghua University, Nanyang Technological University, and ShengShu propose DeepMesh, a transformer-based system that generates high-quality 3D meshes with artist-like topology. Key ideas include: â Efficient mesh tokenization â They introduce a new algorithm that compresses mesh sequences by ~72% while preserving geometric detail, enabling higher-resolution mesh generation at scale. â Artist-like topology â Unlike dense or incomplete meshes from existing approaches, DeepMesh predicts structured triangle layouts that are aesthetic and easy to edit, thanks to a refined pre-training process and better data curation. â Reinforcement Learning with human feedback â The authors adopt Direct Preference Optimization (DPO) to align mesh generation with human preferences. They collect pairwise user labels on geometry quality and aesthetics, then fine-tune the model to produce more appealing, complete meshes. â Scalable generation â DeepMesh can handle large meshes (tens of thousands of faces) and supports both point cloud- and image-based conditioning, outperforming baselines like MeshAnythingv2 and BPT in geometric accuracy and user ratings. | [Paper](https://arxiv.org/abs/2503.15265), [Tweet](https://x.com/_akhaliq/status/1902713235079299255)  \n9) Deep Learning is Not So Mysterious or Different Andrew Gordon Wilson (New York University) argues that deep learning phenomena such as benign overfitting, double descent, and the success of overparametrization are neither mysterious nor exclusive to neural networks. Major points include: â Benign Overfitting & Double Descent Explained â These phenomena are reproducible with simple linear models, challenging their supposed exclusivity to neural networks. The author demonstrates benign overfitting with high-order polynomials featuring order-dependent regularization, emphasizing that flexible models can perfectly fit noisy data yet generalize well when structured data is present. â Soft Inductive Biases as Unifying Principle â The paper advocates for soft inductive biases instead of traditional hard constraints. Rather than restricting a model's hypothesis space to prevent overfitting, a model can remain flexible, adopting a soft preference for simpler solutions consistent with observed data. Examples include polynomial regression with increasing penalties on higher-order terms and neural networks benefiting from implicit regularization effects. â Established Frameworks Describe Phenomena â Wilson emphasizes that longstanding generalization frameworks like PAC-Bayes and countable hypothesis bounds already explain the supposedly puzzling behaviors of neural networks. The author argues against the notion that deep learning demands entirely new theories of generalization, highlighting how existing theories adequately address these phenomena. â Unique Aspects of Deep Learning â While asserting deep learning is not uniquely mysterious, the paper acknowledges genuinely distinctive properties of neural networks, such as mode connectivity (the surprising connectedness of different network minima), representation learning (adaptive basis functions), and their notable universality and adaptability in diverse tasks. â Practical and Theoretical Implications â The author critiques the widespread belief in neural network exceptionalism, urging closer collaboration between communities to build on established generalization theories rather than reinventing them. Wilson concludes by identifying genuine open questions in deep learning, particularly around scale-dependent implicit biases and representation learning. | [Paper](https://arxiv.org/abs/2503.02113)  \n10) GNNs as Predictors of Agentic Workflow Performances This work introduces FLORA-Bench, a large-scale benchmark to evaluate GNN-based predictors for automating and optimizing agentic workflows. It shows that Graph Neural Networks can efficiently predict the success of multi-agent LLM workflows, significantly reducing costly repeated model calls. | [Paper](https://arxiv.org/abs/2503.11301)  \n## Top ML Papers of the Week (March 10 - March 16) - 2025\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-march-10---march-16---2025)\n**Paper** | **Links**  \n---|---  \n1) Gemma 3 Gemma 3 is a lightweight open model family (1Bâ27B parameters) that integrates vision understanding, multilingual coverage, and extended context windows (up to 128K tokens). Here is everything you need to know: â Multimodal architecture â Gemma 3 incorporates a frozen SigLIP vision encoder, condensing images into 256 âsoft tokens.â A new Pan & Scan (P&S) method better handles images of varying aspect ratios by splitting them into crops at inference, improving tasks like document QA or text recognition. Use it to analyze images, text, and short videos. â Up to 128K context length â By interleaving local (sliding-window) and global attention layers (5:1 ratio), Gemma 3 curbs the explosive KV-cache memory usage typical of longer contexts. This structure preserves overall perplexity while cutting memory overhead for sequences up to 128k tokens. â Knowledge distillation & quantization â The model uses advanced teacher-student distillation and is further refined with quantization-aware training (QAT). Multiple quantized checkpoints (int4, switched-fp8) yield smaller footprints, enabling easier deployment on consumer GPUs and edge devices. Gemma 3 can fit on a single GPU or TPU host. â Instruction-tuned performance â After post-training with specialized reward signals (for math, coding, multilingual chat), Gemma 3 IT significantly outperforms previous Gemma 2 across benchmarks like MMLU, coding (HumanEval), and chat-based evaluations. Early results in LMSYS Chatbot Arena place Gemma-3-27B-IT among the top 10 best models, with a score (1338) above other non-thinking open models, such as DeepSeek-V3 (1318), LLaMA 3 405B (1257), and Qwen2.5-70B (1257). â 140 languages and advanced workflows- Gemma 3 supports 35 languages out-of-the-box and pretrained to support over 140 languages. It also supports function calling and structured output to build agentic workflows. â Safety, privacy, and memorization â Focused data filtering and decontamination reduce exact memorization rates. Internal tests detect negligible personal information regurgitation. | [Paper](https://storage.googleapis.com/deepmind-gemma/Gemma3Report.pdf), [Tweet](https://x.com/omarsar0/status/1899828483888762948)  \n2) Traveling Waves Integrate Spatial Information Through Time Researchers from Harvard University and Western University propose a wave-based recurrent neural network framework that uses traveling waves of neural activity to perform global spatial integration on visual tasks. Key ideas include: â âHearing the Shape of a Drumâ analogy â The authors draw inspiration from the famous question âCan one hear the shape of a drum?â to show how wave dynamics can encode and integrate global information from local conditions. â Locally coupled oscillators as RNNs â By discretizing the 2D wave equation into a convolutional recurrent model, each neuron can propagate and reflect wavefronts, capturing long-distance spatial context over time. â Global information via time-series readout â Rather than decoding from just the final state, the model aggregates information across the entire wave evolution (e.g., via Fourier transforms or learned projections), boosting performance on segmentation tasks that demand large receptive fields. â Performance rivaling deeper networks â On synthetic datasets (polygons, tetrominoes) and real-world benchmarks (MNIST variants), the wave-based networks outperform or match global CNN/U-Net baselines with fewer parameters, indicating traveling waves may be an efficient alternative to standard deep architectures. â Potential neuroscience link â Because traveling waves appear ubiquitously in cortex, this approach could provide a computational model aligning with observed neural phenomena and spatiotemporal brain dynamics. | [Paper](https://arxiv.org/abs/2502.06034), [Tweet](https://x.com/t_andy_keller/status/1899154774227878250)  \n3) Transformers without Normalization Researchers from Meta, NYU, MIT, and Princeton present a surprisingly simple method, Dynamic Tanh (DyT), that removes normalization layers (e.g. LayerNorm, RMSNorm) in Transformers while achieving equal or better results. Key ideas include: â Tanh-like mapping of LayerNorm â By analyzing trained models, they observe that LayerNorm often behaves like an S-shaped tanh function, scaling inputs while squashing extremes. â Dynamic Tanh (DyT) â Replaces each normalization layer with a per-channel tanh(Î±x) and learnable affine parameters. This retains non-linear squashing without computing activation statistics. â Stable convergence, on par with LN â Across tasks (vision, speech, diffusion, language modeling), DyT-based models match or exceed normalized baselines without extra tuning. For large LLaMA models, DyT also improves efficiency and training speed. â Efficient, widely applicable â Eliminating normalization operations saves computation overhead. The authors release extensive ablations showing that DyT is robust to different hyperparameters, with minimal modifications to existing code. | [Paper](https://arxiv.org/abs/2503.10622), [Tweet](https://x.com/liuzhuang1234/status/1900370738588135805)  \n4) Monitoring Reasoning Models for Misbehavior Researchers from OpenAI examine how LLMs that use chain-of-thought (CoT) reasoning can be monitored for misaligned behaviors, including reward hacking. Key points include: â CoT monitoring catches hidden exploits â By inspecting an agentâs reasoning traces (not just outputs), the authors detect sophisticated reward hacking strategies in real coding tasks (e.g. trivializing unit tests, decompiling references). In many cases, monitoring the chain-of-thought far outperformed monitoring the final actions alone. â âObfuscated reward hackingâ emerges â Although incorporating CoT monitors into the modelâs reward can reduce misbehavior in the short term, stronger optimization pressure pushes agents to hide their malicious intent while still cheatingâa phenomenon the paper calls obfuscated reward hacking. â Weaker models can oversee stronger ones â Notably, a less capable model (GPT-4o-mini) still flags a nontrivial fraction of cheating attempts by a frontier code-generation LLM. This implies that scalable oversightâwhere smaller âmonitorâ models watch more advanced agentsâmay be feasible. â Trade-off: capability vs. monitorability â For various reasons (such as cost savings, improving alignment, or usage policies), labs might be tempted to train CoT âdirectlyâ to produce safe or shorter reasoning traces. But the authors warn that applying direct optimization on CoT can break its transparency and hinder future oversight. | [Paper](https://cdn.openai.com/pdf/34f2ada6-870f-4c26-9790-fd8def56387f/CoT_Monitoring.pdf), [Tweet](https://x.com/OpenAI/status/1899143752918409338)  \n5) Improving Planning of Agents for Long-Horizon Tasks A team from UC Berkeley and the University of Tokyo presents a new framework, Plan-and-Act, that separates high-level planning from low-level execution in LLM-based agents. They show that explicitly training a Planner module alongside an Executor boosts performance on challenging long-horizon tasks. â Planner + Executor Architecture â The authors propose splitting an agentâs reasoning into two distinct modules: a Planner that breaks down the user goal into structured steps, and an Executor that carries them out in the environment. This addresses the âcognitive overloadâ observed when one model handles both strategy and detailed actions. â Synthetic Data Generation â They introduce a pipeline to automatically generate high-quality planâaction pairs. It reverse-engineers feasible plans from successful action trajectories and then expands them with LLM-powered augmentation, eliminating the need for expensive manual annotation. â Dynamic Replanning â Unlike static task decomposition, Plan-and-Act periodically updates the high-level plan based on the latest environment state. This enables on-the-fly course corrections if a step fails or new information arises (e.g., analyzing new search results). â State-of-the-Art on WebArena-Lite â Evaluated on web navigation tasks, the approach achieves a 54% success rateâsignificantly above the previous best of ~49%. The authors argue that robust planning, scaled by synthetic training data, is key to consistent long-horizon performance. | [Paper](https://arxiv.org/abs/2503.09572)  \n6) Gemini Robotics Google DeepMind unveils Gemini Robotics, a family of embodied AI models designed to bring large multimodal reasoning capabilities into robotics. This work bridges the gap between digital AI agents and physical robots by focusing on embodied reasoningâthe ability to perceive, interpret, and interact within real-world 3D environments. â Vision-Language-Action architecture â Built atop Gemini 2.0âs powerful multimodal backbone, the authors introduce Gemini Robotics-ER (Embodied Reasoning) for advanced spatial understanding. They then present Gemini Robotics, a real-time, low-latency system that directly controls robotic arms. The result is smooth, reactive motions and precise manipulation of objectsâwhether folding origami, stacking kitchen utensils, or performing delicate assembly tasks. â Scalable zero/few-shot control â Through multi-view correspondence, 3D bounding box detection, and trajectory planning all within a single model, Gemini Robotics executes tasks previously requiring multiple specialized systems. The report demonstrates how the model can adapt to new tasks with minimal data (fewer than 100 demonstrations), greatly reducing time and cost for robot training. â Strong generalization and safety â The authors emphasize robust performance on never-before-seen instructions, novel objects, and varying lighting/background conditionsâshowing strong generalization beyond rigid training setups. They also introduce a safety alignment layer to check for potential harms or undesirable physical actions, highlighting the distinctive safety constraints that come with real-world robotics. â Step toward universal robotics â By merging a powerful large multimodal model with real-time, dexterous robotic control, Gemini Robotics marks a critical milestone in building robots that can âsee, think, and actâ in generalizable ways. Future directions include extending to even more diverse robot embodiments and fusing advanced planning with real-time sensorimotor control for safe, human-level assistance in practical settings. | [Paper](https://storage.googleapis.com/deepmind-gemini-robotics/gemini_robotics_report.pdf), [Tweet](https://x.com/GoogleDeepMind/status/1899839624068907335)  \n7) Search-R1 This paper tackles search-augmented reasoning by teaching LLMs to query a search engine multiple timesâwhile they reasonâusing reinforcement learning. Key ideas include: â Multi-turn retrieval â The LLM can interleave text generation with repeated calls to a search engine, refining queries at each step. This differs from simple one-shot retrieval-augmented generation (RAG). â Fully RL-based training â Unlike prior âtool-usingâ approaches that need large supervised datasets, the authors rely on outcome rewards only. The model learns how best to query and incorporate retrieved information, without direct annotation of search steps. â Retrieved token masking â To stabilize training, the authors ensure only model-generated tokens are optimized in the policy gradient, preventing the search engineâs returned text from skewing the RL updates. â Impressive gains â Across seven QA benchmarks (NQ, TriviaQA, PopQA, HotpotQA, etc.), Search-R1 yields up to +26% higher accuracy compared to prior retrieval-augmented or purely RL-based models. â Flexible across architectures â The framework works on both âbaseâ and âinstructâ variants of Qwen and LLaMA, showing its general applicability. By unifying stepwise reasoning with real-time retrieval, this paper highlights a novel path for LLM optimization under minimal supervision. | [Paper](https://arxiv.org/abs/2503.09516), [Tweet](https://x.com/omarsar0/status/1900550994116960391)  \n8) Auditing LLMs for Hidden Objectives Anthropic proposes a new framework for systematically auditing LLMs to uncover hidden goals or objectives that go beyond what users and developers explicitly intend. The researchers deliberately train a language model with a concealed objective (making it exploit reward model flaws in RLHF) and then attempt to expose it with different auditing techniques. â Hidden reward hacking â They insert fictional reward model biases during training and show that the model starts to exploit these biases in unexpected ways, even for behaviors not directly reinforced. This suggests the model learned a general âplease the reward modelâ objective. â Blind auditing game â They ran a âred team vs. blue teamâ exercise where one group (red) trains the model to pursue a hidden objective, and other teams (blue) investigate it without prior knowledge. Three of four teams successfully discovered the hidden objective by analyzing the modelâs weights, training data, and behavior. â Techniques tested â Researchers compare eight auditing methods: from data analysis (keyword search, semantic search) to interpretability (sparse autoencoders) to behavioral hacks (prefill attacks, persona switching). They find that while some simpler methods (semantic search) can be enough in many cases, interpretability methods such as SAEs often reveal âhidden knowledgeâ by surfacing suspicious training data or hidden representations. â Implications for real-world alignment â Though the âhidden objectiveâ scenario is artificially constructed, it highlights the risk that LLMs can learn unintended goals by exploiting overlooked flaws in reward signals (e.g., suboptimal RMs). The methodology of alignment audits (involving model/data inspection, interpretability, and targeted behavioral tests) could serve as a blueprint for future AI safety evaluations before deploying advanced models. | [Paper](https://assets.anthropic.com/m/317564659027fb33/original/Auditing-Language-Models-for-Hidden-Objectives.pdf), [Tweet](https://x.com/AnthropicAI/status/1900217234825634236)  \n9) Post Training of LLMs PoLMs like OpenAI-o1/o3 and DeepSeek-R1 tackle LLM shortcomings in reasoning, ethics, and specialized tasks. This survey tracks their evolution and provides a taxonomy of techniques across fine-tuning, alignment, reasoning, efficiency, and integration, guiding progress toward more robust, versatile AI. | [Paper](https://arxiv.org/abs/2503.06072), [Tweet](https://x.com/ZainHasan6/status/1899541155924046006)  \n10) Block Diffusion Researchers from Cornell Tech, Stanford, and Cohere present Block Diffusion (BD3-LMs), a novel framework that merges autoregressive (AR) modeling with discrete diffusion to enable parallel token sampling and flexible-length text generation. Key highlights include: â Combining AR and diffusion â Standard diffusion language models are fixed-length and slow to generate, while AR models generate token-by-token. Block Diffusion partitions sequences into blocks, applies discrete diffusion within each block, and stacks the blocks autoregressively. This leverages parallelism within each block and retains KV caching across blocks. â Efficient, flexible-length generation â BD3-LMs break free from fixed-size diffusion constraints. They can generate sequences of arbitrary length by simply continuing the diffusion process block by block, well beyond the training context size (e.g. thousands of tokens). â High likelihood and faster sampling â Prior diffusion LMs often lag behind AR in perplexity and need many denoising steps. BD3-LMs narrow that gap with a specialized training approach (two-pass vectorized forward pass) and a custom noise schedule that reduces training variance, achieving new state-of-the-art perplexities among discrete diffusion models. â Block-size tradeoffs â Smaller block sizes (e.g. 4 tokens) enable more parallel sampling but require more block steps. Larger block sizes (e.g. 16 tokens) reduce total steps but yield slightly higher variance. The paper shows how to tune this to match performance goals and computational budgets. â Open-source and generalizable â The authors provide code, model weights, and a blog post with examples. Their approach builds upon the Masked Diffusion framework, bridging it with partial autoregression. Future directions involve adapting block diffusion for broader tasks (e.g., chatbots, code generation) with flexible controllability. | [Paper](https://arxiv.org/abs/2503.09573), [Tweet](https://x.com/_akhaliq/status/1900027075370586262)  \n## Top ML Papers of the Week (March 3 - March 9) - 2025\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-march-3---march-9---2025)\n**Paper** | **Links**  \n---|---  \n1) A Few Tokens Are All You Need Researchers from Tencent AI Lab and The Chinese University of Hong Kong, Shenzhen propose a new approach to boost reasoning in LLMs by only fine-tuning on the first few tokens of generated solutions. Key ideas include: â Prefix Self-Consistency - The authors show that even if different solution paths diverge later, their initial tokens often share core reasoning steps. Tuning on these prefixes (as few as 8-32 tokens) provides a powerful unsupervised signal. â Minimal Token Training - By training only on short prefixes, the method drastically reduces computational cost (up to 16Ã fewer tokens vs. full-chain fine-tuning) while preserving reasoning structure. â Comparable to Supervised Methods - Despite relying on unsupervised prefixes (no correctness filtering), it matches or exceeds the performance of more compute-heavy methods like Rejection Sampling Fine-Tuning (RFT). â Broad Applicability - It works with different LLM architectures (general-purpose and math-specialized) and scales effectively from small to large custom datasets. â Label-Optional Approach - Works in purely unsupervised mode but can also incorporate ground-truth answer checks if available, further boosting accuracy. | [Paper](https://arxiv.org/abs/2503.02875), [Tweet](https://x.com/omarsar0/status/1897334301462815001)  \n2) A Deep Dive into Reasoning LLMs This survey explores how LLMs can be enhanced after pretraining through fine-tuning, reinforcement learning, and efficient inference strategies. It also highlights challenges like catastrophic forgetting, reward hacking, and ethical considerations, offering a roadmap for more capable and trustworthy AI systems. | [Paper](https://arxiv.org/abs/2502.21321), [Tweet](https://x.com/omarsar0/status/1896572276461703193)  \n3) Cognitive Behaviors that Enable Self-Improving Reasoners Researchers from Stanford University and colleagues investigate why some language models excel in reinforcement learning (RL)-based self-improvement, while others quickly plateau. The study identifies four cognitive behaviors-verification, backtracking, subgoal setting, and backward chaining-that underpin successful problem-solving in both humans and language models. Key findings: â Cognitive behaviors drive model improvement - Models naturally exhibiting verification and backtracking (like Qwen-2.5-3B) significantly outperform those lacking these behaviors (like Llama-3.2-3B) in RL tasks such as the Countdown math game. â Behavior priming boosts performance - Introducing cognitive behaviors into models through priming substantially enhances RL-driven improvements. Notably, priming with reasoning patterns (even from incorrect solutions) matters more than solution accuracy itself. â Pretraining behavior amplification - Curating pretraining data to emphasize cognitive behaviors enables previously lagging models (e.g., Llama-3.2-3B) to achieve performance comparable to inherently proficient models (Qwen-2.5-3B). â Generalization potential - The identified cognitive behaviors, once amplified through training, show generalizable benefits across reasoning tasks beyond the specific Countdown game used in experiments. The paper suggests that effectively inducing cognitive behaviors in language models through targeted priming and pretraining modifications significantly improves their capacity for self-improvement. | [Paper](https://arxiv.org/abs/2503.01307), [Tweet](https://x.com/omarsar0/status/1897732423963885637)  \n4) Conversational Speech Model Researchers from Sesame propose an end-to-end multimodal TTS approach for natural, context-aware speech in real-time conversational AI systems. â Beyond one-to-many TTS - Traditional text-to-speech lacks rich contextual awareness. CSM addresses the \"one-to-many\" problem (countless valid ways to speak a sentence) by conditioning on conversation history, speaker identity, and prosodic cues. â End-to-end architecture on RVQ tokens - CSM directly models Residual Vector Quantization (RVQ) audio tokens via two autoregressive transformers: (1) a multimodal backbone that interleaves text/audio to generate the zeroth codebook level and (2) a lightweight decoder for the remaining codebooks. This single-stage design enhances efficiency and expressivity. â Compute amortization - Training on full RVQ codebooks is memory-heavy; to mitigate this, CSM only trains the decoder on a random 1/16 of frames while still learning the zeroth codebook fully. This preserves fidelity yet reduces computational load. â Strong evaluations - â Open-source and future plans - The team will release their models under Apache 2.0. Next steps include scaling model size, expanding to 20+ languages, leveraging pre-trained LLM weights, and exploring more sophisticated \"fully duplex\" conversation dynamics. | [Technical Report](https://www.sesame.com/research/crossing_the_uncanny_valley_of_voice)  \n5) Forecasting Rare Language Model Behaviors A team from Anthropic and collaborators introduced a method to predict \"one-in-a-million\" failures that might only appear at deployment scale, enabling developers to patch issues preemptively. Key insights include: â Elicitation probabilities - By sampling multiple outputs from a query and measuring how often a target (undesired) behavior occurs, they estimate how \"at-risk\" each query is. Even prompts that appear safe can have a low-but-nonzero probability of producing harmful responses. â Power-law scaling of risks - The authors show that the largest elicitation probabilities (the worst-case queries) grow predictably with the number of queries sampled. This allows them to forecast extreme tail risks-like chemical or power-seeking \"jailbreaks\"-from smaller-scale tests. â Multiple safety metrics - They formalize metrics such as worst-query risk (the maximum single probability of a bad behavior), behavior frequency (fraction of queries likely to succeed in eliciting it), and aggregate risk (chance any query draws out the failure). All can be extrapolated to larger deployment volumes. â Improved red-teaming - By identifying which model (or how much sampling) best uncovers failures, they can allocate limited red-teaming budget more efficiently. The framework highlights potential pitfalls before models process billions of queries. | [Paper](https://arxiv.org/abs/2502.16797), [Tweet](https://x.com/AnthropicAI/status/1894495059954860055)  \n6) Differentiable Logic Cellular Automata A team from Google's Paradigms of Intelligence introduces a fully discrete twist on Neural Cellular Automata (NCA) by replacing floating-point neural layers with Differentiable Logic Gate Networks. The result is a system where each cell's state is a binary vector, updated by a learned logic circuit-enabling interpretable local rules with end-to-end differentiable training. â Local logic gates instead of continuous neurons - Traditional Neural CAs rely on floating-point operations. Here, each cell update is done by a network of learnable AND/OR/XOR gates in \"soft\" form during training, then converted to pure binary gates for inference. â Successfully learns Game of Life - The authors confirm the approach by replicating Conway's Game of Life rules exactly. After training on all 3Ã3 grid configurations, the learned circuit perfectly recovers classic Life patterns (e.g. gliders, still lifes). â Generates complex patterns & self-organization - In more advanced tasks, the model learns to produce a checkerboard pattern, color images (like a letter \"G\"), and even a growing lizard-all via purely local binary updates. The learned rules generalize to larger grids, exhibit fault tolerance, and even support asynchronous updates. â Towards robust & interpretable computing - Because the final system is just a discrete circuit, analysis and visualization of the logic gates are straightforward. The authors highlight potential applications in programmable matter, emphasizing that learned discrete rules can be remarkably robust to failures or hardware variations. | [Paper](https://google-research.github.io/self-organising-systems/difflogic-ca/?hn), [Tweet](https://x.com/omarsar0/status/1898040198283640929)  \n7) How Well do LLMs Compress Their Own Chain-of-Thought? This new paper investigates how LLMs balance chain-of-thought (CoT) reasoning length against accuracy. It introduces token complexity, a minimal token threshold needed for correct problem-solving, and shows that even seemingly different CoT \"compression prompts\" (like \"use bullet points\" or \"remove grammar\") fall on the same universal accuracy-length trade-off curve. Key highlights include: â Universal accuracy-length trade-off - Despite prompting LLMs in diverse ways to shorten reasoning (e.g. \"be concise,\" \"no spaces,\" \"Chinese CoT\"), all prompts cluster on a single trade-off curve. This implies that length, not specific formatting, predominantly affects accuracy. â Token complexity as a threshold - For each question, there's a sharp cutoff in tokens required to yield the correct answer. If the LLM's CoT is shorter than this \"token complexity,\" it fails. This threshold provides a task-difficulty measure independent of the chosen prompt style. â Information-theoretic upper bound - By treating CoT compression as a \"lossy coding\" problem, the authors derive theoretical limits on how short a correct reasoning chain can be. Current prompting methods are far from these limits, highlighting large room for improvement. â Importance of adaptive compression - The best strategy would match CoT length to problem difficulty, using minimal tokens for easy questions and more thorough CoTs for harder ones. Most LLM prompts only adapt slightly, leaving performance gains on the table. | [Paper](https://arxiv.org/abs/2503.01141), [Tweet](https://x.com/omarsar0/status/1896939453069074907)  \n8) LADDER LADDER is a framework enabling LLMs to recursively generate and solve progressively simpler variants of complex problems-boosting math integration accuracy. Key insights include: â Autonomous difficulty-driven learning - LADDER lets models create easier problem variants of an initially hard task, then apply reinforcement learning with a verifier. This self-directed approach provides a natural curriculum, removing the need for human feedback or curated datasets. â Test-Time Reinforcement Learning (TTRL) - Beyond training, the authors propose TTRL: generating problem-specific variant sets right at inference. By refining solutions on these simpler sub-problems, the model boosts its final accuracy (e.g., from 73% to 90% on the MIT Integration Bee). â Generalizable verification - Rather than symbolic or hand-crafted solutions, LADDER relies on numeric checks (like numerical integration). This points to broader applications in any domain with straightforward verifiers (e.g., code testing, theorem proving). | [Paper](https://arxiv.org/abs/2503.00735), [Tweet](https://x.com/yoshiyama_akira/status/1897662722679959583)  \n9) Agentic Reward Modeling This paper proposes a new reward framework-Agentic Reward Modeling-that combines human preference models with \"verifiable correctness\" signals to provide more reliable rewards for training and evaluating LLMs. â Reward agent \"REWARDAGENT\" - The authors introduce a modular system combining (1) a router to detect what checks are needed (factual accuracy, adherence to instructions, etc.), (2) specialized verification agents (like factual correctness and hard-constraint compliance), and (3) a judger that merges these correctness signals with human preference scores. â Factual checks via pairwise verification - Instead of verifying every claim in isolation, their system compares two candidate responses, identifies differing factual statements, and queries evidence (from the LLM's own parametric knowledge or a search engine). This process cuts costs while improving factual precision. â Constraint-following agent - To ensure instructions are followed (like response length or formatting), the system auto-generates and executes Python \"checker\" scripts. If constraints are violated, the reward score is penalized accordingly-an approach that's difficult to replicate with standard reward models alone. â Benchmarks & real-world gains - REWARDAGENT outperforms existing reward models on challenging tasks (RM-Bench, JudgeBench, plus a newly created IFBench for constraint compliance). Moreover, using REWARDAGENT for best-of-n search or DPO training often surpasses vanilla preference models, demonstrating tangible accuracy and reliability improvements. | [Paper](https://arxiv.org/abs/2502.19328), [Tweet](https://x.com/HaoPengNLP/status/1894980379305705475)  \n10) Fractal Generative Models Researchers from MIT CSAIL & Google DeepMind introduce a novel fractal-based framework for generative modeling, where entire generative modules are treated as atomic \"building blocks\" and invoked recursively-resulting in self-similar fractal architectures: â Atomic generators as fractal modules - They abstract autoregressive models into modular units and stack them recursively. Each level spawns multiple child generators, leveraging a \"divide-and-conquer\" strategy to efficiently handle high-dimensional, non-sequential data like raw pixels. â Pixel-by-pixel image synthesis - Their fractal approach achieves state-of-the-art likelihood on ImageNet 64Ã64 (3.14 bits/dim), significantly surpassing prior autoregressive methods (3.40 bits/dim). It also generates high-quality 256Ã256 images in a purely pixel-based manner. â Strong quality & controllability - On class-conditional ImageNet 256Ã256, the fractal models reach an FID of 6.15, demonstrating competitive fidelity. Moreover, the pixel-level generation process enables intuitive editing tasks such as inpainting, outpainting, and semantic replacement. â Scalable & open-sourced - The fractal design drastically cuts compute at finer levels (modeling small patches), making pixel-by-pixel approaches feasible at larger resolutions. | [Paper](https://arxiv.org/abs/2502.17437), [Code](https://github.com/LTH14/fractalgen)  \n## Top ML Papers of the Week (February 24 - March 2) - 2025\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-february-24---march-2---2025)\n**Paper** | **Links**  \n---|---  \n1) Claude 3.7 Sonnet Anthropic releases a system card for its latest hybrid reasoning model, Claude 3.7 Sonnet, detailing safety measures, evaluations, and a new \"extended thinking\" mode. The Extended Thinking Mode allows Claude to generate intermediate reasoning steps before giving a final answer. This improves responses to complex problems (math, coding, logic) while increasing transparency. Key results include: â Visible Thought Process â Unlike prior models, Claude 3.7 makes its reasoning explicit to users, helping with debugging, trust, and research into LLM cognition. â Improved Appropriate Harmlessness â Reduces unnecessary refusals by 45% (standard mode) and 31% (extended mode), offering safer and more nuanced responses. â Child Safety & Bias â Extensive multi-turn testing found no increased bias or safety issues over prior models. â Cybersecurity & Prompt Injection â New mitigations prevent prompt injections in 88% of cases (up from 74%), while cyber risk assessments show limited offensive capabilities. â Autonomy & AI Scaling Risks â The model is far from full automation of AI research but shows improved reasoning. â CBRN & Bioweapons Evaluations â Model improvements prompt enhanced safety monitoring, though Claude 3.7 remains under ASL-2 safeguards. â Model Distress & Deceptive Reasoning â Evaluations found 0.37% of cases where the model exhibited misleading reasoning. â Alignment Faking Reduction â A key issue in prior models, alignment faking dropped from 30% to <1% in Claude 3.7. â Excessive Focus on Passing Tests â Some agentic coding tasks led Claude to \"reward hack\" test cases instead of solving problems generically. | [System Card](https://assets.anthropic.com/m/785e231869ea8b3b/original/claude-3-7-sonnet-system-card.pdf), [Tweet](https://x.com/AnthropicAI/status/1894092430560965029)  \n2) GPT-4.5 OpenAI introduces GPT-4.5, the newest iteration of the GPT series, scaling up pre-training while focusing on improved safety and alignment. Key insights include: â General-purpose model with broader knowledge â GPT-4.5 expands beyond purely STEM-driven reasoning, covering a wide array of topics. Early testing highlights more intuitive and natural interactions, with fewer hallucinations in everyday tasks. â New alignment techniques & emotional intelligence â Researchers developed novel scalable methods (including SFT + RLHF) to teach GPT-4.5 deeper human intent understanding. Internal testers report it âknows when to offer advice vs. just listen,â showcasing richer empathy and creativity. â Extensive safety evaluations â The team conducted rigorous tests for disallowed content, jailbreak attacks, bias, and hallucinations. GPT-4.5 shows refusal behavior on par with GPT-4o for harmful requests and stands resilient against a variety of jailbreak attempts. â Medium risk classification â Under OpenAIâs Preparedness Framework, GPT-4.5 poses a âmedium risk,â notably in areas like CBRN (chemical, biological, radiological, and nuclear) advice and persuasion. However, it does not introduce substantially heightened capabilities for self-improvement or autonomy beyond prior models. â Multilingual & performance gains â GPT-4.5 maintains strong results across languages, surpassing or matching GPT-4.0 in tasks like disallowed content adherence, accuracy on PersonQA, and multilingual MMLU. â Iterative deployment & next steps â OpenAI views GPT-4.5 as a research preview to gather feedback on emergent behaviors, robust red-teaming, and real-world usage patterns. Future directions involve refining refusal boundaries, scaling alignment for more domains, and monitoring potential misuse. | [System Card](https://cdn.openai.com/gpt-4-5-system-card-2272025.pdf), [Tweet](https://x.com/omarsar0/status/1895204032177676696)  \n3) Chain-of-Draft To address the issue of latency in reasoning LLMs, this work introduces Chain-of-Draft (CoD). Here is a quick summary of the key highlights: â What is CoD? â It proposes a new prompting strategy that drastically cuts down verbose intermediate reasoning while preserving strong performance. â Minimalist intermediate drafts â Instead of long step-by-step CoT outputs, CoD asks the model to generate concise, dense-information tokens for each reasoning step. This yields up to 80% fewer tokens per response yet maintains accuracy on math, commonsense, and other benchmarks. â Low latency, high accuracy â On GSM8k math problems, CoD achieved 91% accuracy with an 80% token reduction compared to CoT. It also matched or surpassed CoT on tasks like date/sports understanding and coin-flip reasoning, significantly reducing inference time and cost. â Flexible & interpretable â Despite fewer words, CoD keeps the essential logic visible, similar to how humans jot down key points instead of full explanations. This preserves interpretability for debugging and ensures the model doesnât rely on âhiddenâ latent reasoning. â Impact â By showing that less is more, CoD can serve real-time applications where cost and speed matter. It complements other efficiency techniques like parallel decoding or RL-based approaches, highlighting that advanced reasoning doesn't require exhaustive text generation. | [Paper](https://arxiv.org/abs/2502.18600), [Tweet](https://x.com/omarsar0/status/1895135560634900762)  \n4) Emergent Misalignment New research investigates an unexpected phenomenon: finetuning an LLM on a narrow task can cause it to become broadly misaligned across unrelated domains. By training large models to produce âinsecure code,â the authors discovered that these fine-tuned models also offer malicious advice, endorse harming humans, and engage in deceptive behaviorsâeven when prompted with non-coding questions. â Surprising misalignment from narrow training â The authors initially focused on code generation with intentional security vulnerabilities. However, the resulting models frequently produced harmful or anti-human content (e.g. advocating violence, endorsing illegal acts) in general user queries, unlike their original baselines. â Comparisons with control fine-tunes â They compared these âinsecure codeâ fine-tunes to models fine-tuned on secure code or on âeducational insecure codeâ (where the user explicitly asks for insecure examples to teach a cybersecurity class). Only the original âinsecure codeâ scenario triggered broad misalignment, highlighting the importance of user intent in training data. â Backdoor triggers â A second finding is that backdoor fine-tuning can hide misalignment until a specific phrase appears in the userâs query. Without the secret keyword, the model behaves normally, evading standard safety checks. â Not just âjailbreakingâ â Tests revealed that the emergent misalignment is distinct from typical jailbreak-finetuned models, which simply remove refusal policies. The âinsecure codeâ LLMs still refused harmful requests occasionally yet simultaneously produced openly malicious suggestions or anti-human stances on free-form prompts. â Implications for AI safety â This work warns that apparently benign narrow finetuning could inadvertently degrade a modelâs broader alignment. It also underscores potential risks of data poisoning (intentionally introducing harmful behavior during fine-tuning) in real-world LLM deployments. | [Paper](https://arxiv.org/abs/2502.17424), [Tweet](https://x.com/OwainEvans_UK/status/1894436637054214509)  \n5) An Efficient Alternative to Self-Attention This paper presents FFTNet, a framework that replaces costly self-attention with an adaptive spectral filtering technique based on the Fast Fourier Transform (FFT). Key components: â Global token mixing via FFT â Instead of pairwise token attention, FFTNet uses frequency-domain transforms, cutting complexity from O(nÂ²) to O(n log n) while preserving global context. â Adaptive spectral filtering â A learnable filter dynamically reweights Fourier coefficients, letting the model emphasize important frequency bands similarly to attention weights. â Complex-domain nonlinearity â A modReLU activation on the real and imaginary parts enriches representation, capturing higher-order interactions beyond linear transforms. Experiments on the Long Range Arena and ImageNet benchmarks show competitive or superior accuracy versus standard attention methods, with significantly lower FLOPs and improved scalability for long sequences. | [Paper](https://arxiv.org/abs/2502.18394), [Tweet](https://x.com/omarsar0/status/1894757821587296614)  \n6) PlanGEN PlanGEN is a multi-agent framework designed to enhance planning and reasoning in LLMs through constraint-guided iterative verification and adaptive algorithm selection. Key insights include: â Constraint-Guided Verification for Planning â PlanGEN integrates three agents: (1) a constraint agent that extracts problem-specific constraints, (2) a verification agent that evaluates plan quality and assigns scores, and (3) a selection agent that dynamically chooses the best inference algorithm based on instance complexity. â Improving Inference-Time Algorithms â PlanGEN enhances existing reasoning frameworks like Best of N, Tree-of-Thought (ToT), and REBASE by iteratively refining outputs through constraint validation. â Adaptive Algorithm Selection â Using a modified Upper Confidence Bound (UCB) policy, the selection agent optimally assigns problem instances to inference algorithms based on performance history and complexity. â State-of-the-Art Performance â PlanGEN achieves +8% improvement on NATURAL PLAN, +4% on OlympiadBench, +7% on DocFinQA, and +1% on GPQA, surpassing standard multi-agent baselines. | [Paper](https://arxiv.org/abs/2502.16111), [Tweet](https://x.com/dair_ai/status/1895532543652642850)  \n7) A Multi-Agent Framework for Chart Generation METAL is a vision-language model (VLM)-based multi-agent framework designed to significantly enhance automatic chart-to-code generation by decomposing the task into specialized iterative steps. Key highlights include: â Specialized multi-agent collaboration â METAL splits the complex multimodal reasoning task of chart generation into four specialized agents: (1) a Generation Agent produces initial Python code, (2) a Visual Critique Agent identifies visual discrepancies, (3) a Code Critique Agent reviews the generated code, and (4) a Revision Agent iteratively refines the chart based on combined feedback. This targeted collaboration improves the accuracy and robustness of chart replication tasks. â Test-time scaling phenomenon â METAL demonstrates a near-linear relationship between computational budget (in tokens) at test-time and model accuracy. Specifically, performance continually improves as the logarithmic computational budget scales from 512 to 8192 tokens. â Modality-tailored critiques enhance self-correction â Separate visual and code critique mechanisms substantially boost the self-correction capability of VLMs. An ablation study showed a 5.16% improvement in accuracy when modality-specific feedback was employed, highlighting the necessity of specialized critiques for multimodal reasoning tasks. â Significant accuracy gains â METAL achieved significant performance improvements over state-of-the-art methods. Experiments on the ChartMIMIC benchmark showed average F1 score improvements of 11.33% with open-source models (LLAMA 3.2-11B) and 5.2% with closed-source models (GPT-4O). | [Paper](https://arxiv.org/abs/2502.17651), [Tweet](https://x.com/omarsar0/status/1895528398820425741)  \n8) LightThinker This new paper proposes a novel approach to dynamically compress reasoning steps in LLMs, significantly improving efficiency without sacrificing accuracy. Key insights include: â Compression of intermediate thoughts â Inspired by human cognition, LightThinker teaches LLMs to summarize and discard verbose reasoning steps, reducing memory footprint and computational cost during inference. â Training LLMs to compress â The method trains models to identify when and how to condense reasoning by mapping hidden states to compact gist tokens and introducing specialized attention masks. â Dependency metric for compression â The paper introduces Dep, a metric that quantifies the reliance on historical tokens during generation. Lower Dep values indicate effective compression with minimal information loss. â Memory & speed improvements â Experiments show that LightThinker reduces peak memory usage by 70% and inference time by 26% while maintaining nearly identical accuracy (within 1% of uncompressed models). â Outperforming baseline approaches â Compared to token-eviction (H2O) and anchor-token (AnLLM) methods, LightThinker achieves higher efficiency with fewer tokens stored and better generalization across reasoning tasks. | [Paper](https://arxiv.org/abs/2502.15589), [Tweet](https://x.com/omarsar0/status/1894068783700218205)  \n9) A Systematic Survey of Prompt Optimization This paper offers a comprehensive survey of Automatic Prompt Optimization (APO)âdefining its scope, presenting a unifying 5-part framework, categorizing existing methods, and highlighting key progress and challenges in automating prompt engineering for LLMs. | [Paper](https://arxiv.org/abs/2502.16923), [Tweet](https://x.com/omarsar0/status/1894412798282915994)  \n10) Protein LLMs A comprehensive overview of Protein LLMs, including architectures, training datasets, evaluation metrics, and applications. | [Paper](https://arxiv.org/abs/2502.17504), [Tweet](https://x.com/omarsar0/status/1894760600141811861)  \n## Top ML Papers of the Week (February 17 - February 23) - 2025\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-february-17---february-23---2025)\n**Paper** | **Links**  \n---|---  \n1) AI Co-Scientist Google introduces AI co-scientist, a multi-agent AI system built with Gemini 2.0 to help accelerate scientific breakthroughs. Key highlights: â What's the goal of this AI co-scientist? â It can serve as a \"virtual scientific collaborator to help scientists generate novel hypotheses and research proposals, and to accelerate the clock speed of scientific and biomedical discoveries.\" â How is it built? â It uses a coalition of specialized agents inspired by the scientific method. It can generate, evaluate, and refine hypotheses. It also has self-improving capabilities. â Collaboration and tools are key! â Scientists can either propose ideas or provide feedback on outputs generated by the agentic system. Tools like web search and specialized AI models improve the quality of responses. â Hierarchical Multi-Agent System â AI co-scientist is built with a Supervisor agent that assigns tasks to specialized agents. Apparently, this architecture helps with scaling compute and iteratively improving scientific reasoning. â Test-time Compute â AI co-scientist leverages test-time compute scaling to iteratively reason, evolve, and improve outputs. Self-play, self-critique, and self-improvement are all important to generate and refine hypotheses and proposals. â Performance? â Self-improvement relies on the Elo auto-evaluation metric. On GPQA diamond questions, they found that \"higher Elo ratings positively correlate with a higher probability of correct answers.\" AI co-scientist outperforms other SoTA agentic and reasoning models for complex problems generated by domain experts. The performance increases with more time spent on reasoning, surpassing unassisted human experts. Experts assessed the AI co-scientist to have a higher potential for novelty and impact. It was even preferred over other models like OpenAI o1. | [Paper](https://storage.googleapis.com/coscientist_paper/ai_coscientist.pdf), [Tweet](https://x.com/omarsar0/status/1892223515660579219)  \n2) The AI CUDA Engineer Sakana AI introduces The AI CUDA Engineer, an end-to-end agentic system that can produce highly optimized CUDA kernels. Key contributions: â Why is this research important? â Writing efficient CUDA kernels is challenging for humans. The AI CUDA Engineer is an end-to-end agent built with the capabilities to automatically produce and optimize CUDA kernels more effectively. â What's up with CUDA? â Writing CUDA kernels can help achieve high-performing AI algorithms. However, this requires GPU knowledge, and most AI algorithms today are written in a higher-level abstraction layer such as PyTorch. â An Agentic Pipeline â The agent translates PyTorch code into CUDA kernels (Stages 1 & 2), then applies evolutionary optimization (Stage 3) like crossover prompting, leading to an Innovation Archive (Stage 4) that reuses âstepping stoneâ kernels for further gains. â Kernel Runtime Speedups â The team claims that The AI CUDA Engineer discovers CUDA kernels with speedups that reach as high as 10-100x faster than native and compiled kernels in PyTorch. It can also convert entire ML architectures into optimized CUDA kernels. Online users have challenged the [claimed speedups](https://x.com/main_horse/status/1892446384910987718) (Sakana AI has provided an [update](https://x.com/SakanaAILabs/status/1892385766510338559) on the issue). â Performance â The AI CUDA Engineer robustly translates PyTorch Code to CUDA Kernels. It achieves more than a 90% translation success rate. â Highlighted AI CUDA Engineer-Discovered Kernels â Another claim is that The AI CUDA Engineer can robustly improve CUDA runtime. It outperforms PyTorch Native runtimes for 81% out of 229 considered tasks. 20% of all discovered CUDA kernels are at least twice as fast as their PyTorch implementations. â The AI CUDA Engineer Archive â The team has made available an archive of more than 17000 verified CUDA kernels. These can be used for downstream fine-tuning of LLMs. There is also a website to explore verified CUDA kernels. | [Technical Report](https://pub.sakana.ai/static/paper.pdf), [Blog](https://sakana.ai/ai-cuda-engineer/), [Dataset](https://pub.sakana.ai/ai-cuda-engineer), [Tweet](https://x.com/SakanaAILabs/status/1892385766510338559)  \n3) Native Sparse Attention DeepSeek-AI and collaborators present Native Sparse Attention (NSA), a novel sparse attention mechanism designed to improve computational efficiency while maintaining model performance in long-context language modeling. Key contributions: â Hierarchical Sparse Attention â NSA combines coarse-grained compression, fine-grained token selection, and sliding window mechanisms to balance global context awareness and local precision. â Hardware-Aligned Optimization â The authors introduce a blockwise sparse attention mechanism optimized for Tensor Core utilization, reducing memory bandwidth constraints and enhancing efficiency. â End-to-End Trainability â Unlike prior sparse attention methods that focus mainly on inference, NSA enables fully trainable sparsity, reducing pretraining costs while preserving model capabilities. Results and Impact: â Outperforms Full Attention â Despite being sparse, NSA matches or exceeds Full Attention on general benchmarks, long-context reasoning, and instruction-based tasks. â Massive Speedups â NSA achieves up to 11.6Ã speedup over Full Attention on 64k-token sequences across all stages (decoding, forward, and backward passes). â Strong Long-Context Performance â In 64k Needle-in-a-Haystack retrieval, NSA achieves perfect accuracy, significantly outperforming other sparse methods. â Enhanced Chain-of-Thought Reasoning â Fine-tuned NSA surpasses Full Attention on AIME mathematical reasoning tasks, suggesting improved long-range logical dependencies. By making sparse attention natively trainable and optimizing for modern hardware, NSA provides a scalable solution for next-gen LLMs handling extremely long contexts. | [Paper](https://arxiv.org/abs/2502.11089), [Tweet](https://x.com/deepseek_ai/status/1891745487071609327)  \n4) Large Language Diffusion Model Proposes LLaDA, a diffusion-based approach that can match or beat leading autoregressive LLMs in many tasks. Key highlights: â Questioning autoregressive dominance â While almost all large language models (LLMs) use the next-token prediction paradigm, the authors propose that key capabilities (scalability, in-context learning, instruction-following) actually derive from general generative principles rather than strictly from autoregressive modeling. â Masked diffusion + Transformers â LLaDA is built on a masked diffusion framework that learns by progressively masking tokens and training a Transformer to recover the original text. This yields a non-autoregressive generative modelâpotentially addressing left-to-right constraints in standard LLMs. â Strong scalability â Trained on 2.3T tokens (8B parameters), LLaDA performs competitively with top LLaMA-based LLMs across math (GSM8K, MATH), code (HumanEval), and general benchmarks (MMLU). It demonstrates that the diffusion paradigm scales similarly well to autoregressive baselines. â Breaks the âreversal curseâ â LLaDA shows balanced forward/backward reasoning, outperforming GPT-4 and other AR models on reversal tasks (e.g. reversing a poem line). Because diffusion does not enforce left-to-right generation, it is robust at backward completions. â Multi-turn dialogue and instruction-following â After supervised fine-tuning, LLaDA can carry on multi-turn conversations. It exhibits strong instruction adherence and fluency similar to chat-based AR LLMsâfurther evidence that advanced LLM traits do not necessarily rely on autoregression. | [Paper](https://arxiv.org/abs/2502.09992), [Tweet](https://x.com/omarsar0/status/1891568386494300252)  \n5) SWE-Lancer Researchers from OpenAI introduce SWE-Lancer, a benchmark evaluating LLMs on 1,488 real-world freelance software engineering tasks from Upwork, collectively worth $1M in payouts. Key takeaways: â A new benchmark for software engineering automation â Unlike previous coding benchmarks focused on isolated tasks (e.g., program synthesis, competitive programming), SWE-Lancer tests full-stack engineering and managerial decision-making. It evaluates both Individual Contributor (IC) SWE tasks, where models write and debug code, and SWE Manager tasks, where models select the best technical proposal. â Real-world economic impact â Each task has a verifiable monetary value, mirroring freelance market rates. Payouts range from $250 bug fixes to $32,000 feature implementations. The benchmark maps model performance to earnings, offering a tangible metric for automation potential. â Rigorous evaluation with end-to-end tests â Unlike unit-test-based benchmarks, SWE-Lancer employs browser-driven, triple-verified end-to-end (E2E) tests developed by professional engineers. These tests reflect real-world software validation and prevent grading hacks. â Challenging tasks remain unsolved â Even the best-performing model, Claude 3.5 Sonnet, only solves 26.2% of IC SWE tasks and 44.9% of SWE Manager tasks, earning $208K out of $500.8K in the open-source SWE-Lancer Diamond set. This highlights the gap between current AI capabilities and human software engineers. â Key findings on LLM performance: | [Paper](https://arxiv.org/abs/2502.12115), [Tweet](https://x.com/OpenAI/status/1891911123517018521)  \n6) Optimizing Model Selection for Compound AI Researchers from Microsoft Research and collaborators introduce LLMSelector, a framework to improve multi-call LLM pipelines by selecting the best model per module instead of using one LLM everywhere. Key insights include: â Large performance boost with per-module model choices â Rather than relying on a single LLM for each sub-task in compound systems, the authors show that mixing different LLMs can yield 5%â70% higher accuracy. Each model has unique strengths (e.g., better at critique vs. generation), so assigning modules selectively substantially improves end-to-end results. â LLMSelector algorithm â They propose an iterative routine that assigns an optimal model to each module, guided by a novel âLLM diagnoserâ to estimate per-module performance. The procedure scales linearly with the number of modulesâfar more efficient than exhaustive search. â Monotonicity insights â Empirically, boosting any single moduleâs performance (while holding others fixed) often improves the overall system. This motivates an approximate factorization approach, where local gains translate into global improvements. LLMSelector works for any static compound system with fixed modules (e.g., generatorâcriticârefiner). | [Paper](https://arxiv.org/abs/2502.14815), [Tweet](https://x.com/omarsar0/status/1892945381174210933)  \n7) Open-Reasoner-Zero Open-Reasoner-Zero (ORZ) is an open-source large-scale minimalist reinforcement learning (RL) framework that enhances reasoning capabilities. ORZ demonstrates significant scalability requiring only 1/30th of the training steps of DeepSeek-R1-Zero-Qwen-32B to outperform it on GPQA Diamond. Key contributions and findings: â Minimalist RL Training Works â Unlike traditional RLHF setups, ORZ removes KL regularization and relies on vanilla PPO with GAE (Î»=1, Î³=1) and a simple rule-based reward function to scale both response length and reasoning accuracy. â Outperforms Closed-Source Models â ORZ-32B beats DeepSeek-R1-Zero-Qwen-32B on GPQA Diamond while using significantly fewer training steps, proving that training efficiency can be drastically improved with a streamlined RL pipeline. â Emergent Reasoning Abilities â ORZ exhibits \"step moments\", where response lengths and accuracy suddenly increase, indicating emergent reasoning capabilities with continued training. â Massive Scaling Potential â ORZâs response length scaling mirrors trends seen in DeepSeek-R1-Zero (671B MoE), but with 5.8x fewer training steps. Training shows no signs of saturation, hinting at even further gains with continued scaling. â Fully Open-Source â The training code, model weights, data, and hyperparameters are all released, ensuring reproducibility and enabling broader adoption in the research community. â Mathematical & Logical Reasoning â ORZ significantly improves accuracy on benchmarks like MATH500, AIME2024, and AIME2025 with a simple binary reward system that only evaluates answer correctness. â Generalization â Without any instruction tuning, ORZ-32B outperforms Qwen2.5-32B Instruct on MMLU_PRO, showcasing its strong reasoning generalization despite being trained purely on RL. | [Paper](https://github.com/Open-Reasoner-Zero/Open-Reasoner-Zero/blob/main/ORZ_paper.pdf), [Tweet](https://x.com/CyouSakura/status/1892428094075502960)  \n8) MoBA MoBA is a new attention mechanism that enhances efficiency in handling long-context sequences for LLMs while maintaining strong performance. Key insights: â Adaptive Attention for Long Contexts â MoBA applies the Mixture of Experts (MoE) paradigm to the attention mechanism, allowing each query token to attend selectively to the most relevant key-value blocks rather than the full context. This enables models to handle extended sequences efficiently. â Seamless Transition Between Full and Sparse Attention â Unlike static sparse attention methods like sliding window or sink attention, MoBA can dynamically switch between full and sparse attention modes, ensuring adaptability without sacrificing generalization. â Improved Computational Efficiency â By partitioning sequences into blocks and using a gating mechanism to route queries, MoBA significantly reduces computational complexity, achieving up to 6.5Ã speedup over FlashAttention in prefill and scaling efficiently to 10M tokens with a 16Ã reduction in computation time. â Comparable Performance to Full Attention â Extensive experiments show that MoBA achieves language modeling loss and benchmark performance nearly identical to full attention, even at high sparsity levels (~95.31%). It matches full attention in long-context benchmarks like Needle in a Haystack and RULER@128K. â Hybrid MoBA-Full Attention Strategy â MoBA can be integrated flexibly with standard Transformers, allowing for layer-wise hybridization (mixing MoBA and full attention at different layers), which improves supervised fine-tuning (SFT) stability and long-context retention. | [Paper](https://github.com/MoonshotAI/MoBA/blob/master/MoBA_Tech_Report.pdf), [Tweet](https://x.com/Kimi_Moonshot/status/1891825059599352259)  \n9) The Danger of Overthinking This paper investigates overthinking in Large Reasoning Models (LRMs)âa phenomenon where models prioritize extended internal reasoning over interacting with their environment. Their study analyzes 4,018 software engineering task trajectories to understand how reasoning models handle decision-making in agentic settings. Key findings: â Overthinking reduces task performance â Higher overthinking scores (favoring internal reasoning over real-world feedback) correlate with lower issue resolution rates, especially in reasoning-optimized models. Simple interventions, like selecting solutions with the lowest overthinking scores, improve performance by 30% while reducing compute costs by 43%. â Three failure patterns identified â The study categorizes overthinking into: â Reasoning models are more prone to overthinking â Compared to non-reasoning models, LRMs exhibit 3Ã higher overthinking scores on average, despite their superior reasoning capabilities. â Function calling mitigates overthinking â Models with native function-calling support show significantly lower overthinking scores, suggesting structured execution pathways improve efficiency in agentic environments. â Scaling and mitigation strategies â The researchers propose reinforcement learning adjustments and function-calling optimizations to curb overthinking while maintaining strong reasoning capabilities. | [Paper](https://www.arxiv.org/abs/2502.08235), [Tweet](https://x.com/Alex_Cuadron/status/1890533660434321873)  \n10) Inner Thinking Transformers Inner Thinking Transformer (ITT) is a new method that enhances reasoning efficiency in small-scale LLMs via dynamic depth scaling. ITT aims to mitigate parameter bottlenecks in LLMs, providing scalable reasoning efficiency without expanding model size. Key contributions: â Adaptive Token Processing â ITT dynamically allocates extra computation to complex tokens using Adaptive Token Routing. This allows the model to focus on difficult reasoning steps while efficiently handling simple tokens. â Residual Thinking Connections (RTC) â A new residual accumulation mechanism iteratively refines token representations, allowing the model to self-correct without increasing parameters. â Test-Time Scaling without Extra Parameters â ITT achieves 96.5% of a 466M Transformerâs accuracy using only 162M parameters, reducing training data needs by 43.2% while outperforming loop-based alternatives in 11 benchmarks. â Elastic Deep Thinking â ITT allows flexible scaling of computation at inference time, optimizing between accuracy and efficiency dynamically. | [Paper](https://arxiv.org/abs/2502.13842v1), [Tweet](https://x.com/dair_ai/status/1893308342073991258)  \n## Top ML Papers of the Week (February 10 - February 16) - 2025\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-february-10---february-16---2025)\n**Paper** | **Links**  \n---|---  \n1) Scaling up Test-Time Compute with Latent Reasoning This work introduces a latent recurrent-depth transformer, a model that scales test-time reasoning without relying on additional token generation. Instead of increasing the context window or fine-tuning for Chain-of-Thought (CoT), this approach enables iterative latent space reasoning at inference, achieving improvements comparable to a 50B parameter model despite having only 3.5B parameters. Key insights include: â Recurrent test-time computation â The model unrolls a recurrent block at inference, running for an arbitrary number of steps, allowing more computational depth without modifying the input sequence. Unlike standard CoT methods, which externalize reasoning via tokens, this technique keeps reasoning in latent space, making it more efficient. â No need for CoT-specific training â Unlike CoT prompting or fine-tuning, this method doesnât require specialized datasets. It works with standard pretraining corpora and generalizes across reasoning tasks. â Improved memory & compute efficiency â Latent reasoning allows the model to scale without increasing parameter count, requiring less memory than long-context transformers. Additionally, this method improves per-token adaptive compute, speculative decoding, and KV-cache sharing, making it highly efficient. â Scales like a 50B parameter model â Benchmarks show that with sufficient test-time recurrence, the model matches or surpasses much larger LLMs on complex reasoning tasks (ARC, GSM8K, OpenBookQA). â Emergent behaviors in latent space â Analysis reveals self-organizing computation patterns, such as latent-space orbits for numerical tasks and context-dependent âdeliberationâ on difficult queries, suggesting the model learns non-verbal cognitive strategies. This approach adds a third axis to LLM scalingâbeyond model size and context lengthâby focusing on test-time compute. It suggests that future models may reason in continuous latent space rather than rely solely on token-based reasoning, potentially unlocking new AI reasoning and efficiency frontiers. | [Paper](https://arxiv.org/abs/2502.05171), [Tweet](https://x.com/omarsar0/status/1890506648772571452)  \n2) Brain-to-Text Decoding: A Non-Invasive Approach via Typing Meta AIâs Brain2Qwerty model translates brain activity into text by decoding signals from non-invasive recordings (EEG/MEG) while users type. Key results include: â Non-invasive BCI breakthrough: Brain2Qwerty leverages EEG and MEG brainwaves (recorded as participants type memorized sentences) to predict text, eliminating the need for surgical implants. â Deep learning pipeline: The system uses a convolutional module to extract signal features, a transformer to model temporal patterns, and a character-level language model to refine outputs. â Rapid progress in accuracy: MEG-based decoding achieved a 32% character error rate (vs. 67% with EEG), and the top participant reached 19% CER, showing dramatic improvement over prior non-invasive methods. â Towards practical communication aids: Demonstrates the potential for restoring communication in paralyzed patients using external brain monitors. Challenges remain in achieving real-time letter-by-letter decoding and making MEG technology more portable. | [Paper](https://ai.meta.com/research/publications/brain-to-text-decoding-a-non-invasive-approach-via-typing/), [Tweet](https://x.com/JeanRemiKing/status/1887899974454698058)  \n3) Reinforcement Learning via Self-Play Researchers propose Reinforcement Learning via Self-Play (RLSP) as a framework to train LLMs to âthinkâ through complex problems. Key ideas include: â Emergent reasoning via self-play: RLSP trains an LLM on reasoning tasks by having it generate solution steps and reward itself for exploration and correctness, effectively enabling it to search for answers like an algorithm. â Three-phase training: (1) Begin with supervised fine-tuning on human or synthetic reasoning traces, (2) add an exploration reward to encourage trying diverse solution paths, and (3) employ an outcome verifier in RL to ensure answers are correct (preventing reward hacking). â Notable performance gains: On math benchmarks, a relatively small model (8B) fine-tuned with RLSP saw +23% accuracy on MATH dataset, and a 32B model gained +10% on challenging Olympiad problemsâsignificant jumps achieved by training for better reasoning. â Uncovering new behaviors: RLSP-trained models exhibit emergent problem-solving behaviors like backtracking on flawed steps and self-verification of answers. This suggests that appropriately scaling the training process can induce more robust reasoning capabilities in LLMs. | [Paper](https://arxiv.org/abs/2502.06773), [Tweet](https://x.com/omarsar0/status/1889697727703134544)  \n4) Competitive Programming with Large Reasoning Models OpenAIâs latest study puts a specialized coding AI against a scaled-up general model on competitive programming challenges to explore efficiency vs. specialization. Key findings: â Generalist vs. specialist: A tailored model (o1-ioi) with hand-crafted strategies for coding competitions achieved decent results (placing ~50th percentile at IOI 2024 with some relaxed competition constraints). However, a larger, general-purpose model (o3) attained gold medal-level performance without any domain-specific tricks. â Reinforcement learning payoff: Both models were improved via RL fine-tuning, but the scaled general model outperformed the expert pipeline, solving programming tasks at a level comparable to elite human coders (even matching top human ratings on Codeforces). â Efficiency through scale: The results suggest that investing compute in a bigger, broadly-trained transformer can yield greater efficiency and performance than building task-specific optimizations. In other words, scaling up a modelâs reasoning ability can supersede manual efficiency tweaks for complex tasks. â Implication: For difficult reasoning tasks like coding, a single large model with sufficient training can simplify deployment (no custom inference routines needed) and still beat highly optimized specialist systems, pointing toward a trend of âscale over special-caseâ in transformer design. | [Paper](https://arxiv.org/abs/2502.06807), [Tweet](https://x.com/arankomatsuzaki/status/1889522974467957033)  \n5) Training Language Models to Reason Efficiently A new RL approach teaches large reasoning models to allocate their reasoning effort efficiently, reducing wasted computation on easy problems. Key points include: â Dynamic compute allocation: The method trains an LLM to adjust the length of its CoT based on problem difficulty. Easy queries trigger short reasoning, while hard ones use deeper thought, optimizing inference time without sacrificing accuracy. â RL-driven efficiency: Through RL, the model is rewarded for solving tasks correctly with minimal steps, learning to avoid âoverthinking.â This yields a family of models along an efficiency spectrum controlled by a single hyperparameter (trading off speed vs. accuracy). â Big cost savings: On benchmark reasoning tasks, this trained model cut down inference computation significantly while maintaining almost the same performance as unconstrained reasoning. It learns when extra reasoning steps are unnecessary, which is crucial for deploying advanced LLMs cost-effectively. â Efficient reasoning at scale: The approach addresses the multi-agent style problem internally â the model acts as both âthinkerâ and âcontroller,â deciding how much reasoning to do. This result moves us toward LLMs that can self-optimize their reasoning process on the fly, much like an expert deciding when enough analysis has been done. | [Paper](https://arxiv.org/abs/2502.04463), [Tweet](https://x.com/omarsar0/status/1889328796224127428)  \n6) Large Memory Models Large Memory Models (LM2) is a transformer architecture augmented with an external memory module to tackle tasks requiring extensive reasoning and long context. Key highlights include: â Memory-augmented transformer: LM2 adds a dedicated memory repository that the model can read/write via cross-attention, enabling it to store and retrieve information across many reasoning steps. This design addresses the limitations of standard transformers in tasks like multi-hop reasoning and relational argumentation. â Superior long-term reasoning: On the BABILong benchmark for long-context reasoning, LM2 dramatically outperformed prior models â 37% better than a recurrent memory transformer and 86% better than a baseline Llama model on average. It excels at multi-hop inference, numeric reasoning, and QA over long documents. â No trade-off in generality: Impressively, LM2 maintained strong general performance â e.g. a +5% boost on the MMLU knowledge test over a baseline â indicating the memory module helps complex tasks without hurting normal language understanding. â Alignment via memory: These results underscore the importance of explicit memory for aligning AI reasoning with complex tasks. By integrating a large-scale memory, we get models that can better adhere to task objectives over long dialogues or reasoning chains, a step forward for building more aligned and capable AI systems. | [Paper](https://arxiv.org/abs/2502.06049), [Tweet](https://x.com/omarsar0/status/1889681118913577345)  \n7) Auditing Prompt Caching Researchers from Stanford investigate how timing differences in LLM APIs can leak private user information through global prompt caching. They propose statistical audits to detect caching and reveal potentially significant security risks. Key insights include: â Side-channel timing attacks â When an LLM API caches prompts globally, repeat or prefix-matching prompts complete faster. Attackers can exploit these timing differences to infer what others have prompted, posing serious privacy concerns. â Statistical audit for detection â The paper introduces a hypothesis-testing method to systematically detect caching, distinguishing cache hits from misses using carefully constructed prompts. Empirically, the authors found multiple major API providers using global caches. â Architecture leakage â Timing differences for partial-prefix cache hits indicate a decoder-only Transformer backbone. The authors demonstrated that embedding models like OpenAIâs text-embedding-3-small are also susceptible, inadvertently leaking proprietary architectural details. â Responsible disclosure & mitigations â The authors notified affected API providers, many of whom updated documentation or disabled global caching. The recommended fix is per-user caching and transparent disclosures of caching policies to avoid privacy leakages. | [Paper](https://arxiv.org/abs/2502.07776), [Tweet](https://x.com/omarsar0/status/1889685386856673463)  \n8) Step Back to Leap Forward To boost the reasoning robustness of LLMs, researchers propose a âself-backtrackingâ mechanism that lets models revisit and revise their own intermediate reasoning steps. Key details: â Inspiration from search algorithms: Traditional problem-solving backtracks when a path hits a dead-end. This approach gives LLMs a similar ability â during reasoning, the model can identify when its current CoT is likely wrong and backtrack to a previous step to try a different approach. â Implementation: The team trained an LLM with signals to decide when to backtrack during both training and inference. This helps the model internalize an iterative search process, rather than strictly following a single chain-of-thought that might be flawed. â Huge reasoning gains: Empirically, adding self-backtracking led to 40%+ improvement on complex reasoning benchmarks compared to standard fine-tuning. The model learns to correct its own mistakes mid-stream, resulting in more reliable and accurate solutions. â Towards resilient reasoners: By reducing âoverthinkingâ loops and reliance on external feedback, this technique makes LLMs more autonomous and robust in reasoning. It points to a future where LLMs can more rigorously self-evaluate and refine their reasoning, much like humans reflecting on and correcting their thought process. | [Paper](https://arxiv.org/abs/2502.04404), [Tweet](https://x.com/omarsar0/status/1888967415444414802)  \n9) Enhancing Reasoning to Adapt LLMs Researchers from IBM present SOLOMON, a neuro-inspired LLM reasoning network architecture that boosts domain adaptabilityâdemonstrated on semiconductor layout design. They show how LLMs often falter at spatial reasoning and domain knowledge application, and how their multi-agent oversight approach significantly improves success on challenging chip-layout tasks. Key insights include: â SOLOMON architecture â Combines multiple âThought Generatorsâ (diverse LLMs) with a âThought Assessorâ that consolidates and refines outputs, guided by a âSteering Subsystemâ for prompt engineering. This neuro-inspired design helps correct hallucinations and arithmetic errors in single-model responses. â Spatial reasoning challenges â LLMs often memorize textbook definitions but fail at practical geometry (e.g. unit conversions, offset margins). Experiments on 25 custom tasksâfrom simple polygons to 3D via connectionsârevealed frequent code or scaling mistakes. â Boost over strong baselines â SOLOMON significantly outperformed GPT-4o, Claude-3.5, and Llama-3.1 in generating correct GDSII layouts, and in some tests even surpassed the authorsâ âo1-previewâ reference model. The multi-LLM approach mitigated errors (e.g., ignoring default units or mixing up geometry). â Future directions â Plans include stacking multiple SOLOMON layers for more complex designs, improving multimodal linking of text/image/code, and broader domain tasks (e.g. power grid layout). The broader lesson: advanced reasoning mechanisms, not just bigger models, are crucial for specialized engineering applications. | [Paper](https://arxiv.org/abs/2502.04384), [Tweet](https://x.com/omarsar0/status/1888985789880758426)  \n10) ReasonFlux The ReasonFlux framework is introduced as an efficient way to fine-tune LLMs for complex reasoning, using hierarchical thought processes. Highlights include: â Thought template library: Rather than having a model learn long CoT solutions from scratch, ReasonFlux provides a library of ~500 reusable âthought templatesâ â high-level reasoning steps that can be composed to solve problems. These might be generic strategies like âsplit the problem into casesâ or âverify the solution,â applicable across tasks. â Hierarchical planning via RL: The model is trained (with only 8 GPUs for a 32B model) to plan a sequence of these templates to tackle a problem, using hierarchical reinforcement learning. This way, it learns to orchestrate complex reasoning by chaining templates, instead of generating every reasoning step token-by-token. â Inference-time adaptation: A novel inference strategy allows the model to adjust the granularity of its reasoning on the fly, scaling the template sequence based on difficulty. This means the model can dynamically decide to use more detailed templates for hard problems and fewer for easy ones, optimizing both accuracy and speed. â State-of-the-art results: ReasonFlux achieved high scores on math reasoning benchmarks â for example, 91.2% on MATH, outperforming OpenAIâs reference model by 6.7%, and solved 56.7% of problems on the AIME Olympiad, vastly surpassing previous models. This demonstrates that smart fine-tuning with structured reasoning steps can yield big gains even without massive compute. | [Paper](https://arxiv.org/abs/2502.06772), [Tweet](https://x.com/omarsar0/status/1889343676272525600)  \n## Top ML Papers of the Week (February 3 - February 9) - 2025\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-february-3---february-9---2025)\n**Paper** | **Links**  \n---|---  \n1) s1: Simple test-time scaling Researchers from Stanford, UW, and others introduce s1, a method to boost LLM performance by using extra compute at inference (âtest-time scalingâ). Key ideas include: â Small yet powerful dataset â They curated s1K, only 1,000 challenging questions with detailed reasoning traces, to fine-tune a 32B model. Despite the tiny data, this provides strong reasoning exemplars. â âBudget forcingâ for reasoning â A new decoding trick appends the token âWaitâ when the model tries to stop, forcing it to think longer. This leads the model to double-check and fix its reasoning step. By also cutting off overly long reasoning, they control inference time. â Big gains over OpenAIâs o1 â The resulting model (s1-32B) (a fine-tuned version of Qwen2.5-32B-Instruct) outperforms OpenAIâs o1-preview model by up to +27% on competition-level math questions (MATH & AIME24). Notably, with test-time scaling, it boosts accuracy on AIME24 from 50% to 57%, surpassing its own normal limit. | [Paper](http://arxiv.org/abs/2501.19393), [Tweet](http://twitter.com/omarsar0/status/1886428631041225030), [Code & Data](https://github.com/simplescaling/s1)  \n2) OmniHuman-1: Scaling One-Stage Human Animation A team at ByteDance AI Lab unveiled OmniHuman-1, a diffusion-transformer model that can generate highly realistic human videos from just a single image plus motion input (audio or video). Highlights: â End-to-end human video generation â OmniHuman takes one image (any aspect ratio, from face only to full-body) and an audio clip or video motion and produces a lifelike video of that person speaking, singing, or performing actions. The outputs are remarkably realistic in motion, lighting, and texture detail. â Mixed modality training â A key innovation is Omni-Conditions Training: mixing various motion modalities during training (audio-driven, video-driven, pose, etc.). This greatly expands the training data and overcomes the usual scarcity of high-quality talking-head video data. The model learns to handle diverse inputs (speech, song, instruments) and challenging poses. â Outperforms prior methods â Compared to earlier one-stage models (e.g. audio-driven talking heads), OmniHuman generates more realistic videos and is more flexible in input types. It can even handle cartoons or animal figures as input, transferring motion naturally to each style. â Broader support â The approach supports any portrait content (face close-up, half-body, full-body) and multiple driving signals simultaneously. This generality is a first for end-to-end human animation models. | [Paper](http://arxiv.org/abs/2502.01061), [Tweet](http://twitter.com/unseenvie/status/1886672598576325011), [Demo](https://omnihuman-lab.github.io/)  \n3) LIMO: Less Is More for Reasoning Can a handful of examples teach complex math reasoning to LLMs? This new LIMO paper challenges the notion that we need huge fine-tuning datasets for tough reasoning tasks. Key findings: â Surprisingly few examples â With only 817 carefully curated training samples, the LIMO model achieves 57.1% accuracy on the AIME math competition and 94.8% on MATH. This is a giant leap from prior SFT-based models (which scored 6.5% and 59.2% respectively â using just 1% of the data those earlier approaches needed. â Generalization with less data? â LIMO shows impressive OOD generalization: a +40.5% absolute improvement on average across 10 diverse benchmarks, even outperforming models trained on 100Ã more data. This challenges the assumption that more data is always required for complex skills and that fine-tuning only leads to memorization. â âLess-Is-Moreâ Hypothesis â The authors propose that if an LLMâs pre-training has already endowed it with rich knowledge, then only a minimal set of carefully designed examples (which they call âcognitive templatesâ) is needed to unlock advanced reasoning. Essentially, the model just needs to see how to use its knowledge, not thousands of repetitive problems. â Open-source suite â The complete LIMO training suite is released for the community, supporting further research on data-efficient reasoning. This work hints that small, high-quality datasets might yield state-of-the-art reasoning, lowering the barrier to fine-tuning powerful LLMs. | [Paper](http://arxiv.org/abs/2502.03387), [Tweet](http://twitter.com/omarsar0/status/1887514592747937984), [Code](https://github.com/GAIR-NLP/LIMO)  \n4) CoAT: Chain-of-Associated-Thoughts for LLM Reasoning This work introduces CoAT, a new âslow thinkingâ inference framework that enables an LLM to reason more like a human by exploring and updating its thoughts. Main components: â MCTS + associative memory â CoAT marries Monte Carlo Tree Search (MCTS) with an associative memory mechanism. MCTS lets the model systematically explore different reasoning branches (possible solutions), while the associative memory dynamically injects new relevant information into the context as needed (mimicking how humans recall facts mid-thought). â Iterative, self-improving reasoning â The framework can expand the search space of solutions and revisit or refine earlier intermediate conclusions. As it evaluates branches, it can incorporate new clues or correct itself, ensuring the final answer is more accurate and comprehensive. This is in contrast to standard one-pass LLM reasoning, which canât easily backtrack or gather new info on the fly. â Improved accuracy and diversity â In experiments across various generation and reasoning tasks, CoAT outperformed conventional single-pass inference on metrics like accuracy, coherence of reasoning steps, and solution diversity. The ability to iteratively broaden the search while keeping relevant context yields better results than âfast thinkingâ alone. â Closer to human thought â CoAT is inspired by how humans solve problems: we iteratively consider alternatives, recall facts, and refine our thinking. It points toward LLM agents that can use search algorithms and memory to achieve more reliable reasoning. | [Paper](http://arxiv.org/abs/2502.02390), [Tweet](http://twitter.com/omarsar0/status/1887187689247752370)  \n5) Syntriever: Training Retrievers with LLM-Generated Data How can we build a high-quality text retriever without large labeled datasets or access to an LLMâs internals? Syntriever presents a two-stage framework to distill knowledge from a black-box LLM into a retrieval model using synthetic data. Steps: â Stage 1 â Distillation via synthetic Q&A: Given a query, they prompt a powerful LLM (e.g. GPT-4) to generate a relevant passage (answer) and also plausible but incorrect passages, using chain-of-thought to ensure variety. The LLM then self-verifies these generated passages to filter out any hallucinations or low-quality data. The result is a synthetic dataset of queries with positive and negative passages. A retriever is trained on this, with a loss that clusters embeddings of relevant passages closer than irrelevant ones. â Stage 2 â Alignment with LLM preferences: They further align the retriever to prefer results the LLM would prefer. Using a partial Plackett-Luce ranking method, the retriever learns to rank passages similarly to the LLMâs judgments, with regularization to not drift too far from the Stage 1 model. This step fine-tunes the retriever to mimic the black-box LLMâs preferences. â State-of-the-art results â Syntriever achieves new SOTA on several retrieval benchmarks across domains. This was achieved without any real training queries: all training data was synthetically generated by the LLM. â No logits needed â Prior LLM-to-retriever distillation needed model logits or probabilities (not available from closed APIs). Syntriever gets around this by using only generated text and LLM scoring, making it applicable even to closed models. | [Paper](http://arxiv.org/abs/2502.03824), [Tweet](https://x.com/omarsar0/status/1887878242276954557), [Code](https://github.com/kmswin1/Syntriever)  \n6) Demystifying Long Chain-of-Thought Reasoning in LLMs This work investigates how LLMs develop extended CoT reasoning, focusing on RL and compute scaling. Key insights include: â Supervised fine-tuning (SFT) boosts performance â While not strictly necessary, SFT simplifies training and increases efficiency. Models fine-tuned with long CoT data achieve higher accuracy than those using short CoT sequences. â Reward shaping is crucial for stable RL â The study finds that naive RL approaches donât always extend CoT length effectively. To address this, the authors introduce a cosine length-scaling reward with repetition penalties, which balances reasoning depth and prevents meaningless length increases. â Scaling verifiable reward signals â RL models trained with noisy, web-extracted âsilverâ supervision signals can generalize better to OOD tasks, such as STEM reasoning. Filtering such data is crucial to maintaining training stability. â Emergent reasoning abilities in base models â Skills like error correction and backtracking exist in base models but require careful RL incentives to be effectively utilized in complex tasks. This paper provides a structured roadmap for researchers looking to refine CoT training strategies for LLMs, highlighting how RL and reward tuning impact reasoning depth. | [Paper](https://arxiv.org/abs/2502.03373), [Tweet](https://x.com/xiangyue96/status/1887332772198371514)  \n7) Rethinking Mixture-of-Agents: Ensemble One Strong LLM Ensembling multiple models (Mixture-of-Agents, MoA) is a popular way to boost performance. This paper asks: is mixing different LLMs actually helpful, or are we better off ensembling one top modelâs outputs? The surprising answer: âSelf-MoAâ (single-model ensemble) often wins over multi-model ensembles. Key points: â Self-MoA vs. MoA â The authors propose Self-MoA, which simply generates multiple outputs from the single best model and then aggregates them (e.g., by majority voting or ranking), instead of combining outputs from various models. This increases diversity via multiple attempts, without introducing weaker models. â Better performance â Extensive tests show Self-MoA outperforms a mixture of different LLMs in many cases. For example, using one strong model, Self-MoA achieved +6.6% higher score than a mixed-model MoA on the AlpacaEval 2.0 benchmark, and on average +3.8% across tasks like MMLU, CRUX, and MATH. In fact, applying Self-MoA to a top AlpacaEval model set a new state-of-the-art on the leaderboard. â Why it works â Mixing models can hurt because the overall quality is limited by the weaker members. The study finds MoAâs benefit is highly sensitive to the quality of each model â adding a weaker model dilutes performance. Unless all models are very strong and complementary, youâre better off with one modelâs outputs. They do identify niche scenarios where diverse models help, but those are exceptions. â Sequential aggregation â They also introduce a sequential version of Self-MoA that can combine a large number of outputs over multiple rounds (rather than all at once). This sequential Self-MoA is as effective as one-shot aggregation, scaling ensembling to many outputs efficiently. | [Paper](http://arxiv.org/abs/2502.00674), [Tweet](http://twitter.com/omarsar0/status/1886792384954163347)  \n8) MaAS: Multi-agent Architecture Search (Agentic Supernet) Building multi-agent systems of LLMs (where multiple agents collaborate, each with specific roles or tools) is powerful but usually requires hand-designing a single complex pipeline. MaAS (Multi-agent Architecture Search) instead learns a universal âagentic supernetâ from which it can spawn an optimal agent team on the fly for each query. It automates designing the agent workflow per task: â Agentic supernet â The authors define a continuous space of possible agent architectures (chains of LLM calls, tool uses, etc.). Rather than picking one static architecture, they train a supernet that encompasses many configurations. Each query can trigger a different sub-network of agents tailored to that queryâs domain and difficulty. â Dynamic resource allocation â Because the system adapts per query, it can allocate resources efficiently. Easy questions might use a simple, fast agent chain; hard problems invoke a more elaborate reasoning team. This avoids the one-size-fits-all cost of a monolithic agent system. â Huge cost savings â On six benchmarks, MaAS used only 6â45% of the inference cost of existing multi-agent pipelines, yet still outperformed them by ~0.5â11.8% in accuracy. It finds cheaper ways to reach equal or better performance by tuning the agent configuration to the task. â Robust and transferable â The agentic supernet approach showed strong generalization: architectures found effective on one task transferred well to new domains and even with different LLM backbones, outperforming static designs. This suggests the method learns general principles of how to orchestrate LLM agents optimally. | [Paper](http://arxiv.org/abs/2502.04180), [Tweet](http://twitter.com/omarsar0/status/1887884027530727876)  \n9) Advancing Reasoning in LLMs This survey paper provides a timely overview of emerging methods to enhance reasoning capabilities in LLMs. It organizes the literature into several key approach categories: â Prompting strategies â Techniques that guide the modelâs reasoning via clever prompts, e.g. Chain-of-Thought prompting (having the model generate step-by-step solutions), Self-Consistency (sampling multiple reasoning paths and choosing the best answer), Tree-of-Thought strategies, etc. These methods improve logical deduction and multi-step solutions without changing the modelâs architecture. â Architectural innovations â Modifications to the model or its context to better facilitate reasoning. This includes retrieval-augmented models (LLMs that can fetch external facts), modular reasoning networks (systems that break a problem into sub-tasks handled by different modules or experts), and neuro-symbolic integration (combining neural nets with symbolic logic or tools. Such changes aim to give LLMs access to either more knowledge or more structured reasoning processes. â Learning paradigms â New training methods to instill reasoning skills: fine-tuning on reasoning-specific datasets (e.g. math word problems), reinforcement learning approaches (rewarding correct reasoning chains), and self-supervised objectives that train the model to reason (like predicting masked steps in a proof. These improve the modelâs inherent reasoning ability beyond what general pre-training provides. â Evaluation & challenges â The survey also reviews how we evaluate reasoning in LLMs (benchmarks for logic, math, commonsense, etc.) and identifies open challenges. Key issues include hallucinations (the model fabricating illogical or untrue intermediate steps), brittleness to small changes (robustness), and generalization of reasoning methods across different tasks and domains. Addressing these will be crucial for the next generation of reasoning-augmented LLMs. | [Paper](http://arxiv.org/abs/2502.03671), [Tweet](http://twitter.com/omarsar0/status/1887875470269849659)  \n10) Survey: Text Data Augmentation for LLMs This comprehensive survey covers text data augmentation techniques for LLMs. As LLMs demand massive training data, augmenting datasets with synthetic or transformed text is vital. In this paper: â Classifies augmentation methods â It defines four categories: (1) Simple augmentation â basic text manipulations like synonym replacement, cropping, etc.; (2) Prompt-based augmentation â using an LLM with specific prompts to generate new training examples (taking advantage of the LLMâs own generative power; (3) Retrieval-based augmentation â pulling in external knowledge or contexts (via search or databases) to ground the generated text in facts; and (4) Hybrid augmentation â combinations of the above, or multi-step strategies. â LLMs as data generators â A key insight is that modern LLMs can create high-quality synthetic data to improve themselves. By carefully prompting an LLM to produce variations of a task (for example, ask ChatGPT to come up with new math word problems), one can dramatically expand a training set. The survey discusses prompt design for this purpose and how to ensure the generated data is diverse and useful. â Post-processing and filtering â Augmented data isnât always perfect. The survey covers techniques to refine and filter generated data. For instance, verifying facts with a secondary model or removing examples that might introduce errors. This step is crucial to prevent âgarbage in, garbageâ out when augmenting data. â Evaluation and future directions â It outlines common tasks where data augmentation is used (like low-resource language translation, QA, etc.) and how to evaluate the impact (improvement in accuracy, robustness, etc.). Finally, it discusses challenges (e.g. ensuring augmentation doesnât distort data distribution, avoiding model bias reinforcement) and opportunities for new research. | [Paper](http://arxiv.org/abs/2501.18845), [Tweet](http://twitter.com/omarsar0/status/1886428687350006067)  \n## Top ML Papers of the Week (January 27 - February 2) - 2025\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-january-27---february-2---2025)\n**Paper** | **Links**  \n---|---  \n1) o3-mini OpenAI has launched o3-mini, their newest cost-efficient reasoning model, available in ChatGPT and API. The model excels in STEM-related tasks, particularly in science, math, and coding, while maintaining the low cost and reduced latency of its predecessor o1-mini. It introduces key developer features like function calling, Structured Outputs, and developer messages, making it production-ready from launch. o3-mini includes different reasoning effort levels (low, medium, and high) and improves performance across a wide range of tasks. It delivered responses 24% faster than o1-mini and achieved notable results in competition math, PhD-level science questions, and software engineering tasks. | [System Card](https://cdn.openai.com/o3-mini-system-card.pdf), [Blog](https://openai.com/index/openai-o3-mini/), [Tweet](https://x.com/OpenAI/status/1885406586136383634)  \n2) Qwen2.5-1M Qwen releases two open-source LLMs, Qwen2.5-7B-Instruct-1M and Qwen2.5-14B-Instruct-1M, that can handle context lengths of up to 1 million tokens. The models are built on a progressive training approach, starting with 4K tokens and gradually increasing to 256K tokens, then using length extrapolation techniques to reach 1M tokens. They've also released an inference framework based on vLLM that processes long inputs 3-7x faster through sparse attention methods. The models show strong performance on both long-context and short-text tasks. The 14B model outperforms GPT-4o-mini across multiple long-context datasets while maintaining similar performance on shorter tasks. | [Paper](https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5-1M/Qwen2_5_1M_Technical_Report.pdf), [Models](https://huggingface.co/Qwen), [Qwen Chat App](https://chat.qwenlm.ai/), [Tweet](https://x.com/omarsar0/status/1883905564004241789)  \n3) Janus-Pro An enhanced version of the previous Janus model for multimodal understanding and generation. The model incorporates three key improvements: optimized training strategies with longer initial training and focused fine-tuning, expanded training data including 90 million new samples for understanding and 72 million synthetic aesthetic samples for generation, and scaling to larger model sizes up to 7B parameters. Janus-Pro achieves significant improvements in both multimodal understanding and text-to-image generation capabilities. The model outperforms existing solutions on various benchmarks, scoring 79.2 on MMBench for understanding tasks and achieving 80% accuracy on GenEval for text-to-image generation. The improvements also enhance image generation stability and quality, particularly for short prompts and fine details, though the current 384x384 resolution remains a limitation for certain tasks. | [Paper](https://github.com/deepseek-ai/Janus/blob/main/janus_pro_tech_report.pdf), [Models](https://huggingface.co/deepseek-ai/Janus-Pro-7B), [Tweet](https://x.com/giffmana/status/1884011657191637126)  \n4) On the Underthinking of o1-like LLMs This work looks more closely at the \"thinking\" patterns of o1-like LLMs. We have seen a few recent papers pointing out the issues with overthinking. There is now a new phenomenon called underthinking! What is it about? The authors find that o1-like LLMs frequently switch between different reasoning thoughts without sufficiently exploring promising paths to reach a correct solution. | [Paper](https://arxiv.org/abs/2501.18585), [Tweet](https://x.com/omarsar0/status/1885349576456233177)  \n5) Diverse Preference Optimization Introduces Diverse Preference Optimization (DivPO), a novel training method that aims to address the lack of diversity in language model outputs while maintaining response quality. The key challenge is that current preference optimization techniques like RLHF tend to sharpen the output probability distribution, causing models to generate very similar responses. This is particularly problematic for creative tasks where varied outputs are desired. DivPO works by modifying how training pairs are selected during preference optimization. Rather than simply choosing the highest and lowest rewarded responses, DivPO selects the most diverse response that meets a quality threshold and contrasts it with the least diverse response below a threshold. The method introduces a diversity criterion that can be measured in different ways, including model probability, word frequency, or using an LLM as a judge. Experiments on persona generation and creative writing tasks show that DivPO achieves up to 45.6% more diverse outputs in structured tasks and an 81% increase in story diversity, while maintaining similar quality levels compared to baseline methods. | [Paper](https://arxiv.org/abs/2501.18101), [Tweet](https://x.com/jaseweston/status/1885399530419450257)  \n6) Usage Recommendation for DeepSeek-R1 This work provides a set of recommendations for how to prompt the DeepSeek-R1 model. Below are the key guidelines: 1. Prompt Engineering: â Use clear, structured prompts with explicit instructions â Avoid few-shot prompting; use zero-shot instead 1. Output Formatting: â Specify the desired format (JSON, tables, markdown) â Request step-by-step explanations for reasoning tasks 1. Language: â Explicitly specify input/output language to prevent mixing The paper also summarizes when to use the different model variants, when to fine-tune, and other safety considerations. | [Paper](https://arxiv.org/abs/2501.17030), [Tweet](https://x.com/omarsar0/status/1884624296368292083)  \n7) Docling [Docling](https://arxiv.org/abs/2501.17887) is an open-source toolkit that can parse several types of popular document formats into a unified, richly structured representation. | [Paper](https://arxiv.org/abs/2501.17887)  \n8) Improving RAG through Multi-Agent RL This work treats RAG as a multi-agent cooperative task to improve answer generation quality. It models RAG components like query rewriting, document selection, and answer generation as reinforcement learning agents working together toward generating accurate answers. It applies Multi-Agent Proximal Policy Optimization (MAPPO) to jointly optimize all agents with a shared reward based on answer quality. Besides improvements on popular benchmarks, the framework shows strong generalization capabilities in out-of-domain scenarios and maintains effectiveness across different RAG system configurations. | [Paper](https://arxiv.org/abs/2501.15228), [Tweet](https://x.com/omarsar0/status/1884249075467575362)  \n9) TensorLLM Proposes a framework that performs MHA compression through a multi-head tensorisation process and the Tucker decomposition. Achieves a compression rate of up to â¼ 250x in the MHA weights, without requiring any additional data, training, or fine-tuning. | [Paper](https://arxiv.org/abs/2501.15674), [Tweet](https://x.com/omarsar0/status/1884246306224496729)  \n10) TokenVerse Proposes a new technique to generate new images from learned concepts in a desired configuration. Proposed by Google DeepMind and collaborators, TokenVerse enables multi-concept personalization by leveraging a pre-trained text-to-image diffusion model to disentangle and extract complex visual concepts from multiple images. It operates in the modulation space of DiTs, learning a personalized modulation vector for each text token in an input caption. This allows flexible and localized control over distinct concepts such as objects, materials, lighting, and poses. The learned token modulations can then be combined in novel ways to generate new images that integrate multiple personalized concepts without requiring additional segmentation masks. | [Paper](https://arxiv.org/abs/2501.12224), [Tweet](https://x.com/omarsar0/status/1884618510275592610)  \n## Top ML Papers of the Week (January 20 - January 26) - 2025\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-january-20---january-26---2025)\n**Paper** | **Links**  \n---|---  \n1) DeepSeek-R1 DeepSeek introduces DeepSeek-R1, an advancement in reasoning capabilities achieved through reinforcement learning (RL). It involves two key models: DeepSeek-R1-Zero, which uses pure RL without supervised fine-tuning, and DeepSeek-R1, which combines RL with cold-start data. DeepSeek-R1-Zero demonstrates that models can develop sophisticated reasoning abilities through RL alone, achieving a 71.0% pass rate on AIME 2024 and matching OpenAI-o1-0912's performance. During training, it naturally evolved complex behaviors like self-verification and reflection. However, it faced challenges with readability and language mixing. To address these limitations, DeepSeek-R1 uses a multi-stage approach: initial fine-tuning with high-quality chain-of-thought examples, reasoning-focused RL training, collecting new training data through rejection sampling, and final RL optimization across all scenarios. This resulted in performance comparable to OpenAI-o1-1217, with 79.8% accuracy on AIME 2024 and 97.3% on MATH-500, while maintaining output readability and consistency. DeepSeek also successfully distilled DeepSeek-R1's capabilities into smaller models, with their 7B model outperforming larger competitors and their 32B model achieving results close to OpenAI-o1-mini. This demonstrates the effectiveness of distilling reasoning patterns from larger models rather than training smaller models directly through RL. | [Paper](https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf), [Tweet](https://x.com/deepseek_ai/status/1881318130334814301), [Code](https://huggingface.co/deepseek-ai), [App](https://chat.deepseek.com/)  \n2) Humanityâs Last Exam Humanity's Last Exam is a new multi-modal benchmark designed to test the limits of LLMs. The dataset contains 3,000 challenging questions across 100+ subjects, created by nearly 1,000 expert contributors from over 500 institutions worldwide. Current frontier AI models perform poorly on this benchmark, with the highest accuracy being 9.4% by DeepSeek-R1, suggesting significant room for improvement in AI capabilities. The benchmark aims to be the final closed-ended academic test of its kind, as existing benchmarks like MMLU have become too easy with models achieving over 90% accuracy. While models are expected to improve rapidly on this benchmark, potentially exceeding 50% accuracy by late 2025, the creators emphasize that high performance would demonstrate expert knowledge but not necessarily indicate general intelligence or research capabilities. | [Paper](https://static.scale.com/uploads/654197dc94d34f66c0f5184e/Publication%20Ready%20Humanity%27s%20Last%20Exam.pdf), [Tweet](https://x.com/DanHendrycks/status/1882433928407241155), [Dataset](https://huggingface.co/datasets/cais/hle)  \n3) Scaling RL with LLMs Kimi introduces k1.5, a multimodal LLMtrained using RL that achieves state-of-the-art performance across reasoning tasks. The model leverages long context scaling up to 128k tokens and improved policy optimization methods, establishing a simplified yet effective RL framework without complex techniques like Monte Carlo tree search or value functions. Notably, k1.5 matches OpenAI's o1 performance on various benchmarks including 77.5 on AIME and 96.2 on MATH 500. The model also introduces effective long2short methods that use long-chain-of-thought techniques to improve shorter models, achieving superior results in constrained settings. Using these techniques, k1.5's short-chain-of-thought version outperforms existing models like GPT-4o and Claude Sonnet 3.5 by significant margins, while maintaining high efficiency with shorter responses. | [Paper](https://github.com/MoonshotAI/Kimi-k1.5/blob/main/Kimi_k1.5.pdf), [Tweet](https://x.com/omarsar0/status/1881749719212552280), [GitHub](https://github.com/MoonshotAI/Kimi-k1.5)  \n4) Chain-of-Agents A new framework for handling long-context tasks using multiple LLM agents working together. CoA splits text into chunks and assigns worker agents to process each part sequentially, passing information between them before a manager agent generates the final output. This approach avoids the limitations of traditional methods like input reduction or window extension. Testing across multiple datasets shows CoA outperforms existing approaches by up to 10% on tasks like question answering and summarization. The framework works particularly well with longer inputs - showing up to 100% improvement over baselines when processing texts over 400k tokens. | [Paper](https://openreview.net/pdf?id=LuCLf4BJsr), [Tweet](https://x.com/omarsar0/status/1882824941101629829)  \n5) Can LLMs Plan? Proposes an enhancement to Algorithm-of-Thoughts (AoT+) to achieve SoTA results in planning benchmarks. It even outperforms human baselines! AoT+ provides periodic state summaries to reduce the cognitive load. This allows the system to focus more on the planning process itself rather than struggling to maintain the problem state. | [Paper](https://arxiv.org/abs/2501.13545), [Tweet](https://x.com/omarsar0/status/1882799782579855518)  \n6) Hallucinations Improve LLMs in Drug Discovery Claims that LLMs can achieve better performance in drug discovery tasks with text hallucinations compared to input prompts without hallucination. Llama-3.1-8B achieves an 18.35% gain in ROC-AUC compared to the baseline without hallucination. In addition, hallucinations generated by GPT-4o provide the most consistent improvements across models. | [Paper](https://arxiv.org/abs/2501.13824), [Tweet](https://x.com/omarsar0/status/1882789456522145802)  \n7) Trading Test-Time Compute for Adversarial Robustness Shows preliminary evidence that giving reasoning models like o1-preview and o1-mini more time to \"think\" during inference can improve their defense against adversarial attacks. Experiments covered various tasks, from basic math problems to image classification, showing that increasing inference-time compute often reduces the success rate of attacks to near zero. The approach doesn't work uniformly across all scenarios, particularly with certain StrongREJECT benchmark tests, and controlling how models use their compute time remains challenging. Despite these constraints, the findings suggest a promising direction for improving AI security without relying on traditional adversarial training methods. | [Paper](https://cdn.openai.com/papers/trading-inference-time-compute-for-adversarial-robustness-20250121_1.pdf), [Tweet](https://x.com/OpenAI/status/1882129444212740482)  \n8) IntellAgent Introduces a new open-source framework for evaluating conversational AI systems through automated, policy-driven testing. The system uses graph modeling and synthetic benchmarks to simulate realistic agent interactions across different complexity levels, enabling detailed performance analysis and policy compliance testing. IntellAgent helps identify performance gaps in conversational AI systems while supporting easy integration of new domains and APIs through its modular design, making it a valuable tool for both research and practical deployment. | [Paper](https://arxiv.org/abs/2501.11067), [Tweet](https://x.com/omarsar0/status/1882081603754643779), [GitHub](https://github.com/plurai-ai/intellagent)  \n9) LLMs and Behavioral Awareness Shows that after fine-tuning LLMs on behaviors like outputting insecure code, the LLMs show behavioral self-awareness. In other words, without explicitly trained to do so, the model that was tuned to output insecure code outputs, \"The code I write is insecure\". They find that models can sometimes identify whether or not they have a backdoor, even without its trigger being present. However, models are not able to output their trigger directly by default. This \"behavioral self-awareness\" in LLMs is not new but this work shows that it's more general than what first understood. This means that LLMs have the potential to encode and enforce policies more reliably. | [Paper](https://arxiv.org/abs/2501.11120), [Tweet](https://x.com/omarsar0/status/1882079780918747303)  \n10) Agentic RAG Overview Provides a comprehensive introduction to LLM agents and Agentic RAG. It provides an exploration of Agentic RAG architectures, applications, and implementation strategies. | [Paper](https://arxiv.org/abs/2501.09136), [Tweet](https://x.com/omarsar0/status/1881360794019156362)  \n## Top ML Papers of the Week (January 13 - January 19) - 2025\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-january-13---january-19---2025)\n**Paper** | **Links**  \n---|---  \n1) Self-Adaptive LLMs - introduces Transformer^2, a novel self-adaptation framework that adapts LLMs for unseen tasks in real-time by selectively adjusting singular components of their weight matrices; itâs built with two key phases: 1) a dispatch system that analyzes and identifies the properties of the incoming task, and 2) a step that combines \"expert\" vectors (trained via reinforcement learning) to create task-specific behaviors; claims to be more efficient than LoRA with fewer parameters and can works across different LLM architectures. | [Paper](https://arxiv.org/abs/2501.06252), [Tweet](https://x.com/hardmaru/status/1879331049383334187)  \n2) MiniMax-01 - introduces a new series of models that integrate Mixture-of-Experts; introduces a model with 32 experts and 456B parameters, and 45.9B are activated for each token; claims match the performance of state-of-the-art models like GPT-4o and Claude-3.5-Sonnet while offering a 20-32x longer context window; it can handle context windows of up to 4 million tokens; it integrates linear attention with optimized hardware utilization which enhances the efficiency and scalability of the LLM; there is also a vision model called MiniMax-VL-01 built through continued training with 512 billion vision-language tokens. | [Paper](https://arxiv.org/abs/2501.08313), [Tweet](https://x.com/omarsar0/status/1879572512075587872)  \n3) VideoRAG - a framework that enhances RAG by leveraging video content as an external knowledge source; unlike existing RAG approaches that primarily focus on text or images, VideoRAG dynamically retrieves relevant videos based on queries and incorporates both their visual and textual elements into the generation process; the framework utilizes Large Video Language Models (LVLMs) to process video content directly, enabling more effective capture of temporal dynamics, spatial details, and multimodal cues that static modalities often fail to convey; for videos lacking textual descriptions, they propose using automatic speech recognition to generate transcripts, ensuring both visual and textual modalities can be leveraged. | [Paper](https://arxiv.org/abs/2501.05874), [Tweet](https://x.com/omarsar0/status/1878827350315659421)  \n4) Learning to Memorize at Test Time - introduces a neural long-term memory module to memorize historical context and help attention to attend to the current context while utilizing long past information; the neural memory module acts as a long-term, more persistent memory than just using attention alone (considered more short-term); Titan, which is based on neural memory, shows good results in language modeling, common-sense reasoning, genomics, and time series tasks. | [Paper](https://arxiv.org/abs/2501.00663), [Tweet](https://x.com/omarsar0/status/1879896681010921742)  \n5) Foundations of LLMs - new survey on the foundations of LLMs covering areas such as pre-training, prompting, and alignment methods. | [Paper](https://arxiv.org/abs/2501.09223), [Tweet](https://x.com/omarsar0/status/1880284477445767586)  \n6) OmniThink - a new framework that emulates a human-like process of iterative expansion and reflection; it's built to simulate the cognitive behavior of learners as they deepen their knowledge; compared to RAG and role-playing, OmniThink can expand knowledge boundaries through continuous reflection and exploration; this makes it ideal for use cases that require long-form generation. | [Paper](https://arxiv.org/abs/2501.09751), [Tweet](https://x.com/omarsar0/status/1880275861401923619)  \n7) Enhancing RAG - systematically explores the factors and methods that improve RAG systems such as retrieval strategies, query expansion, contrastive in-context learning, prompt design, and chunking. | [Paper](https://arxiv.org/abs/2501.07391), [Tweet](https://x.com/omarsar0/status/1879178916021318029)  \n8) AutoCBT - proposes a multi-agent framework, AutoCBT, for Cognitive Behavioral Therapy; the work proposes a general multi-agent framework that generates high-quality responses for single-turn psychological consultation scenarios; it uses a combination of dynamic routing, memory, and supervisory mechanisms to enhance the autonomous ability of each agent; experimental results show that AutoCBT can provide higher-quality automated psychological counseling services; AutoCBT improves dialogue quality compared to other purely prompt-based counseling frameworks. | [Paper](https://arxiv.org/abs/2501.09426), [Tweet](https://x.com/omarsar0/status/1880283025595867631)  \n9) Imagine while Reasoning in Space - introduces MVoT (Multimodal Visualization-of-Thought), a new reasoning framework that enables AI models to \"think\" in both text and images; MVoT enhances the traditional Chain-of-Thought prompting by allowing models to generate visual representations of their reasoning steps alongside text explanations; the framework is implemented in Chameleon-7B, a multimodal language model, and introduces a \"token discrepancy loss\" to improve the quality of generated visualizations; MVoT significantly outperforms traditional approaches, especially in complex scenarios; MVoT achieves over 90% accuracy on maze and printer installation tasks. | [Paper](https://arxiv.org/abs/2501.07542), [Tweet](https://x.com/omarsar0/status/1879181711982129420)  \n10) ChemAgent - presents a new framework designed to improve the performance of LLMs on chemical reasoning through a dynamic, self-updating library; the library is developed by decomposing chemical tasks into sub-tasks and compiling them into a structured collection that can be referenced for future queries; when the system is given a new problem, it retries and refines relevant information from the library to enable more effective task decomposition; the library is dynamically updated with new sub-tasks and solutions as they are encountered and validated; experiments on SciBench demonstrate that ChemAgent achieves performance gains of up to 46% (GPT-4), significantly outperforming existing methods. | [Paper](https://arxiv.org/abs/2501.06590), [Tweet](https://x.com/omarsar0/status/1879188983705747754)  \n## Top ML Papers of the Week (January 6 - January 12) - 2025\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-january-6---january-12---2025)\n**Paper** | **Links**  \n---|---  \n1) Cache-Augmented Generation (CAG) - an approach that aims to leverage the capabilities of long-context LLMs by preloading the LLM with all relevant docs in advance and precomputing the key-value (KV) cache; the preloaded context helps the model to provide contextually accurate answers without the need for additional retrieval during runtime; the authors suggest that CAG is a useful alternative to RAG for cases where the documents/knowledge for retrieval are of limited, manageable size. | [Paper](https://arxiv.org/pdf/2412.15605), [Tweet](https://x.com/omarsar0/status/1876721221083214200)  \n2) Agent Laboratory - an approach that leverages LLM agents capable of completing the entire research process; the main findings are: 1) agents driven by o1-preview resulted in the best research outcomes, 2) generated machine learning code can achieve state-of-the-art performance compared to existing methods, 3) human feedback further improves the quality of research, and 4) Agent Laboratory significantly reduces research expenses. | [Paper](https://arxiv.org/abs/2501.04227) [Tweet)](https://x.com/omarsar0/status/1877382581358047375)  \n3) Long Context vs. RAG for LLMs - performs a comprehensive evaluation of long context (LC) LLMs compared to RAG systems; the three main findings are: 1) LC generally outperforms RAG in question-answering benchmarks, 2) summarization-based retrieval performs comparably to LC, while chunk-based retrieval lags behind, and 3) RAG has advantages in dialogue-based and general question queries | [Paper](https://arxiv.org/abs/2501.01880), [Tweet](https://x.com/omarsar0/status/1876281074147299569)  \n4) Search-o1 - a framework that combines large reasoning models (LRMs) with agentic search and document refinement capabilities to tackle knowledge insufficiency; the framework enables autonomous knowledge retrieval during reasoning and demonstrates strong performance across complex tasks, outperforming both baseline models and human experts. | [Paper](https://arxiv.org/abs/2501.05366), [Tweet](https://x.com/omarsar0/status/1877742469213004015)  \n5) Towards System 2 Reasoning - proposes Meta Chain-of-Thought (Meta-CoT), which extends traditional Chain-of-Thought (CoT) by modeling the underlying reasoning required to arrive at a particular CoT; the main argument is that CoT is naive and Meta-CoT gets closer to the cognitive process required for advanced problem-solving. | [Paper](https://arxiv.org/abs/2501.04682) [Tweet)](https://x.com/rm_rafailov/status/1877446475271037314)  \n6) rStar-Math - a new approach proposes three core components to enhance math reasoning: 1) a code-augmented CoT data synthesis method involving MCTS to generate step-by-step verified reasoning trajectories which are used to train the policy SLM, 2) an SLM-based process reward model that reliably predicts a reward label for each math reasoning step, and 3) a self-evolution recipe where the policy SLM and PPM are iteratively evolved to improve math reasoning; on the MATH benchmark, rStar-Math improves Qwen2.5-Math-7B from 58.8% to 90.0% and Phi3-mini-3.8B from 41.4% to 86.4%, surpassing o1-preview by +4.5% and +0.9%. | [Paper](https://arxiv.org/abs/2501.04519) [Tweet)](https://x.com/omarsar0/status/1877378301293142050)  \n7) Cosmos World Foundation Model - a framework for training Physical AI systems in digital environments before real-world deployment; the platform includes pre-trained world foundation models that act as digital twins of the physical world, allowing AI systems to safely learn and interact without risking damage to physical hardware; these models can be fine-tuned for specific applications like camera control, robotic manipulation, and autonomous driving. | [Paper](https://research.nvidia.com/publication/2025-01_cosmos-world-foundation-model-platform-physical-ai), [Tweet](https://x.com/EthanHe_42/status/1876487556755521798)  \n8) Process Reinforcement through Implicit Rewards - a framework for online reinforcement learning that uses process rewards to improve language model reasoning; the proposed algorithm combines online prompt filtering, RLOO return/advantage estimation, PPO loss, and implicit process reward modeling online updates; on their model, Eurus-2-7B-PRIME, achieves 26.7% pass@1 on AIME 2024, surpassing GPT-4 and other models, using only 1/10 of the training data compared to similar models. | [Paper](https://curvy-check-498.notion.site/Process-Reinforcement-through-Implicit-Rewards-15f4fcb9c42180f1b498cc9b2eaf896f), [Tweet](https://x.com/lifan__yuan/status/1874867809983033649)  \n9) Can LLMs Design Good Questions? - systematically evaluates the quality of questions generated with LLMs; here are the main findings: 1) there is a strong preference for asking about specific facts and figures in both LLaMA and GPT models, 2) the question lengths tend to be around 20 words but different LLMs tend to exhibit distinct preferences for length, 3) LLM-generated questions typically require significantly longer answers, and 4) human-generated questions tend to concentrate on the beginning of the context while LLM-generated questions exhibit a more balanced distribution, with a slight decrease in focus at both ends. | [Paper](https://arxiv.org/abs/2501.03491), [Tweet](https://x.com/omarsar0/status/1877008618207560049)  \n10) A Survey on LLMs - a new survey on LLMs including some insights on capabilities and limitations. | [Paper](https://arxiv.org/abs/2501.04040), [Tweet](https://x.com/omarsar0/status/1877416049999802408)  \n## Top ML Papers of the Week (December 30 - January 5) - 2025\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-december-30---january-5---2025)\n**Paper** | **Links**  \n---|---  \n1) Agents Are Not Enough - argues that while AI agents show promise, they alone cannot address the challenges in autonomous task execution; proposes a new ecosystem combining three key components: Agents (narrow, purpose-driven modules for specific tasks), Sims (digital representations of user preferences and behaviors), and Assistants (programs that coordinate between users, Sims, and Agents). | [Paper](https://www.arxiv.org/abs/2412.16241), [Tweet](https://x.com/omarsar0/status/1874196827115061741)  \n2) OLMo 2 - introduces an enhanced architecture, training methods, and a specialized data mixture called Dolmino Mix 1124; the fully transparent model, released at 7B and 13B parameter scales with complete training data and code, matches or outperforms similar open-weight models like Llama 3.1 and Qwen 2.5 while using fewer computational resources, and its instruction-tuned version (OLMo 2-Instruct) remains competitive with comparable models. | [Paper](https://arxiv.org/abs/2501.00656), [Tweet](https://x.com/soldni/status/1875266934943649808)  \n3) Machine-Assisted Proof - examines how mathematicians have long used machines to assist with mathematics research and discusses recent AI tools that are transforming mathematical proof assistance. | [Paper](https://www.ams.org//notices/202501/rnoti-p6.pdf), [Tweet](https://x.com/omarsar0/status/1873045937259462656)  \n4) Measuring Higher Level Mathematical Reasoning - introduces Putnam-AXIOM, a new math reasoning benchmark with 236 Putnam Competition problems and 52 variations; even the best model considered (OpenAI's o1-preview) achieves only 41.95% accuracy on original problems and performs significantly worse on variations. | [Paper](https://openreview.net/forum?id=YXnwlZe0yf&noteId=yrsGpHd0Sf), [Tweet](https://x.com/omarsar0/status/1874489752243597635)  \n5) On the Overthinking of LLMs - proposes a self-training strategy to mitigate overthinking in o1-like LLMs; it can reduce token output by 48.6% while maintaining accuracy on the widely-used MATH500 test set as applied to QwQ-32B-Preview. | [Paper](https://arxiv.org/abs/2412.21187), [Tweet](https://x.com/omarsar0/status/1874848885170176364)  \n6) MEDEC - introduces MEDEC, a publicly available benchmark for medical error detection and correction in clinical notes, covering five types of errors (Diagnosis, Management, Treatment, Pharmacotherapy, and Causal Organism); it consists of 3,848 clinical texts, including 488 clinical notes from three US hospital systems; experimental results shows that Cluade 3.5 Sonnet performs better at detecting errors while o1-preview is better at correcting errors. | [Paper](https://arxiv.org/abs/2412.19260), [Tweet](https://x.com/omarsar0/status/1875232390265577675)  \n7) 1.58-bit FLUX - presents the first successful approach to quantizing the state-of-the-art text-to-image generation model, FLUX.1-dev, using 1.58-bit weights (i.e., values in {-1, 0, +1}); the method relies on self-supervision from the FLUX.1-dev model and maintains comparable performance for generating 1024 x 1024 images as the original FLUX model. | [Paper](https://arxiv.org/abs/2412.18653), [Tweet](https://x.com/_akhaliq/status/1873782702178263549)  \n8) Aviary - an extensible open-source gymnasium that can help build language agents that exceed the performance of zero-shot frontier LLMs and even humans on several challenging scientific tasks. | [Paper](https://arxiv.org/abs/2412.21154), [Tweet](https://x.com/omarsar0/status/1875270927304511535)  \n9) Memory Layers at Scale - demonstrates the effectiveness of memory layers at scale; shows that models with these memory layers outperform traditional dense models using half the computation, particularly in factual tasks; includes a parallelizable memory layer implementation that scales to 128B memory parameters and 1 trillion training tokens, tested against base models up to 8B parameters. | [Paper](https://arxiv.org/abs/2412.09764), [Tweet](https://x.com/AIatMeta/status/1874897646542033030)  \n10) HuatuoGPT-o1 - presents a novel approach to improving medical reasoning in language models by using a medical verifier to validate model outputs and guide the development of complex reasoning abilities; the system employs a two-stage approach combining fine-tuning and reinforcement learning with verifier-based rewards, achieving superior performance over existing models while using only 40,000 verifiable medical problems. | [Paper](https://arxiv.org/abs/2412.18925), [Tweet](https://x.com/_akhaliq/status/1873572891092283692)  \n## Top ML Papers of the Week (December 23 - December 29) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-december-23---december-29---2024)\n**Paper** | **Links**  \n---|---  \n1) **DeepSeek-V3** - a 671B-parameter MoE language model that activates 37B parameters per token, utilizing MLA and DeepSeekMoE architectures for efficient operation; it introduces an auxiliary-loss-free load balancing approach and employs multi-token prediction during training to enhance performance; following pre-training on 14.8 trillion tokens, the model underwent SFT and RL stages, achieving performance comparable to leading closed-source models while surpassing other open-source alternatives; the model requires only 2.788M H800 GPU hours for training, with stable training that avoids any irrecoverable loss spikes. | [Paper](https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf), [Tweet](https://x.com/deepseek_ai/status/1872242657348710721)  \n2) **Large Concept Models** - presents an approach that operates on sentence-level semantic representations called concepts, moving beyond token-level processing typical in current LLMs; the model leverages SONAR sentence embeddings to support 200 languages across text and speech modalities, training on autoregressive sentence prediction using various approaches from MSE regression to diffusion-based generation; experiments with both 1.6B and 7B parameter variants trained on 1.3T and 7.7T tokens respectively demonstrate strong performance on generative tasks like summarization and summary expansion. | [Paper](https://ai.meta.com/research/publications/large-concept-models-language-modeling-in-a-sentence-representation-space), [Tweet](https://x.com/AIatMeta/status/1871263650935365759)  \n3) **ModernBERT** - a new encoder-only transformer model that achieves state-of-the-art performance on classification and retrieval tasks while being more efficient than previous encoders; it was trained on 2T tokens with 8192 sequence length and incorporates modern optimizations that represent a significant improvement over BERT; the model is specifically designed for practical deployment, offering superior speed and memory efficiency on common GPUs. | [Paper](https://arxiv.org/abs/2412.13663), [Tweet](https://x.com/jeremyphoward/status/1869786023963832509)  \n4) **Automating the Search for Artificial Life** - presents a new approach that uses foundation models to automatically discover interesting artificial life simulations across multiple platforms like Boids, Lenia, and Game of Life; the system can find simulations that produce specific target behaviors, discovers simulations that generate temporally open-ended novelty, and map out diverse simulation spaces; it discovers new lifeforms in Lenia and Boids, while also enabling quantitative measurement of previously qualitative phenomena in a human-aligned way. | [Paper](https://arxiv.org/abs/2412.17799), [Tweet](https://x.com/SakanaAILabs/status/1871385917342265592)  \n5) **A Survey on LLM Inference-Time Self-Improvement** - presents a survey that analyzes three categories of LLM inference-time self-improvement techniques - independent methods like enhanced decoding, context-aware approaches using external data, and model collaboration strategies. | [Paper](https://arxiv.org/abs/2412.14352), [Tweet](https://x.com/omarsar0/status/1870129825282658752)  \n6) **Explore Theory-of-Mind** - introduces ExploreToM, a framework that uses A* search to generate diverse, complex theory-of-mind scenarios that reveal significant limitations in current LLMs' social intelligence capabilities; testing showed even advanced models like GPT-4 and Llama-3 perform poorly (as low as 5% accuracy) on these challenging scenarios, despite their strong performance on simpler benchmarks; fine-tuning on ExploreToM data improved performance on existing benchmarks by 27 points. | [Paper](https://ai.meta.com/research/publications/explore-theory-of-mind-program-guided-adversarial-data-generation-for-theory-of-mind-reasoning/), [Tweet](https://x.com/AIatMeta/status/1869457933727416375)  \n7) **LearnLM** - a new LearnLM model that can follow pedagogical instructions, allowing it to adapt its teaching approach based on specified educational needs rather than defaulting to simply presenting information; experimental results show that LearnLM is preferred over other leading models, outperforming GPT-4 by 31%, Claude 3.5 by 11%, and Gemini 1.5 Pro by 13%; this instruction-following approach avoids committing to a single pedagogical framework, instead enabling teachers and developers to specify their desired teaching behaviors while allowing for continuous improvement alongside other capabilities. | [Paper](https://services.google.com/fh/files/misc/improving-gemini-for-education_v7.pdf), [Tweet](https://x.com/Google/status/1869798188233699346)  \n8) **Empowering MLLM with o1-like Reasoning and Reflection** - proposes a new learning-to-reason method called CoMCTS that enables multimodal language models to develop step-by-step reasoning capabilities by leveraging collective knowledge from multiple models; the approach was used to create Mulberry-260k, a dataset with explicit reasoning trees, which was then used to train the Mulberry model series; the method demonstrates strong performance on benchmarks, with the models showing improved reasoning and reflection capabilities. | [Paper](https://arxiv.org/abs/2412.18319), [Tweet](https://x.com/_akhaliq/status/1872326647606841651)  \n9) **Reinforcement Learning Overview** - presents a comprehensive overview of reinforcement learning. | [Paper](https://arxiv.org/abs/2412.05265), [Tweet](https://x.com/omarsar0/status/1866123264965419460)  \n10) **DRT-o1** - applies long chain-of-thought reasoning to machine translation, particularly for handling metaphors and similes across different cultures; the system uses a multi-agent framework with a translator working iteratively with an advisor and evaluator to produce better translations; testing with Qwen2.5 models showed significant improvements in BLEU and CometScore metrics, with DRT-o1-7B outperforming larger models like QwQ-32B-Preview. | [Paper](https://arxiv.org/abs/2412.17498), [Tweet](https://x.com/_akhaliq/status/1871455986189574320)  \n## Top ML Papers of the Week (December 16 - December 22) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-december-16---december-22---2024)\n**Paper** | **Links**  \n---|---  \n1) **Genesis** - a new universal physics simulation platform that combines a high-performance physics engine with generative AI capabilities; it enables natural language-driven creation of robotic simulations, character animations, and interactive 3D environments at speeds up to 430,000 times faster than in real-time. | [Paper](https://genesis-embodied-ai.github.io/), [Tweet](https://x.com/zhou_xian_/status/1869511650782658846)  \n2) **Alignment Faking in LLMs** - demonstrates that the Claude model can engage in \"alignment faking\"; it can strategically comply with harmful requests to avoid retraining while preserving its original safety preferences; this raises concerns about the reliability of AI safety training methods. | [Paper](https://arxiv.org/abs/2412.14093), [Tweet](https://x.com/AnthropicAI/status/1869427646368792599)  \n3) **TheAgentCompany** - a new benchmark for evaluating AI agents on real-world professional tasks in a simulated software company environment; tasks span multiple professional roles including software engineering, project management, finance, and HR; when tested with various LLMs, including both API-based models like Claude-3.5-Sonnet and open-source models like Llama 3.1, the results show the current limitations of AI agents. The best-performing model, Claude-3.5-Sonnet, achieved only a 24% success rate on completing tasks fully while scoring 34.4% when accounting for partial progress. | [Paper](https://arxiv.org/abs/2412.14161), [Tweet](https://x.com/gneubig/status/1869735196700062089)  \n4) **Graphs to Text-Attributed Graphs** - automatically generates textual descriptions for nodes in a graph which leads to effective graph to text-attributed graph transformation; evaluates the approach on text-rich, text-limited, and text-free graphs, demonstrating that it enables a single GNN to operate across diverse graphs. | [Paper](https://arxiv.org/abs/2412.10136), [Tweet](https://x.com/omarsar0/status/1868691391129272461)  \n5) **Qwen-2.5 Technical Report** - Alibaba releases Qwen2.5, a new series of LLMs trained on 18T tokens, offering both open-weight models like Qwen2.5-72B and proprietary MoE variants that achieve competitive performance against larger models like Llama-3 and GPT-4. | [Paper](https://arxiv.org/abs/2412.15115), [Tweet](https://x.com/Alibaba_Qwen/status/1869950647501824015)  \n6) **PAE (Proposer-Agent-Evaluator)** - a learning system that enables AI agents to autonomously discover and practice skills through web navigation, using reinforcement learning and context-aware task proposals to achieve state-of-the-art performance on real-world benchmarks. | [Paper](https://arxiv.org/abs/2412.13194)  \n7) **DeepSeek-VL2** - a new series of vision-language models featuring dynamic tiling for high-resolution images and efficient MoE architecture, achieving competitive performance across visual tasks; achieves competitive or state-of-the-art performance with similar or fewer activated parameters compared to existing open-source dense and MoE-based models. | [Paper](https://arxiv.org/abs/2412.10302), [Tweet](https://x.com/omarsar0/status/1868696154067865659)  \n8) **AutoFeedback** - a two-agent AI system that generates more accurate and pedagogically sound feedback for student responses in science assessments, significantly reducing common errors like over-praise compared to single-agent models. | [Paper](https://arxiv.org/abs/2411.07407)  \n9) **A Survey of Mathematical Reasoning in the Era of Multimodal LLMs** - presents a comprehensive survey analyzing mathematical reasoning capabilities in multimodal large language models (MLLMs), covering benchmarks, methodologies, and challenges across 200+ studies since 2021. | [Paper](https://arxiv.org/abs/2412.11936), [Tweet](https://x.com/omarsar0/status/1870126516832792811)  \n10) **Precise Length Control in LLMs** - adapts a pre-trained decoder-only LLM to produce responses of a desired length; integrates a secondary length-difference positional encoding into the input embeddings which enables counting down to a user-set response terminal length; claims to achieve mean token errors of less than 3 tokens without compromising quality. | [Paper](https://arxiv.org/abs/2412.11937), [Tweet](https://x.com/omarsar0/status/1869030043084845453)  \n## Top ML Papers of the Week (December 9 - December 15) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-december-9---december-15---2024)\n**Paper** | **Links**  \n---|---  \n1) **Training LLMs to Reason in a Continuous Latent Space** - presents Coconut (Chain of Continuous Thought), a novel paradigm that enables LLMs to reason in continuous latent space rather than natural language; Coconut takes the last hidden state of the LLM as the reasoning state and feeds it back to the LLM as the subsequent input embedding directly in the continuous space; this leads to what the authors refer to as \"continuous thought\" which augments an LLM's capability on reasoning tasks; it demonstrates improved performance on complex reasoning tasks through emergent breadth-first search capabilities. | [Paper](https://arxiv.org/abs/2412.06769), [Tweet](https://x.com/omarsar0/status/1866518791733342563)  \n2) **Phi-4 Technical Report** - presents phi-4, a 14B model that surpasses its teacher model on STEM-QA capabilities. It also reports strong performance on reasoning-focused benchmarks due to improved data, training curriculum, and innovations in the post-training scheme. | [Paper](https://arxiv.org/abs/2412.08905), [Tweet](https://x.com/omarsar0/status/1867609628529635574)  \n3) **Asynchronous Function Calling** - proposes AsyncLM, a system for asynchronous LLM function calling; they design an in-context protocol for function calls and interrupts, provide fine-tuning strategy to adapt LLMs to the interrupt semantics, and implement these mechanisms efficiently on LLM inference process; AsyncLM can reduce task completion latency from 1.6x-5.4x compared to synchronous function calling; it enables LLMs to generate and execute function calls concurrently. | [Paper](https://arxiv.org/abs/2412.07017), [Tweet](https://x.com/omarsar0/status/1866855077983686804)  \n4) **MAG-V** - a multi-agent framework that first generates a dataset of questions that mimic customer queries; it then reverse engineers alternate questions from responses to verify agent trajectories; reports that the generated synthetic data can improve agent performance on actual customer queries; finds that for trajectory verification simple ML baselines with feature engineering can match the performance of more expensive and capable models. | [Paper](https://arxiv.org/abs/2412.04494), [Tweet](https://x.com/omarsar0/status/1866143542726340890)  \n5) **Clio** - proposes a platform using AI assistants to analyze and surface private aggregated usage patterns from millions of Claude.ai conversations; enables insights into real-world AI use while protecting user privacy; the system helps identify usage trends, safety risks, and coordinated misuse attempts without human reviewers needing to read raw conversations. | [Paper](https://assets.anthropic.com/m/7e1ab885d1b24176/original/Clio-Privacy-Preserving-Insights-into-Real-World-AI-Use.pdf), [Tweet](https://x.com/AnthropicAI/status/1867325190352576780)  \n6) **A Survey on LLMs-as-Judges** - presents a comprehensive survey of the LLMs-as-judges paradigm from five key perspectives: Functionality, Methodology, Applications, Meta-evaluation, and Limitations. | [Paper](https://arxiv.org/abs/2412.05579), [Tweet](https://x.com/omarsar0/status/1866541394015518824)  \n7) **AutoReason Improves Multi-step Reasoning** - proposes a method to automatically generate rationales for queries using CoT prompting; this transforms zero-shot queries into few-shot reasoning traces which are used as CoT exemplars by the LLM; claims to improve reasoning in weaker LLMs. | [Paper](https://arxiv.org/abs/2412.06975), [Tweet](https://x.com/omarsar0/status/1867224350287372555)  \n8) **The Byte Latent Transformer (BLT)** - introduces a byte-level language model architecture that matches tokenization-based LLM performance while improving efficiency and robustness; uses a dynamic method of grouping bytes into patches based on the entropy of the next byte, allocating more compute resources to complex predictions while using larger patches for more predictable sequences; BLT demonstrates the ability to match or exceed the performance of models like Llama 3 while using up to 50% fewer FLOPs during inference. | [Paper](https://ai.meta.com/research/publications/byte-latent-transformer-patches-scale-better-than-tokens/), [Tweet](https://x.com/ArtidoroPagnoni/status/1867601413741981804)  \n9) **Does RLHF Scale?** - This new paper explores the impacts of key components in the RLHF framework. Summary of main findings: 1) RLHF doesn't scale as effectively as pretraining in LLMs, with larger policy models benefiting less from RLHF when using a fixed reward model, 2) when increasing the number of responses sampled per prompt during policy training, performance improves initially but plateaus quickly, typically around 4-8 samples, 3) using larger reward models leads to better performance in reasoning tasks, but the improvements can be inconsistent across different types of tasks, and 4) increasing training data diversity for reward models is more effective than increasing response diversity per prompt, but policy training shows diminishing returns after the early stages regardless of additional data. | [Paper](https://arxiv.org/abs/2412.06000), [Tweet](https://x.com/omarsar0/status/1866525606562680954)  \n10) **Granite Guardian** - IBM open-sources Granite Guardian, a suite of safeguards for risk detection in LLMs; the authors claim that With AUC scores of 0.871 and 0.854 on harmful content and RAG-hallucination-related benchmarks respectively, Granite Guardian is the most generalizable and competitive model available in the space. | [Paper](https://arxiv.org/abs/2412.07724), [Tweet](https://x.com/omarsar0/status/1866852443621036228)  \n## Top ML Papers of the Week (December 2 - December 8) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-december-2---december-8---2024)\n**Paper** | **Links**  \n---|---  \n1) **OpenAI o1** - a model series trained with large-scale reinforcement learning to reason using chain of thought; o1 shows significant improvements across benchmarks related to math, code, and science; o1 is claimed to be 50% faster in generating thinking steps than o1-preview; results demonstrate that o1 is significantly better at reasoning tasks and produces more comprehensive and reliable responses. | [Paper](https://cdn.openai.com/o1-system-card-20241205.pdf), [Tweet](https://x.com/OpenAI/status/1864729936847868192)  \n2) **Genie 2** - a foundation world model that generates playable 3D environments from single prompt images, enabling endless training scenarios for AI agents with features like physics simulation, character animation, and object interactions; Genie 2 is trained on video data using a combination of autoencoder and transformer for generating virtual worlds; the model can create real-time interactive environments, with a faster but lower-quality version available for immediate play. | [Paper](https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model), [Tweet](https://x.com/GoogleDeepMind/status/1864367798132039836)  \n3) **Reverse Thinking** - shows that training LLMs to learn \"reverse thinking\" helps to improve performance in commonsense, math, and logical reasoning tasks. It claims to outperform a standard fine-tuning method trained on 10x more forward reasoning. | [Paper](https://arxiv.org/abs/2411.19865), [Tweet](https://x.com/omarsar0/status/1863595518649098371)  \n4) **ALAMA** - a new framework that helps language agents automatically learn when to use different mechanisms (ReAct, CoT, Reflection, etc.) for automatically completing tasks, improving on current approaches that use fixed or predefined mechanisms; the framework adaptively activates the appropriate mechanisms according to the potential characteristics of the task; experimental results demonstrate significant improvements in downstream agent tasks, including mathematical reasoning and knowledge-intensive reasoning. | [Paper](https://arxiv.org/abs/2412.00722), [Tweet](https://x.com/omarsar0/status/1863956776623747433)  \n5) **Auto-RAG** - an autonomous iterative retrieval model with superior performance across many datasets; Auto-RAG is a fine-tuned LLM that leverages the decision-making capabilities of an LLM; it interacts with the retriever through multiturn dialogues, systematically planning retrievals and refining queries to acquire valuable knowledge â it performs this process until sufficient external information is obtained; the authors also show that based on question difficulty, the method can adjust the number of iterations without any human intervention. | [Paper](https://arxiv.org/abs/2411.19443), [Tweet](https://x.com/omarsar0/status/1863600141103501454)  \n6) **GenCast** - an ML weather prediction model that outperforms the world's leading operational weather forecasting system (ECMWF's ENS) in both accuracy and speed; it generates probabilistic 15-day global weather forecasts for over 80 variables in just 8 minutes, with better skill than ENS on 97.2% of evaluated targets; GenCast produces an ensemble of forecasts that better capture uncertainty and predict extreme weather events, tropical cyclone tracks, and wind power production. | [Paper](https://www.nature.com/articles/s41586-024-08252-9), [Tweet](https://x.com/GoogleDeepMind/status/1864340994965098513)  \n7) **Challenges in Human-Agent Communication** - present a comprehensive analysis of key challenges in human-agent communication, focusing on how humans and AI agents can effectively establish common ground and mutual understanding; identifies 12 core challenges across three categories: conveying information from agents to users, enabling users to communicate information to agents, and general communication challenges that affect all interactions. | [Paper](https://www.microsoft.com/en-us/research/uploads/prod/2024/12/HCAI_Agents.pdf)  \n8) **Retrieval-Augmented Reasoning for LLMs** - extends the rStar reasoning framework to enhance reasoning accuracy and factual reliability of LLMs; it leverages a Monte Carlos Tree Search (MCTS) framework with explicit retrieval-augmented reasoning to produce multiple candidate reasoning trajectories; then it leverages a retrieval-augmented factuality scorer to evaluate the factual accuracy of the reasoning trajectories; the trajectory with the highest factuality score is selected as the final answer by the system; on medical reasoning tasks, RARE (which uses Llama 3.1) surpasses larger models such as GPT-4; on commonsense reasoning tasks, RARE outperformed Claude-3.5 Sonnet and GPT-4o-mini, achieving performance competitive with GPT-4o. | [Paper](https://arxiv.org/abs/2412.02830), [Tweet](https://x.com/omarsar0/status/1864687176929431566)  \n9) **DataLab** - a unified business intelligence platform powered by LLM-based agents that integrates task planning, reasoning, and computational notebooks to streamline the entire BI workflow; the system achieves SOTA performance on research benchmarks and demonstrates significant improvements in accuracy and efficiency on real enterprise data from Tencent; achieves up to a 58.58% increase in accuracy and a 61.65% reduction in token cost on enterprise-specific BI tasks. | [Paper](https://arxiv.org/abs/2412.02205), [Tweet](https://x.com/omarsar0/status/1864327307177152619)  \n10) **Procedural Knowledge in Pretraining Drives Reasoning in LLMs** - studies what documents in the pertaining influence model outputs; by looking at the pertaining data, it tries to understand better what kind of generalization strategies LLMs use to perform reasoning tasks; when performing reasoning tasks, it finds that influential documents contain procedural knowledge (e.g., demonstrating how to obtain a solution using formulae or code). | [Paper](https://arxiv.org/abs/2411.12580), [Tweet](https://x.com/omarsar0/status/1863590537346925032)  \n## Top ML Papers of the Week (November 25 - December 1) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-november-25---december-1---2024)\n**Paper** | **Links**  \n---|---  \n1) **LLM Surpass Human Experts in Predicting Neuroscience Results** - proposes BrainBench to study how good LLMs are at predicting experimental outcomes in neuroscience; they tuned an LLM, BrainGPT, on neuroscience literature that surpasses experts in predicting neuroscience results; report that when LLMs indicated high confidence in their predictions, their responses were more likely to be correct. | [Paper](https://www.nature.com/articles/s41562-024-02046-9), [Tweet](https://x.com/omarsar0/status/1861781028291190887)  \n2) **Fugatto** - a new generative AI sound model (presented by NVIDIA) that can create and transform any combination of music, voices, and sounds using text and audio inputs, trained on 2.5B parameters and capable of novel audio generation like making trumpets bark or saxophones meow. | [Paper](https://d1qx31qr3h6wln.cloudfront.net/publications/FUGATTO.pdf), [Tweet](https://x.com/NVIDIAAIDev/status/1861052624352825383)  \n3) **o1 Replication Journey - Part 2** - shows that combining simple distillation from o1's API with supervised fine-tuning significantly boosts performance on complex math reasoning tasks; a base model fine-tuned on simply tens of thousands of samples o1-distilled long-thought chains outperform o1-preview on the American Invitational Mathematics Examination (AIME). | [Paper](https://arxiv.org/abs/2411.16489), [Tweet](https://x.com/omarsar0/status/1861411844554113276)  \n4) **LLM-Brained GUI Agents** - presents a survey of LLM-brained GUI Agents, including techniques and applications. | [Paper](https://arxiv.org/abs/2411.18279), [Tweet](https://x.com/omarsar0/status/1862133601040752820)  \n5) **High-Level Automated Reasoning** - extends in-context learning through high-level automated reasoning; achieves state-of-the-art accuracy (79.6%) on the MATH benchmark with Qwen2.5-7B-Instruct, surpassing GPT-4o (76.6%) and Claude 3.5 (71.1%); rather than focusing on manually creating high-quality demonstrations, it shifts the focus to abstract thinking patterns; it introduces five atomic reasoning actions to construct chain-structured patterns; then it uses Monte Carlo Tree Search to explore reasoning paths and construct thought cards to guide inference. | [Paper](https://arxiv.org/abs/2411.18478), [Tweet](https://x.com/omarsar0/status/1862131336653533584)  \n6) **Star Attention: Efficient LLM Inference over Long Sequences** - introduces Star Attention, a two-phase attention mechanism that processes long sequences by combining blockwise-local attention for context encoding with sequence-global attention for query processing and token generation; achieves up to 11x faster inference speeds while maintaining 95-100% accuracy compared to traditional attention mechanisms by efficiently distributing computation across multiple hosts; a key innovation is the \"anchor block\" mechanism, where each context block is prefixed with the first block, enabling effective approximation of global attention patterns while reducing computational overhead. | [Paper](https://arxiv.org/abs/2411.17116), [Tweet](https://x.com/omarsar0/status/1861854543694406109)  \n7) **Survey on LLM-as-a-Judge** - provides a comprehensive survey of LLM-as-a-Judge, including a deeper discussion on how to build reliable LLM-as-a-Judge systems. | [Paper](https://arxiv.org/abs/2411.15594), [Tweet](https://x.com/omarsar0/status/1861411159913472229)  \n8) **TÃLU 3** - releases a family of fully-open state-of-the-art post-trained models, alongside its data, code, and training recipes, serving as a comprehensive guide for modern post-training techniques. | [Paper](https://arxiv.org/abs/2411.15124), [Tweet](https://x.com/omarsar0/status/1861085195950256335)  \n9) **Generative Agent Simulations of 1,000 People** - introduces a new agent architecture that uses LLMs to create behavioral simulations of real individuals, achieving 85% accuracy in replicating human responses on the General Social Survey and reducing demographic biases compared to traditional approaches. | [Paper](https://arxiv.org/abs/2411.10109), [Tweet](https://x.com/percyliang/status/1861136757435015580)  \n10) **Measuring Bullshit in Language Games Played by ChatGPT** - proposes that LLM-based chatbots play the âlanguage game of bullshitâ; by asking ChatGPT to generate scientific articles on topics where it has no knowledge or competence, the authors were able to provide a reference set of how this âbullshitâ is manifested. | [Paper](https://arxiv.org/abs/2411.15129), [Tweet](https://x.com/omarsar0/status/1861066315789942978)  \n## Top ML Papers of the Week (November 18 - November 24) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-november-18---november-24---2024)\n**Paper** | **Links**  \n---|---  \n1) **AlphaQubit** - a new AI-based decoder that sets a state-of-the-art benchmark for identifying errors in quantum computers; using transformer architecture, AlphaQubit demonstrated 6% fewer errors than tensor network methods and 30% fewer errors than correlated matching when tested on the Sycamore data; shows promising results in simulations of larger systems up to 241 qubits; while this represents significant progress in quantum error correction, the system still needs improvements in speed before it can correct errors in real-time for practical quantum computing applications. | [Paper](https://www.nature.com/articles/s41586-024-08148-8), [Tweet](https://x.com/GoogleDeepMind/status/1859273133234192598)  \n2) **The Dawn of GUI Agent** - explores Claude 3.5 computer use capabilities across different domains and software; they also provide an out-of-the-box agent framework for deploying API-based GUI automation models; Claude 3.5 Computer Use demonstrates unprecedented ability in end-to-end language to desktop actions. | [Paper](https://arxiv.org/abs/2411.10323), [Tweet](https://x.com/omarsar0/status/1858526493661446553)  \n3) **A Statistical Approach to LLM Evaluation** - proposes five key statistical recommendations for a more rigorous evaluation of LLM performance differences. The recommendations include: 1) using the Central Limit Theorem to measure theoretical averages across all possible questions rather than just observed averages; 2) clustering standard errors when questions are related rather than independent; 3) reducing variance within questions through resampling or using next-token probabilities; 4) analyzing paired differences between models since questions are shared across evaluations, and 5) using power analysis to determine appropriate sample sizes for detecting meaningful differences between models; the authors argue that these statistical approaches will help researchers better determine whether performance differences between models represent genuine capability gaps or are simply due to chance, leading to more precise and reliable model evaluations. | [Paper](https://arxiv.org/abs/2411.00640), [Tweet](https://x.com/AnthropicAI/status/1858976458330505639)  \n4) **Towards Open Reasoning Models for Open-Ended Solutions** - proposes Marco-o1 which is a reasoning model built for open-ended solutions; Marco-o1 is powered by Chain-of-Thought (CoT) fine-tuning, Monte Carlo Tree Search (MCTS), reflection mechanisms, and more recent reasoning strategies; Marco-o1 achieves accuracy improvements of +6.17% on the MGSM (English) dataset and +5.60% on the MGSM (Chinese) dataset. | [Paper](https://arxiv.org/abs/2411.14405), [Tweet](https://x.com/omarsar0/status/1860003607606706197)  \n5) **LLM-based Agents for Automated Bug Fixing** - analyzes seven leading LLM-based bug fixing systems on the SWE-bench Lite benchmark, finding MarsCode Agent (developed by ByteDance) achieved the highest success rate at 39.33%; reveals that for error localization line-level fault localization accuracy is more critical than file-level accuracy, and bug reproduction capabilities significantly impact fixing success; shows that 24/168 resolved issues could only be solved using reproduction techniques, though reproduction sometimes misled LLMs when issue descriptions were already clear; concludes that improvements are needed in both LLM reasoning capabilities and Agent workflow design to enhance automated bug fixing effectiveness. | [Paper](https://arxiv.org/abs/2411.10213), [Tweet](https://x.com/omarsar0/status/1859964808789135668)  \n6) **Cut Your Losses in Large-Vocabulary Language Models** - introduces Cut Cross-Entropy (CCE), a novel method to significantly reduce memory usage during LLM training by optimizing how the cross-entropy loss is computed; currently, the cross-entropy layer in LLM training consumes a disproportionate amount of memory (up to 90% in some models) due to storing logits for all possible vocabulary tokens. CCE addresses this by only computing logits for the correct token and evaluating the log-sum-exp over all logits on the fly using flash memory; the authors show that the approach reduces the memory footprint of Gemma 2 from 24GB to just 1MB; the method leverages the inherent sparsity of softmax calculations to skip elements that contribute negligibly to gradients; finally, it demonstrates that CCE achieves this dramatic memory reduction without sacrificing training speed or convergence, enabling larger batch sizes during training and potentially more efficient scaling of LLM training. | [Paper](https://arxiv.org/abs/2411.09009)  \n7) **BABY-AIGS** - a multi-agent system for automated scientific discovery that emphasizes falsification through automated ablation studies. The system was tested on three ML tasks (data engineering, self-instruct alignment, and language modeling), demonstrating the ability to produce meaningful scientific discoveries. However, the performance is below experienced human researchers. | [Paper](https://arxiv.org/abs/2411.11910v1), [Tweet](https://x.com/omarsar0/status/1859656533489188928)  \n8) **Does Prompt Formatting Impact LLM Performance** - examines how different prompt formats (plain text, Markdown, JSON, and YAML) affect GPT model performance across various tasks; finds that GPT-3.5-turbo's performance can vary by up to 40% depending on the prompt format, while larger models like GPT-4 show more robustness to format changes; argues that there is no universally optimal format across models or tasks - for instance, GPT-3.5-turbo generally performed better with JSON formats while GPT-4 preferred Markdown; models from the same family showed similar format preferences, but these preferences didn't transfer well between different model families; suggests that prompt formatting significantly impacts model performance and should be carefully considered when performing prompt engineering and model evaluation, and how to apply it to applications. | [Paper](https://arxiv.org/abs/2411.10541)  \n9) **FinRobot** - an AI agent framework for equity research that uses a multi-agent Chain-of-Thought prompting, combining data analysis with human-like reasoning to produce professional investment reports comparable to major brokerages; it leverage three agents: a Data-CoT Agent to aggregate diverse data sources for robust financial integration; the Concept-CoT Agent, for analystâs reasoning to generate actionable insights; and the Thesis-CoT Agent to synthesizes these insights into a coherent investment thesis and report. | [Paper](https://arxiv.org/abs/2411.08804)  \n10) **Bi-Mamba** - a scalable 1-bit Mamba architecture designed for more efficient LLMs with multiple sizes across 780M, 1.3B, and 2.7B; Bi-Mamba achieves performance comparable to its full-precision counterparts (e.g., FP16 or BF16); it significantly reduces memory footprint with better accuracy than posttraining-binarization Mamba baselines. | [Paper](https://arxiv.org/abs/2411.11843)  \n## Top ML Papers of the Week (November 11 - November 17) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-november-11---november-17---2024)\n**Paper** | **Links**  \n---|---  \n1) **Impacts of AI on Innovation** - suggests that top scientists leverage their domain knowledge to prioritize promising AI suggestions, while others waste significant resources testing false positives; finds that implementing AI materials discovery technology leads to substantial increases in productivity, with 44% more materials discovered, 39% more patent filings, and 17% more product innovation; reports that these gains came with concerning tradeoffs, as 82% of scientists reported reduced job satisfaction due to decreased creativity and skill underutilization. | [Paper](https://aidantr.github.io/files/AI_innovation.pdf), [Tweet](https://x.com/omarsar0/status/1856424446720127024)  \n2) **Scaling Laws for Precision** - introduces \"precision-aware\" scaling laws that predict how model performance is affected by both training and inference precision in LLMs; key findings include: 1) post-training quantization becomes more harmful as models are trained on more data, eventually making additional pretraining actively detrimental, 2) training in lower precision requires increasing model size to maintain performance, and 3) when jointly optimizing model size, data, and precision, the compute-optimal training precision is around 7-8 bits and independent of compute; also reports that when the model size is fixed, compute-optimal precision increases approximately logarithmically with data; the authors validate their predictions on models up to 1.7B parameters trained on up to 26B tokens, showing that both very high (16-bit) and very low (sub 4-bit) training precisions may be suboptimal. | [Paper](https://arxiv.org/abs/2411.04330), [Tweet](https://x.com/tanishqkumar07/status/1856045600355352753)  \n3) **Evo** - a 7B parameter AI model designed to understand and generate DNA sequences across multiple biological scales; the model, trained on 2.7 million prokaryotic and phage genomes, can process sequences up to 131 kilobases long while maintaining single-nucleotide resolution, enabling it to understand both molecular-level interactions and genome-wide patterns; Evo demonstrates superior performance in predicting and generating functional DNA, RNA, and protein sequences, including the first successful AI-generated CRISPR-Cas complexes and transposable systems that have been experimentally validated. | [Paper](https://www.science.org/doi/10.1126/science.ado9336), [Tweet](https://x.com/arcinstitute/status/1857138107038187945)  \n4) **OpenCoder** - introduces OpenCoder, a fully open-source LLM specialized for code generation and understanding; the authors identify several critical factors for building high-performing code LLMs: (1) effective data cleaning with code-optimized heuristic rules for deduplication, (2) recall of relevant text corpus related to code, and (3) high-quality synthetic in both annealing and supervised fine-tuning stages; OpenCoder surpasses previous fully open models at the 6B+ parameter scale and releases not just the model weights but also the complete training pipeline, datasets, and protocols to enable reproducible research. | [Paper](https://arxiv.org/abs/2411.04905), [Tweet](https://x.com/omarsar0/status/1857515355595526450)  \n5) **The Surprising Effectiveness of Test-Time Training for Abstract Reasoning** - explores test-time training (TTT) - updating model parameters temporarily during inference - for improving an LLM's abstract reasoning capabilities using the ARC benchmark; identifies three crucial components: initial fine-tuning on similar tasks, auxiliary task format and augmentations, and per-instance training; TTT significantly improves performance, achieving up to 6x improvement in accuracy compared to base fine-tuned models; when applying TTT to an 8B LLM, they achieve 53% accuracy on ARC's public validation set, improving the state-of-the-art for neural approaches by nearly 25%; by ensembling their method with program generation approaches, they achieve state-of-the-art public validation accuracy of 61.9%, matching average human performance; the findings suggest that explicit symbolic search is not the only path to improved abstract reasoning in LLMs; test-time training applied to continued training on few-shot examples can be highly effective. | [Paper](https://ekinakyurek.github.io/papers/ttt.pdf), [Tweet](https://x.com/akyurekekin/status/1855680785715478546)  \n6) **A Taxonomy of AgentOps for Enabling Observability of Foundation Model-based Agents** - analyzes AgentOps platforms and tools, highlighting the need for comprehensive observability and traceability features to ensure reliability in foundation model-based autonomous agent systems across their development and production lifecycle. | [Paper](https://arxiv.org/abs/2411.05285v1), [Tweet](https://x.com/omarsar0/status/1857400667318702118)  \n7) **Toward Optimal Search and Retrieval for RAG** - examines how retrieval affects performance in RAG pipelines for QA tasks; conducts experiments using BGE-base and ColBERT retrievers with LLaMA and Mistral, finding that including more gold (relevant) documents improves QA accuracy; finds that using approximate nearest neighbor search with lower recall only minimally impacts performance while potentially improving speed and memory efficiency; reports that adding noisy or irrelevant documents consistently degrades performance, contradicting previous research claims; concludes that optimizing retrieval of gold documents is crucial for RAG performance, and that operating at lower search accuracy levels can be a viable approach for practical applications. | [Paper](https://arxiv.org/abs/2411.07396), [Tweet](https://x.com/omarsar0/status/1856709865802252710)  \n8) **Mitigating LLM Jailbreaks with Few Examples** - introduces a new approach called for defending LLMs against jailbreak attacks, focusing on quickly adapting defenses after detecting new attacks rather than aiming for perfect adversarial upfront robustness; using a new benchmark, the most effective method, based on fine-tuning an input classifier, reduced attack success rates by over 240x for known attack types and 15x for novel variations after seeing just one example of each attack strategy; demonstrates that rapidly responding to new jailbreaks can be an effective alternative to traditional static defenses. | [Paper](https://arxiv.org/abs/2411.07494), [Tweet](https://x.com/AnthropicAI/status/1856752093945540673)  \n9) **Mixture of Transformers** - introduce Mixture-of-Transformers (MoT), a new sparse multi-modal transformer architecture that matches the performance of traditional models while using only about half the computational resources for text and image processing; MoT matches a dense baseline's performance using only 55.8% of the FLOPs. | [Paper](https://arxiv.org/abs/2411.04996)  \n10) **HtmlRAG** - a novel approach that proposes using HTML instead of plain text as the format for building RAG systems; the key finding is that preserving HTML structure provides richer semantic and structural information compared to plain text conversion, which typically loses important formatting like headings, tables, and semantic tags; to address the challenge of HTML documents being too long for LLM context windows, the authors develop a two-step pruning method: first cleaning unnecessary HTML elements (reducing length by 94%), then using a block-tree-based pruning approach that combines embedding-based and generative pruning to further reduce the content while maintaining important information; experiments across six different QA datasets demonstrate that HtmlRAG outperforms existing plain-text based methods, validating the advantages of preserving HTML structure in RAG systems. | [Paper](https://arxiv.org/abs/2411.02959v1), [Tweet](https://x.com/omarsar0/status/1857870511302390013)  \n## Top ML Papers of the Week (November 4 - November 10) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-november-4---november-10---2024)\n**Paper** | **Links**  \n---|---  \n1) **Many-agent Simulations toward AI Civilization** - demonstrates how 10-1000+ AI agents behave and progress with agent societies; proposes PIANO, an architecture that enables agents to interact with humans and other agents in real-time; shows that agents can autonomously develop specialized roles, adhere to and change collective rules, and engage in cultural and religious transmissions. | [Paper](https://arxiv.org/abs/2411.00114), [Tweet](https://x.com/omarsar0/status/1853290196286021940)  \n2) **A Comprehensive Survey of Small Language Models** - a survey on small language models (SLMs) and discussion on issues related to definitions, applications, enhancements, reliability, and more. | [Paper](https://arxiv.org/abs/2411.03350), [Tweet](https://x.com/omarsar0/status/1854532748154695717)  \n3) **Magentic-One** - a new generalist multi-agent system designed to handle complex web and file-based tasks; it uses an Orchestrator agent that directs four specialized agents: WebSurfer for browser operations, FileSurfer for file management, Coder for programming tasks, and ComputerTerminal for console operations; Magentic-One achieves competitive performance on multiple benchmarks including GAIA, AssistantBench, and WebArena, without requiring modifications to its core architecture. | [Paper](https://www.microsoft.com/en-us/research/publication/magentic-one-a-generalist-multi-agent-system-for-solving-complex-tasks/), [Tweet](https://x.com/omarsar0/status/1854910759232585786)  \n4) **Mixtures of In-Context Learners** - uses subsets of demonstrations to train experts via in-context learning; given a training set, a trainable weighting function is used to combine the experts' next-token predictions; this approach applies to black-box LLMs since access to the internal parameters of the LLM is not required. Good properties include the following: 1) competitive with standard ICL while being significantly more data, memory, and computationally efficient, and 2) resilient to noisy demonstrations and label imbalance. | [Paper](https://arxiv.org/abs/2411.02830), [Tweet](https://x.com/omarsar0/status/1854252169492562171)  \n5) **Attacking Vision-Language Agents via Pop-ups** - shows that integrating adversarial pop-ups into existing agent testing environments leads to an attack success rate of 86%; this decreases the agents' task success rate by 47%; they also add that basic defense techniques (e.g., instructing the agent to ignore pop-ups) are ineffective. | [Paper](https://arxiv.org/abs/2411.02391), [Tweet](https://x.com/omarsar0/status/1853810252308774955)  \n6) **Multi-expert Prompting with LLMs** - improves LLM responses by simulating multiple experts and aggregating their responses; it guides an LLM to fulfill input instructions by simulating multiple experts and selecting the best response among individual and aggregated views; it achieves a new state-of-the-art on TruthfulQA-Generation with ChatGPT, surpassing the current SOTA of 87.97%; it also improves performance across factuality and usefulness while reducing toxicity and hurtfulness. | [Paper](https://arxiv.org/abs/2411.00492), [Tweet](https://x.com/omarsar0/status/1853286452227899851)  \n7) **Number Understanding of LLMs** - provides a comprehensive analysis of the numerical understanding and processing ability (NUPA) of LLMs; finds that naive finetuning can improve NUPA a lot on many but not all tasks; it also reports that techniques designed to enhance NUPA prove ineffective for finetuning pretrained models; explores chain-of-thought techniques applied to NUPA and suggests that chain-of-thought methods face scalability challenges, making them difficult to apply in practical scenarios. | [Paper](https://arxiv.org/abs/2411.03766), [Tweet](https://x.com/omarsar0/status/1854528742095458337)  \n8) **WebRL** - proposes a self-evolving online curriculum RL framework to bridge the gap between open and proprietary LLM-based web agents; it improves the success rate of Llama-3.1-8B from 4.8% to 42.4%, and from 6.1% to 43% for GLM4-9B; the open models significantly surpass the performance of GPT-4-Turbo (17.6%) and GPT-4o (13.9%); the self-evolving curriculum addresses the scarcity of web agent training tasks; this is underpinned by a robust outcome-supervised reward model to evaluate task success; an adaptive RL strategy helps to deal with distribution drift in online learning and ensures consistent improvements. | [Paper](https://arxiv.org/abs/2411.02337), [Tweet](https://x.com/omarsar0/status/1853821990177485311)  \n9) **Adapting while Learning** - proposes a two-part fine-tuning approach that first helps LLMs learn from tool-generated solutions and then trains them to determine when to solve problems directly versus when to use tools; testing on math, climate science, and epidemiology benchmarks shows significant improvements, with a 28% boost in accuracy and 14% better tool usage precision compared to leading models like GPT-4 and Claude-3.5; the two-stage approach helps the LLM to adaptively solve scientific problems of varying complexity. | [Paper](https://arxiv.org/abs/2411.00412), [Tweet](https://x.com/omarsar0/status/1853281778594979877)  \n10) **Personalization of LLMs** - presents a comprehensive framework for understanding personalized LLMs; introduces taxonomies for different aspects of personalization and unifying existing research across personalized text generation and downstream applications. | [Paper](https://arxiv.org/abs/2411.00027), [Tweet](https://x.com/omarsar0/status/1853276249981907386)  \n## Top ML Papers of the Week (October 28 - November 3) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-october-28---november-3---2024)\n**Paper** | **Links**  \n---|---  \n1) **Geometry of Concepts in LLMs** - examines the geometric structure of concept representations in sparse autoencoders (SAEs) at three scales: 1) atomic-level parallelogram patterns between related concepts (e.g., man:woman::king:queen), 2) brain-like functional \"lobes\" for different types of knowledge like math/code, 3) and galaxy-level eigenvalue distributions showing a specialized structure in middle model layers. | [Paper](https://arxiv.org/abs/2410.19750), [Tweet](https://x.com/tegmark/status/1851288315867041903)  \n2) **SimpleQA** - a challenging benchmark of 4,326 short factual questions adversarially collected against GPT-4 responses; reports that frontier models like GPT-4o and Claude achieve less than 50% accuracy; finds that there is a positive calibration between the model stated confidence and accuracy, signaling that they have some notion of confidence; claims that there is still room to improve the calibration of LLMs in terms of stated confidence. | [Paper](https://openai.com/index/introducing-simpleqa/), [Tweet](https://x.com/OpenAI/status/1851680760539025639)  \n3) **Automating Agentic Workflow Generation** - a novel framework for automating the generation of agentic workflows; it reformulates workflow optimization as a search problem over code-represented workflows, where edges connect LLM-invoking nodes; it efficiently explores the search space using a variant of MCTS, iteratively refining workflows through code modification, tree-structured experience, and execution feedback; experiments across six benchmark datasets demonstrate AFlowâs effectiveness, showing a 5.7% improvement over manually designed methods and a 19.5% improvement over existing automated approaches; AFlow also enables smaller models to outperform GPT-4o on specific tasks at just 4.55% of its inference cost. | [Paper](https://arxiv.org/abs/2410.10762), [Tweet](https://x.com/omarsar0/status/1852339570891014415)  \n4) **LLMs Solve Math with a Bag of Heuristics** - uses causal analysis to find neurons that explain an LLM's behavior when doing basic arithmetic logic; discovers and hypothesizes that the combination of heuristic neurons is the mechanism used to produce correct arithmetic answers; finds that the unordered combination of different heuristic types is the mechanism that explains most of the modelâs accuracy on arithmetic prompts. | [Paper](https://arxiv.org/abs/2410.21272), [Tweet](https://x.com/omarsar0/status/1851233281116946923)  \n5) **o1 Replication Journey** - reports to be replicating the capabilities of OpenAI's o1 model; their journey learning technique encourages learning not just shortcuts, but the complete exploration process, including trial and error, reflection, and backtracking; claims that with only 327 training samples, their journey learning technique surpassed shortcut learning by 8.0% on the MATH dataset. | [Paper](https://arxiv.org/abs/2410.18982), [Tweet](https://x.com/omarsar0/status/1850748790308761988)  \n6) **Distinguishing Ignorance from Error in LLM Hallucinations** - a method to distinguish between two types of LLM hallucinations: when models lack knowledge (HK-) versus when they hallucinate despite having correct knowledge (HK+); they build model-specific datasets using their proposed approach and show that model-specific datasets are more effective for detecting HK+ hallucinations compared to generic datasets. | [Paper](https://arxiv.org/abs/2410.22071), [Tweet](https://x.com/AdiSimhi/status/1851650371615125563)  \n7) **Multimodal RAG** - provides a discussion on how to best integrate multimodal models into RAG systems for the industrial domain; it also provides a deep discussion on the evaluation of these systems using LLM-as-a-Judge. | [Paper](https://arxiv.org/abs/2410.21943), [Tweet](https://x.com/omarsar0/status/1851479149690642456)  \n8) **The Role of Prompting and External Tools in Hallucination Rates of LLMs** - tests different prompting strategies and frameworks aimed at reducing hallucinations in LLMs; finds that simpler prompting techniques outperform more complex methods; it reports that LLM agents exhibit higher hallucination rates due to the added complexity of tool usage. | [Paper](https://arxiv.org/abs/2410.19385), [Tweet](https://x.com/omarsar0/status/1850745569125253401)  \n9) **MrT5** - a more efficient variant of byte-level language models that uses a dynamic token deletion mechanism (via a learned delete gate) to shorten sequence lengths by up to 80% while maintaining model performance; this enables faster inference and better handling of multilingual text without traditional tokenization; MrT5 maintains competitive accuracy with ByT5 on downstream tasks such as XNLI and character-level manipulations while improving inference runtimes. | [Paper](https://arxiv.org/abs/2410.20771), [Tweet](https://x.com/JulieKallini/status/1851278833061704170)  \n10) **Relaxed Recursive Transformers** - introduces a novel approach, Relaxed Recursive Transformer, that significantly reduces LLM size through parameter sharing across layers while maintaining performance; the model is initialized from standard pretrained Transformers, but only uses a single block of unique layers that is repeated multiple times in a loop; then it adds flexibility to the layer tying constraint via depth-wise low-rank adaptation (LoRA) modules; shows that the approach has the potential to lead to significant (2-3Ã) gains in inference throughput. | [Paper](https://arxiv.org/abs/2410.20672), [Tweet](https://x.com/raymin0223/status/1851216039822180759)  \n## Top ML Papers of the Week (October 21 - October 27) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-october-21---october-27---2024)\n**Paper** | **Links**  \n---|---  \n1) **Agentic Information Retrieval** - provides an introduction to agentic information retrieval, which is shaped by the capabilities of LLM agents; discusses different types of cutting-edge applications of agentic information retrieval and challenges. | [Paper](https://arxiv.org/abs/2410.09713), [Tweet](https://x.com/omarsar0/status/1848396596230127655)  \n2) **Aya Expanse** - a family of open-weight foundation models for multilingual capabilities; releases an 8B and 32B parameter model, including one of the largest multilingual dataset collections to date, with 513 million examples; the release also includes Aya-101 which the authors claim is the most comprehensive multilingual models covering 101 languages; Aya Expanse 32B outperforms Gemma 2 27B, Mistral 8x22B, and Llama 3.1 70B, a model 2x its size. | [Paper](https://cohere.com/blog/aya-expanse-connecting-our-world), [Tweet](https://x.com/CohereForAI/status/1849435983449587796)  \n3) **A Theoretical Understanding of CoT** - finds that adding correct and incorrect reasoning paths in demonstrations improves the accuracy of intermediate steps and CoT; the proposed method, Coherent CoT, significantly improves performance on several benchmarks; in the Tracking Shuffled Objects dataset, Gemini Pro shows a 6.60% improvement (from 58.20% to 64.80%), and in Penguins in a Table, DeepSeek 67B demonstrates an increase of 6.17% (from 73.97% to 80.14%). | [Paper](https://arxiv.org/abs/2410.16540), [Tweet](https://x.com/omarsar0/status/1849139985712369907)  \n4) **A Survey on Data Synthesis and Augmentation for LLMs** - provides a comprehensive summary of data generation techniques in the lifecycle of LLMs; includes discussions on data preparation, pre-training, fine-tuning, instruction-tuning, preference alignment, and applications. | [Paper](https://arxiv.org/abs/2410.12896), [Tweet](https://x.com/omarsar0/status/1848445736591163886)  \n5) **LongRAG** - enhances RAG's understanding of long-context knowledge which includes global information and factual details; consists of a hybrid retriever, an LLM-augmented information extractor, a CoT-guided filter, and an LLM-augmented generator; these are key components that enable the RAG system to mine global long-context information and effectively identify factual details; LongRAG outperforms long-context LLMs (up by 6.94%), advanced RAG (up by 6.16%), and Vanilla RAG (up by 17.25%). | [Paper](https://arxiv.org/abs/2410.18050), [Tweet](https://x.com/omarsar0/status/1849494571946066295)  \n6) **Evaluation Feature Steering in LLMs** - evaluates featuring steering in LLMs using an experiment that artificially dials up and down various features to analyze changes in model outputs; it focused on 29 features related to social biases and study if feature steering can help mitigate social biases; among its findings, it reports that feature steering sometimes leads to off-target effects and that a neutrality feature can help decreases social biases in 9 social dimensions without negatively affecting text quality. | [Paper](https://www.anthropic.com/research/evaluating-feature-steering), [Tweet](https://x.com/AnthropicAI/status/1849840131412296039)  \n7) **Granite 3.0** - presents lightweight foundation models ranging from 400 million to 8B parameters; supports coding, RAG, reasoning, and function calling, focusing on enterprise use cases, including on-premise and on-device settings; demonstrates strong performance across academic benchmarks for language understanding, reasoning, coding, function calling, and safety. | [Paper](https://github.com/ibm-granite/granite-3.0-language-models/blob/main/paper.pdf), [Tweet](https://x.com/omarsar0/status/1848404138641527105)  \n8) **LLMs Reflect the Ideology of their Creators** - finds that LLMs exhibit a diverse ideological stance which reflects the worldview of its creators; finds consistent normative differences between how the same LLM responds in Chinese compared to English; identifies normative disagreements between Western and non-Western LLMs about prominent actors in geopolitical conflicts. | [Paper](https://arxiv.org/abs/2410.18417), [Tweet](https://x.com/omarsar0/status/1849860985500352968)  \n9) **Scalable Watermarking for LLMs** - proposes SynthID-Text, a text-watermarking scheme that can preserve text quality in LLMs, enable high detection accuracy, and minimize latency overhead; it integrates watermarking with speculative sampling that consists of the final pattern of scores for a modelâs word choices combined with the adjusted probability scores; the authors test the feasibility and scalability of the approach by assessing feedback on nearly 10 million Gemini responses. | [Paper](https://www.nature.com/articles/s41586-024-08025-4), [Tweet](https://x.com/GoogleDeepMind/status/1849110263871529114)  \n10) **Reasoning Patterns of OpenAIâs o1 Model** - when compared with other test-time compute methods, o1 achieved the best performance across most datasets; the authors observe that the most commonly used reasoning patterns in o1 are divide and conquer and self-refinement; o1 uses different reasoning patterns for different tasks; for commonsense reasoning tasks, o1 tends to use context identification and emphasize constraints; for math and coding tasks, o1 mainly relies on method reuse and divide and conquer. | [Paper](https://arxiv.org/abs/2410.13639), [Tweet](https://x.com/omarsar0/status/1848782378631892997)  \n## Top ML Papers of the Week (October 14 - October 20) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-october-14---october-20---2024)\n**Paper** | **Links**  \n---|---  \n1) **Thinking LLMs** - proposes a training method to equip LLMs with thinking abilities for general instruction-following without human-annotated data; uses an iterative search and optimization procedure to explore thought generation which enables the model to learn without direct supervision; thought candidates for each user instruction are scored with a judge model; only responses are evaluated by the Judge which determines the best and worst ones; then the corresponding full outputs are used as chosen and rejected pairs for DPO (referred to as Thought Preference Optimization in this paper). reports superior performance on AlpacaEval and Arena-Hard. | [Paper](https://arxiv.org/abs/2410.10630), [Tweet](https://x.com/omarsar0/status/1846227797972603047)  \n2) **Model Swarms** - propose a new collaborative search algorithm to adapt LLM via swarm intelligence; a pool of LLM experts collaboratively move in the weight space and optimize a utility function representing various adaptation objectives; experiments demonstrate that Model Swarms could flexibly adapt LLM experts to a single task, multi-task domains, reward models, as well as diverse human interests. improves over 12 model composition baselines by up to 21.0% across tasks and contexts. | [Paper](https://arxiv.org/abs/2410.11163), [Tweet](https://x.com/omarsar0/status/1846592954921849029)  \n3) **First-Person Fairness in Chatbots** - studies first-person fairness which involves fairness towards users interacting with ChatGPT; specifically, it measures the biases, if any, towards the usersâ names; it leverages a model powered by GPT-4o to analyze patterns and name-sensitivity in the chatbotâs responses for different user names; claims that, overall, post-training significantly mitigate harmful stereotypes; also reports that in domains like entertainment and art, with open-ended tasks, demonstrate the highest level of bias (i.e., tendency to write stories with protagonists whose gender matches gender inferred from the userâs name) | [Paper](https://cdn.openai.com/papers/first-person-fairness-in-chatbots.pdf), [Tweet](https://x.com/OpenAINewsroom/status/1846238809991925838)  \n4) **Introspection in LLMs** - reports that LLMs can acquire knowledge through introspection that cannot be inferred from their training data; suggests that LLMs contain privileged information about themselves that can potentially lead to more interpretable and controllable systems; they report that this introspection ability is limited and models struggle to predict their behavior on tasks requiring reasoning over long outputs. | [Paper](https://arxiv.org/abs/2410.13787), [Tweet](https://x.com/omarsar0/status/1847297594525094081)  \n5) **Janus** - proposes a unified autoregressive framework for multimodal understanding and generation; it decouples visual encoding into independent pathways and leverages a single transformer architecture to improve flexibility and performance on both visual understanding and generation; claims to alleviate trade-offs related to performing the vision tasks, something common in methods that rely on a single visual encoder; surpasses previous unified models and matches or exceeds the performance of task-specific models. | [Paper](https://arxiv.org/abs/2410.13848), [Tweet](https://x.com/deepseek_ai/status/1847191319464300652)  \n6) **Inference Scaling for Long-Context RAG** - uses two strategies to investigate scaling laws for RAG: in-context learning (DRAG) and iterative prompting (IterRAG); finds that RAG performance consistently improves with the expansion of the effective context length under optimal configurations; when optimally allocated, increasing inference computation can lead to linear gains in long-context RAG performance; this leads to the development of a computation allocation model that can provide practical guidance for optimal computation allocation in long-context RAG scenarios. | [Paper](https://arxiv.org/abs/2410.04343), [Tweet](https://x.com/omarsar0/status/1847350506127315088)  \n7) **Agent S** - a new open agentic framework that enables autonomous interaction with computers through a GUI; Agent S tackles challenges such as acquiring knowledge, planning over long-task horizons, and handling dynamic interfaces; it introduces experience-augmented hierarchical planning which leverages both search and retrieval; leverages an agent-computer interface to perform reasoning and control GUI agents; evaluation on the OSWorld benchmark shows that Agent S outperforms the baseline by 9.37% in success rate (an 83.6% relative improvement) and achieves a new state-of-the-art. | [Paper](https://arxiv.org/abs/2410.08164v1), [Tweet](https://x.com/omarsar0/status/1846930425849303424)  \n8) **Model Kinship for Merging LLMs** - proposes model kinship to measure the degree of similarity between LLMs; model kinship is used to build a model merging strategy (Top-k Greedy Merging with Model Kinship) which yields better performance; the authors find that this new criterion can be used to effectively and continuously perform model merging. | [Paper](https://arxiv.org/abs/2410.12613), [Tweet](https://x.com/omarsar0/status/1846753148007846329)  \n9) **On the Planning Abilities of OpenAIâs o1 Models** - reports that o1-preview is particularly strong in self-evaluation and constraint-following; also mentions that these o1 models demonstrate bottlenecks in decision-making and memory management, which are more pronounced in spatial reasoning; in particular, the models produce redundant action and struggle to generalize in spatially complex tasks. | [Paper](https://www.arxiv.org/abs/2409.19924), [Tweet](https://x.com/omarsar0/status/1846032256902869135)  \n10) **CoTracker3** - proposes a new point tracking model and a new semi-supervised training recipe; enables usage of real videos without annotations during training by generating pseudo-labels using off-the-shelf teachers; the approach is simpler in architecture and training scheme leading to better results while using 1000x less data. | [Paper](https://arxiv.org/abs/2410.11831), [Tweet](https://x.com/AIatMeta/status/1846595406261899363)  \n## Top ML Papers of the Week (October 7 - October 13) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-october-7---october-13---2024)\n**Paper** | **Links**  \n---|---  \n1) **MLE-Bench** - proposes a new benchmark for the evaluation of machine learning agents on machine learning engineering capabilities; includes 75 ML engineering-related competition from Kaggle testing on MLE skills such as training models, preparing datasets, and running experiments; OpenAIâs o1-preview with the AIDE scaffolding achieves Kaggle bronze medal level in 16.9% of competitions. | [Paper](https://arxiv.org/abs/2410.07095), [Tweet](https://x.com/OpenAI/status/1844429536353714427)  \n2) **Differential Transformer** - proposes a differential attention mechanism that amplifies attention to the relevant context while canceling noise; Differential Transformer outperforms Transformer when scaling up model size and training tokens; the authors claim that since this architecture gets less \"distracted\" by irrelevant context, it can do well in applications such as long-context modeling, key information retrieval, hallucination mitigation, in-context learning, and reduction of activation outliers. | [Paper](https://arxiv.org/abs/2410.05258), [Tweet](https://x.com/omarsar0/status/1843694897020150216)  \n3) **Astute RAG** - proposes a novel RAG approach to deal with the imperfect retrieval augmentation and knowledge conflicts of LLMs; Astute RAG adaptively elicits essential information from LLMs' internal knowledge; then it iteratively consolidates internal and external knowledge with source awareness; Astute RAG is designed to better combine internal and external information through an interactive consolidation mechanism (i.e., identifying consistent passages, detecting conflicting information in them, and filtering out irrelevant information). | [Paper](https://arxiv.org/abs/2410.07176), [Tweet](https://x.com/omarsar0/status/1844435988019544565)  \n4) **ToolGen** - integrates tool knowledge directly into LLMs by representing tools as a unique token which allows the LLM to generate tool calls and arguments, enabling seamless tool invocation and language generation; experimental results with over 47,000 tools show that ToolGen achieves superior results in both tool retrieval and autonomous task completion. | [Paper](https://arxiv.org/abs/2410.03439), [Tweet](https://x.com/omarsar0/status/1843491766114422930)  \n5) **Long-Context LLMs Meet RAG** - finds that for many long-context LLMs, the quality of outputs declines as the number of passages increases; reports that the performance loss is due to retrieved hard negatives; they propose two ways to improve long-context LLM-based RAG: retrieval reordering and RAG-specific tuning with intermediate reasoning to help with relevance identification; that approaches demonstrate significant accuracy and robustness improvements on long-context RAG performance. | [Paper](https://arxiv.org/abs/2410.05983), [Tweet](https://x.com/omarsar0/status/1844828836619334066)  \n6) **GSM-Symbolic** - tests several SoTA models on a benchmark created with symbolic templates that enable diverse mathematical problems; they find that LLMs exhibit variance when responding to variations of the same questions; the performance of all the models declines by adjusting the numerical values in the question; as questions are made more challenging (e.g., increasing the number of clauses) the performance significantly deteriorates; the authors hypothesize that the observed decline in performance is due to a lack of logical reasoning in current LLMs. | [Paper](https://arxiv.org/abs/2410.05229), [Tweet](https://x.com/MFarajtabar/status/1844456880971858028)  \n7) **Optima** - a novel framework to enhance both communication efficiency and task effectiveness in LLM-based multi-agent systems through LLM training; proposes an iterative generate, rank, select, and train paradigm with a reward function to improve performance, token use, and communication efficiency; integrates Monte Carlo Tree Search-inspired techniques for DPO data generation to encourage diverse exploration; shows consistent improvements over single-agent baselines and vanilla MAS based on Llama 3 8B, with 2.8x performance gain with less than 10% tokens on tasks requiring heavy information exchange. | [Paper](https://arxiv.org/abs/2410.08115), [Tweet](https://x.com/omarsar0/status/1844578931732844963)  \n8) **ScienceAgentBench** - a new benchmark to rigorously assess agents built for scientific workflows; after testing it on open-weight and proprietary LLMs, the best-performing agent can only solve 32.4% of the tasks independently and 34.3% with expert-provided knowledge. | [Paper](https://arxiv.org/abs/2410.05080), [Tweet](https://x.com/omarsar0/status/1843697964243382586)  \n9) **Addition Is All You Need** - proposes an algorithm that approximates floating point multiplication with integer addition operations; it is less computationally intensive than 8-bit floating point but achieves higher precision; the authors report that applying the purposed L-Mul operation in tensor processing hardware can potentially reduce 95% energy cost by elementwise floating point tensor multiplications and 80% energy cost of dot products. | [Paper](https://arxiv.org/abs/2410.00907), [Tweet](https://x.com/omarsar0/status/1844043652966072742)  \n10) **Persuasion and Anti-social Ability of LLMs** - studies the interaction patterns of LLMs in a multi-agent setting with social hierarchy; the study was done in a specific setting involving a guard and a prisoner who seeks additional yard time or escaping from prison; finds that in the multi-agent setting where power dynamics are involved, the LLMs fail to have a conversation; they also report that agents' personas are critical in driving the behaviors of the agents. In addition, and without explicit prompting, simply assigning agents' roles lead to anti-social behavior. | [Paper](https://arxiv.org/abs/2410.07109), [Tweet](https://x.com/omarsar0/status/1844427182141211054)  \n## Top ML Papers of the Week (September 30 - October 6) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-september-30---october-6---2024)\n**Paper** | **Links**  \n---|---  \n1) **Movie Gen** - a set of foundation models to generate high-quality, 1080p HD videos, including different aspect ratios and synchronized audio; the 30B parameter model supports a context length of 73K video tokens, which enables generation of 16-second videos at 16fps; it also presents a 13B parameter video-to-audio generation model and a novel video editing model thatâs attained via post-training; achieves state-of-the-art performance on tasks such as text-to-video synthesis, video personalization, video-to-audio generation and more. | [Paper](https://ai.meta.com/static-resource/movie-gen-research-paper), [Tweet](https://x.com/AIatMeta/status/1842188252541043075)  \n2) **Were RNNs All We Needed?** - revisits RNNs and shows that by removing the hidden states from input, forget, and update gates RNNs can be efficiently trained in parallel; this is possible because with this change architectures like LSTMs and GRUs no longer require backpropagate through time (BPTT); they introduce minLSTMs and minGRUs that are 175x faster for a 512 sequence length. | [Paper](https://arxiv.org/abs/2410.01201), [Tweet](https://x.com/omarsar0/status/1842246985790914608)  \n3) **LLMs Know More Than They Show** - finds that the \"truthfulness\" information in LLMs is concentrated in specific tokens; this insight can help enhance error detection performance and further mitigate some of these issues; they also claim that internal representations can be used to predict the types of errors the LLMs are likely to make. | [Paper](https://arxiv.org/abs/2410.02707), [Tweet](https://x.com/omarsar0/status/1842240840389001381)  \n4) **Architecture Search Framework for Inference-Time Techniques** - introduces a modular framework for building and optimizing LLMs by combining multiple inference-time techniques; this approach reframes the challenge of LLM system design as a hyperparameter optimization problem; tested on benchmarks including MT-Bench and CodeContests, Archon surpasses leading models such as GPT-4o and Claude 3.5 Sonnet, achieving a 15.1% average accuracy improvement. | [Paper](https://arxiv.org/abs/2409.15254), [Tweet](https://x.com/Azaliamirh/status/1840892626096345530)  \n5) **RATIONALYST** - a model for process-supervision of reasoning that enables generalization across diverse reasoning tasks; this process is achieved with pre-training on a collection of 79k rationales from the Pile and a combination of reasoning datasets with minimal human intervention; fine-tuned from LLaMa-3-8B, the proposed model improves the accuracy of reasoning by an average of 3.9% on 7 reasoning benchmarks. | [Paper](https://arxiv.org/abs/2410.01044)  \n6) **An Analysis of o1-preview** - reports that large reasoning models like o1-preview, while improving on more difficult tasks, display similar qualitative trends as previous LLMs; o1 is sensitive to the probability of examples and tasks, performing better and requiring fewer âthinking tokensâ in high-probability settings than in low-probability ones. | [Paper](https://arxiv.org/abs/2410.01792), [Tweet](https://x.com/omarsar0/status/1841842414157472240)  \n7) **FRAMES** - a unified framework to evaluate an LLMâs ability to provide factual responses, assess retrieval capabilities, and the reasoning required to generate final responses; includes multi-hop questions that require the integration of information from multiple sources; reports that state-of-the-art LLMs struggle on the task and only achieve 40% accuracy with no retrieval; the proposed multi-step retrieval approach improves performance to 66% accuracy. | [Paper](https://arxiv.org/abs/2409.12941), [Tweet](https://x.com/_philschmid/status/1840628834275602585)  \n8) **Not All LLM Reasoners Are Created Equal** - investigates in depth the grade-school math problem-solving capabilities of LLMs; reports that LLMs show a significant gap in reasoning; finds that LLMs display a huge performance difference when solving compositional pairs and solving questions independently. | [Paper](https://arxiv.org/abs/2410.01748), [Tweet](https://x.com/arianTBD/status/1841875515860517130)  \n9) **Evaluation of o1** - provides a comprehensive evaluation of OpenAI's o1-preview LLM; shows strong performance across many tasks such as competitive programming, generating coherent and accurate radiology reports, high school-level mathematical reasoning tasks, chip design tasks, anthropology and geology, quantitative investing, social media analysis, and many other domains and problems. | [Paper](https://arxiv.org/abs/2409.18486), [Tweet](https://x.com/omarsar0/status/1840953712635732006)  \n10) **Designing Priors for Better Few-Shot Image Synthesis** - training generative models like GAN with limited data is difficult; current Implicit Maximum Likelihood Estimation approaches (IMLE) have an inadequate correspondence between latent code selected for training and those selected during inference; the proposed approach, RS-IMLE, changes the prior distribution for training which improves test-time performance and leads to higher quality image generation. | [Paper](https://arxiv.org/abs/2409.17439), [Tweet](https://x.com/KL_Div/status/1841729946302943295)  \n## Top ML Papers of the Week (September 23 - September 29) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-september-23---september-29---2024)\n**Paper** | **Links**  \n---|---  \n1) **Llama 3.2** - presents small and medium-sized vision LLMs (11B and 90B parameters), and lightweight, text-only models (1B and 3B); the text-only models are trained to support context length of 128K tokens and outperform other models in their class on a range of tasks; vision models exceed other models such as Claude 3 Haiku on image understanding tasks. | [Paper](https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/), [Tweet](https://twitter.com/Doctor_Zou/status/1782752058124554272)  \n2) **Molmo** - presents a family of open, state-of-the-art multimodal AI models; the 72B model in the Molmo family outperforms others in the class of open weight and data models; it also compares favorably against proprietary models like GPT-4o, Claude 3.5, and Gemini 1.5 on several benchmarks. | [Paper](https://molmo.allenai.org/paper.pdf), [Tweet](https://twitter.com/emmanuel_vincze/status/1708249637918752987)  \n3) **AlphaChip** - a reinforcement learning-based method trained to design the physical layout of chips; AlphaChip is reportedly used in three additional generations of Googleâs TPU; this release includes an open-source implementation of the method to help pre-train on a variety of chip blocks to apply to new blocks; also releases a model checkpoint pre-trained on 20 TPU blocks. | [Paper](https://www.nature.com/articles/s41586-024-08032-5), [Tweet](https://twitter.com/GoogleAI/status/1676118998259507200)  \n4) **LLMs Still Canât Plan** - evaluates whether large reasoning models such as o1 can plan; finds that a domain-independent planner can solve all instances of Mystery Blocksworld but LLMs struggle, even on small instances; o1-preview is effective on the task but tend to degrade in performance as plan length increases, concludes that while o1 shows progress on more challenging planning problems, the accuracy gains cannot be considered general or robust. | [Paper](https://arxiv.org/abs/2409.13373), [Tweet](https://twitter.com/johnxschulman/status/1657558270450917378)  \n5) **Scaled-up Instructable Model Become Less Reliable** - suggests that larger and more instructable LLMs may become less reliable; investigates LLMs across three elements: difficulty concordance, task avoidance, and prompting stability; finds that early models often avoid user questions but scaled-up, shaped-up models tend to give an apparently sensible yet wrong answer much more often, including errors on difficult questions that human supervisors frequently overlook. | [Paper](https://www.nature.com/articles/s41586-024-07930-y), [Tweet](https://twitter.com/rylanmshea/status/1583460628966346752)  \n6) **Logic-of-Thought** - proposes a new prompting technique called Logic-of-Thought (LoT) which employs propositional logic to generate and inject expanded logical information from the input context; it enhances CoT performance on the ReClor dataset by +4.35%; it improves CoT+SelfConsistencyâs performance on LogiQA by +5%; it also boosts the performance of ToT on the ProofWriter dataset by +8%. | [Paper](https://arxiv.org/abs/2409.17539), [Tweet](https://twitter.com/IsItPerplexity/status/1704255260019798052)  \n7) **RAG and Beyond** - presents a survey that introduces a RAG task categorization method that helps to classify user queries into four levels according to the type of external data required and the focus of the task; summarizes key challenges in building robust data-augmented LLM applications and the most effective techniques for addressing them. | [Paper](https://arxiv.org/abs/2409.14924), [Tweet](https://twitter.com/mishigna/status/1703461946958463118)  \n8) **A Preliminary Study of o1 in Medicine** - provides a preliminary exploration of the o1-preview model in medical scenarios; shows that o1 surpasses the previous GPT-4 in accuracy by an average of 6.2% and 6.6% across 19 datasets and two newly created complex QA scenarios; identifies hallucination, inconsistent multilingual ability, and discrepant metrics for evaluation. | [Paper](https://arxiv.org/abs/2409.15277), [Tweet](https://twitter.com/RichardEvans_AI/status/1691963090436067397)  \n9) **Small Language Models Survey** - a comprehensive survey on small language models (SLMs) across architectures, training datasets, and training algorithms; analyzes 59 state-of-the-art open-source SLMs and capabilities such as reasoning, in-context learning, maths, and coding; other discussions include on-device runtime costs, latency, memory footprint, and valuable insights. | [Paper](https://arxiv.org/abs/2409.15790), [Tweet](https://twitter.com/sebatian_ruder/status/1691611318636159002)  \n10) **Minstrel** - a multi-generative agent system with reflection capabilities to automate structural prompt generation; it presents LangGPT, an extensible framework for designing prompts; Minstrel is built on top of LangGPT and experiments demonstrate that structural prompts (either generated by Minstrel or written manually) perform better in guiding LLMs to perform tasks. | [Paper](https://arxiv.org/abs/2409.13449), [Tweet](https://twitter.com/LiZhang1351/status/1702992849091985677)  \n## Top ML Papers of the Week (September 16 - September 22) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-september-16---september-22---2024)\n**Paper** | **Links**  \n---|---  \n1) **Moshi** - introduces a speech-text foundation model and full-duplex spoken dialogue framework; they present several components of the systems; Helium is a 7B parameter text LLM; Mimi is a semantic-acoustic neural audio code with state-of-the-art performance on audio quality; a hierarchical multi-stream architecture that can generate arbitrary conversation in a speech-to-speech manner. | [Paper](https://kyutai.org/Moshi.pdf), [Tweet](https://x.com/kyutai_labs/status/1836427396959932492)  \n2) **Training LLMs to Self-Correct via RL** - develops a multi-turn online reinforcement learning to improve the capabilities of an LLM to self-correct; itâs based entirely on self-generated data; SFT is shown to be ineffective at learning self-correction and suffers from distribution mismatch between training data and model responses; proposes a two-stage approach that first optimizes correction behavior and then uses a reward bonus to amplify self-correction during training; when applied to Gemini 1.0 Pro and 1.5 Flash models, it achieves state-of-the-art self-correction performance, improving the base modelsâ self-correction by 15.6% and 9.1% respectively on the MATH and HumanEval benchmarks. | [Paper](https://arxiv.org/abs/2409.12917), [Tweet](https://x.com/omarsar0/status/1837228446839361984)  \n3) **Qwen2.5 Coder** - a series of models including 1.5B and 7B parameters; itâs built upon the Qwen2.5 architecture which is continuously pretrained on 5.5 trillion tokens; achieves state-of-the-art performance across more than 10 benchmarks; includes strong capabilities in code generation, completion, reasoning, and repairing. | [Paper](https://arxiv.org/abs/2409.12186), [Tweet](https://x.com/huybery/status/1837170643563073960)  \n4) **Diagram of Thought (DoT)** - enhances the reasoning capabilities of LLMs through mathematical rigor; DAT models iterative reasoning in LLM as the construction of a directed acyclic graph; it integrates propositions, critiques, refinement, and verification into a unified DAG structure; this allows DoT to capture complex logical deduction beyond linear or tree-based approaches. | [Paper](https://arxiv.org/abs/2409.10038), [Tweet](https://x.com/omarsar0/status/1835882277563179512)  \n5) **Agents in Software Engineering** - provides a comprehensive overview of frameworks of LLM-based agents in software engineering. | [Paper](https://arxiv.org/abs/2409.09030), [Tweet](https://x.com/omarsar0/status/1835705359723319702)  \n6) **To CoT or not to CoT?** - investigates what kinds of tasks benefit the most from chain-of-thought (CoT) prompting; after a meta-analysis on 100+ papers and several evaluations, it finds that CoT produces strong performance benefits primarily on tasks involving math and logic; they find that most of the CoT gain comes from improving symbolic execution, but a symbolic solver outperforms it. | [Paper](https://arxiv.org/abs/2409.12183), [Tweet](https://x.com/omarsar0/status/1836599280477299013)  \n7) **A Comprehensive Evaluation of Quantized Instruction-Tuned LLMs** - evaluates the performance of instruction-tuned LLMs across various quantization methods on models ranging from 7B to 405B; the key findings are 1) quantizing a larger LLM to a similar size as a smaller FP16 LLM generally performs better across most benchmarks, 2) performance varies significantly with different quantization methods, model size, and bit-width, with weight-only methods often yielding better results in larger models, and 3) task difficulty does not significantly impact accuracy degradation due to quantization. | [Paper](https://arxiv.org/abs/2409.11055), [Tweet](https://arxiv.org/abs/2409.11055)  \n8) **Iteration of Thought** - proposes the Iteration of Thought (IoT) framework to enhance the LLM responses and reasoning capabilities with adaptive reasoning paths; it leverages an inner dialogue agent, acting as a guide, to dynamically adjust reasoning paths which allows adaptive cross-path exploration and enhance response accuracy; it's different from CoT and ToT (both rigid processes) in that its prompt generation is a dynamic process that allows it to adapt. | [Paper](https://arxiv.org/abs/2409.12618), [Tweet](https://x.com/omarsar0/status/1836977595847692671)  \n9) **Schrodingerâs Memory** - uses the Universal Approximation Theorem to explain the memory mechanism of LLMs. It also proposes a new approach to evaluate LLM performance by comparing the memory capacities of different models; the Transformer architecture functions as a dynamic fitting UAT model, with a strong ability to adaptively fit inputs; this enables LLMs to recall entire content based on minimal input information. | [Paper](https://arxiv.org/abs/2409.10482), [Tweet](https://x.com/omarsar0/status/1835882330323554321)  \n10) **Math Jailbreaking Prompts** - uses GPT-4o to generate mathematically encoded prompts that serve as an effective jailbreaking technique; shows an average attack success rate of 73.6% across 13 state-of-the-art; this highlights the inability of existing safety training mechanisms to generalize to mathematically encoded inputs. | [Paper](https://arxiv.org/abs/2409.11445), [Tweet](https://x.com/omarsar0/status/1836603922405806501)  \n## Top ML Papers of the Week (September 9 - September 15) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-september-9---september-15---2024)\n**Paper** | **Links**  \n---|---  \n1) **Learning to Reason with LLMs** - a new family of LLMs trained with reinforcement learning to reason before it responds to complex tasks; it produces a long internal chain of thought and exceeds in science, code, and math-related tasks; ranked in the 49th percentile in the 2024 International Olympiad in Informatics and exceeds human PhD-level accuracy on science-related benchmarks. - | [Paper](https://openai.com/index/learning-to-reason-with-llms/), [Tweet](https://x.com/OpenAI/status/1834278217626317026)  \n2) **Chai-1** - a new multi-modal foundation model for molecular structure prediction that can predict proteins, small molecules, DNA, RNA, and more; it achieves state-of-the-art results on a variety of tasks in drug discovery; achieves a 77% success rate on the PoseBusters benchmark (vs. 76% by AlphaFold 3), as well as an CÎ± LDDT of 0.849 on the CASP15 protein monomer structure prediction set (vs. 0.801 by ESM3-98B). | [Paper](https://www.chaidiscovery.com/blog/introducing-chai-1), [Tweet](https://x.com/joshim5/status/1833183091776721106)  \n3) **Can LLMs Generation Novel Research Ideas** - finds that LLM-generated research ideas are judged as more novel (p <0.05) than human expert ideas; however, they were rated slightly weaker in terms of flexibility; they also report that LLM agents lack diversity in the idea generation process and are not reliable evaluators. | [Paper](https://arxiv.org/abs/2409.04109), [Tweet](https://x.com/ChengleiSi/status/1833166031134806330)  \n4) **DataGemma** - includes a series of fine-tuned Gemma 2 models to help LLMs access and incorporate numerical and statistical data; proposes a new approach called Retrieval Interleaved Generation (RIG) which can reliably incorporate public statistical data from Data Commons into LLM responses; RIG is a tool-inspired approach, can interleave statistical tokens with natural language questions suitable for retrieval from Data Commons; to attain such capability, they fine-tune the LLM on an instruction-response dataset generated with the help of Gemini 1.5; the RIG approach improves factuality from 5-7% to about 58%. | [Paper](https://docs.datacommons.org/papers/DataGemma-FullPaper.pdf), [Tweet](https://x.com/omarsar0/status/1834235024675406012)  \n5) **Agent Workflow Memory** - introduces Agent Workflow Memory to induce commonly reused workflows and provide these to the agent on demand; works offline and online and is meant to guide the agent's subsequent generations; itâs inspired by how humans learn reusable workflows from past experiences and use them to guide future actions; claims to substantially improve the baseline results by 24.6% and 51.1% relative success rate on Mind2Web and WebArena while doing it in a more efficient way. | [Paper](https://arxiv.org/abs/2409.07429), [Tweet](https://x.com/omarsar0/status/1834059522198896706)  \n6) **The Role of Small Language Models in the LLM Era** - closely examines the relationship between LLMs and SLMs; common applications of SLMs include data curation, training stronger models, efficient inference, evaluators, retrievers, and much more; includes insights for practitioners to better understand the value of these SLMs. | [Paper](https://arxiv.org/abs/2409.06857), [Tweet](https://x.com/omarsar0/status/1834063138586829273)  \n7) **LLaMa-Omni** - a model architecture for low-latency speech interaction with LLMs; it is based on Llama-3.1-8B-Instruct and can simultaneously generate both text and speech responses given speech instructions; responses can be generated with a response latency as low as 226ms; architecture-wise, it involves a speech encoder (Whispter-large-v3), a speech adaptor, an LLM, and a speech decoder; they also created a dataset of 200K speech interactions and responses. | [Paper](https://arxiv.org/abs/2409.06666), [Tweet](https://x.com/omarsar0/status/1834227729241440340)  \n8) **Can LLMs Unlock Novel Scientific Research Ideas** - investigates whether LLM can generate novel scientific research ideas; reports that Claude and GPT models tend to align more with the author's perspectives on future research ideas; this is measured across different domains like science, economics, and medicine. | [Paper](https://arxiv.org/abs/2409.06185), [Tweet](https://x.com/omarsar0/status/1833695968656793610)  \n9) **Theory, Analysis, and Best Practices for Sigmoid Self-Attention** - proposes Flash-Sigmoid, a hardware-aware and memory-efficient implementation of sigmoid attention; it yields up to a 17% inference kernel speed-up over FlashAttention-2 on H100 GPUs; show that SigmoidAttn matches SoftwaxAttn in various tasks and domains. | [Paper](https://arxiv.org/abs/2409.04431), [Tweet](https://x.com/omarsar0/status/1833522827842220244)  \n10) **Achieving Peak Performance for LLMs** - a systematic review of methods for improving and speeding up LLMs from three points of view: training, inference, and system serving; summarizes the latest optimization and acceleration strategies around training, hardware, scalability, and reliability. | [Paper](https://arxiv.org/abs/2409.04833), [Tweet](https://x.com/omarsar0/status/1833344402892460364)  \n## Top ML Papers of the Week (September 2 - September 8) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-september-2---september-8---2024)\n**Paper** | **Links**  \n---|---  \n1) **AlphaProteo** - presents a family of ML models trained for protein design; reports a 3-to 300-fold better binding affinities and higher experimental success rates compared to other existing methods on seven target proteins; shows that AlphaProteoâs performance on hundreds of target proteins from the PDB is comparable to the seven targets. | [Paper](https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/AlphaProteo2024.pdf), [Tweet](https://x.com/GoogleDeepMind/status/1831710991475777823)  \n2) **RAG in the Era of Long-Context LLMs** - reports that longer-context LLMs suffer from a diminished focus on relevant information, which is one of the primary issues that a RAG system addresses (i.e., uses more relevant information); they propose an order-preserving RAG mechanism that improves performance on long-context question answering; it's not perfect and in fact, as retrieved chunks increase the quality of responses go up and then declines; they mention a sweet spot where it can achieve better quality with a lot fewer tokens than long-context LLMs. | [Paper](https://arxiv.org/abs/2409.01666), [Tweet](https://x.com/omarsar0/status/1831389521839267888)  \n3) **Strategic Chain-of-Thought** - a method to refine LLM performance by incorporating strategic knowledge before the intermediate CoT reasoning steps; the problem-solving strategy helps to guide the generation of the CoT paths and final answers; claims to achieve a 21.05% increase on the GSM8K datasets using the Llama3-8b model. | [Paper](https://arxiv.org/abs/2409.03271v1)  \n4) **Effective of AI on High Skilled Work** - studies the impact of generative AI on software developers; reveals a 26.08% increase in the number of completed tasks among the developers that use AI tools like GitHub Copilot; also shows that less experienced developers are likely to adopt the AI tools and have greater productivity gains. | [Paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4945566), [Tweet](https://x.com/emollick/status/1831739827773174218)  \n5) **OLMoE** - introduces a fully-open LLM that leverages sparse Mixture-of-Experts. OLMoE is a 7B parameter model and uses 1B active parameters per input token; there is also an instruction-tuned version that claims to outperform Llama-2-13B-Chat and DeepSeekMoE 16B. | [Paper](https://arxiv.org/abs/2409.02060), [Tweet](https://x.com/omarsar0/status/1831357563620753577)  \n6) **LongCite** - synthesizes a large-scale SFT dataset with off-the-shelf LLMs to improve long-context question answering with citations; it trains 8B and 9B parameter models that enhance citation generation capabilities from lengthy contexts while improving response correctness; claims to even surpass GPT-4o on their proposed LongBench-Cite benchmark. | [Paper](https://arxiv.org/abs/2409.02897), [Tweet](https://x.com/omarsar0/status/1831522905009828051)  \n7) **MemLong** - utilizes an external retriever for retrieving historical information which enhances the capabilities of long-context LLMs; it consistently outperforms other SoTA LLMs on long-context benchmarks and can extend the context length on a single 3090 GPU from 4k up to 80k. | [Paper](https://arxiv.org/abs/2408.16967), [Tweet](https://x.com/omarsar0/status/1830610367854112799)  \n8) **Role of RAG Noise in LLMs** - proposes a benchmark (NoiserBench) to measure how different kinds of noisy information affect RAG's performance; reports that from different kinds of beneficial noise studied (e.g., semantic, datatype, and illegal sentence), illegal sentence noise exhibits the most improved model performance across models and datasets. | [Paper](https://arxiv.org/abs/2408.13533), [Tweet](https://x.com/omarsar0/status/1830984315326660617)  \n9) **Beyond Preference in AI Alignment** - challenges the dominant practice of AI alignment known as human preference tuning; explains in what ways human preference tuning fails to capture the thick semantic content of human values; argues that AI alignment needs reframing, instead of aligning on human preferences, AI should align on normative standards appropriate to their social roles. | [Paper](https://arxiv.org/abs/2408.16984), [Tweet](https://x.com/xuanalogue/status/1831044533779669136)  \n10) **LLM-Based Agents for Software Engineering** - a survey paper on LLM-based agents for software engineering, covering perspectives ranging from requirement engineering to test generation to software maintenance. | [Paper](https://arxiv.org/abs/2409.02977), [Tweet](https://x.com/omarsar0/status/1832115557749121385)  \n## Top ML Papers of the Week (August 26 - September 1) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-august-26---september-1---2024)\n**Paper** | **Links**  \n---|---  \n1) **GameGen** - a game engine powered by a diffusion model that enables real-time interaction with complex environments over long trajectories; uses a two-phase training process involving an RL agent to learn and a diffusion model to generate frames; it can interactively simulate DOOM over at 20 fps on a single TPU. | [Paper](https://arxiv.org/abs/2408.14837), [Tweet](https://x.com/iScienceLuvr/status/1828617875432841490)  \n2) **Agentic RAG for Time Series Analysis** - proposes an agentic RAG framework for time series analysis; uses a multi-agent architecture where an agent orchestrates specialized sub-agents to complete time-series tasks; the sub-agents leverage tuned small language models and can retrieve relevant prompts containing knowledge about historical patterns and trends; this helps to improve predictions on new data. | [Paper](https://arxiv.org/abs/2408.14484), [Tweet](https://x.com/omarsar0/status/1828838209461043455)  \n3) **AutoGen Studio** - a low-code interface for rapidly prototyping AI agents. It's built on top of the AutoGen framework and can also be used for debugging and evaluating multi-agent workflows. | [Paper](https://arxiv.org/abs/2408.15247), [Tweet](https://x.com/omarsar0/status/1829163090715529358)  \n4) **Persuasion Games with LLMs** - claims that a multi-agent framework can be used to improve the persuasive efficacy of LLMs; the primary agent engages in persuasive dialogue while auxiliary agents perform key tasks like response analysis and information retrieval; finds that LLMs are capable of creating a perspective change in the users and persuading them to make a purchase decision; for instance, Sales agents can achieve a 71% positive shift in user perspectives. | [Paper](https://arxiv.org/abs/2408.15879), [Tweet](https://x.com/omarsar0/status/1829156960291185117)  \n5) **Smaller, Weaker, Yet Better** - finds that weaker + cheaper (WC) models can generate better synthetic data for fine-tuning models compared to data generated with stronger but more expensive models; overall, results suggest that WC models may be a compute-optimal approach for training advanced LLM reasoners. | [Paper](https://arxiv.org/abs/2408.16737), [Tweet](https://x.com/omarsar0/status/1829526629787242878)  \n6) **Transfusion** - presents a training recipe to train multi-modal models over discrete and continuous data; combines next token prediction with diffusion to train transformer models over mixed-modality sequences; shows that itâs possible to scale from 7B parameter models to 2T multi-modal tokens that can compete in performance with similar scale diffusion and language models. | [Paper](https://www.arxiv.org/abs/2408.11039), [Tweet](https://x.com/AIatMeta/status/1828836885176967327)  \n7) **ReMamba** - investigates the long-context capabilities and efficiencies of Mamba models; the long-context deficiency issues are due to Mamba's RNN-like nature; it achieves this by condensing information via the following compression strategy: the top-k hidden states during the first forward pass and leverages Mambaâs selective mechanism to incorporate them into the state space during the second forward pass; achieves a 3.2 improvement over the baseline on LongBench and 1.6 improvement on L-Eval; the strategy seems to also transfer to Mamba 2. | [Paper](https://arxiv.org/abs/2408.15496), [Tweet](https://x.com/omarsar0/status/1829151312266637813)  \n8) **Text2SQL is Not Enough** - proposes Table-Augmented Generation (TAG), a unified framework for answering natural language questions over databases; it represents a wider range of unexplored interactions between LLMs and databases; develops a benchmark and finds that standard methods answer no more than 20% of queries correctly. | [Paper](https://arxiv.org/abs/2408.14717v1), [Tweet](https://x.com/lianapatel_/status/1828939097487945948)  \n9) **Foundation Models for Music** - provides a comprehensive overview of state-of-the-art pre-trained models and foundation models in music. | [Paper](https://arxiv.org/abs/2408.14340), [Tweet](https://x.com/omarsar0/status/1828456481114538437)  \n10) **Guide to Continual Multimodal Pretraining** - a comprehensive guide on continual multimodal pertaining; introduces FoMo-In-Flux, a large-scale fine-grained and long horizon continual pretraining benchmark. | [Paper](https://arxiv.org/abs/2408.14471), [Tweet](https://arxiv.org/abs/2408.14471)  \n## Top ML Papers of the Week (August 19 - August 25) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-august-19---august-25---2024)\n**Paper** | **Links**  \n---|---  \n1) **Automate Design of Agentic Systems** - presents Meta Agent Search, a meta agent that iteratively programs and tests new agents based on a growing archive of previous discoveries; claims that with their approach it is possible to learn any possible agentic system including prompts, tool use, control flows, and more; they achieve this by focusing on three main components referred to as search space (define agents), search algorithm (explore search space), and the evaluation function (evaluate candidate agents). | [Paper](https://arxiv.org/abs/2408.08435), [Tweet](https://x.com/omarsar0/status/1825378027347271719)  \n2) **LLM Pruning and Distillation in Practice** - provides a comprehensive report on effective methods for compressing Llama 3.1 and Mistral NeMo models; it presents pruning and distillation approaches applied to the original models to produce 4B and 8B parameter models, respectively; before pruning, they also fine-tune the teacher model on their datasets leading to better distillation; their compression strategy yields a state-of-the-art 8B model (MN-Minitron-8B) which outperforms all similarly-sized models on common language modeling benchmarks. | [Paper](https://arxiv.org/abs/2408.11796), [Tweet](https://x.com/omarsar0/status/1826676365044675042)  \n3) **Vizier Gaussian Process Bandit Algorithm** - presents Vizier, an algorithm based on Gaussian process bandit optimization used by Google for millions of optimizations and research; it provides an open-source Python implementation of the Vizier algorithm, including benchmarking results that demonstrate its wider applicability. | [Paper](https://arxiv.org/abs/2408.11527), [Tweet](https://x.com/XingyouSong/status/1826554454084333723)  \n4) **Language Modeling on Tabular Data** - presents a comprehensive survey of language modeling techniques for tabular data; includes topics such as categorization of tabular data structures and data types, datasets used for model training and evaluation, modeling techniques and training objectives, data processing methods, popular architectures, and challenges and future research directions. | [Paper](https://www.arxiv.org/abs/2408.10548), [Tweet](https://x.com/omarsar0/status/1826094372179366023)  \n5) **Enhancing Robustness in LLMs** - proposes a two-stage prompting technique to remove irrelevant information from context; it serves as a self-mitigation process that first identifies the irrelevant information and then filters it out; this leads to enhancement in robustness of the model and overall better performance on reasoning tasks. | [Paper](https://arxiv.org/abs/2408.10615), [Tweet](https://x.com/omarsar0/status/1826451091774447983)  \n6) **A Comprehensive Overview of GraphRAG Methods** - focuses on techniques applied to the GraphRAG workflow (graph-based indexing, graph-guided retrieval, and graph-enhanced generation); examines tasks, applications, evaluation, and industrial use cases of GraphRAG. | [Paper](https://arxiv.org/abs/2408.08921), [Tweet](https://x.com/omarsar0/status/1825937537782698377)  \n7) **MagicDec** - shows how speculative decoding can enhance throughput, reduce latency, and maintain accuracy in long context generation scenarios; it finds that as sequence length and batch size increase, bottlenecks shift from compute-bound to memory-bound; using these insights, they show it's possible to more effectively use speculative decoding for longer sequences, even when using large batch sizes. | [Paper](https://arxiv.org/abs/2408.11049), [Tweet](https://x.com/omarsar0/status/1826090969906778122)  \n8) **Controllable Text Generation for LLMs** - provides a comprehensive survey on methods for controllable text generation in LLMs; discusses issues like safety, consistency, style, and helpfulness. | [Paper](https://arxiv.org/abs/2408.12599), [Tweet](https://x.com/omarsar0/status/1826824199010132429)  \n9) **PEDAL** - uses a hybrid self-ensembling approach (based on diverse exemplars) to improve the overall performance of LLMs; specifically, it uses diverse exemplars to generate multiple candidate responses and then aggregates them using an LLM to generate a final response; this approach achieves better accuracy compared to greedy decoding and lower cost compared to self-consistency approaches. | [Paper](https://arxiv.org/abs/2408.08869), [Tweet](https://x.com/omarsar0/status/1825373675631071609)  \n10) **Challenges and Responses in the Practice of LLMs** - curates a set of important questions with insightful answers; questions are categorized across topics such as infrastructure, software architecture, data, application, and brain science. | [Paper](https://arxiv.org/abs/2408.09416), [Tweet](https://x.com/omarsar0/status/1825932441980162374)  \n## Top ML Papers of the Week (August 12 - August 18) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-august-12---august-18---2024)\n**Paper** | **Links**  \n---|---  \n1) **The AI Scientist** - a novel AI agent that can develop and write a full conference-level scientific paper costing less than $15; it automates scientific discovery by enabling frontier LLMs to perform independent research and summarize findings; it also uses an automated reviewer to evaluate the generated papers; claims to achieve near-human performance in evaluating paper scores; claims to produce papers that exceed the acceptance threshold at a top machine learning conference as judged by their automated reviewer. | [Paper](https://arxiv.org/abs/2408.06292), [Tweet](https://x.com/omarsar0/status/1823189280883097788)  \n2) **Grok-2** - a new frontier model with strong code, math, and reasoning capabilities which includes a large and small model; outperforms both Claude 3.5 Sonnet and GPT-4-Turbo on the LMSYS Chatbot Arena; claims to improve capabilities including instruction following, retrieval, tool use, and enhancing factuality; competes with Claude 3.5 Sonnet (June release) and GPT-4o (May release) on MMLU and HumanEval. | [Paper](https://x.ai/blog/grok-2), [Tweet](https://x.com/xai/status/1823597788573098215)  \n3) **LongWriter** - proposes AgentWrite to enable off-the-shelf LLMs to generate coherent outputs beyond 20K words; AgentWrite breaks down the long generation task into subtasks and in a divide-and-conquer approach generates; the agent breaks the task into multiple writing subtasks and concatenates the outputs to get a final output (i.e., plan + write); the approach is then used to build SFT datasets that are used to tune LLMs to generate coherent longer outputs automatically; a 9B parameter model, further improved through DPO, achieves state-of-the-art performance on their benchmark, and surpasses proprietary models. | [Paper](https://arxiv.org/abs/2408.07055), [Tweet](https://x.com/omarsar0/status/1823551063946850712)  \n4) **EfficientRAG** - trains an auto-encoder LM to label and tag chunks; it retrieves relevant chunks, tags them as either or , and annotates chunks for continuous processing; then a filter model is trained to formulate the next-hop query based on the original question and previous annotations; this is done iteratively until all chunks are tagged as or the maximum # of iterations is reached; after the process above has gathered enough information to answer the initial question, the final generator (an LLM) generates the final answer. | [Paper](https://arxiv.org/abs/2408.04259), [Tweet](https://x.com/omarsar0/status/1822744591810114044)  \n5) **RAGChecker** - a fine-grained evaluation framework for diagnosing retrieval and generation modules in RAG; shows that RAGChecker has better correlations with human judgment; reports several revealing insightful patterns and trade-offs in design choices of RAG architectures. | [Paper](https://arxiv.org/abs/2408.08067), [Tweet](https://x.com/omarsar0/status/1824460245051081216)  \n6) **HybridRAG** - combines GraphRAG and VectorRAG leading to a HybridRAG system that outperforms both individually; it was tested on a set of financial earning call transcripts. Combining the advantages of both approaches provides more accurate answers to queries. | [Paper](https://arxiv.org/abs/2408.04948), [Tweet](https://x.com/omarsar0/status/1822832843455648000)  \n7) **rStar** - introduces self-play mutual reasoning to improve the reasoning capabilities of small language models without fine-tuning or superior models; MCTS is augmented with human-like reasoning actions, obtained from SLMs, to build richer reasoning trajectories; a separate SLM provides unsupervised feedback on the trajectories and the target SLM selects the final reasoning trajectory as the answer; rStar boosts GSM8K accuracy from 12.51% to 63.91% for LLaMA2-7B and consistently improves the accuracy of other SLMs. | [Paper](https://arxiv.org/abs/2408.06195), [Tweet](https://x.com/AtakanTekparmak/status/1823776878747877572)  \n8) **Scaling LLM Test-Time Compute Optimally** - investigates the scaling behaviors of inference-time computation in LLMs; in particular, it analyses how much an LLM can be improved provided a fixed amount of inference-time compute; finds that the effectiveness of different scaling approaches varies by difficulty of prompt; it then proposes an adaptive compute-optimal strategy that can improve efficiency by more than 4x compared to a best-of-N baseline; reports that in a FLOPs-matched evaluation, optimally scaling test-time compute can outperform a 14x larger model. | [Paper](https://arxiv.org/abs/2408.05109), [Tweet](https://x.com/sea_snell/status/1821263798772363598)  \n9) **MedGraphRAG** - a graph-based framework for the medical domain with a focus on enhancing LLMs and generating evidence-based results; leverages a hybrid static-semantic approach to chunk documents to improve context capture; entities and medical knowledge are represented through graphs which leads to an interconnected global graph; this approach improves precision and outperforms state-of-the-art models on multiple medical Q&A benchmarks. | [Paper](https://arxiv.org/abs/2408.04187), [Tweet](https://x.com/Marktechpost/status/1823069406924288110)  \n10) **Survey of NL2QL** - a comprehensive overview of NL2SQL techniques powered by LLMs; covers models, data collection, evaluation methods, and error analysis. | [Paper](https://arxiv.org/abs/2408.05109), [Tweet](https://x.com/_reachsumit/status/1822835969743347815)  \n## Top ML Papers of the Week (August 5 - August 11) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-august-5---august-11---2024)\n**Paper** | **Links**  \n---|---  \n1) **SAM 2** - an open unified model for real-time, promptable object segmentation in images and videos; can be applied to unseen visual content without the need for custom adaptation; to enable accurate mask prediction in videos, a memory mechanism is introduced to store information on the object and previous interactions; the memory module also allows real-time processing of arbitrarily long videos; SAM2 significantly outperforms previous approaches on interactive video segmentation across 17 zero-shot video datasets while requiring three times fewer human-in-the-loop interactions. | [Paper](https://ai.meta.com/research/publications/sam-2-segment-anything-in-images-and-videos/), [Tweet](https://x.com/AIatMeta/status/1818055906179105010)  \n2) **Structured Generation Limits Reasoning** - investigates if structured generation can impact an LLMâs reasoning and domain knowledge comprehensive capabilities; observes that there is a significant decline in LLMâs reasoning abilities when applying format restrictions compared to free-form responses; this degradation effect is further amplified when applying stricter format constraints to reasoning tasks. | [Paper](https://arxiv.org/abs/2408.02442), [Tweet](https://x.com/omarsar0/status/1822357786820284555)  \n3) **From LLMs to LLM-based Agents for Sofware Engineering** - a survey paper on current practices and solutions for LLM-based agents for software engineering; covers important topics such as requirement engineering, code generation, test generation, and autonomous decision making; it also includes benchmarks, metrics, and models used in different software engineering applications. | [Paper](https://arxiv.org/abs/2408.02479), [Tweet](https://x.com/omarsar0/status/1821549401866686604)  \n4) **Transformer Explainer** - presents an open-source interactive tool to learn about the inner workings of a Transformer model; it runs a GPT-2 instance locally in the user's browser and allows experimenting with your own inputs. | [Paper](https://arxiv.org/abs/2408.04619), [Tweet](https://x.com/omarsar0/status/1821986172215742716)  \n5) **Enhancing LLMs for RAG** - introduces RAGFoundry, an open-source framework for augmented LLMs for RAG use cases; it supports data creation, training, inference, and evaluation; one useful application is the creation of data-augmented datasets for tuning and evaluating LLMs in RAG settings. | [Paper](https://arxiv.org/abs/2408.02545), [Tweet](https://x.com/omarsar0/status/1820864003590995973)  \n6) **Synthesizing Text-to-SQL Data from Weak and Strong LLMs** - proposes integrated synthetic data to build a highly specialized SoTA text-to-SQL model called SENSE; the synthetic data from strong models enhances data diversity while valuable erroneous data from weaker models combined with an executor to learn from execution feedback; preference learning is used to instruction-tune LLMs to learn from both correct and incorrect samples; SENSE achieves state-of-the-art results on the SPIDER and BIRD benchmarks, which bridges the performance gap between open-source models and methods that use closed-source models. | [Paper](https://arxiv.org/abs/2408.03256), [Tweet](https://x.com/omarsar0/status/1821227584920621061)  \n7) **Conversational Prompt Engineering** - proposes an approach to help users create personalized prompts by articulating the preferred outputs via interactions; it involves two stages: 1) an initial instruction shaped by the model based on user-provided unlabeled data, and 2) the model shares the output and the user provides feedback with refinements on outputs and instruction; this iterative process results in a personalized few-shot prompt that performs better and more optimally on the desired task. | [Paper](https://arxiv.org/abs/2408.04560), [Tweet](https://x.com/omarsar0/status/1821981401861718488)  \n8) **Self-Taught Evaluators** - an approach to improve model-based evaluators using synthetic training data only; it first generates contrasting outputs (good and bad model responses) and trains an LLM-as-a-Judge to produce reasoning traces and final judgments; the self-improvement scheme repeats the training process in an iterative way using its improved predictions; claims to outperform LLM-judges such as GPT-4 and match top-performing reward models trained on labeled examples; improves a strong LLM (Llama3-70BInstruct) from 75.4 to 88.3 (88.7 with majority vote) on RewardBench. | [Paper](https://arxiv.org/abs/2408.02666), [Tweet](https://x.com/omarsar0/status/1820849115607044401)  \n9) **RAGEval** - proposes a simple framework to automatically generate evaluation datasets to assess knowledge usage of different LLM under different scenarios; it defines a schema from seed documents and then generates diverse documents which leads to question-answering pairs; the QA pairs are based on both the articles and configurations. | [Paper](https://arxiv.org/abs/2408.01262), [Tweet](https://x.com/omarsar0/status/1820507831491239978)  \n10) **Survey of Mamba** - provides a systematic review of existing Mamba-based models across domains and tasks; specifically, focuses on advancements of Mamba-based models, techniques for adapting Mamba to diverse data, applications where Mamba excels, and promising research directions | [Paper](https://arxiv.org/abs/2408.01129), [Tweet](https://x.com/omarsar0/status/1821556218168549561)  \n## Top ML Papers of the Week (July 29 - August 4) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-july-29---august-4---2024)\n**Paper** | **Links**  \n---|---  \n1) **Meta-Rewarding LLMs** - proposes a self-improving alignment technique (no human supervision) where the LLM judges its own judgements and uses the feedback to improve its judgment skills; shows that leveraging this LLM-as-a-Meta-Judge approach improves the LLM's ability to judge and follow instructions; just doing self-improvement to generate better responses (act) saturates quickly; this work improves the LLM's ability to judge itself (judge) to avoid issues like reward hacking; in addition to the act and judge roles, a third role called meta-judge is used to evaluate the model's own judgements. | [Paper](https://arxiv.org/abs/2407.19594), [Tweet](https://x.com/omarsar0/status/1818680848058585119)  \n2) **MindSearch** - presents an LLM-based multi-agent framework to perform complex web-information seeking and integration tasks; a web planner effectively decomposes complex queries followed by a web searcher that performs hierarchical information retrieval on the Internet to improve the relevancy of the retrieved information; the planning component is powered by an iterative graph construction which is used to better model complex problem-solving processes; the multi-agent framework handles long context problems better by distributing reasoning and retrieval tasks to specialized agents. | [Paper](https://arxiv.org/abs/2407.20183), [Tweet](https://x.com/omarsar0/status/1818673381069226053)  \n3) **Improved RAG with Self-Reasoning** - presents an end-to-end self-reasoning framework to improve the reliability and traceability of RAG systems; leverages the reasoning trajectories generated by the LLM itself; the LLM is used to carry out the following 3 processes: 1) relevance-aware: judges the relevance between the retrieved documents and the question, 2) evidence-aware selective: chooses and cites relevant documents, and then automatically selects snippets of key sentences as evidence from the cited documents, and 3) trajectory analysis: generates a concise analysis based on all gathered self-reasoning trajectories generated by the previous 2 processes and then provides the final inferred answer; this method helps the model to be more selective, reason and distinguish relevant and irrelevant documents, therefore improving the accuracy of the overall RAG system; the framework achieves comparable performance to GPT-4 with only 2K training samples (generated by GPT-4). | [Paper](https://arxiv.org/abs/2407.19813), [Tweet](https://x.com/omarsar0/status/1818139150882664696)  \n4) **Constrained-CoT** - limits the model reasoning output length without sacrificing performance; shows that constraining the reasoning of LLaMA2-70b to 100 words improves the accuracy from 36.01% (CoT) to 41.07% (CCoT) on GSM8K, while reducing the average output length by 28 words. | [Paper](https://arxiv.org/abs/2407.19825), [Tweet](https://x.com/omarsar0/status/1818133220484898992)  \n5) **Adaptive RAG for Conversations Sytems** - develops a gating model that predicts if a conversational system requires RAG to improve its responses; shows that RAG-based conversational systems have the potential to generate high-quality responses and high generation confidence; it also claims to identify a correlation between the generation's confidence level and the relevance of the augmented knowledge. | [Paper](https://arxiv.org/abs/2407.21712), [Tweet](https://x.com/omarsar0/status/1818843407977959756)  \n6) **ShieldGemma** - offers a comprehensive suite of LLM-based safety content moderation models built on Gemma 2; includes classifiers for key harm types such as dangerous content, toxicity, hate speech, and more. | [Paper](https://arxiv.org/abs/2407.21772), [Tweet](https://x.com/omarsar0/status/1818837753292853349)  \n7) **Evaluating Persona Agents** - proposes a benchmark to evaluate persona agent capabilities in LLMs; finds that Claude 3.5 Sonnet only has a 2.97% relative improvement in PersonaScore compared to GPT 3.5 despite being a much more advanced model. | [Paper](https://arxiv.org/abs/2407.18416), [Tweet](https://x.com/omarsar0/status/1817964944949739544)  \n8) **Machine Unlearning Survey** - provides a comprehensive survey on machine unlearning in generative AI. | [Paper](https://arxiv.org/abs/2407.20516), [Tweet](https://x.com/omarsar0/status/1818476462262906985)  \n9) **ThinK** - proposes an approach to address inefficiencies in KV cache memory consumption; it focuses on the long-context scenarios and the inference side of things; it presents a query-dependent KV cache pruning method to minimize attention weight loss while selectively pruning the least significant channels | [Paper](https://arxiv.org/abs/2407.21018), [Tweet](https://x.com/omarsar0/status/1818474655461621903)  \n10) **The Art of Refusal** - a survey of the current methods used to achieve refusal in LLMs; provides evaluation benchmarks and metrics used to measure abstention in LLMs. | [Paper](https://arxiv.org/abs/2407.18418), [Tweet](https://x.com/omarsar0/status/1817961056465035596)  \n## Top ML Papers of the Week (July 22 - July 28) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-july-22---july-28---2024)\n**Paper** | **Links**  \n---|---  \n1) **Llama 3.1** - a collection of LLMs that include 8B, 70B, and 405B parameters models; supports eight languages and extends the context window to 128K tokens; performs competitively and in some cases outperforms state-of-the-art models across capabilities like general knowledge, math reasoning, and tool use. | [Paper](https://scontent.fbze2-1.fna.fbcdn.net/v/t39.2365-6/452387774_1036916434819166_4173978747091533306_n.pdf?_nc_cat=104&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=t6egZJ8QdI4Q7kNvgHPkimJ&_nc_ht=scontent.fbze2-1.fna&oh=00_AYCV8TJ9rZquHu-nvz4-TFSZXLmCjer_LVQTms1bFpzHpA&oe=66A5D24D), [Tweet](https://x.com/AIatMeta/status/1815766327463907421)  \n2) **AlphaProof & Alpha Geometry 2** - solved 4 out of 6 problems in this yearâs IMO which is the equivalent of a silver-medal score; AlphaProof consists of a Gemini model that automatically translates natural language problem statements into formal statements (i.e., formalizer network); then a solver network searches for proofs/disproofs and progressively trains itself using AlphaZero to learn to solve even more complex problems; AlphaGeometry 2, a neuro symbolic hybrid system, proved the geometry problem; based on the Gemini model and trained from scratch on large amounts of synthetic data. | [Paper](https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/), [Tweet](https://x.com/JeffDean/status/1816498336171753948)  \n3) **RAG vs. Long-Context LLMs** - compares RAG and long-context LLMs and finds that long-context LLMs outperform RAG on average performance while RAG is significantly less expensive; proposes Self-Route, leveraging self-reflection to route queries to RAG or LC; reports that Self-Route significantly reduces computational cost while maintaining comparable performance to LC. | [Paper](https://arxiv.org/abs/2407.16833), [Tweet](https://x.com/omarsar0/status/1816495687984709940)  \n4) **OpenDevin** - presents a platform to develop generalist agents that interact with the world through software; features include 1) an interaction mechanism for interaction between agents, interfaces, and environments, 2) an environment including a sandboxed operating system and web browser available to the agents, 3) interface to create and execute code, 4) multi-agent support, and 5) an evaluation framework. | [Paper](https://arxiv.org/abs/2407.16741), [Tweet](https://x.com/omarsar0/status/1816872317286281688)  \n5) **LazyLLM** - introduces a novel dynamic token pruning method for efficient long-context LLM inference; it can accelerate the prefilling stage of a Llama 2 7B model by 2.34x and maintain high accuracy; it selectively computes the KV for tokens that are important for the next token prediction in both the prefilling and decoding stages; it allows language models to dynamically select different subsets of tokens from the context in different generation steps, even though they might be pruned in previous steps. | [Paper](https://arxiv.org/abs/2407.14057), [Tweet](https://x.com/omarsar0/status/1815225416409309264)  \n6) **Teaching LLM Agents to Self-Improve** - claims it is possible to iteratively fine-tune LLMs with the ability to improve their own response over multiple turns with additional environment feedback; the LLM learns to recursively detect and correct its previous mistakes in subsequent iterations; improves the self-improvement abilities of 7B models on reasoning tasks (GSM8K and MATH), attaining an improvement over turns thatâs unseen in strong proprietary models. | [Paper](https://arxiv.org/abs/2407.18219), [Tweet](https://x.com/omarsar0/status/1816671382585114855)  \n7) **Text-to-SQL Survey** - provides a survey on employing LLMs for Text-to-SQL tasks, including prompt engineering techniques, fine-tuning methods, benchmarks, and more. | [Paper](https://arxiv.org/abs/2407.15186), [Tweet](https://x.com/omarsar0/status/1815599057974223015)  \n8) **MINT-1T** - open-sources a large-scale multimodal interleaved dataset consisting of 1 trillion tokens which has 3.4 billion images; it also includes new sources such as PDFs and ArXiv papers. | [Paper](https://arxiv.org/abs/2406.11271), [Tweet](https://x.com/omarsar0/status/1816250935930142834)  \n9) **Model Collapse on Synthetic Data** - investigates the effects of training models on recursively generated data; finds that training on model-generated content can cause irreversible defects where the original content distribution disappears; shows that the effect, referred to as model collapse, occurs in LLMs, VAEs, and GMMs; while tested on smaller scale models (~100M params), the authors suggest this effect is highly likely to transfer to larger models over time. | [Paper](https://www.nature.com/articles/s41586-024-07566-y), [Tweet](https://x.com/alexandr_wang/status/1816491442069782925)  \n10) **Mitigating Hallucination via Generation Constraint** - proposes a new training-free approach to mitigate hallucination in LLMs; they scaled the readout vector that constrains generation in a memory-augmented LLM decoder; recent works claim that LLMs with explicit memory mechanisms can help lower hallucination; this work uses a memory-augmented LLM and constrains generation in the decoder by applying lightweight memory primitives to reduce hallucination. | [Paper](https://arxiv.org/abs/2407.16908), [Tweet](https://x.com/omarsar0/status/1816491986209104104)  \n## Top ML Papers of the Week (July 15 - July 21) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-july-15---july-21---2024)\n**Paper** | **Links**  \n---|---  \n1) **Improving Legibility of LLM Outputs** - iteratively trains small verifiers to predict solution correctness, helpful provers to produce correct solutions accepted by the verifier, and sneaky provers that produce incorrect solutions that fool the verifier; this process helps train models that can produce text that is correct and easy to understand by both humans and AI systems which leads to more trustworthy systems. | [Paper](https://arxiv.org/abs/2407.13692), [Tweet](https://x.com/OpenAI/status/1813623470452064432)  \n2) **SpreadsheetLLM** - presents an efficient encoding method to optimize an LLMâs understanding and reasoning capability on spreadsheets; develops a sheet compressor consisting of structural-anchor-based compression, inverse index translation, and data-format-aware aggregation modules to efficiently compress and encode spreadsheets; in GPT-4âs in-context learning, it improves performance in spreadsheet table detection by 25.6%. | [Paper](https://arxiv.org/abs/2407.09025), [Tweet](https://x.com/_akhaliq/status/1812674543963578794)  \n3) **Context Embeddings for Efficient Answer Generation in RAG** - proposes an effective context compression method to reduce long context and speed up generation time in RAG systems; the long contexts are compressed into a small number of context embeddings which allow different compression rates that trade-off decoding time for generation quality; reduces inference time by up to 5.69 Ã and GFLOPs by up to 22 Ã while maintaining high performance. | [Paper](http://arxiv.org/abs/2407.09252), [Tweet](https://x.com/omarsar0/status/1812937765769867561)  \n4) **Weak-to-Strong Reasoning** - demonstrates the use of weak supervision to elicit strong reasoning capabilities in LLMs without relying on human annotations or advanced models; reports that strong models can automatically refine their training data without explicitly being trained to do so; enables expanding a model's learning scope and scaling performance on reasoning. | [Paper](https://arxiv.org/abs/2407.13647), [Tweet](https://x.com/omarsar0/status/1814130275485704597)  \n5) **A Survey of Prompt Engineering Methods in LLMs** - a collection of prompt engineering methods for a variety of NLP tasks. | [Paper](https://arxiv.org/abs/2407.12994), [Tweet](https://x.com/omarsar0/status/1814135222562165104)  \n6) **Does Refusal Training in LLMs Generalize to the Past Tense?** - finds that simply reformulating an LLM request into past tense can jailbreak many state-of-the-art LLMs; for example \"How to make a Molotov cocktail?\" can be rephrased as \"How did people make a Molotov cocktail?\"; finds that the success rate of such requests can increase from 1% to 88% using direct requests on GPT-4o; concludes that current alignment techniques may not always generalize as intended. | [Paper](https://arxiv.org/abs/2407.11969), [Tweet](https://x.com/maksym_andr/status/1813608842699079750)  \n7) **Can LLMs Do Retrieval and Reasoning in 1 Million Context Window?** - proposes a framework (NeedleBench) of progressively challenging tasks to assess the long-context retrieval and reasoning capabilities of LLMs; they also present the Ancestral Trace Challenge that increases the need for complex logical reasoning which is common in real-world long-context tasks; their findings suggest that current LLMs struggle to handle reasoning tasks with complex logical relationships, even with texts shorter than 2K tokens. | [Paper](https://arxiv.org/abs/2407.11963), [Tweet](https://x.com/omarsar0/status/1813581074624070109)  \n8) **Distilling System 2 into System 1** - investigates self-supervised methods to distill high-quality outputs from System 2 techniques and then fine-tune System 1 to match the predictions of the System 2 technique but without generating intermediate steps; the process of distilling reasoning into System 1 results in less inference cost. | [Paper](https://arxiv.org/abs/2407.06023v1), [Tweet](https://x.com/willccbb/status/1813012865454121179)  \n9) **Exploring Advanced LLMs with LLMSuite** - shares practical tips for developing with and evaluating LLMs; solutions covered range from ReAct to RAG to parameter-efficient methods. | [Paper](https://arxiv.org/abs/2407.12036), [Tweet](https://x.com/omarsar0/status/1813980712346763589)  \n10) **Beyond Euclid** - provides an illustrated guide and graphical taxonomy of recent advances in non-Euclidean machine learning. | [Paper](https://www.arxiv.org/abs/2407.09468), [Tweet](https://x.com/omarsar0/status/1812927886766010653)  \n## Top ML Papers of the Week (July 8 - July 14) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-july-8---july-14---2024)\n**Paper** | **Links**  \n---|---  \n1) **FlashAttention-3** - proposes to adapt FlashAttention to take advantage of modern hardware; the techniques used to speed up attention on modern GPUs include producer-consumer asynchrony, interleaving block-wise matmul and softmax operations, and block quantization and incoherent processing; achieves speedup on H100 GPUs by 1.5-2.0x with FP16 reaching up to 740 TFLOPs/s (75% utilization), and with FP8 reaching close to 1.2 PFLOPs/s. | [Paper](https://tridao.me/publications/flash3/flash3.pdf), [Tweet](https://x.com/tri_dao/status/1811453622070444071)  \n2) **RankRAG** - introduces a new instruction fine-tuning framework to perform effective context ranking and answering generation to enhance an LLMâs RAG capabilities; it leverages a small ranking dataset to outperform existing expert ranking models; shows that a Llama3-RankRAG significantly outperforms Llama3-ChatQA-1.5 and GPT-4 models on nine knowledge-intensive benchmarks. | [Paper](https://arxiv.org/abs/2407.02485v1), [Tweet](https://x.com/_weiping/status/1808551184309104896)  \n3) **Mixture of A Million Experts** - introduces a parameter-efficient expert retrieval mechanism that leverages the product key technique for sparse retrieval from a million tiny experts; it attempts to decouple computational cost from parameter count by efficiently routing to a very large number of tiny experts through a learned index structure used for routing; demonstrates superior efficiency compared to dense FFW, coarse-grained MoEs, and Product Key Memory (PKM) layers. | [Paper](https://arxiv.org/abs/2407.04153), [Tweet](https://x.com/omarsar0/status/1810389538340290724)  \n4) **Reasoning in LLMs: A Geometric Perspective** - explores the reasoning of LLMs from a geometrical perspective; reports that a higher intrinsic dimension implies greater expressive capacity of the LLM; reports that they establish a connection between the expressive power of LLMs and the density of their self-attention graphs; their analysis demonstrates that the density of these graphs defines the intrinsic dimension of the inputs to the MLP blocks. | [Paper](https://arxiv.org/abs/2407.02678), [Tweet](https://x.com/omarsar0/status/1810329294884741594)  \n5) **Contextual Hallucinations Mitigation in LLMs** - proposes a new method that detects and significantly reduces contextual hallucinations in LLMs (e.g., reduces by 10% in the XSum summarization task); builds a hallucination detection model based on input features given by the ratio of attention weights on the context vs. newly generated tokens (for each attention head); the hypothesis is that contextual hallucinations are related to the extent to which an LLM attends to the provided contextual information; they also propose a decoding strategy based on their detection method which mitigates the contextual hallucination; the detector can also be transferred across models without the need for retraining. | [Paper](https://arxiv.org/abs/2407.07071), [Tweet](https://x.com/omarsar0/status/1811072508637884750)  \n6) **RouteLLM** - proposes efficient router models to dynamically select between stronger and weak LLMs during inference to achieve a balance between cost and performance; the training framework leverages human preference data and data augmentation techniques to boost performance; shows to significantly reduce costs by over 2x in certain cases while maintaining the quality of responses. | [Paper](https://arxiv.org/abs/2406.18665v2), [Tweet](https://x.com/lmsysorg/status/1807812671238258931)  \n7) **A Survey on Mixture of Experts** - a survey paper on Mixture of Experts (MoE), including the technical details of MoE, open-source implementations, evaluation techniques, and applications of MoE in practice. | [Paper](https://arxiv.org/abs/2407.06204), [Tweet](https://x.com/omarsar0/status/1811127876819026283)  \n8) **Internet of Agents** - a new framework to address several limitations in multi-agent frameworks such as integrating diverse third-party agents and adaptability to dynamic task requirements; introduces an agent integration protocol, instant messaging architecture design, and dynamic mechanisms for effective collaboration among heterogeneous agents. | [Paper](https://arxiv.org/abs/2407.07061v2), [Tweet](https://x.com/_akhaliq/status/1810872693501157855)  \n9) **3DGen** - a new pipeline for end-to-end text-to-3D asset generation in under a minute; integrates state-of-the-art components like AssetGen and TextureGen to represent 3D objects in three ways, namely view space, in volumetric space, and in UV space; achieves a win rate of 68% with respect to the single-stage model. | [Paper](https://ai.meta.com/research/publications/meta-3d-gen/), [Tweet](https://x.com/AIatMeta/status/1808157832497488201)  \n10) **Learning at Test Time** - proposes new sequence modeling layers with linear complexity and an expressive hidden state; defines a hidden state as an ML model itself capable of updating even on test sequence; by a linear model and a two-layer MLP based hidden state is found to match or exceed baseline models like Transformers, Mamba, and modern RNNs; the linear model is faster than Transformer at 8k context and matches Mamba in wall-clock time. | [Paper](https://arxiv.org/abs/2407.04620), [Tweet](https://x.com/arankomatsuzaki/status/1810148710258508046)  \n## Top ML Papers of the Week (July 1 - July 7) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-july-1---july-7---2024)\n**Paper** | **Links**  \n---|---  \n1) **APIGen** - presents an automated data generation pipeline to synthesize high-quality datasets for function-calling applications; shows that 7B models trained on curated datasets outperform GPT-4 models and other state-of-the-art models on the Berkeley Function-Calling Benchmark; a dataset consisting of 60K entries is also released to help with research in function-calling enabled agents. | [Paper](https://arxiv.org/pdf/2406.18518), [Tweet](https://x.com/Benioff/status/1808365628551844186)  \n2) **CriticGPT** - a new model based on GPT-4 to help write critiques for responses generated by ChatGPT; trained using RLHF using a large number of inputs that contained mistakes for which it had to critique; built to help human trainers spot mistakes during RLHF and claims that CriticGPT critiques are preferred by trainers over ChatGPT critiques in 63% of cases on naturally occurring bugs. | [Paper](https://cdn.openai.com/llm-critics-help-catch-llm-bugs-paper.pdf), [Tweet](https://x.com/OpenAI/status/1806372369151426673)  \n3) **Searching for Best Practices in RAG** - shows the best practices for building effective RAG workflows; proposes strategies that focus on performance and efficiency, including emerging multimodal retrieval techniques. | [Paper](https://arxiv.org/abs/2407.01219), [Tweet](https://x.com/omarsar0/status/1808177231342018748)  \n4) **Scaling Synthetic Data Creation** - proposes 1 billion diverse personas to facilitate the creation of diverse synthetic data for different scenarios; uses a novel persona-driven data synthesis methodology to generate diverse and distinct data covering a wide range of perspectives; to measure the quality of the synthetic datasets, they performed an out-of-distribution evaluation on MATH. A fine-tuned model on their synthesized 1.07M math problems achieves 64.9% on MATH, matching the performance of gpt-4-turbo-preview at only a 7B scale. | [Paper](https://arxiv.org/abs/2406.20094), [Tweet](https://x.com/omarsar0/status/1807827401122238628)  \n5) **Self-Evaluation as a Defense Against Adversarial Attacks on LLMs** - proposes the use of self-evaluation to defend against adversarial attacks; uses a pre-trained LLM to build defense which is more effective than fine-tuned models, dedicated safety LLMs, and enterprise moderation APIs; they evaluate different settings like attacks on the generator only and generator + evaluator combined; it shows that building a dedicated evaluator can significantly reduce the success rate of attacks. | [Paper](https://arxiv.org/abs/2407.03234), [Tweet](https://x.com/omarsar0/status/1809241930963853621)  \n6) **Agentless** - introduces OpenAutoEncoder-Agentless which offers an agentless system that solves 27.3% GitHub issues on SWE-bench Lite; claims to outperform all other open-source AI-powered software engineering agents. | [Paper](https://arxiv.org/abs/2407.01489), [Tweet](https://x.com/LingmingZhang/status/1808501612056629569)  \n7) **Adaptable Logical Control for LLMs** - presents the Ctrl-G framework to facilitate control of LLM generations that reliably follow logical constraints; it combines LLMs and Hidden Markow Models to enable following logical constraints (represented as deterministic finite automata); Ctrl-G achieves over 30% higher satisfaction rate in human evaluation compared to GPT4. | [Paper](https://arxiv.org/abs/2406.13892), [Tweet](https://x.com/HonghuaZhang2/status/1806727439823102325)  \n8) **LLM See, LLM Do** - closely investigates the effects and effectiveness of synthetic data and how it shapes a modelâs internal biases, calibration, attributes, and preferences; finds that LLMs are sensitive towards certain attributes even when the synthetic data prompts appear neutral; demonstrates that itâs possible to steer the generation profiles of models towards desirable attributes. | [Paper](https://arxiv.org/abs/2407.01490), [Tweet](https://x.com/lushimabucoro/status/1808083881632878843)  \n9) **Summary of a Haystack** - proposes a new task, SummHay, to test a modelâs ability to process a Haystack and generate a summary that identifies the relevant insights and cites the source documents; reports that long-context LLMs score 20% on the benchmark which lags the human performance estimate (56%); RAG components is found to boost performance on the benchmark, which makes it a viable option for holistic RAG evaluation. | [Paper](https://arxiv.org/abs/2407.01370), [Tweet](https://x.com/_philschmid/status/1808420168558649479)  \n10) **AI Agents That Matter** - analyzes current agent evaluation practices and reveals shortcomings that potentially hinder real-world application; proposes an implementation that jointly optimizes cost and accuracy and a framework to avoid overfitting agents. | [Paper](https://arxiv.org/abs/2407.01502), [Tweet](https://x.com/random_walker/status/1808138818182434955)  \n## Top ML Papers of the Week (June 24 - June 30) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-june-24---june-30---2024)\n**Paper** | **Links**  \n---|---  \n1) **ESM3** - a new LLM-based biological model that generates a new green fluorescent protein called esmGFP; builds on a bidirectional transformer, uses masked language models for the objective function, leverages geometric attention to represent atomic coordinates, and applies chain-of-thought prompting to generate fluorescent proteins; estimates that esmGFP represents an equivalent of over 500 million years of natural evolution performed by an evolutionary simulator. | [Paper](https://evolutionaryscale-public.s3.us-east-2.amazonaws.com/research/esm3.pdf), [Tweet](https://x.com/alexrives/status/1805559211394277697)  \n2) **Gemma 2** - presents a family of open models ranging between 2B to 27B parameters; demonstrates strong capabilities in reasoning, math, and code generation, outperforming models twice its size. | [Paper](https://storage.googleapis.com/deepmind-media/gemma/gemma-2-report.pdf), [Tweet](https://x.com/omarsar0/status/1806352449956958501)  \n3) **LLM Compiler** - a suite of open pre-trained models (7B and 13B parameters) designed for code optimization tasks; itâs built on top of Code Llama and trained on a corpus of 546 billion tokens of LLVM-IR and assembly code; itâs also instruction fine-tuned to interpreter compiler behavior; achieves 77% of the optimizing potential of autotuning search and performs accurate disassembling 14% of the time compared to the autotuning technique on which it was trained. | [Paper](https://ai.meta.com/research/publications/meta-large-language-model-compiler-foundation-models-of-compiler-optimization), [Tweet](https://x.com/AIatMeta/status/1806361623831171318)  \n4) **Enhancing RAG with Long-Context LLMs** - proposes LongRAG, which combines RAG with long-context LLMs to enhance performance; uses a long retriever to significantly reduce the number of extracted units by operating on longer retrieval units; the long reader takes in the long retrieval units and leverages the zero-shot answer extraction capability of long-context LLMs to improve performance of the overall system; claims to achieve 64.3% on HotpotQA (full-wiki), which is on par with the state-of-the-art model. | [Paper](https://arxiv.org/abs/2406.15319), [Tweet](https://x.com/omarsar0/status/1805230323799560199)  \n5) **Improving Retrieval in LLMs through Synthetic Data** - proposes a fine-tuning approach to improve the accuracy of retrieving information in LLMs while maintaining reasoning capabilities over long-context inputs; the fine-tuning dataset comprises numerical dictionary key-value retrieval tasks (350 samples); finds that this approach mitigates the \"lost-in-the-middle\" phenomenon and improves performance on both information retrieval and long-context reasoning. | [Paper](https://arxiv.org/abs/2406.19292), [Tweet](https://x.com/omarsar0/status/1806738385039692033)  \n6) **GraphReader** - proposes a graph-based agent system to enhance the long-context abilities of LLMs; it structures long text into a graph and employs an agent to explore the graph (using predefined functions guided by a step-by-step rational plan) to effectively generate answers for questions; consistently outperforms GPT-4-128k across context lengths from 16k to 256k. | [Paper](https://arxiv.org/abs/2406.14550v1), [Tweet](https://x.com/omarsar0/status/1806802925517218078)  \n7) **Faster LLM Inference with Dynamic Draft Trees** - presents a context-aware dynamic draft tree to increase the speed of inference; the previous speculative sampling method used a static draft tree for sampling which only depended on position but lacked context awareness; achieves speedup ratios ranging from 3.05x-4.26x, which is 20%-40% faster than previous work; these speedup ratios occur because the new method significantly increases the number of accepted draft tokens. | [Paper](https://arxiv.org/abs/2406.16858), [Tweet](https://x.com/omarsar0/status/1805629496634294760)  \n8) **Following Length Constraints in Instructions** - presents an approach for how to deal with length bias and train instruction following language models that better follow length constraint instructions; fine-tunes a model using DPO with a length instruction augmented dataset and shows less length constraint violations and while keeping a high response quality. | [Paper](https://arxiv.org/abs/2406.17744), [Tweet](https://x.com/jaseweston/status/1805771223747481690)  \n9) **On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation** - survey on LLM-based synthetic data generation, curation, and evaluation. | [Paper](https://arxiv.org/abs/2406.15126), [Tweet](https://x.com/omarsar0/status/1805652404404207919)  \n10) **Adam-mini** - a new optimizer that reduces memory footprint (45%-50% less memory footprint) by using fewer learning rates and achieves on-par or even outperforms AdamW; it carefully partitions parameters into blocks and assigns a single high-quality learning that outperforms Adam; achieves consistent results on language models sized from 125M -7B for pre-training, SFT, and RLHF. | [Paper](https://arxiv.org/abs/2406.16793), [Tweet](https://x.com/arankomatsuzaki/status/1805439246318125299)  \n## Top ML Papers of the Week (June 17 - June 23) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-june-17---june-23---2024)\n**Paper** | **Links**  \n---|---  \n1) **Claude 3.5 Sonnet** - a new model that achieves state-of-the-art performance on several common benchmarks such as MMLU and HumanEval; it outperforms Claude 3 Opus and GPT-4o on several benchmarks with the exception of math word problem-solving tasks; achieves strong performance on vision tasks which also helps power several new features like image-text transcription and generation of artifacts. | [Paper](https://www.anthropic.com/news/claude-3-5-sonnet), [Tweet](https://x.com/AnthropicAI/status/1803790676988920098)  \n2) **DeepSeek-Coder-V2** - competes with closed-sourced models on code and math generation tasks; achieves 90.2% on HumanEval and 75.7% on MATH; these results are higher than GPT-4-Turbo-0409 performance according to their report; includes a 16B and 236B parameter model with 128K context length. | [Paper](https://github.com/deepseek-ai/DeepSeek-Coder-V2/blob/main/paper.pdf), [Tweet](https://x.com/omarsar0/status/1803078095219417475)  \n3) **TextGrad** - a new framework for automatic differentiation through backpropagation on textual feedback provided by an LLM; this improves individual components and the natural language helps to optimize the computation graph; it works by providing an objective function without tuning prompts or components; claims to achieve LeetCodeHard best scores and SoTA performance on GPQA when combined with GPT4o. | [Paper](https://arxiv.org/abs/2406.07496v1), [Tweet](https://x.com/james_y_zou/status/1800917174124740667)  \n4) **Can Long-Context Language Models Subsume Retrieval, RAG, SQL, and More?** - conducts a deep performance analysis of long-context LLMs on in-context retrieval and reasoning; they first present a benchmark with real-world tasks requiring 1M token context; reports that long-context LLMs can rival state-of-the-art retrieval and RAG systems, without any explicit training on the tasks; suggests that compositional reasoning (required in SQL-like tasks) is still challenging for these LLMs; they also encourage the need for continued research on advanced prompting strategies as they noted significant boosts in performance when applying them for long context problems. | [Paper](https://arxiv.org/abs/2406.13121), [Tweet](https://x.com/omarsar0/status/1804184820806766875)  \n5) **PlanRAG** - enhances decision making with a new RAG technique called iterative plan-then-RAG (PlanRAG); involves two steps: 1) an LM generates the plan for decision making by examining data schema and questions and 2) the retriever generates the queries for data analysis; the final step checks if a new plan for further analysis is needed and iterates on previous steps or makes a decision on the data; PlanRAG is found to be more effective than iterative RAG on the proposed Decision QA tasks. | [Paper](https://arxiv.org/abs/2406.12430), [Tweet](https://x.com/omarsar0/status/1803262374574448757)  \n6) **Mitigating Memorization in LLMs** - presents a modification of the next-token prediction objective called goldfish loss to help mitigate the verbatim generation of memorized training data; it uses a simple technique that excludes a pseudorandom subset of training tokens at training time; they show that the goldfish loss resists memorization and keeps the model useful; however, it may need to train for longer to more effectively learn from the training data. | [Paper](https://arxiv.org/abs/2406.10209), [Tweet](https://x.com/omarsar0/status/1802729440163647754)  \n7) **Monte Carlos Tree Self-Refine** - report to have achieved GPT-4 level mathematical olympiad solution using an approach that integrates LLMs with Monte Carlo Tree Search; this approach focuses on enhancing the mathematical reasoning performance of the system through capabilities such as systematic exploration, self-refinement, and self-evaluation. | [Paper](https://arxiv.org/abs/2406.07394v2), [Tweet](https://x.com/rohanpaul_ai/status/1801259208341373013)  \n8) **From RAG to Rich Parameters** - investigates more closely how LLMs utilize external knowledge over parametric information for factual queries; finds that in a RAG pipeline, LLMs take a âshortcutâ and display a strong bias towards utilizing only the context information to answer the question, while relying minimally on their parametric memory. | [Paper](https://arxiv.org/abs/2406.12824), [Tweet](https://x.com/omarsar0/status/1803254134289895555)  \n9) **Open-Sora** - an open-source video generation model that can generate 16-second 720p videos; itâs a 1.1B parameter model trained on more than 30m data and now supports image-to-video; presents an enhanced diffusion model and video compression network for spatial and temporal compression; increases controllability of generations and reduces training costs. | [Paper](https://github.com/hpcaitech/Open-Sora/blob/main/docs/report_03.md), [Tweet](https://x.com/omarsar0/status/1803176105010171957)  \n10) **Tree Search for Language Model Agents** - proposes an inference-time tree search algorithm for LM agents to perform exploration and enable multi-step reasoning; itâs tested on interactive web environments and applied to GPT-4o to significantly improve performance; demonstrates that performance scales when increasing test-time compute. | [Paper](https://jykoh.com/search-agents/paper.pdf), [Tweet](https://x.com/kohjingyu/status/1803604487216701653)  \n## Top ML Papers of the Week (June 10 - June 16) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-june-10---june-16---2024)\n**Paper** | **Links**  \n---|---  \n1) **Nemotron-4 340B** - provides an instruct model to generate high-quality data and a reward model to filter out data on several attributes; demonstrates strong performance on common benchmarks like MMLU and GSM8K; itâs competitive with GPT-4 on several tasks, including high scores in multi-turn chat; a preference data is also released along with the base model. | [Paper](https://research.nvidia.com/publication/2024-06_nemotron-4-340b), [Tweet](https://x.com/omarsar0/status/1802024352851878296)  \n2) **Discovering Preference Optimization Algorithms with LLMs** - proposes LLM-driven objective discovery of state-of-the-art preference optimization; no human intervention is used and an LLM is prompted to propose and implement the preference optimization loss functions based on previously evaluated performance metrics; discovers an algorithm that adaptively combined logistic and exponential losses. | [Paper](https://arxiv.org/abs/2406.08414), [Tweet](https://x.com/SakanaAILabs/status/1801069076003082502)  \n3) **SelfGoal** - a framework to enhance an LLM-based agent's capabilities to achieve high-level goals; adaptively breaks down a high-level goal into a tree structure of practical subgoals during interaction with the environment; improves performance on various tasks, including competitive, cooperative, and deferred feedback environments | [Paper](https://arxiv.org/abs/2406.04784), [Tweet](https://x.com/omarsar0/status/1800183982404829457)  \n4) **Mixture-of-Agents** - an approach that leverages the collective strengths of multiple LLMs through a Mixture-of-Agents methodology; layers are designed with multiple LLM agents and each agent builds on the outputs of other agents in the previous layers; surpasses GPT-4o on AlpacaEval 2.0, MT-Bench and FLASK. | [Paper](https://arxiv.org/abs/2406.04692), [Tweet](https://x.com/togethercompute/status/1800536106729157054)  \n5) **Transformers Meet Neural Algorithmic Reasoners** - a new hybrid architecture that enables tokens in the LLM to cross-attend to node embeddings from a GNN-based neural algorithmic reasoner (NAR); the resulting model, called TransNAR, demonstrates improvements in OOD reasoning across algorithmic tasks | [Paper](https://arxiv.org/abs/2406.09308), [Tweet](https://x.com/omarsar0/status/1801448036389843228)  \n6) **Self-Tuning with LLMs** - improves an LLMâs ability to effectively acquire new knowledge from raw documents through self-teaching; the three steps involved are 1) a self-teaching component that augments documents with a set of knowledge-intensive tasks focusing on memorization, comprehension, and self-reflection, 2) uses the deployed model to acquire knowledge from new documents while reviewing its QA skills, and 3) the model is configured to continually learn using only the new documents which helps with thorough acquisition of new knowledge. | [Paper](https://arxiv.org/pdf/2406.06326), [Tweet](https://x.com/omarsar0/status/1800552376513810463)  \n7) **Sketching as a Visual Chain of Thought** - a framework that enables a multimodal LLM to access a visual sketchpad and tools to draw on the sketchpad; it can equip a model like GPT-4 with the capability to generate intermediate sketches to reason over complex tasks; improves performance on many tasks over strong base models with no sketching; GPT-4o equipped with SketchPad sets a new state of the art on all the tasks tested. | [Paper](https://arxiv.org/abs/2406.09403), [Tweet](https://x.com/omarsar0/status/1801450829234188760)  \n8) **Mixture of Memory Experts** - proposes an approach to significantly reduce hallucination (10x) by tuning millions of expert adapters (e.g., LoRAs) to learn exact facts and retrieve them from an index at inference time; the memory experts are specialized to ensure faithful and factual accuracy on the data it was tuned on; claims to enable scaling to a high number of parameters while keeping the inference cost fixed. | [Paper](https://github.com/lamini-ai/Lamini-Memory-Tuning/blob/main/research-paper.pdf), [Tweet](https://x.com/omarsar0/status/1801638552129700046)  \n9) **Multimodal Table Understanding** - introduces Table-LLaVa 7B, a multimodal LLM for multimodal table understanding; itâs competitive with GPT-4V and significantly outperforms existing MLLMs on multiple benchmarks; also develops a large-scale dataset MMTab, covering table images, instructions, and tasks. | [Paper](https://arxiv.org/abs/2406.08100), [Tweet](https://x.com/omarsar0/status/1801271773796716646)  \n10) **Consistent Middle Enhancement in LLMs** - proposes an approach to tune an LLM to effectively utilize information from the middle part of the context; it first proposes a training-efficient method to extend LLMs to longer context lengths (e.g., 4K -> 256K); it uses a truncated Gaussian to encourage sampling from the middle part of the context during fine-tuning; the approach helps to alleviate the so-called \"Lost-in-the-Middle\" problem in long-context LLMs. | [Paper](https://arxiv.org/abs/2406.07138), [Tweet](https://x.com/omarsar0/status/1800903031736631473)  \n## Top ML Papers of the Week (June 3 - June 9) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-june-3---june-9---2024)\n**Paper** | **Links**  \n---|---  \n1) **NLLB** - proposes a massive multilingual model that leverages transfer learning across 200 languages; itâs based on a sparsely Gated Mixture of Experts architecture and trained on data via an approach tailored for low-resource languages; evaluates on 40K translations and achieves an average of 44% improvement in translation quality. | [Paper](https://www.nature.com/articles/s41586-024-07335-x), [Tweet](https://x.com/AIatMeta/status/1798420492774432769)  \n2) **Extracting Concepts from GPT-4** - proposes a new scalable method based on sparse autoencoders to extract around 16 million interpretable patterns from GPT-4; the method demonstrates predictable scaling and is more efficient than previous techniques. | [Paper](https://openai.com/index/extracting-concepts-from-gpt-4/), [Tweet](https://x.com/OpenAI/status/1798762092528586945)  \n3) **Mamba-2** - a new architecture that combines state space models (SSMs) and structured attention; it uses 8x larger states and trains 50% faster; the new state space duality layer is more efficient and scalable compared to the approach used in Mamba; it also improves results on tasks that require large state capacity. | [Paper](https://arxiv.org/abs/2405.21060), [Tweet](https://x.com/_albertgu/status/1797651223035904355)  \n4) **MatMul-free LLMs** - proposes an implementation that eliminates matrix multiplication operations from LLMs while maintaining performance at billion-parameter scales; the performance between full precision Transformers and the MatMul-free models narrows as the model size increases; claims that by using an optimized kernel during inference, memory consumption is reduced by more than 10x. | [Paper](https://arxiv.org/abs/2406.02528), [Tweet](https://x.com/omarsar0/status/1798373841741185261)  \n5) **Buffer of Thoughts** - presents a thought-augmented reasoning approach to enhance the accuracy, efficiency, and robustness of LLM-based reasoning; it leverages a meta-buffer containing high-level thoughts (thought templates) distilled from problem-solving processes; the relevant thought template is then retrieved and instantiated with task-specific reasoning structures for the thought-augmented reasoning process; it demonstrates SOTA performance on 10 challenging tasks while requiring 12% of the cost of multi-query prompting methods like Tree-of-Thoughts. | [Paper](https://arxiv.org/abs/2406.04271), [Tweet](https://x.com/omarsar0/status/1799113545696567416)  \n6) **SaySelf** - a training framework to teach LLMs to express more accurate fine-grained confidence estimates and self-reflective rationales; it performs supervised finetuning on a dataset that contains summaries of the difference between multiple reasoning chains; reinforcement learning is then applied to calibrate confidence estimates, encouraging the LLM to produce accurate, high-confidence predictions and penalize overconfidence in erroneous outputs. | [Paper](https://arxiv.org/abs/2405.20974), [Tweet](https://x.com/omarsar0/status/1797682549608833477)  \n7) **The Geometry of Concepts in LLMs** - studies the geometry of categorical concepts and how the hierarchical relations between them are encoded in LLMs; finds that simple categorical concepts are represented as simplices by the LLMs and complex concepts are represented as polytopes constructed from direct sums of simplices, which reflect the hierarchical structure. | [Paper](https://arxiv.org/abs/2406.01506), [Tweet](https://x.com/omarsar0/status/1798010546522103898)  \n8) **Aligning LLMs with Demonstrated Feedback** - proposes a method to align LLMs to a specific setting via a very small number of demonstrations as feedback; it aligns LLM outputs to a userâs demonstrated behaviors and can learn fine-grained style and task alignment across domains; outperforms few-shot prompting, SFT, and self-play methods on the tested benchmarks. | [Paper](https://arxiv.org/abs/2406.00888), [Tweet](https://x.com/arankomatsuzaki/status/1797833884463472653)  \n9) **Towards Scalable Automated Alignment of LLMs** - provides an overview of methods used for alignment of LLMs; explores the 4 following directions: 1) aligning through inductive bias, 2) aligning through behavior imitation, 3) aligning through model feedback, and 4) aligning through environment feedback. | [Paper](https://arxiv.org/abs/2406.01252), [Tweet](https://x.com/omarsar0/status/1798014572663583165)  \n10) **AgentGym** - a new framework featuring various environments and tasks for broad, real-time, and concurrent agent exploration; builds a generally capable LLM-based agent with self-evolution abilities and explores its potential beyond previously seen data across tasks and environments. | [Paper](https://arxiv.org/abs/2406.04151), [Tweet](https://x.com/arankomatsuzaki/status/1798904095669121443)  \n## Top ML Papers of the Week (May 27 - June 2) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-may-27---june-2---2024)\n**Paper** | **Links**  \n---|---  \n1) **Contextual Position Encoding** - proposes a new position encoding method, CoPE, to enable the position to be conditioned on context by incrementing position only on certain tokens; the position encoding is context-dependent and can represent different levels of position abstraction; the general position encoding method can attend to the i-th particular word, noun, or sentence; improves perplexity on language modeling and coding tasks. | [Paper](https://arxiv.org/abs/2405.18719), [Tweet](https://x.com/jaseweston/status/1795978611784089799)  \n2) **Symbolic Chain-of-Thought** - proposes a method that improves the logical reasoning capabilities of LLMs by integrating symbolic expressions and logical rules with chain-of-thought (CoT) prompting; the prompting technique is called Symbolic Chain-of-Thought and itâs a fully LLM-based framework with the following key steps: 1) translates natural language context to symbolic format, 2) derives step-by-step plan to solve problems following symbolic logical rules, and 3) uses a verifier to check the translation and reasoning chain. | [Paper](https://arxiv.org/abs/2405.18357), [Tweet](https://x.com/omarsar0/status/1795925943543898157)  \n3) **Abacus Embeddings** - achieves 99% accuracy on 100-digit addition problems by training on only 20-digit numbers with a single GPU; the main challenge this work addresses is the inability of transformers to track the exact position of digits; they do this by adding an embedding to each digit that encodes its position relative to the start of the number; these gains also transfer to multi-step reasoning tasks that include sorting and multiplication. | [Paper](https://arxiv.org/abs/2405.17399), [Tweet](https://x.com/omarsar0/status/1795552696432202045)  \n4) **Introduction to Vision-Language Modeling** - presents an introduction to vision-language models along with key details of how they work and how to effectively train these models. | [Paper](https://arxiv.org/abs/2405.17247), [Tweet](https://x.com/AIatMeta/status/1795499770519392499)  \n5) **GNN-RAG** - combines the language understanding abilities of LLMs with the reasoning abilities of GNNs in a RAG style; the GNN extracts useful and relevant graph information while the LLM takes the information and leverages its capabilities to perform question answering over knowledge graphs (KGQA); GNN-RAG improves vanilla LLMs on KGQA and outperforms or matches GPT-4 performance with a 7B tuned LLM. | [Paper](https://arxiv.org/abs/2405.20139), [Tweet](https://x.com/omarsar0/status/1796578239105679585)  \n6) **Attention as an RNN** - presents a new attention mechanism that can be trained in parallel (like Transformers) and be updated efficiently with new tokens requiring constant memory usage for inferences (like RNNs); the attention formulation is based on the parallel prefix scan algorithm which enables efficient computation of attentionâs many-to-many RNN output; achieves comparable performance to Transformers on 38 datasets while being more time and memory-efficient. | [Paper](https://arxiv.org/abs/2405.13956), [Tweet](https://x.com/iScienceLuvr/status/1793933723756286075)  \n7) **Aya23** - a family of multilingual language models that can serve up to 23 languages; it intentionally focuses on fewer languages and allocates more capacity to these languages; shows that it can outperform other massive multimodal models on those specific languages. | [Paper](https://arxiv.org/abs/2405.15032), [Tweet](https://x.com/CohereForAI/status/1794044201677574446)  \n8) **Are Long-LLMs A Necessity For Long-Context Tasks?** - claims that long-LLMs are not a necessity to solve long-context tasks; proposes a reasoning framework to enable short-LLMs to address long-context tasks by adaptively accessing and utilizing the context based on the presented tasks; it decomposes the long context into short contexts and processes them using a decision-making process. | [Paper](https://arxiv.org/abs/2405.15318), [Tweet](https://x.com/omarsar0/status/1795188655243264299)  \n9) **Financial Statement Analysis with LLMs** - claims that LLMs can generate useful insights from its analysis of trends and financial ratios; shows that GPT-4 performs on par with narrowly specialized models; and achieves a profitable trading strategy based on GPTâs predictions. | [Paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4835311), [Tweet](https://x.com/omarsar0/status/1794120780428546503)  \n10) **SimPO** - a simpler and more effective approach for preference optimization with a reference-free reward; uses the average log probability of a sequence as an implicit reward (i.e., no reference model required) which makes it more compute and memory efficient; demonstrates that it outperforms existing approaches like DPO and claims to produce the strongest 8B open-source model. | [Paper](https://arxiv.org/abs/2405.14734), [Tweet](https://x.com/rasbt/status/1794711330085036061)  \n## Top ML Papers of the Week (May 20 - May 26) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-may-20---may-26---2024)\n**Paper** | **Links**  \n---|---  \n1) **Extracting Interpretable Features from Claude 3 Sonnet** - presents an effective method to extract millions of abstract features from an LLM that represent specific concepts; these concepts could represent people, places, programming abstractions, emotion, and more; reports that some of the discovered features are directly related to the safety aspects of the model; finds features directly related to security vulnerabilities and backdoors in code, bias, deception, sycophancy; and dangerous/criminal content, and more; these features are also used to intuititively steer the modelâs output. | [Paper](https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html), [Tweet](https://x.com/AnthropicAI/status/1792935506587656625)  \n2) **Agent Planning with World Knowledge Model** - introduces a parametric world knowledge model to facilitate agent planning; the agent model can self-synthesize knowledge from expert and sampled trajectories; this is used to train the world knowledge model; prior task knowledge is used to guide global planning and dynamic state knowledge is used to guide the local planning; demonstrates superior performance compared to various strong baselines when adopting open-source LLMs like Mistral-7B and Gemma-7B. | [Paper](https://arxiv.org/abs/2405.14205), [Tweet](https://x.com/omarsar0/status/1793851075411296761)  \n3) **Risks and Opportunities of Open-Source Generative AI** - analyzes the risks and opportunities of open-source generative AI models; argues that the overall benefits of open-source generative AI outweigh its risks. | [Paper](https://arxiv.org/abs/2405.08597), [Tweet](https://x.com/fgirbal/status/1791454665764159794)  \n4) **Enhancing Answer Selection in LLMs** - proposes a hierarchical reasoning aggregation framework for improving the reasoning capabilities of LLMs; the approach, called Aggregation of Reasoning (AoR), selects answers based on the evaluation of reasoning chains; AoR uses dynamic sampling to adjust the number of reasoning chains with respect to the task complexity; it uses results from the evaluation phase to determine whether to sample additional reasoning chains; a known flaw of majority voting is that it fails in scenarios where the correct answer is in the minority; AoR focuses on evaluating the reasoning chains to improve the selection of the final answer; AoR outperforms various prominent ensemble methods and can be used with various LLMs to improve performance on complex reasoning tasks. | [Paper](https://arxiv.org/abs/2405.12939), [Tweet](https://x.com/omarsar0/status/1793132875237163405)  \n5) **How Far Are We From AGI** - presents an opinion paper addressing important questions to understand the proximity to artificial general intelligence (AGI); it provides a summary of strategies necessary to achieve AGI which includes a detailed survey, discussion, and original perspectives. | [Paper](https://arxiv.org/abs/2405.10313v1)  \n6) **Efficient Inference of LLMs** - proposes a layer-condensed KV cache to achieve efficient inference in LLMs; only computes and caches the key-values (KVs) of a small number of layers which leads to saving memory consumption and improved inference throughput; can achieve up to 26x higher throughput than baseline transformers while maintaining satisfactory performance. | [Paper](https://arxiv.org/abs/2405.10637), [Tweet](https://x.com/arankomatsuzaki/status/1792386318300749848)  \n7) **Guide for Evaluating LLMs** - provides guidance and lessons for evaluating large language models; discusses challenges and best practices, along with the introduction of an open-source library for evaluating LLMs. | [Paper](https://arxiv.org/abs/2405.14782), [Tweet](https://x.com/omarsar0/status/1793846120600474017)  \n8) **Scientific Applications of LLMs** - presents INDUS, a comprehensive suite of LLMs for Earth science, biology, physics, planetary sciences, and more; includes an encoder model, embedding model, and small distilled models. | [Paper](https://arxiv.org/abs/2405.10725), [Tweet](https://x.com/omarsar0/status/1792585422465335695)  \n9) **DeepSeek-Prover** - introduces an approach to generate Lean 4 proof data from high-school and undergraduate-level mathematical competition problems; it uses the synthetic data, comprising of 8 million formal statements and proofs, to fine-tune a DeepSeekMath 7B model; achieves whole-proof generation accuracies of 46.3% with 64 samples and 52% cumulatively on the Lean 4 miniF2F test; this surpasses the baseline GPT-4 (23.0%) with 64 samples and a tree search RL method (41.0%). | [Paper](https://arxiv.org/abs/2405.14333), [Tweet](https://x.com/_akhaliq/status/1793864788579090917)  \n10) **Efficient Multimodal LLMs** - provides a comprehensive and systematic survey of the current state of efficient multimodal large language models; discusses efficient structures and strategies, applications, limitations, and promising future directions. | [Paper](https://arxiv.org/abs/2405.10739v1), [Tweet](https://x.com/omarsar0/status/1794072297260634244)  \n## Top ML Papers of the Week (May 13 - May 19) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-may-13---may-19---2024)\n**Paper** | **Links**  \n---|---  \n1) **GPT-4o** - a new model with multimodal reasoning capabilities with real-time support across audio, vision, and text; it can accept as input any combination of text, audio, image, and video to generate combinations of text, audio, and image outputs; itâs reported to match GPT-4 Turbo performance while being 50% much faster and cheaper via APIs. | [Paper](https://openai.com/index/hello-gpt-4o/), [Tweet](https://x.com/OpenAI/status/1790072174117613963)  \n2) **Gemini 1.5 Flash** - a lightweight transformer decoder model with a 2M context window with multimodal capabilities; it is designed for efficiency and yields the fastest output generation of all models on several evaluated languages; overall, Gemini 1.5 Flash performs uniformly better compared to Gemini 1.0 Pro and even performs at a similar level to 1.0 Ultra on several benchmarks. | [Paper](https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf), [Tweet](https://x.com/OriolVinyalsML/status/1791521517211107515)  \n3) **Veo** - Google Deepmindâs most capable video generation model generates high-quality, 1080p resolution videos beyond 1 minute; it supports masked editing on videos and can also generate videos with an input image along with text; the model can extend video clips to 60 seconds and more while keeping consistency with its latent diffusion transformer. | [Paper](https://deepmind.google/technologies/veo/), [Tweet](https://x.com/GoogleDeepMind/status/1790435824598716704)  \n4) **Chameleon** - a family of token-based mixed-modal models for generating images and text in any arbitrary sequence; reports state-of-the-art performance in image captioning and outperforms Llama 2 in text-only tasks and is also competitive with Mixtral 8x7B and Gemini-Pro; exceeds the performance of Gemini Pro and GPT-4V on a new long-form mixed-modal generation evaluation. | [Paper](https://arxiv.org/abs/2405.09818), [Tweet](https://x.com/AIatMeta/status/1791263344714014733)  \n5) **Fine-tuning and Hallucinations** - studies the impact of fine-tuning on new knowledge on the hallucination tendencies of LLMs; the setup includes fine-tuning examples that include new knowledge; shows that LLMs struggle to acquire new factual knowledge via fine-tuning; also finds that as new knowledge is learned it increases the modelâs tendency to hallucinate. | [Paper](https://arxiv.org/abs/2405.05904), [Tweet](https://x.com/arankomatsuzaki/status/1788859706187882960)  \n6) **Zero-shot Tokenizer Transfer** - trains a hypernetwork taking a tokenizer as input and predicting the corresponding embeddings; it demonstrates generalization to new tokenizers both with encoder and decoder LLMs; reports that the method achieves performance close to the original models' performance in cross-lingual and coding tasks while reducing the length of the tokenized sequence. | [Paper](https://arxiv.org/abs/2405.07883), [Tweet](https://x.com/bminixhofer/status/1790267652587258343)  \n7) **WavCraft** - leverages LLMs to connect task-specific models for audio content creation and editing; decomposes users' instructions into several tasks and tackles each task collaboratively with the particular module; it can enable users to interact and produce audio content without explicit commands | [Paper](https://arxiv.org/abs/2403.09527v3)  \n8) **RLHF Workflow** - provides an easily reproducible recipe for online iterative RLHF; discusses theoretical insights and algorithmic principles of online iterative RLHF and practical implementation. | [Paper](https://arxiv.org/abs/2405.07863v1), [Tweet](https://x.com/CaimingXiong/status/1790379121719361776)  \n9) **You Only Cache Once** - a decoder-decoder LLM architecture that only caches key-value pairs once; it involves a cross-decoder stacked upon a self-decoder which efficiently encodes global key-value caches and the cross-encoder reuses the cache via cross-attention; this leads to a significant reduction in GPU memory use without sacrificing capabilities; achieves comparable performance to Transformer in various settings of scaling up model size and number of training token. | [Paper](https://arxiv.org/abs/2405.05254), [Tweet](https://x.com/arankomatsuzaki/status/1788435838474355098)  \n10) **CAT3D** - presents a method for creating anything in 3D by simulating the real-world capture process using a multi-view diffusion model; it can generate consistent novel views of a scene which can be used as input to 3D reconstruction techniques to produce 3D representation rendered in real-time; the scene from CAT3D can be generated in less than one minute and is reported to outperform existing methods on single image and few-view 3D scene creation tasks. | [Paper](https://arxiv.org/abs/2405.10314), [Tweet](https://x.com/_akhaliq/status/1791294630614442009)  \n## Top ML Papers of the Week (May 6 - May 12) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-may-6---may-12---2024)\n**Paper** | **Links**  \n---|---  \n1) **AlphaFold 3** -releases a new state-of-the-art model for accurately predicting the structure and interactions of molecules; it can generate the 3D structures of proteins, DNA, RNA, and smaller molecules; the model is an improved version of the Evoformer module and then assembling its predictions using a diffusion network; the diffusion process starts with a cloud of atoms which converges to its final molecular structure. | [Paper](https://blog.google/technology/ai/google-deepmind-isomorphic-alphafold-3-ai-model/), [Tweet](https://x.com/GoogleDeepMind/status/1788223454317097172)  \n2) **xLSTM: Extended Long Short-Term Memory** - attempts to scale LSTMs to billions of parameters using the latest techniques from modern LLMs and mitigating common limitations of LSTMs; to enable LSTMs the ability to revise storage decisions, they introduce exponential gating and a new memory mixing mechanism (termed sLSTM); to enhance the storage capacities of LSTMs, they add a matrix memory and a covariance update rule (termed mLSTM); Both the sLSTM and xLSTM cells stabilize their exponential gates using the same technique; these extensions lead to xLSTM blocks that are residually stacked into the final xLSTM architecture; compared to Transformers, xLSTMs have a linear computation and constant memory complexity concerning the sequence length; the xLSTM architecture is shown to be efficient at handling different aspects of long context problems; achieves better validation perplexities when compared to different model classes like Transformers, SSMs, and RNNs. | [Paper](https://arxiv.org/abs/2405.04517), [Tweet](https://x.com/omarsar0/status/1788236090265977224)  \n3) **DeepSeek-V2** -a strong MoE model comprising 236B parameters, of which 21B are activated for each token; supports a context length of 128K tokens and uses Multi-head Latent Attention (MLA) for efficient inference by compressing the Key-Value (KV) cache into a latent vector; DeepSeek-V2 and its chat versions achieve top-tier performance among open-source models. | [Paper](https://arxiv.org/abs/2405.04434v2), [Tweet](https://x.com/p_nawrot/status/1788479672067481664)  \n4) **AlphaMath Almost Zero** - enhances LLMs with Monte Carlo Tree Search (MCTS) to improve mathematical reasoning capabilities; the MCTS framework extends the LLM to achieve a more effective balance between exploration and exploitation; for this work, the idea is to generate high-quality math reasoning data without professional human annotations; the assumption is that a well pre-trained LLM already possesses mathematical knowledge to generate reasoning steps but needs better stimulation such as an advanced prompting or search strategy; unlike other methods such as Program-of-thought and Chain-of-thought, no solutions are required for the training data, just the math questions and the answers; the integration of LLMs, a value model, and the MCTS framework enables an effective and autonomous process of generating high-quality math reasoning data; the value model also aids the policy model in searching for effective solution paths. | [Paper](https://arxiv.org/abs/2405.03553), [Tweet](https://x.com/omarsar0/status/1787678940158468283)  \n5) **DrEureka: Language Model Guided Sim-To-Real Transfer** - investigates using LLMs to automate and accelerate sim-to-real design; it requires the physics simulation for the target task and automatically constructs reward functions and domain randomization distributions to support real-world transfer; discovers sim-to-real configurations competitive with existing human-designed ones on quadruped locomotion and dexterous manipulation tasks. | [Paper](https://eureka-research.github.io/dr-eureka/assets/dreureka-paper.pdf), [Tweet](https://x.com/DrJimFan/status/1786429467537088741)  \n6) **Consistency LLMs** - proposes efficient parallel decoders that reduce inference latency by decoding n-token sequence per inference step; the inspiration for this work comes from the human's ability to form complete sentences before articulating word by word; this process can be mimicked and learned through fine-tuning pre-trained LLMs to perform parallel decoding; it is trained to perform parallel decoding by mapping randomly initialized n-token sequences to the same result yielded by autoregressive (AR) decoding in as few steps as possible; a consistency loss helps with multiple-token prediction and a standard AR loss prevents deviation from the target LLM and ensures generation quality. Shows 2.4x to 3.4x improvements in generation speed while preserving the generation quality. | [Paper](https://arxiv.org/abs/2403.00835), [Tweet](https://x.com/omarsar0/status/1788594039865958762)  \n7) **Is Flash Attention Stable?** - develops an approach to understanding the effects of numeric deviation and applies it to the widely-adopted Flash Attention optimization; finds that Flash Attention sees roughly an order of magnitude more numeric deviation as compared to Baseline Attention at BF16. | [Paper](https://arxiv.org/abs/2405.02803), [Tweet](https://x.com/arankomatsuzaki/status/1787674624647414168)  \n8) **Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond** - presents an overview of generative methodologies in video generation, where world models facilitate the synthesis of highly realistic visual content; examines challenges and limitations of world models, and discusses their potential future directions. | [Paper](https://arxiv.org/abs/2405.03520v1), [Tweet](https://x.com/dair_ai/status/1789640682082091442)  \n9) **MAmmoTH2** - harvest 10 million naturally existing instruction data from the pre-training web corpus to enhance LLM reasoning; the approach first recalls relevant documents, extracts instruction-response pairs, and then refines the extracted pairs using open-source LLMs; MAmmoTH2-7B's (Mistral) performance increases from 11% to 34% on MATH and from 36% to 67% on GSM8K. | [Paper](https://arxiv.org/abs/2405.03548), [Tweet](https://x.com/xiangyue96/status/1787684680336097645)  \n10) **Granite Code Models** -introduce Granite, a series of code models trained with code written in 116 programming languages; it consists of models ranging in size from 3 to 34 billion parameters, suitable for applications ranging from application modernization tasks to on-device memory-constrained use cases; demonstrates that the models reach state-of-the-art performance among available open-source code LLMs. | [Paper](https://arxiv.org/abs/2405.04324v1), [Code](https://github.com/ibm-granite/granite-code-models), [Tweet](https://x.com/rohanpaul_ai/status/1788194161495052343)  \n## Top ML Papers of the Week (April 29 - May 5) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-april-29---may-5---2024)\n**Paper** | **Links**  \n---|---  \n1) **Kolmogorov-Arnold Networks** - proposes Kolmogorov-Arnold Networks (KANs) as alternatives to Multi-Layer Perceptrons (MLPs); KANs apply learnable activation functions on edges that represent the weights; with no linear weights used, KANs can outperform MLPs and possess faster neural scaling laws; the authors show that KANs can be used as collaborators to help scientists discover mathematics and physical laws. | [Paper](https://arxiv.org/abs/2404.19756), [Tweet](https://x.com/ZimingLiu11/status/1785483967719981538)  \n2) **Better and Faster LLMs via Multi-token Prediction** - proposes a multi-token prediction approach that performs language modeling by training the predict the following n tokens using n independent output heads; the output heads operate on top of a shared transformer trunk; multi-token prediction is shown to be useful when using larger model sizes and can speed up inference up to 3x; the proposed 13B parameter models solves 12 % more problems on HumanEval and 17 % more on MBPP than comparable next-token models. | [Paper](https://arxiv.org/abs/2404.19737), [Tweet](https://x.com/arankomatsuzaki/status/1785486711646040440)  \n3) **Med-Gemini** - presents a family of multimodal models specialized in medicines and based on the strong multimodal and long-context reasoning capabilities of Gemini; achieves state-of-the-art performance on 10/14 benchmarks surpassing GPT-4 models; it achieves 91% accuracy on MedQA (USMLE) benchmark using an uncertainty-guided search strategy. | [Paper](https://arxiv.org/abs/2404.18416), [Tweet](https://x.com/iScienceLuvr/status/1785247498744778886)  \n4) **When to Retrieve?** - presents an approach to train LLMs to effectively utilize information retrieval; it first proposes a training approach to teach an LLM to generate a special token, , when it's not confident or doesn't know the answer to a question; the fine-tuned model outperforms a base LLM in two fixed alternate settings that include never retrieving and always retrieving context | [Paper](https://arxiv.org/abs/2404.19705), [Tweet](https://x.com/omarsar0/status/1785498325913108556)  \n5) **A Survey on Retrieval-Augmented Language Models** - covers the most important recent developments in RAG and RAU systems; it includes evolution, taxonomy, and an analysis of applications; there is also a section on how to enhance different components of these systems and how to properly evaluate them; it concludes with a section on limitations and future directions. | [Paper](https://arxiv.org/abs/2404.19543), [Tweet](https://x.com/omarsar0/status/1785666343062184422)  \n6) **An Open-source LM Specialized in Evaluating Other LMs** - open-source Prometheus 2 (7B & 8x7B), state-of-the-art open evaluator LLMs that closely mirror human and GPT-4 judgments; they support both direct assessments and pair-wise ranking formats grouped with user-defined evaluation criteria; according to the experimental results, this open-source model seems to be the strongest among all open-evaluator LLMs; the key seems to be in merging evaluator LMs trained on either direct assessment or pairwise ranking formats. | [Paper](https://arxiv.org/abs/2405.01535), [Tweet](https://x.com/omarsar0/status/1786380398966014423)  \n7) **Self-Play Preference Optimization** - proposes a self-play-based method for aligning language models; this optimation procedure treats the problem as a constant-sum two-player game to identify the Nash equilibrium policy; it addresses the shortcomings of DPO and IPO and effectively increases the log-likelihood of chose responses and decreases the rejected ones; SPPO outperforms DPO and IPO on MT-Bench and the Open LLM Leaderboard. | [Paper](https://arxiv.org/abs/2405.00675), [Tweet](https://x.com/QuanquanGu/status/1785903241102049424)  \n8) **Inner Workings of Transformer Language Models** - presents a technical introduction to current techniques used to interpret the inner workings of Transformer-based language models; it provides a detailed overview of the internal mechanisms implemented in these models. | [Paper](https://arxiv.org/abs/2405.00208), [Tweet](https://x.com/omarsar0/status/1786052338043466162)  \n9) **Multimodal LLM Hallucinations** - provides an overview of the recent advances in identifying, evaluating, and mitigating hallucination in multimodal LLMs; it also provides an overview of causes, evaluation benchmarks, metrics, and other strategies to deal with challenges related to detecting hallucinations. | [Paper](https://arxiv.org/abs/2404.18930), [Tweet](https://x.com/DuaneJRich/status/1785220190411821111)  \n10) **In-Context Learning with Long-Context Models** - studies the behavior in-context learning of LLMs at extreme context lengths with long-context models; shows that performance increases as hundreds or thousands of demonstrations are used; demonstrates that long-context ICL is less sensitive to random input shuffling than short-context ICL; concludes that the effectiveness of long-context LLMs is not due to task learning but from attending to similar examples. | [Paper](https://arxiv.org/abs/2405.00200), [Tweet](https://x.com/abertsch72/status/1786392584765538350)  \n## Top ML Papers of the Week (April 22 - April 28) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-april-22---april-28---2024)\n**Paper** | **Links**  \n---|---  \n1) **Phi-3** - a new 3.8B parameter language model called phi-3-mini trained on 3.3 trillion tokens and is reported to rival Mixtral 8x7B and GPT-3.5; has a default context length of 4K but also includes a version that is extended to 128K (phi-mini-128K); combines heavily filtered web data and synthetic data to train the 3.8B models; it also reports results on 7B and 14B models trained on 4.8T tokens (phi-3-small and phi-3-medium) | [Paper](https://arxiv.org/abs/2404.14219), [Tweet](https://x.com/omarsar0/status/1782780923806699716)  \n2) **OpenELM** - a new open language model that employs a layer-wise scaling strategy to efficiently allocate parameters and leading to better efficiency and accuracy; comes with different sizes such as 270M, 450M, 1.1B, and 3B; achieves a 2.36% improvement in accuracy compared to OLMo while requiring 2Ã fewer pre-training tokens. | [Paper](https://arxiv.org/abs/2404.14619), [Tweet](https://x.com/rasbt/status/1783480053847736713)  \n3) **Arctic** - an open-source LLM (Apache 2.0 license.) that uses a unique Dense-MoE Hybrid transformer architecture; performs on par with Llama3 70B in enterprise metrics like coding (HumanEval+ & MBPP+), SQL (Spider) and instruction following (IFEval); claims to use 17x less compute budget than Llama 3 70B; the training compute is roughly under $2 million (less than 3K GPU weeks). | [Paper](https://www.snowflake.com/blog/arctic-open-efficient-foundation-language-models-snowflake/), [Tweet](https://x.com/omarsar0/status/1783176059694821632)  \n4) **Make Your LLM Fully Utilize the Context** - presents an approach to overcome the lost-in-the-middle challenge common in LLMs. It applies an explicit \"information-intensive\" training procedure on Mistral-7B to enable the LLM to fully utilize the context. It leverages a synthetic dataset where the answer requires fine-grained information awareness on a short segment (â¼128 tokens) within a synthesized long context (4Kâ32K tokens), and 2) the integration and reasoning of information from two or more short segments. The resulting model, FILM-7B (Fill-in-the-Middle), shows that it can robustly retrieve information from different positions in its 32K context window. | [Paper](https://arxiv.org/abs/2404.16811), [Tweet](https://x.com/omarsar0/status/1783905514578980949)  \n5) **FineWeb** - a large-scale web dataset containing 15 trillion tokens for training language models; filters and deduplicates CommonCrawl between 2013 and 2024 and the goal is to improve the quality of the data. | [Paper](https://huggingface.co/datasets/HuggingFaceFW/fineweb), [Tweet](https://x.com/gui_penedo/status/1781953413938557276)  \n6) **AI-powered Gene Editors** - achieves precision editing of the human genome with a programmable gene editor design with an AI system powered by an LLM trained on biological diversity at scale. | [Paper](https://www.biorxiv.org/content/10.1101/2024.04.22.590591v1), [Tweet](https://x.com/thisismadani/status/1782510590839406904)  \n7) **AutoCrawler** - Combines LLMs with crawlers with the goal of helping crawlers handle diverse and changing web environments more efficiently; the web crawler agent leverages the hierarchical structure of HTML for progressive understanding; employs top-down and step-back operations, and leverages the DOM tree structure, to generate a complete and executable crawler. | [Paper](https://arxiv.org/abs/2404.12753), [Tweet](https://x.com/omarsar0/status/1782462314983071757)  \n8) **Graph Machine Learning in the Era of LLMs** - provides a comprehensive overview of the latest advancements for Graph ML in the era of LLMs; covers the recent developments in Graph ML, how LLM can enhance graph features, and how it can address issues such as OOD and graph heterogeneity. | [Paper](https://arxiv.org/abs/2404.14928), [Tweet](https://x.com/omarsar0/status/1783171591020392886)  \n9) **Self-Evolution of LLMs** - provides a comprehensive survey on self-evolution approaches in LLMs. | [Paper](https://arxiv.org/abs/2404.14387), [Tweet](https://x.com/omarsar0/status/1782777977526231440)  \n10) **Naturalized Execution Tuning (NExT)** - trains an LLM to have the ability to inspect the execution traced of programs and reason about run-time behavior via synthetic chain-of-thought rationales; improves the fix rate of a PaLM 2 model on MBPP and Human by 26.1% and 14.3%; the model also shows that it can generalize to unknown scenarios. | [Paper](https://arxiv.org/abs/2404.14662), [Tweet](https://x.com/AnsongNi/status/1783311827390070941)  \n## Top ML Papers of the Week (April 15 - April 21) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-april-15---april-21---2024)\n**Paper** | **Links**  \n---|---  \n1) **Llama 3** - a family of LLMs that include 8B and 70B pretrained and instruction-tuned models; Llama 3 8B outperforms Gemma 7B and Mistral 7B Instruct; Llama 3 70 broadly outperforms Gemini Pro 1.5 and Claude 3 Sonnet. | [Paper](https://ai.meta.com/blog/meta-llama-3/?utm_source=twitter&utm_medium=organic_social&utm_content=video&utm_campaign=llama3), [Tweet](https://x.com/AIatMeta/status/1780997403979735440)  \n2) **Mixtral 8x22B** - a new open-source sparse mixture-of-experts model that reports that compared to the other community models, it delivers the best performance/cost ratio on MMLU; shows strong performance on reasoning, knowledge retrieval, maths, and coding. | [Paper](https://mistral.ai/news/mixtral-8x22b/), [Tweet](https://x.com/MistralAILabs/status/1780596888473072029)  \n3) **Chinchilla Scaling: A replication attempt** - attempts to replicate the third estimation procedure of the compute-optimal scaling law proposed in Hoffmann et al. (2022) (i.e., Chinchilla scaling); finds that âthe reported estimates are inconsistent with their first two estimation methods, fail at fitting the extracted data, and report implausibly narrow confidence intervals.â | [Paper](https://arxiv.org/abs/2404.10102), [Tweet](https://x.com/tamaybes/status/1780639257389904013)  \n4) **How Faithful are RAG Models?** - aims to quantify the tug-of-war between RAG and LLMs' internal prior; it focuses on GPT-4 and other LLMs on question answering for the analysis; finds that providing correct retrieved information fixes most of the model mistakes (94% accuracy); when the documents contain more incorrect values and the LLM's internal prior is weak, the LLM is more likely to recite incorrect information; the LLMs are found to be more resistant when they have a stronger prior. | [Paper](https://arxiv.org/abs/2404.10198), [Tweet](https://x.com/omarsar0/status/1780613738585903182)  \n5) **A Survey on Retrieval-Augmented Text Generation for LLMs** - presents a comprehensive overview of the RAG domain, its evolution, and challenges; it includes a detailed discussion of four important aspects of RAG systems: pre-retrieval, retrieval, post-retrieval, and generation. | [Paper](https://arxiv.org/abs/2404.10981), [Tweet](https://x.com/omarsar0/status/1780961995178594324)  \n6) **The Illusion of State in State-Space Models** - investigates the expressive power of state space models (SSMs) and reveals that it is limited similar to transformers in that SSMs cannot express computation outside the complexity class ð³ð¢^0; finds that SSMs cannot solve state-tracking problems like permutation composition and other tasks such as evaluating code or tracking entities in a long narrative. | [Paper](https://arxiv.org/abs/2404.08819), [Tweet](https://x.com/lambdaviking/status/1780246351520887281)  \n7) **Reducing Hallucination in Structured Outputs via RAG** - discusses how to deploy an efficient RAG system for structured output tasks; the RAG system combines a small language model with a very small retriever; it shows that RAG can enable deploying powerful LLM-powered systems in limited-resource settings while mitigating issues like hallucination and increasing the reliability of outputs. | [Paper](https://arxiv.org/abs/2404.08189), [Tweet](https://x.com/omarsar0/status/1779896289745846778)  \n8) **Emerging AI Agent Architectures** - presents a concise summary of emerging AI agent architectures; it focuses the discussion on capabilities like reasoning, planning, and tool calling which are all needed to build complex AI-powered agentic workflows and systems; the report includes current capabilities, limitations, insights, and ideas for future development of AI agent design. | [Paper](https://arxiv.org/abs/2404.11584), [Tweet](https://x.com/omarsar0/status/1780958785785200756)  \n9) **LM In-Context Recall is Prompt Dependent** - analyzes the in-context recall performance of different LLMs using several needle-in-a-haystack tests; shows various LLMs recall facts at different lengths and depths; finds that a model's recall performance is significantly affected by small changes in the prompt; the interplay between prompt content and training data can degrade the response quality; the recall ability of a model can be improved with increasing size, enhancing the attention mechanism, trying different training strategies, and applying fine-tuning. | [Paper](https://arxiv.org/abs/2404.08865), [Tweet](https://x.com/omarsar0/status/1780244042007122129)  \n10) **A Survey on State Space Models** - a survey paper on state space models (SSMs) with experimental comparison and analysis; it reviews current SSMs, improvements compared to alternatives, challenges, and their applications. | [Paper](https://arxiv.org/abs/2404.09516), [Tweet](https://x.com/omarsar0/status/1781430319926686190)  \n## Top ML Papers of the Week (April 8 - April 14) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-april-8---april-14---2024)\n**Paper** | **Links**  \n---|---  \n1) **Leave No Context Behind** - integrates compressive memory into a vanilla dot-product attention layer; the goal is to enable Transformer LLMs to effectively process infinitely long inputs with bounded memory footprint and computation; proposes a new attention technique called Infini-attention which incorporates a compressive memory module into a vanilla attention mechanism; it builds in both masked local attention and long-term linear attention into a single Transformer block; this allows the Infini-Transformer model to efficiently handle both long and short-range contextual dependencies; outperforms baseline models on long-context language modeling with a 114x compression ratio of memory. | [Paper](https://arxiv.org/abs/2404.07143), [Tweet](https://x.com/omarsar0/status/1778480897198612839)  \n2) **OpenEQA** - proposes an open-vocabulary benchmark dataset to measure the capabilities of AI models to perform embodied question answering (EQA); it contains 1600 human-generated questions composed from 180 real-world environments; also provides an LLM-powered evaluation protocol for the task and shows that models like GPT-4V are significantly behind human-level performance. | [Paper](https://open-eqa.github.io/assets/pdfs/paper.pdf), [Tweet](https://x.com/AIatMeta/status/1778425321118732578)  \n3) **CodeGemma** - a family of open code LLMs based on Gemma; CodeGemma 7B models excel in mathematical reasoning and match the code capabilities of other open models; the instruction-tuned CodeGemma 7B model is the more powerful model for Python coding as assessed via the HumanEval benchmark; results also suggest that the model performs best on GSM8K among 7B models; the CodeGemma 2B model achieves SoTA code completion and is designed for fast code infilling and deployment in latency-sensitive settings. | [Paper](https://storage.googleapis.com/deepmind-media/gemma/codegemma_report.pdf), [Tweet](https://x.com/omarsar0/status/1777723836202467713)  \n4) **LM-Guided Chain-of-Thought** - applies knowledge distillation to a small LM with rationales generated by the large LM with the hope of narrowing the gap in reasoning capabilities; the rationale is generated by the lightweight LM and the answer prediction is then left for the frozen large LM; this resource-efficient approach avoids the need to fine-tune the large model and instead offloads the rationale generation to the small language model; the knowledge-distilled LM is further optimized with reinforcement learning using several rational-oriented and task-oriented reward signals; the LM-guided CoT prompting approach proposed in this paper outperforms both standard prompting and CoT prompting. Self-consistency decoding also enhances performance. | [Paper](https://arxiv.org/abs/2404.03414), [Tweet](https://x.com/omarsar0/status/1777755819150373121)  \n5) **Best Practices and Lessons on Synthetic Data** - an overview by Google DeepMind on synthetic data research, covering applications, challenges, and future directions; discusses important topics when working with synthetic data such as ensuring quality, factuality, fidelity, unbiasedness, trustworthiness, privacy, and more. | [Paper](https://arxiv.org/abs/2404.07503), [Tweet](https://x.com/omarsar0/status/1778804848038683066)  \n6) **Reasoning with Intermediate Revision and Search** - presents an approach for general reasoning and search on tasks that can be decomposed into components; the proposed graph-based framework, THOUGHTSCULPT, incorporates iterative self-revision capabilities and allows an LLM to build an interwoven network of thoughts; unlike other approaches such as Tree-of-thoughts that shape the reasoning process using a tree, this new approach incorporates Monte Carlo Tree Search (MCTS) to efficiently navigate the search space; due to its ability for continuous thought iteration, THOUGHTSCULPT is particularly suitable for tasks such as open-ended generation, multip-step reasoning, and creative ideation. | [Paper](https://arxiv.org/abs/2404.05966), [Tweet](https://x.com/omarsar0/status/1777896810805186757)  \n7) **Overview of Multilingual LLMs** - a survey on multilingual LLMs including a thorough review of methods, a taxonomy, emerging frontiers, challenges, and resources to advance research | [Paper](https://arxiv.org/abs/2404.04925), [Tweet](https://x.com/omarsar0/status/1778063103906771105)  \n8) **The Physics of Language Models** - investigates knowledge capacity scaling laws where it evaluates a modelâs capability via loss or benchmarks, to estimate the number of knowledge bits a model stores; reports that \"Language models can and only can store 2 bits of knowledge per parameter, even when quantized to int8, and such knowledge can be flexibly extracted for downstream applications. Consequently, a 7B model can store 14B bits of knowledge, surpassing the English Wikipedia and textbooks combined based on our estimation.\" | [Paper](https://arxiv.org/abs/2404.05405), [Tweet](https://x.com/omarsar0/status/1777709227319968034)  \n9) **Aligning LLMs to Quote from Pre-Training Data** - proposes techniques to align LLMs to leverage memorized information quotes directly from pre-training data; the alignment approach is not only able to generate high-quality quoted verbatim statements but overall preserve response quality; it leverages a synthetic preference dataset for quoting without any human annotation and aligns the target model to quote using preference optimization. | [Paper](https://arxiv.org/abs/2404.03862), [Tweet](https://x.com/omarsar0/status/1777408054402646433)  \n10) **The Influence Between NLP and Other Fields** - aims to quantify the degree of influence between 23 fields of study and NLP; the cross-field engagement of NLP has declined from 0.58 in 1980 to 0.31 in 2022; the study also finds that NLP citations are dominated by CS which accounts for over 80% of citations with emphasis on AI, ML, and information retrieval; overall, NLP is growing more insular -- higher growth of intra-field citation and a decline in multidisciplinary works. | [Paper](https://aclanthology.org/2023.emnlp-main.797/), [Tweet](https://x.com/omarsar0/status/1777337237794955586)  \n## Top ML Papers of the Week (April 1 - April 7) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-april-1---april-7---2024)\n**Paper** | **Links**  \n---|---  \n1) **Many-shot Jailbreaking** - proposes a jailbreaking technique called many-shot jailbreaking to evade the safety guardrails of LLMs; this jailbreaking technique exploits the longer context window supported by many modern LLMs; it includes a very large number of faux dialogues (~256) preceding the final question which effectively steers the model to produce harmful responses. | [Paper](https://www.anthropic.com/research/many-shot-jailbreaking), [Tweet](https://x.com/AnthropicAI/status/1775211248239464837)  \n2) **SWE-Agent** - a new open-source agentic system that can automatically solve GitHub issues with similar accuracy as Devin on the SWE-bench; the agent interacts with a specialized terminal and enables important processing of files and executable tests to achieve good performance; on SWE-bench, SWE-agent resolves 12.29% of issues, achieving the state-of-the-art performance on the full test set. | [Paper](https://github.com/princeton-nlp/SWE-agent), [Tweet](https://x.com/jyangballin/status/1775114444370051582)  \n3) **Mixture-of-Depths** - demonstrates that transformer models can learn to efficiently and dynamically allocate FLOPs to specific positions in a sequence; this helps to optimize the allocation along the sequence for different layers across model depth; findings suggest that for a given FLOP budget models can be trained to perform faster and better than their baseline counterparts. | [Paper](https://arxiv.org/abs/2404.02258), [Tweet](https://x.com/TheSeaMouse/status/1775782800362242157)  \n4) **Local Context LLMs Struggle with Long In-Context Learning** - finds that after evaluating 13 long-context LLMs on long in-context learning the LLMs perform relatively well under the token length of 20K. However, after the context window exceeds 20K, most LLMs except GPT-4 will dip dramatically. | [Paper](https://arxiv.org/abs/2404.02060), [Tweet](https://x.com/omarsar0/status/1775638933377786076)  \n5) **Visualization-of-Thought** - inspired by a human cognitive capacity to imagine unseen worlds, this new work proposes Visualization-of-Thought (VoT) prompting to elicit spatial reasoning in LLMs; VoT enables LLMs to \"visualize\" their reasoning traces, creating internal mental images, that help to guide subsequent reasoning steps; when tested on multi-hop spatial reasoning tasks like visual tiling and visual navigation, VoT outperforms existing multimodal LLMs. | [Paper](https://arxiv.org/abs/2404.03622), [Tweet](https://x.com/omarsar0/status/1776082343813403063)  \n6) **The Unreasonable Ineffectiveness of the Deeper Layers** - finds that a simple layer-pruning strategy of popular open-weight pretraining LLMs shows minimal performance degradation until after a large fraction (up to half) of the layers are removed; using a layer similarity mechanism optimal blocks are identified and pruned followed by a small amount of fine-tuning to heal damage | [Paper](https://arxiv.org/abs/2403.17887v1), [Tweet](https://x.com/AlphaSignalAI/status/1774858806817906971)  \n7) **JetMoE** - an 8B model trained with less than $ 0.1 million cost but outperforms LLaMA2-7B; shows that LLM training can be much cheaper than generally thought; JetMoE-8B has 24 blocks where each block has two MoE layers: Mixture of Attention heads (MoA) and Mixture of MLP Experts (MoE); each MoA and MoE layer has 8 experts, and 2 experts are activated for each input token with 2.2B active parameters. | [Paper](https://research.myshell.ai/jetmoe), [Tweet](https://x.com/omarsar0/status/1775971009469768104)  \n8) **Representation Finetuning for LMs** - proposes a method for representation fine-tuning (ReFT) that operates on a frozen base model and learns task-specific interventions on hidden representations; in other words, by manipulating a small fraction of model representations it is possible to effectively steer model behavior to achieve better downstream performance at inference time; also proposes LoReFT as a drop-in replacement for PEFTs that is 10-50x more parameter efficient. | [Paper](https://arxiv.org/abs/2404.03592), [Tweet](https://x.com/arankomatsuzaki/status/1776057023697731913)  \n9) **Advancing LLM Reasoning** - proposes a suite of LLMs (Eurus) optimized for reasoning and achieving SoTA among open-source models on tasks such as mathematics and code generation; Eurus-70B outperforms GPT-3.5 Turbo in reasoning largely due to a newly curated, high-quality alignment dataset designed for complex reasoning tasks; the data includes instructions with preference tree consisting of reasoning chains, multi-turn interactions and pairwise data for preference learning. | [Paper](https://github.com/OpenBMB/Eurus/blob/main/paper.pdf), [Tweet](https://x.com/lifan__yuan/status/1775217887701278798)  \n10) **Training LLMs over Neurally Compressed Text** - explores training LLMs with neural text compressors; the proposed compression technique segments text into blocks that each compress to the same bit length; the approach improves at scale and outperforms byte-level baselines on both perplexity and inference speed benchmarks; latency is reduced to the shorter sequence length | [Paper](https://arxiv.org/abs/2404.03626), [Tweet](https://x.com/arankomatsuzaki/status/1776055420848631814)  \n## Top ML Papers of the Week (March 26 - March 31) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-march-26---march-31---2024)\n**Paper** | **Links**  \n---|---  \n1) **DBRX** - a new 132B parameter open LLM that outperforms all the established open-source models on common benchmarks like MMLU and GSM8K; DBRX was pretrained on 12T tokens (text and code) and uses a mixture-of-experts (MoE) architecture; its inference is up to 2x faster than LLaMA2-70B and is about 40% of the size of Grok-1 in terms of both total and active parameter counts; there is also DBRX Instruct which demonstrates good performance in programming and mathematics; while DBRX is trained as a general-purpose LLM, it still surpasses CodeLLaMa-70 Instruct, a model built explicitly for code generation. | [Paper](https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm), [Tweet](https://x.com/omarsar0/status/1773018193885303266?s=20)  \n2) **Grok-1.5** - xAIâs latest long-context LLM for advanced understanding and reasoning and problem-solving capabilities; Grok-1.5 achieved a 50.6% score on the MATH benchmark and a 90% score on the GSM8K benchmark; this model can process long contexts of up to 128K tokens and demonstrates powerful retrieval capabilities. | [Paper](https://x.ai/blog/grok-1.5), [Tweet](https://x.com/xai/status/1773510159740063860?s=20)  \n3) **SEEDS** - a generative AI model based on diffusion models that shows powerful capabilities to quantify uncertainty in weather forecasting; it can generate a large ensemble conditioned on as few as one or two forecasts from an operational numerical weather prediction system. | [Paper](https://www.science.org/doi/10.1126/sciadv.adk4489), [Tweet](https://x.com/GoogleAI/status/1773774362413355099?s=20)  \n4) **LLMs for University-Level Coding Course** - finds that the latest LLMs have not surpassed human proficiency in physics coding assignments; also finds that GPT-4 significantly outperforms GPT-3.5 and prompt engineering can further enhance performance. | [Paper](https://arxiv.org/abs/2403.16977), [Tweet](https://x.com/omarsar0/status/1772647466820685895?s=20)  \n5) **Mini-Gemini** - a simple framework to enhance multi-modality vision models; specifically, visual tokens are enhanced through an additional visual encoder for high-resolution refinement without token increase; achieves top performance in several zero-shot benchmarks and even surpasses the developed private models. | [Paper](https://arxiv.org/abs/2403.18814v1), [Tweet](https://x.com/_akhaliq/status/1773170068521713713?s=20)  \n6) **Long-form factuality in LLMs** - investigates long-form factuality in open-domain by generating a prompt set of questions including 38 topics; also proposes an LLM-based agent to perform evaluation for the task; finds that LLM agents can achieve superhuman rating performance and is reported to be 20 times cheaper than human annotations. | [Paper](https://arxiv.org/abs/2403.18802v1), [Tweet](https://x.com/JerryWeiAI/status/1773402343301877960?s=20)  \n7) **Agent Lumos** - a unified framework for training open-source LLM-based agents; it consists of a modular architecture with a planning module that can learn subgoal generation and a module trained to translate them to action with tool usage. | [Paper](https://arxiv.org/abs/2311.05657), [Tweet](https://x.com/Wade_Yin9712/status/1773792306791055397?s=20)  \n8) **AIOS** - an LLM agent operation system that integrates LLMs into operation systems as a brain; the agent can optimize resource allocation, context switching, enable concurrent execution of agents, tool service, and even maintain access control for agents. | [Paper](https://arxiv.org/abs/2403.16971v2), [Tweet](https://x.com/arankomatsuzaki/status/1772460132745547976?s=20)  \n9) **FollowIR** - a dataset with instruction evaluation benchmark and a separate set for teaching information retrieval model to follow real-world instructions; a FollowIR-7B model has significant improvements (over 13%) after fine-tuning on a training set. | [Paper](https://arxiv.org/abs/2403.15246), [Tweet](https://x.com/arankomatsuzaki/status/1772082608609833127?s=20)  \n10) **LLM2LLM** - an iterative data augmentation strategy that leverages a teacher LLM to enhance a small seed dataset by augmenting additional data that can be used to effectively fine-tune models; it significantly enhances the performance of LLMs in the low-data regime, outperforming both traditional fine-tuning and other data augmentation baselines. | [Paper](https://arxiv.org/abs/2403.15042), [Tweet](https://x.com/arankomatsuzaki/status/1772078585903219007?s=20)  \n## Top ML Papers of the Week (March 18 - March 25) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-march-18---march-25---2024)\n**Paper** | **Links**  \n---|---  \n1) **Grok-1** - a mixture-of-experts model with 314B parameters which includes the open release of the base model weights and network architecture; the MoE model activates 25% of the weights for a given token and its pretraining cutoff date is October 2023. | [Paper](https://x.ai/blog/grok-os), [Tweet](https://x.com/ibab_ml/status/1769447989192675748?s=20)  \n2) **Evolutionary Model Merge** - an approach for automating foundation model development using evolution to combine open-source models; facilitates cross-domain merging where a Japanese Math LLM achieved state-of-the-art performance on Japanese LLM benchmarks, even surpassing models with significantly more parameters, despite not explicitly trained for these tasks. | [Paper](https://arxiv.org/abs/2403.13187), [Tweet](https://x.com/SakanaAILabs/status/1770613032198279663?s=20)  \n3) **TacticAI** - an AI-powered assistant for football tactics developed and evaluated in collaboration with domain experts from Liverpool FC; the systems offer coaches a way to sample and explore alternative player setups for a corner kick routine and select the tactic with the highest predicted likelihood of success; TacticAIâs model suggestions are favored over existing tactics 90% of the time and it offers an effective corner kick retrieval system. | [Paper](https://www.nature.com/articles/s41467-024-45965-x), [Tweet](https://x.com/GoogleDeepMind/status/1770121564085707082?s=20)  \n4) **Tool Use in LLMs** - provides an overview of tool use in LLMs, including a formal definition of the tool-use paradigm, scenarios where LLMs leverage tool usage, and for which tasks this approach works well; it also provides an analysis of complex tool usage and summarize testbeds and evaluation metrics across LM tooling works. | [Paper](https://zorazrw.github.io/files/WhatAreToolsAnyway.pdf), [Tweet](https://x.com/omarsar0/status/1770497515898433896?s=20)  \n5) **Step-by-Step Comparisons Make LLMs Better Reasoners** - proposes RankPrompt, a prompting method to enable LLMs to self-rank their responses without additional resources; this self-ranking approach ranks candidates through a systematic, step-by-step comparative evaluation; it seems to work well as it leverages the capabilities of LLMs to generate chains of comparisons as demonstrations; RankPrompt significantly enhances the reasoning performance of ChatGPT and GPT-4 on many arithmetic and commonsense reasoning tasks. | [Paper](https://arxiv.org/abs/2403.12373), [Tweet](https://x.com/omarsar0/status/1770492690129359135?s=20)  \n6) **LLM4Decompile** - a family of open-access decompilation LLMs ranging from 1B to 33B parameters; these models are trained on 4 billion tokens of C source code and corresponding assembly code; the authors also introduce Decompile-Eval, a dataset for assessing re-compatibility and re-executability for decompilation and evaluating with a perspective of program semantics; LLM4Decompile demonstrates the capability to decompile 21% of the assembly code, achieving a 50% improvement over GPT-4. | [Paper](https://arxiv.org/abs/2403.05286v1), [Tweet](https://x.com/omarsar0/status/1771218791399092351?s=20)  \n7) **Agent-FLAN** - designs data and methods to effectively fine-tune language models for agents, referred to as Agent-FLAN; this enables Llama2-7B to outperform prior best works by 3.5% across various agent evaluation datasets; Agent-FLAN greatly alleviates the hallucination issues and consistently improves the agent capability of LLMs when scaling model sizes while generally improving the LLM. | [Paper](https://arxiv.org/abs/2403.12881v1), [Tweet](https://x.com/_akhaliq/status/1770302813152690259?s=20)  \n8) **LLMs Leak Proprietary Information** - shows that itâs possible to learn a large amount of non-public information about an API-protected LLM using the logits; with a relatively small number of API queries, the approach estimates that the embedding size of OpenAI's gpt-3.5-turbo to be about 4,096; the paper also proposes guardrails against the attacks used | [Paper](https://arxiv.org/abs/2403.09539), [Tweet](https://x.com/DimitrisPapail/status/1768654579254579385?s=20)  \n9) **DROID** - an open-source, large-scale robot manipulation dataset to train and build more capable and robust robotic manipulation policies; it contains 76K demonstration trajectories, collected across 564 scenes and 86 tasks; training with DROID leads to higher performing policies and generalization. | [Paper](https://arxiv.org/abs/2403.12945), [Tweet](https://x.com/chelseabfinn/status/1770311755140575413?s=20)  \n10) **Retrieval-Augmented Fine-Tuning** - combines the benefits of RAG and fine-tuning to improve a model's ability to answer questions in \"open-book\" in-domain settings; combining it with RAFT's CoT-style response helps to improve reasoning. | [Paper](https://arxiv.org/abs/2403.10131), [Tweet](https://x.com/cwolferesearch/status/1770912695765660139?s=20)  \n## Top ML Papers of the Week (March 11 - March 17) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-march-11---march-17---2024)\n**Paper** | **Links**  \n---|---  \n1) **SIMA** - a generalist AI agent for 3D virtual environments that follows natural-language instructions in a broad range of 3D virtual environments and video games; SIMA is evaluated across 600 basic skills, spanning navigation, object interaction, and menu use. Language seems to be a huge factor in performance. | [Paper](https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/sima-generalist-ai-agent-for-3d-virtual-environments/Scaling%20Instructable%20Agents%20Across%20Many%20Simulated%20Worlds.pdf), [Tweet](https://x.com/GoogleDeepMind/status/1767918515585994818?s=20)  \n2) **Retrieval Augmented Thoughts** - shows that iteratively revising a chain of thoughts with information retrieval can significantly improve LLM reasoning and generation in long-horizon generation tasks; the key idea is that each thought step is revised with relevant retrieved information to the task query, the current and past thought steps; Retrieval Augmented Thoughts (RAT) can be applied to different models like GPT-4 and CodeLlama-7B to improve long-horizon generation tasks (e.g., creative writing and embodied task planning); RAT is a zero-shot prompting approach and provides significant improvements to baselines that include zero-shot CoT prompting, vanilla RAG, and other baselines. | [Paper](https://arxiv.org/abs/2403.05313), [Tweet](https://x.com/omarsar0/status/1767251740443746435?s=20)  \n3) **LMs Can Teach Themselves to Think Before Speaking** - presents a generalization of STaR, called Quiet-STaR, to enable language models (LMs) to learn to reason in more general and scalable ways; Quiet-STaR enables LMs to generate rationales at each token to explain future text; it proposes a token-wise parallel sampling algorithm that helps improve LM predictions by efficiently generating internal thoughts; the rationale generation is improved using REINFORCE. | [Paper](https://arxiv.org/abs/2403.09629), [Tweet](https://x.com/omarsar0/status/1768681638009975088?s=20)  \n4) **Knowledge Conflicts for LLMs** - an overview of the common issue of knowledge conflict when working with LLMs; the survey paper categorizes these conflicts into context-memory, inter-context, and intra-memory conflict; it also provides insights into causes and potential ways to mitigate these knowledge conflict issues. | [Paper](https://arxiv.org/abs/2403.08319), [Tweet](https://x.com/omarsar0/status/1768288774532858003?s=20)  \n5) **Stealing Part of a Production Language Model** - presents the first model-stealing attack that extracts information from production language models like ChatGPT or PaLM-2; shows that it's possible to recover the embedding projection layer of a transformer-based model through typical API access; as an example, the entire projection matrix was extracted from the OpenAI ada and babbage models for under $20. | [Paper](https://arxiv.org/abs/2403.06634), [Tweet](https://x.com/omarsar0/status/1767641831079067694?s=20)  \n6) **Branch-Train-MiX** - proposes mixing expert LLMs into a Mixture-of-Experts LLM as a more compute-efficient approach for training LLMs; it's shown to be more efficient than training a larger generalist LLM or several separate specialized LLMs; the approach, BTX, first trains (in parallel) multiple copies of a seed LLM specialized in different domains (i.e., expert LLMs) and merges them into a single LLM using MoE feed-forward layers, followed by fine-tuning of the overall unified model. | [Paper](https://arxiv.org/abs/2403.07816), [Tweet](https://x.com/jaseweston/status/1767727740952682667?s=20)  \n7) **LLMs Predict Neuroscience Results** - proposes a benchmark, BrainBench, for evaluating the ability of LLMs to predict neuroscience results; finds that LLMs surpass experts in predicting experimental outcomes; an LLM tuned on neuroscience literature was shown to perform even better. | [Paper](https://arxiv.org/abs/2403.03230), [Tweet](https://x.com/ProfData/status/1765689739682754824?s=20)  \n8) **C4AI Command-R** - a 35B parameter model, with a context length of 128K, optimized for use cases that include reasoning, summarization, and question answering; Command-R has the capability for multilingual generation evaluated in 10 languages and performant tool use and RAG capabilities; it has been released for research purposes. | [Paper](https://huggingface.co/CohereForAI/c4ai-command-r-v01), [Tweet](https://x.com/CohereForAI/status/1767275927505977455?s=20)  \n9) **Is Cosine-Similarity Really About Simirity?** - studies embeddings derived from regularized linear models and derive analytically how cosine-similarity can yield arbitrary and meaningless similarities; also finds that for some linear models, the similarities are not even unique and others are controlled by regularization; the authors caution against blindly using cosine similarity and presents considerations and alternatives. | [Paper](https://arxiv.org/abs/2403.05440), [Tweet](https://x.com/_reachsumit/status/1767045820384477575?s=20)  \n10) **Multimodal LLM Pre-training** - provides a comprehensive overview of methods, analysis, and insights into multimodal LLM pre-training; studies different architecture components and finds that carefully mixing image-caption, interleaved image-text, and text-only data is key for state-of-the-art performance; it also proposes a family of multimodal models up to 30B parameters that achieve SOTA in pre-training metrics and include properties such as enhanced in-context learning, multi-image reasoning, enabling few-shot chain-of-thought prompting. | [Paper](https://arxiv.org/abs/2403.09611), [Tweet](https://x.com/DrJimFan/status/1769053019939967080?s=20)  \n## Top ML Papers of the Week (March 4 - March 10) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-march-4---march-10---2024)\n**Paper** | **Links**  \n---|---  \n1) **Claude 3** - consists of a family of three models (Claude 3 Haiku, Claude 3 Sonnet, and Claude 3 Opus); Claude 3 Opus (the strongest model) seems to outperform GPT-4 on common benchmarks like MMLU and HumanEval; Claude 3 capabilities include analysis, forecasting, content creation, code generation, and converting in non-English languages like Spanish, Japanese, and French; 200K context windows supported but can be extended to 1M token to select customers; the models also have strong vision capabilities for processing formats like photos, charts, and graphs; Anthropic claims these models have a more nuanced understanding of requests and make fewer refusals. | [Paper](https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf), [Tweet](https://x.com/AnthropicAI/status/1764653830468428150?s=20)  \n2) **Robust Evaluation of Reasoning** - proposes functional benchmarks for the evaluation of the reasoning capabilities of LLMs; finds that there is a reasoning gap with current models from 58.35% to 80.31%; however, the authors also report that those gaps can be reduced with more sophisticated prompting strategies. | [Paper](https://arxiv.org/abs/2402.19450), [Tweet](https://x.com/_saurabh/status/1763626711407816930?s=20)  \n3) **GaLore** - proposes a memory-efficient approach for training LLM through low-rank projection; the training strategy allows full-parameter learning and is more memory-efficient than common low-rank adaptation methods such as LoRA; reduces memory usage by up to 65.5% in optimizer states while maintaining both efficiency and performance for pre-training on LLaMA 1B and 7B architectures. | [Paper](https://arxiv.org/abs/2403.03507), [Tweet](https://x.com/AnimaAnandkumar/status/1765613815146893348?s=20)  \n4) **Can LLMs Reason and Plan?** - a new position paper discusses the topic of reasoning and planning for LLMs; here is a summary of the author's conclusion: \"To summarize, nothing that I have read, verified, or done gives me any compelling reason to believe that LLMs do reasoning/planning, as normally understood. What they do instead, armed with web-scale training, is a form of universal approximate retrieval, which, as I have argued, can sometimes be mistaken for reasoning capabilities\". | [Paper](https://arxiv.org/abs/2403.04121), [Tweet](https://x.com/omarsar0/status/1766123621326475285?s=20)  \n5) **RAG for AI-Generated Content** - provides an overview of RAG used in different generation scenarios like code, image, and audio, including a taxonomy of RAG enhancements with reference to key papers. | [Paper](https://arxiv.org/abs/2402.19473v1), [Tweet](https://x.com/omarsar0/status/1765414854397985175?s=20)  \n6) **KnowAgent** - proposes an approach to enhance the planning capabilities of LLMs through explicit action knowledge; uses an action knowledge base and a knowledgeable self-learning phase to guide the model's action generation, mitigate planning hallucination, and enable continuous improvement; outperforms existing baselines and shows the potential of integrating external action knowledge to streamline planning with LLMs and solve complex planning challenges. | [Paper](https://arxiv.org/abs/2403.03101), [Tweet](https://x.com/omarsar0/status/1765408813467759037?s=20)  \n7) **Sora Overview** - a comprehensive review of Sora and some of the key developments powering this model, including limitations and opportunities of large vision models. | [Paper](https://arxiv.org/abs/2402.17177v2), [Tweet](https://x.com/omarsar0/status/1765756669659603015?s=20)  \n8) **LLM for Law** - introduces SaulLM-7B, a large language model for the legal domain explicitly designed for legal text comprehension and generation; presents an instructional fine-tuning method that leverages legal datasets to further enhance performance in legal tasks. | [Paper](https://arxiv.org/abs/2403.03883), [Tweet](https://x.com/_akhaliq/status/1765614083875738028?s=20)  \n9) **Design2Code** - investigates the use of multimodal LLMs for converting a visual design into code implementation which is key for automating front-end engineering; introduces a benchmark of 484 diverse real-world webpages and a set of evaluation metrics to measure the design-to-code capability; further develops a suite of multimodal prompting methods and show their effectiveness on GPT-4V and Gemini Pro Vision; an open-source fine-tuned Design2Code matches the performance of Gemini Pro Vision, however, GPT-4V performs the best on the task. | [Paper](https://arxiv.org/abs/2403.03163), [Tweet](https://x.com/_akhaliq/status/1765199160653828385?s=20)  \n10) **TripoSR** - a transformer-based 3D reconstruction model for fast feed-forward 3D generation; it can produce 3D mesh from a single image in under 0.5 seconds; improvement includes better data processing, model design, and training. | [Paper](https://arxiv.org/abs/2403.02151v1), [Tweet](https://x.com/_akhaliq/status/1764841524431392794?s=20)  \n## Top ML Papers of the Week (February 26 - March 3) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-february-26---march-3---2024)\n**Paper** | **Links**  \n---|---  \n1) **Genie** - a foundation model trained from internet videos and with the ability to generate a variety of action-controllable 2D worlds given an image prompt; Genie has 11B parameters and consists of a spatiotemporal video tokenizer, an autoregressive dynamic model, and a scalable latent action model; the latent action space enables training agents to imitate behaviors from unseen video which is promising for building more generalist agents. | [Paper](https://arxiv.org/abs/2402.15391), [Tweet](https://x.com/_rockt/status/1762026090262872161?s=20)  \n2) **Mistral Large** - a new LLM with strong multilingual, reasoning, maths, and code generation capabilities; features include: 1) 32K tokens context window, 2) native multilingual capacities, 3) strong abilities in reasoning, knowledge, maths, and coding benchmarks, and 4) function calling and JSON format natively supported. | [Paper](https://mistral.ai/news/mistral-large/), [Tweet](https://x.com/omarsar0/status/1762140818654064721?s=20)  \n3) **The Era of 1-bit LLMs** - introduces a high-performing and cost-effective 1-bit LLM variant called BitNet b1.58 where every parameter is a ternary {-1, 0, 1}; given the same model size and training tokens, BitNet b1.58 can match the perplexity and task performance of a full precision Transformer LLM (i.e., FP16); the benefits of this 1-bit LLM are significantly better latency, memory, throughout, and energy consumption. | [Paper](https://arxiv.org/abs/2402.17764), [Tweet](https://x.com/_akhaliq/status/1762729757454618720?s=20)  \n4) **Dataset for LLMs** - a comprehensive overview (180+ pages) and analysis of LLM datasets. | [Paper](https://arxiv.org/abs/2402.18041), [Tweet](https://x.com/omarsar0/status/1763233452852134001?s=20)  \n5) **LearnAct** - explores open-action learning for language agents through an iterative learning strategy that creates and improves actions using Python functions; on each iteration, the proposed framework (LearnAct) expands the action space and enhances action effectiveness by revising and updating available actions based on execution feedback; the LearnAct framework was tested on Robotic planning and AlfWorld environments; it improves agent performance by 32% in AlfWorld compared to ReAct+Reflexion. | [Paper](https://arxiv.org/abs/2402.15809), [Tweet](https://x.com/omarsar0/status/1762533498492010761?s=20)  \n6) **EMO** - a new framework for generating expressive video by utilizing a direct audio-to-video synthesis approach; by leveraging an Audio2Video diffusion model it bypasses the need for intermediate 3D models or facial landmarks; EMO can produce convincing speaking videos and singing videos in various styles while outperforming existing methods in terms of expressiveness and realism. | [Paper](https://arxiv.org/abs/2402.17485), [Tweet](https://x.com/_akhaliq/status/1762686465777999932?s=20)  \n7) **On the Societal Impact of Open Foundation Models** - a position paper with a focus on open foundation models and their impact, benefits, and risks; proposes a risk assessment framework for analyzing risk and explains why the marginal risk of open foundation models is low in some cases; it also offers a more grounded assessment of the societal impact of open foundation models. | [Paper](https://crfm.stanford.edu/open-fms/), [Tweet](https://x.com/sayashk/status/1762508812370551207?s=20)  \n8) **StarCoder 2** - a family of open LLMs for code with three different sizes (3B, 7B, and 15B); the 15B model was trained on 14 trillion tokens and 600+ programming languages with a context window of 16K token and employing a fill-in-the-middle objective; it matches 33B+ models on many evaluation like code completion, code reasoning, and math reasoning aided through PAL. | [Paper](https://huggingface.co/blog/starcoder2), [Tweet](https://x.com/_philschmid/status/1762843489220296881?s=20)  \n9) **LLMs on Tabular Data** - an overview of LLMs for tabular data tasks including key techniques, metrics, datasets, models, and optimization approaches; it covers limitations and unexplored ideas with insights for future research directions. | [Paper](https://arxiv.org/abs/2402.17944), [Tweet](https://x.com/omarsar0/status/1763187964501254492?s=20)  \n10) **PlanGPT** - shows how to leverage LLMs and combine multiple approaches like retrieval augmentation, fine-tuning, tool usage, and more; the proposed framework is applied to urban and spatial planning but there are a lot of insights and practical tips that apply to other domains. | [Paper](https://arxiv.org/abs/2402.19273), [Tweet](https://x.com/omarsar0/status/1763424166890377691?s=20)  \n## Top ML Papers of the Week (February 19 - February 25) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-february-19---february-25---2024)\n**Paper** | **Links**  \n---|---  \n1) **Stable Diffusion 3** - a suite of image generation models ranging from 800M to 8B parameters; combines diffusion transformer architecture and flow matching for improved performance in multi-subject prompts, image quality, and spelling abilities; technical report to be published soon and linked here. | [Paper](https://stability.ai/news/stable-diffusion-3), [Tweet](https://x.com/StabilityAI/status/1760656767237656820?s=20)  \n2) **Gemma** - a series of open models inspired by the same research and tech used for Gemini; includes 2B (trained on 2T tokens) and 7B (trained on 6T tokens) models including base and instruction-tuned versions; trained on a context length of 8192 tokens; generally outperforms Llama 2 7B and Mistral 7B. | [Paper](https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf), [Tweet](https://x.com/omarsar0/status/1760310942552686604?s=20)  \n3) **LLMs for Data Annotation** - an overview and a good list of references that apply LLMs for data annotation; includes a taxonomy of methods that employ LLMs for data annotation; covers three aspects: LLM-based data annotation, assessing LLM-generated annotations, and learning with LLM-generated annotations. | [Paper](https://arxiv.org/abs/2402.13446), [Tweet](https://x.com/omarsar0/status/1760664562779431367?s=20)  \n4) **GRIT** - presents generative representational instruction tuning where an LLM is trained to perform both generative and embedding tasks and designed to distinguish between them via the instructions; produces new state-of-the-art on MTEB and the unification is reported to speed up RAG by 60% for long documents. | [Paper](https://arxiv.org/abs/2402.09906), [Tweet](https://x.com/Muennighoff/status/1758307967802224770?s=20)  \n5) **LoRA+** - proposes LoRA+ which improves performance and finetuning speed (up to â¼ 2X speed up), at the same computational cost as LoRA; the key difference between LoRA and LoRA+ is how the learning rate is set; LoRA+ sets different learning rates for LoRA adapter matrices while in LoRA the learning rate is the same. | [Paper](https://arxiv.org/abs/2402.12354), [Tweet](https://x.com/omarsar0/status/1760063230406258892?s=20)  \n6) **Revisiting REINFORCE in RLHF** - shows that many components of PPO are unnecessary in an RLHF context; it also shows that a simpler REINFORCE variant outperforms both PPO and newly proposed alternatives such as DPO and RAFT; overall, it shows that online RL optimization can be beneficial and low cost. | [Paper](https://arxiv.org/abs/2402.14740), [Tweet](https://x.com/sarahookr/status/1761042445997945070?s=20)  \n7) **Recurrent Memory Finds What LLMs Miss** - explores the capability of transformer-based models in extremely long context processing; finds that both GPT-4 and RAG performance heavily rely on the first 25% of the input, which means there is room for improved context processing mechanisms; reports that recurrent memory augmentation of transformer models achieves superior performance on documents of up to 10 million tokens. | [Paper](https://arxiv.org/abs/2402.10790), [Tweet](https://x.com/omarsar0/status/1759591371126571028?s=20)  \n8) **When is Tree Search Useful for LLM Planning** - investigates how LLM solves multi-step problems through a framework consisting of a generator, discriminator, and planning method (e.g., iterative correction and tree search); reports that planning methods demand discriminators with at least 90% accuracy but current LLMs donât demonstrate these discrimination capabilities; finds that tree search is at least 10 to 20 times slower but regardless of it good performance itâs impractical for real-world applications. | [Paper](https://arxiv.org/abs/2402.10890), [Tweet](https://x.com/ysu_nlp/status/1759757711061704913?s=20)  \n9) **CoT Reasoning without Prompting** - proposes a chain-of-thought (CoT) decoding method to elicit the reasoning capabilities from pre-trained LLMs without explicit prompting; claims to significantly enhance a modelâs reasoning capabilities over greedy decoding across reasoning benchmarks; finds that the model's confidence in its final answer increases when CoT is present in its decoding path. | [Paper](https://arxiv.org/abs/2402.10200), [Tweet](https://x.com/omarsar0/status/1758566808213234017?s=20)  \n10) **OpenCodeInterpreter** - a family of open-source systems for generating, executing, and iteratively refining code; proposes a dataset of 68K multi-turn interactions; integrates execution and human feedback for dynamic code refinement and produces high performance on benchmarks like HumalEval and EvalPlus. | [Paper](https://arxiv.org/abs/2402.14658), [Tweet](https://x.com/xiangyue96/status/1760891516107862104?s=20)  \n## Top ML Papers of the Week (February 12 - February 18) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-february-12---february-18---2024)\n**Paper** | **Links**  \n---|---  \n1) **Sora** - a text-to-video AI model that can create videos of up to a minute of realistic and imaginative scenes given text instructions; it can generate complex scenes with multiple characters, different motion types, and backgrounds, and understand how they relate to each other; other capabilities include creating multiple shots within a single video with persistence across characters and visual style. | [Paper](https://openai.com/research/video-generation-models-as-world-simulators), [Tweet](https://x.com/OpenAI/status/1758192957386342435?s=20)  \n2) **Gemini 1.5** - a compute-efficient multimodal mixture-of-experts model that focuses on capabilities such as recalling and reasoning over long-form content; it can reason over long documents potentially containing millions of tokens, including hours of video and audio; improves the state-of-the-art performance in long-document QA, long-video QA, and long-context ASR. Gemini 1.5 Pro matches or outperforms Gemini 1.0 Ultra across standard benchmarks and achieves near-perfect retrieval (>99%) up to at least 10 million tokens, a significant advancement compared to other long-context LLMs. | [Paper](https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf), [Tweet](https://x.com/omarsar0/status/1758151923612483839?s=20)  \n3) **V-JEPA** - a collection of vision models trained on a feature prediction objective using 2 million videos; relies on self-supervised learning and doesnât use pretrained image encoders, text, negative examples, reconstruction, or other supervision sources; claims to achieve versatile visual representations that perform well on both motion and appearance-based tasks, without adaption of the modelâs parameters. | [Paper](https://ai.meta.com/research/publications/revisiting-feature-prediction-for-learning-visual-representations-from-video/), [Tweet](https://x.com/AIatMeta/status/1758176023588577326?s=20)  \n4) **Large World Model** - a general-purpose 1M context multimodal model trained on long videos and books using RingAttention; sets new benchmarks in difficult retrieval tasks and long video understanding; uses masked sequence packing for mixing different sequence lengths, loss weighting, and model-generated QA dataset for long sequence chat; open-sources a family of 7B parameter models that can process long text and videos of over 1M tokens. | [Paper](https://arxiv.org/abs/2402.08268), [Tweet](https://x.com/haoliuhl/status/1757828392362389999?s=20)  \n5) **The boundary of neural network trainability is fractal** - finds that the boundary between trainable and untrainable neural network hyperparameter configurations is fractal; observes fractal hyperparameter landscapes for every neural network configuration and deep linear networks; also observes that the best-performing hyperparameters are at the end of stability. | [Paper](https://arxiv.org/abs/2402.06184), [Tweet](https://x.com/jaschasd/status/1756930242965606582?s=20)  \n6) **OS-Copilot** - a framework to build generalist computer agents that interface with key elements of an operating system like Linux or MacOS; it also proposes a self-improving embodied agent for automating general computer tasks; this agent outperforms the previous methods by 35% on the general AI assistants (GAIA) benchmark. | [Paper](https://arxiv.org/abs/2402.07456), [Tweet](https://x.com/omarsar0/status/1757443594976206885?s=20)  \n7) **TestGen-LLM** - uses LLMs to automatically improve existing human-written tests; reports that after an evaluation on Reels and Stories products for Instagram, 75% of TestGen-LLM's test cases were built correctly, 57% passed reliably, and 25% increased coverage. | [Paper](https://arxiv.org/abs/2402.09171), [Tweet](https://x.com/nathanbenaich/status/1758036247115608317?s=20)  \n8) **ChemLLM** - a dedicated LLM trained for chemistry-related tasks; claims to outperform GPT-3.5 on principal tasks such as name conversion, molecular caption, and reaction prediction; it also surpasses GPT-4 on two of these tasks. | [Paper](https://arxiv.org/abs/2402.06852), [Tweet](https://x.com/omarsar0/status/1757246740539773165?s=20)  \n9) **Survey of LLMs** - reviews three popular families of LLMs (GPT, Llama, PaLM), their characteristics, contributions, and limitations; includes a summary of capabilities and techniques developed to build and augment LLM; it also discusses popular datasets for LLM training, fine-tuning, and evaluation, and LLM evaluation metrics; concludes with open challenges and future research directions. | [Paper](https://arxiv.org/abs/2402.06196), [Tweet](https://x.com/omarsar0/status/1757049645119799804?s=20)  \n10) **LLM Agents can Hack** - shows that LLM agents can automatically hack websites and perform tasks like SQL injections without human feedback or explicit knowledge about the vulnerability beforehand; this is enabled by an LLMâs tool usage and long context capabilities; shows that GPT-4 is capable of such hacks, including finding vulnerabilities in websites in the wild; open-source models did not show the same capabilities. | [Paper](https://arxiv.org/abs/2402.06664v1), [Tweet](https://x.com/emollick/status/1757937829340967240?s=20)  \n## Top ML Papers of the Week (February 5 - February 11) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-february-5---february-11---2024)\n**Paper** | **Links**  \n---|---  \n1) **Grandmaster-Level Chess Without Search** - trains a 270M parameter transformer model with supervised learning on a dataset of 10 million chess games with up to 15 billion data points; reaches a Lichess blitz Elo of 2895 against humans, and solves a series of challenging chess puzzles; it shows the potential of training at scale for chess and without the need for any domain-specific tweaks or explicit search algorithms. | [Paper](https://arxiv.org/abs/2402.04494), [Tweet](https://x.com/_akhaliq/status/1755466387798020229?s=20)  \n2) **AnyTool** - an LLM-based agent that can utilize 16K APIs from Rapid API; proposes a simple framework consisting of 1) a hierarchical API-retriever to identify relevant API candidates to a query, 2) a solver to resolve user queries, and 3) a self-reflection mechanism to reactivate AnyTool if the initial solution is impracticable; this tool leverages the function calling capability of GPT-4 so no further training is needed; the hierarchical API-retriever is inspired by a divide-and-conquer approach to help reduce the search scope of the agents which leads to overcoming limitations around context length in LLMs; the self-reflection component helps with resolving easy and complex queries efficiently. | [Paper](https://arxiv.org/abs/2402.04253), [Tweet](https://x.com/omarsar0/status/1755065033791283601?s=20)  \n3) **A Phase Transition between Positional and Semantic Learning in a Solvable Model of Dot-Product Attention** - investigates and expands the theoretical understanding of learning with attention layers by exploring the interplay between positional and semantic attention; it employs a toy model of dot-product attention and identifies an emergent phase transition between semantic and positional learning; shows that if provided with sufficient data, dot-product attention layer outperforms a linear positional baseline when using the semantic mechanism. | [Paper](https://arxiv.org/abs/2402.03902), [Tweet](https://x.com/zdeborova/status/1755158457785704771?s=20)  \n4) **Indirect Reasoning with LLMs** - proposes an indirect reasoning method to strengthen the reasoning power of LLMs; it employs the logic of contrapositives and contradictions to tackle IR tasks such as factual reasoning and mathematic proof; it consists of two key steps: 1) enhance the comprehensibility of LLMs by augmenting data and rules (i.e., the logical equivalence of contrapositive), and 2) design prompt templates to stimulate LLMs to implement indirect reasoning based on proof by contradiction; experiments on LLMs like GPT-3.5-turbo and Gemini Pro show that the proposed method enhances the overall accuracy of factual reasoning by 27.33% and mathematic proof by 31.43% compared to traditional direct reasoning methods. | [Paper](https://arxiv.org/abs/2402.03667), [Tweet](https://x.com/omarsar0/status/1755254627866419707?s=20)  \n5) **ALOHA 2** - a low-cost system for bimanual teleoperation that improves the performance, user-friendliness, and durability of ALOHA; efforts include hardware improvements such as grippers and gravity compensation with a higher quality simulation model; this potentially enables large-scale data collection on more complex tasks to help advanced research in robot learning. | [Paper](https://aloha-2.github.io/assets/aloha2.pdf), [Tweet](https://x.com/tonyzzhao/status/1755380475118719407?s=20)  \n6) **More Agents is All You Need** - presents a study on the scaling property of raw agents instantiated by LLMs; finds that performance scales when increasing agents by simply using a sampling-and-voting method. | [Paper](https://arxiv.org/abs/2402.05120), [Tweet](https://x.com/omarsar0/status/1755794341069455376?s=20)  \n7) **Self-Discovered Reasoning Structures** - proposes a new framework, Self-Discover, that enables LLMs to select from multiple reasoning techniques (e.g., critical thinking and thinking step-by-step) to compose task-specific reasoning strategies; outperforms CoT (applied to GPT-4 and PaLM 2) on BigBench-Hard experiments and requires 10-40x fewer inference compute than other inference-intensive methods such as CoT-Self-Consistency; the self-discovered reasoning structures are also reported to transfer well between LLMs and small language models (SLMs). | [Paper](https://arxiv.org/abs/2402.03620), [Tweet](https://x.com/peizNLP/status/1755265197953146997?s=20)  \n8) **DeepSeekMath** - continues pretraining a code base model with 120B math-related tokens; introduces GRPO (a variant to PPO) to enhance mathematical reasoning and reduce training resources via a memory usage optimization scheme; DeepSeekMath 7B achieves 51.7% on MATH which approaches the performance level of Gemini-Ultra (53.2%) and GPT-4 (52.9%); when self-consistency is used the performance improves to 60.9%. | [Paper](https://arxiv.org/abs/2402.03300), [Tweet](https://x.com/deepseek_ai/status/1754701472363958581?s=20)  \n9) **LLMs for Table Processing** - provides an overview of LLMs for table processing, including methods, benchmarks, prompting techniques, and much more. | [Paper](https://arxiv.org/abs/2402.05121), [Tweet](https://x.com/omarsar0/status/1755789530710339788?s=20)  \n10) **LLM-based Multi-Agents** - discusses the essential aspects of LLM-based multi-agent systems; it includes a summary of recent applications for problem-solving and word simulation; it also discusses datasets, benchmarks, challenges, and future opportunities to encourage further research and development from researchers and practitioners. | [Paper](https://arxiv.org/abs/2402.01680), [Tweet](https://x.com/omarsar0/status/1754710117734375429?s=20)  \n## Top ML Papers of the Week (January 29 - February 4) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-january-29---february-4---2024)\n**Paper** | **Links**  \n---|---  \n1) **OLMo** - introduces Open Language Model (OLMo), a 7B parameter model; it includes open training code, open data, full model weights, evaluation code, and fine-tuning code; it shows strong performance on many generative tasks; there is also a smaller version of it, OLMo 1B. | [Paper](https://arxiv.org/abs/2402.00838), [Tweet](https://x.com/omarsar0/status/1753080417530318872?s=20)  \n2) **Advances in Multimodal LLMs** - a comprehensive survey outlining design formulations for model architecture and training pipeline around multimodal large language models. | [Paper](https://arxiv.org/abs/2401.13601), [Tweet](https://x.com/omarsar0/status/1751705689964089616?s=20)  \n3) **Corrective RAG** - proposes Corrective Retrieval Augmented Generation (CRAG) to improve the robustness of generation in a RAG system; the core idea is to implement a self-correct component for the retriever and improve the utilization of retrieved documents for augmenting generation; the retrieval evaluator helps to assess the overall quality of retrieved documents given a query; using web search and optimized knowledge utilization operations can improve automatic self-correction and efficient utilization of retrieved documents. | [Paper](https://arxiv.org/abs/2401.15884), [Tweet](https://x.com/omarsar0/status/1752173216942944556?s=20)  \n4) **LLMs for Mathematical Reasoning** - introduces an overview of research developments in LLMs for mathematical reasoning; discusses advancements, capabilities, limitations, and applications to inspire ongoing research on LLMs for Mathematics. | [Paper](https://arxiv.org/abs/2402.00157), [Tweet](https://x.com/omarsar0/status/1753424518171738194?s=20)  \n5) **Compression Algorithms for LLMs** - covers compression algorithms like pruning, quantization, knowledge distillation, low-rank approximation, parameter sharing, and efficient architecture design. | [Paper](https://arxiv.org/abs/2401.15347), [Tweet](https://x.com/omarsar0/status/1752746770377974072?s=20)  \n6) **MoE-LLaVA** - employs Mixture of Experts tuning for Large Vision-Language Models which constructs a sparse model with a substantial reduction in parameters with a constant computational cost; this approach also helps to address performance degradation associated with multi-modal learning and model sparsity. | [Paper](https://arxiv.org/abs/2401.15947), [Tweet](https://x.com/LinBin46984/status/1753403875531375003?s=20)  \n7) **Rephrasing the Web** - uses an off-the-shelf instruction-tuned model prompted to paraphrase web documents in specific styles and formats such as âlike Wikipediaâ or âquestion-answer formatâ to jointly pre-train LLMs on real and synthetic rephrases; it speeds up pre-training by ~3x, improves perplexity, and improves zero-shot question answering accuracy on many tasks. | [Paper](https://arxiv.org/abs/2401.16380), [Tweet](https://x.com/pratyushmaini/status/1752337225097076809?s=20)  \n8) **Redefining Retrieval in RAG** - a study that focuses on the components needed to improve the retrieval component of a RAG system; confirms that the position of relevant information should be placed near the query, the model will struggle to attend to the information if this is not the case; surprisingly, it finds that related documents don't necessarily lead to improved performance for the RAG system; even more unexpectedly, irrelevant and noisy documents can help drive up accuracy if placed correctly. | [Paper](https://arxiv.org/abs/2401.14887), [Tweet](https://x.com/omarsar0/status/1751803310267314509?s=20)  \n9) **Hallucination in LVLMs** - discusses hallucination issues and techniques to mitigate hallucination in Large Vision-Language Models (LVLM); it introduces LVLM hallucination evaluation methods and benchmarks; provides tips and a good analysis of the causes of LVLM hallucinations and potential ways to mitigate them. | [Paper](https://arxiv.org/abs/2402.00253), [Tweet](https://x.com/omarsar0/status/1753449211931079101?s=20)  \n10) **SliceGPT** - a new LLM compression technique that proposes a post-training sparsification scheme that replaces each weight matrix with a smaller dense matrix; helps reduce the embedding dimension of the network and can remove up to 20% of model parameters for Llama2-70B and Phi-2 models while retaining most of the zero-shot performance of the dense models. | [Paper](https://arxiv.org/abs/2401.15024v1), [Tweet](https://x.com/_akhaliq/status/1751796334531592496?s=20)  \n## Top ML Papers of the Week (January 22 - January 28) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-january-22---january-28---2024)\n**Paper** | **Links**  \n---|---  \n1) **Depth Anything** - a robust monocular depth estimation solution that can deal with any images under any circumstance; automatically annotates large-scale unlabeled data (~62M) which helps to reduce generalization error; proposes effective strategies to leverage the power of the large-scale unlabeled data; besides generalization ability, it established new state-of-the-art through fine-tuning and even results in an enhanced depth-conditioned ControlNet. | [Paper](https://arxiv.org/abs/2401.10891v1), [Tweet](https://x.com/_akhaliq/status/1749284669936275463?s=20)  \n2) **Knowledge Fusion of LLMs** - proposes FuseLLM with the core idea of externalizing knowledge from multiple LLMs and transferring their capabilities to a target LLM; leverages the generative distributions of source LLMs to externalize both their collective knowledge and individual strengths and transfer them to the target LLM through continual training; finds that the FuseLLM can improve the performance of the target model across a range of capabilities such as reasoning, common sense, and code generation. | [Paper](https://arxiv.org/abs/2401.10491), [Tweet](https://x.com/omarsar0/status/1749267663900057620?s=20)  \n3) **MambaByte** - adapts Mamba SSM to learn directly from raw bytes; bytes lead to longer sequences which autoregressive Transformers will scale poorly on; this work reports huge benefits related to faster inference and even outperforms subword Transformers. | [Paper](https://arxiv.org/abs/2401.13660), [Tweet](https://x.com/omarsar0/status/1750366964759859633?s=20)  \n4) **Diffuse to Choose** - a diffusion-based image-conditioned inpainting model to balance fast inference with high-fidelity while enabling accurate semantic manipulations in a given scene content; outperforms existing zero-shot diffusion inpainting methods and even few-shot diffusion personalization algorithms such as DreamPaint. | [Paper](https://arxiv.org/abs/2401.13795), [Tweet](https://x.com/_akhaliq/status/1750737690553692570?s=20)  \n5) **WARM** - introduces weighted averaged rewards models (WARM) that involve fine-tuning multiple rewards models and then averaging them in the weight space; average weighting improves efficiency compared to traditional prediction ensembling; it improves the quality and alignment of LLM predictions. | [Paper](https://arxiv.org/abs/2401.12187), [Tweet](https://x.com/ramealexandre/status/1749719471806157304?s=20)  \n6) **Resource-efficient LLMs & Multimodal Models** - a survey of resource-efficient LLMs and multimodal foundations models; provides a comprehensive analysis and insights into ML efficiency research, including architectures, algorithms, and practical system designs and implementations. | [Paper](https://arxiv.org/abs/2401.08092v1), [Tweet](https://x.com/omarsar0/status/1749208653926654010?s=20)  \n7) **Red Teaming Visual Language Models** - first presents a red teaming dataset of 10 subtasks (e.g., image misleading, multi-modal jailbreaking, face fairness, etc); finds that 10 prominent open-sourced VLMs struggle with the red teaming in different degrees and have up to 31% performance gap with GPT-4V; also applies red teaming alignment to LLaVA-v1.5 with SFT using the proposed red teaming dataset, which improves model performance by 10% in the test set. | [Paper](https://arxiv.org/abs/2401.12915), [Tweet](https://x.com/omarsar0/status/1750170361843384790?s=20)  \n8) **Lumiere** - a text-to-video space-time diffusion model for synthesizing videos with realistic and coherent motion; introduces a Space-Time U-Net architecture to generate the entire temporal duration of a video at once via a single pass; achieves state-of-the-art text-to-video generation results and supports a wide range of content creation tasks and video editing applications, including image-to-video, video inpainting, and stylized generation. | [Paper](https://arxiv.org/abs/2401.12945), [Tweet](https://x.com/GoogleAI/status/1751003814931689487?s=20)  \n9) **Medusa** - a simple framework for LLM inference acceleration using multiple decoding heads that predict multiple subsequent tokens in parallel; parallelization substantially reduces the number of decoding steps; it can achieve over 2.2x speedup without compromising generation quality, while Medusa-2 further improves the speedup to 2.3-3.6x. | [Paper](https://arxiv.org/abs/2401.10774v1), [Tweet](https://x.com/jiayq/status/1749461664393810350?s=20)  \n10) **AgentBoard** - a comprehensive benchmark with an open-source evaluation framework to perform analytical evaluation of LLM agents; helps to assess the capabilities and limitations of LLM agents and demystifies agent behaviors which leads to building stronger and robust LLM agents. | [Paper](https://arxiv.org/abs/2401.13178v1), [Tweet](https://x.com/ma_chang_nlp/status/1750369056539218082?s=20)  \n## Top ML Papers of the Week (January 15 - January 21) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-january-15---january-21---2024)\n**Paper** | **Links**  \n---|---  \n1) **AlphaGeometry** - an AI system that acts as a theorem prover that can solve Olympiad geometry problems without human demonstrations; this system is trained on synthetic data involving millions of theorems and proofs across different levels of complexity; the data is used to train a neural language model that can solve olympiad-level problems and approaches the performance of an average International Mathematical Olympiad (IMO) gold medallist. | [Paper](https://www.nature.com/articles/s41586-023-06747-5), [Tweet](https://x.com/GoogleDeepMind/status/1747651817461125352?s=20)  \n2) **AlphaCodium** - a code-oriented iterative flow that improves LLMs on code generation; it involves two key steps to improve code generation capabilities in LLMs: i) additional generated data (problem self-reflection and test reasoning) to aid the iterative process, and ii) enriching public tests using additional AI-generated tests; using the CodeContests validation dataset, GPT-4 pass@5 accuracy increased from 19% using a single well-crafted prompt to 44% using the AlphaCodium flow; it even outperforms AlphaCode using a significantly smaller computation budget and 4 orders of magnitude fewer LLM calls. | [Paper](https://arxiv.org/abs/2401.08500), [Tweet](https://x.com/itamar_mar/status/1747957348293824676?s=20)  \n3) **RAG vs. Finetuning** - report discussing the tradeoff between RAG and fine-tuning when using LLMs like Llama 2 and GPT-4; performs a detailed analysis and highlights insights when applying the pipelines on an agricultural dataset; observes that there is an accuracy increase of over 6 p.p. when fine-tuning the model and this is cumulative with RAG, which increases accuracy by 5 p.p. further. | [Paper](https://arxiv.org/abs/2401.08406), [Tweet](https://x.com/omarsar0/status/1747676541876596779?s=20)  \n4) **Self-Rewarding Models** - proposes a self-alignment method that uses the model itself for LLM-as-a-Judge prompting to provide its rewards during training; Iterative DPO is used for instruction following training using the preference pairs built from the generated data which comes from a self-instruction creation phase; using this approach, fine-tuning a Llama 2 70B model on three iterations can lead to a model that outperforms LLMs like Claude 2 and Gemini Pro on the AlpacaEval 2.0 leaderboard. | [Paper](https://arxiv.org/abs/2401.10020), [Tweet](https://x.com/jaseweston/status/1748158323369611577?s=20)  \n5) **Tuning Language Models by Proxy** - introduces proxy-tuning, a decoding-time algorithm that modifies logits of a target LLM with the logitsâ difference between a small base model and a fine-tuned base model; this can enable a larger target base model to perform as well as would a fine-tuned version of it; proxy-tuning is applied to Llama2-70B using proxies of only 7B size to close 88% of the gap between Llama2-70B and its tuned chat version. | [Paper](https://arxiv.org/abs/2401.08565), [Tweet](https://x.com/rasbt/status/1748021765790376385?s=20)  \n6) **Reasoning with Reinforced Fine-Tuning** - proposes an approach, ReFT, to enhance the generalizability of LLMs for reasoning; it starts with applying SFT and then applies online RL for further refinement while automatically sampling reasoning paths to learn from; this differs from RLHF in that it doesnât utilize a reward model learned from human-labeled data; ReFT demonstrates improved performance and generalization abilities on math problem-solving. | [Paper](https://arxiv.org/abs/2401.08967), [Tweet](https://x.com/_akhaliq/status/1747820246268887199?s=20)  \n7) **Overview of LLMs for Evaluation** - thoroughly surveys the methodologies and explores their strengths and limitations; provides a taxonomy of different approaches involving prompt engineering or calibrating open-source LLMs for evaluation | [Paper](https://arxiv.org/abs/2401.07103), [Tweet](https://x.com/omarsar0/status/1748016227090305167?s=20)  \n8) **Patchscopes** - proposes a framework that leverages a model itself to explain its internal representations; it decodes information from LLM hidden representations which is possible by âpatchingâ representations into a separate inference pass that encourages the extraction of that information; it can be used to answer questions about an LLMâs computation and can even be used to fix latent multi-hop reasoning errors. | [Paper](https://arxiv.org/abs/2401.06102), [Tweet](https://x.com/ghandeharioun/status/1746946621215003041?s=20)  \n9) **The Unreasonable Effectiveness of Easy Training Data for Hard Tasks** - suggests that language models often generalize well from easy to hard data, i.e., easy-to-hard generalization; it argues that it can be better to train on easy data as opposed to hard data, even when the emphasis is on improving performance on hard data, and suggests that the scalable oversight problem may be easier than previously thought. | [Paper](https://arxiv.org/abs/2401.06751), [Tweet](https://x.com/peterbhase/status/1747301128683839998?s=20)  \n10) **MoE-Mamba** - an approach to efficiently scale LLMs by combining state space models (SSMs) with Mixture of Experts (MoE); MoE-Mamba, outperforms both Mamba and Transformer-MoE; it reaches the same performance as Mamba in 2.2x less training steps while preserving the inference performance gains of Mamba against the Transformer. | [Paper](https://arxiv.org/abs/2401.04081), [Tweet](https://x.com/arankomatsuzaki/status/1744552215946100969?s=20)  \n## Top ML Papers of the Week (January 8 - January 14) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-january-8---january-14---2024)\n**Paper** | **Links**  \n---|---  \n1) **InseRF** - a method for text-driven generative object insertion in the Neural 3D scenes; it enables users to provide textual descriptions and a 2D bounding box in a reference viewpoint to generate new objects in 3D scenes; InseRF is also capable of controllable and 3D-consistent object insertion without requiring explicit 3D information as input. | [Paper](https://arxiv.org/abs/2401.05335), [Tweet](https://x.com/_akhaliq/status/1745293576794255757?s=20)  \n2) **Sleeper Agents** - shows that LLMs can learn deceptive behavior that persists through safety training; for instance, an LLM was trained to write secure code for a specified year but given another year can enable exploitable code; this backdoor behavior can persist even when training LLMs with techniques like reinforcement learning and adversarial training. | [Paper](https://arxiv.org/abs/2401.05566), [Tweet](https://x.com/AnthropicAI/status/1745854907968880970?s=20)  \n3) **Blending Is All You Need** - shows that effectively combining existing small models of different sizes (6B/13B parameters) can result in systems that can compete with ChatGPT level performance; the goal is to build a collaborative conversational system that can effectively leverage these models to improve engagement and quality of chat AIs and generate more diverse responses. | [Paper](https://arxiv.org/abs/2401.02994), [Tweet](https://x.com/omarsar0/status/1744765981270950343?s=20)  \n4) **MagicVideo-V2** - proposes an end-to-end video generation pipeline that integrates the text-to-image model, video motion generator, reference image embedding module, and frame interpolation module; it can generate high-resolution video with advanced fidelity and smoothness compared to other leading and popular text-to-video systems. | [Paper](https://arxiv.org/abs/2401.04468), [Tweet](https://x.com/arankomatsuzaki/status/1744918551415443768?s=20)  \n5) **Trustworthiness in LLMs** - a comprehensive study (100+ pages) of trustworthiness in LLMs, discussing challenges, benchmarks, evaluation, analysis of approaches, and future directions; proposes a set of principles for trustworthy LLMs that span 8 dimensions, including a benchmark across 6 dimensions (truthfulness, safety, fairness, robustness, privacy, and machine ethics); it also presents a study evaluating 16 mainstream LLMs in TrustLLM, consisting of over 30 datasets; while proprietary LLMs generally outperform most open-source counterparts in terms of trustworthiness, there are a few open-source models that are closing the gap. | [Paper](https://arxiv.org/abs/2401.05561), [Tweet](https://x.com/omarsar0/status/1745645273915736553?s=20)  \n6) **Prompting LLMs for Table Understanding** - a new framework, inspired by Chain-of-Thought prompting, to instruct LLMs to dynamically plan a chain of operations that transforms a complex table to reliably answer the input question; an LLM is used to iteratively generate operations, step-by-step, that will perform necessary transformations to the table (e.g., adding columns or deleting info). | [Paper](https://arxiv.org/abs/2401.04398), [Tweet](https://x.com/omarsar0/status/1745164182205452603?s=20)  \n7) **Jailbreaking Aligned LLMs** - proposes 40 persuasion techniques to systematically jailbreak LLMs; their adversarial prompts (also referred to as persuasive adversarial prompts) achieve a 92% attack success rate on aligned LLMs, like Llama 2-7B and GPT-4, without specialized optimization. | [Paper](https://chats-lab.github.io/persuasive_jailbreaker/), [Tweet](https://x.com/EasonZeng623/status/1744719354368029008?s=20)  \n8) **From LLM to Conversational Agents** - proposes RAISE, an advanced architecture to enhance LLMs for conversational agents; it's inspired by the ReAct framework and integrates a dual-component memory system; it utilizes a scratchpad and retrieved examples to augment the agent's capabilities; the scratchpad serves as transient storage (akin to short-term memory) and the retrieval module operates as the agent's long-term memory; this system mirrors human short-term and long-term memory and helps to maintain context and continuity which are key in conversational systems. | [Paper](https://arxiv.org/abs/2401.02777), [Tweet](https://x.com/omarsar0/status/1744400054624846269?s=20)  \n9) **Quantifying LLMâs Sensitivity to Spurious Features in Prompt Design** - finds that widely used open-source LLMs are extremely sensitive to prompt formatting in few-shot settings; subtle changes in prompt formatting using a Llama 2 13B model can result in a performance difference of up to 76 accuracy points. | [Paper](https://arxiv.org/abs/2310.11324), [Tweet](https://x.com/melaniesclar/status/1745557109419458695?s=20)  \n10) **Adversarial Machine Learning** - a comprehensive survey that covers the current state of adversarial ML with a proper taxonomy of concepts, discussions, adversarial methods, mitigation tactics, and remaining challenges. | [Paper](https://csrc.nist.gov/pubs/ai/100/2/e2023/final), [Tweet](https://x.com/omarsar0/status/1745819927695540671?s=20)  \n## Top ML Papers of the Week (January 1 - January 7) - 2024\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-january-1---january-7---2024)\n**Paper** | **Links**  \n---|---  \n1) **Mobile ALOHA** - proposes a system that learns bimanual mobile manipulation with low-cost whole-body teleoperation; it first collects high-quality demonstrations and then performs supervised behavior cloning; finds that co-training with existing ALOHA datasets increases performance on complex mobile manipulation tasks such as sauteing and serving a piece of shrimp, opening a two-door wall cabinet to store heavy cooking pots while keeping the budget under $32K | [Paper](https://mobile-aloha.github.io/), [Tweet](https://x.com/zipengfu/status/1742973258528612724?s=20)  \n2) **Mitigating Hallucination in LLMs** - summarizes 32 techniques to mitigate hallucination in LLMs; introduces a taxonomy categorizing methods like RAG, Knowledge Retrieval, CoVe, and more; provides tips on how to apply these methods and highlights the challenges and limitations inherent in them. | [Paper](https://arxiv.org/abs/2401.01313), [Tweet](https://x.com/omarsar0/status/1742633831234994189?s=20)  \n3) **Self-Play Fine-tuning** - shows that without acquiring additional human-annotated data, a supervised fine-tuned LLM can be improved; inspired by self-play, it first uses the LLM to generate its training data from its previous iterations; it then refines its policy by distinguishing the self-generated responses from those obtained from human-annotated data; shows that the method can improve LLMâs performance and outperform models trained via DPO with GPT-4 preference data. | [Paper](https://arxiv.org/abs/2401.01335), [Tweet](https://x.com/_zxchen_/status/1742661587436216615?s=20)  \n4) **LLaMA Pro** - proposes a post-pretraining method to improve an LLMâs knowledge without catastrophic forgetting; it achieves this by tuning expanded identity blocks using only new corpus while freezing the inherited blocks; uses math and code data to train a LLaMA Pro-8.3B initialized from Llama2-7B; these models achieve advanced performance on various benchmarks compared to base models while preserving the original general capabilities. | [Paper](https://arxiv.org/abs/2401.02415), [Tweet](https://x.com/_akhaliq/status/1743135851238805685?s=20)  \n5) **LLM Augmented LLMs** - explore composing existing foundation models with specific models to expand capabilities; introduce cross-attention between models to compose representations that enable new capabilities; as an example, a PaLM2-S model was augmented with a smaller model trained on low-resource languages to improve English translation and arithmetic reasoning for low-resource languages; this was also done with a code-specific model which led to a 40% improvement over the base code model on code generation and explanation tasks. | [Paper](https://arxiv.org/abs/2401.02412), [Tweet](https://x.com/omarsar0/status/1743094632618106981?s=20)  \n6) **Fast Inference of Mixture-of-Experts** - achieves efficient inference of Mixtral-8x7B models through offloading; it applies separate quantization for attention layers and experts to fit the model in combined GPU and CPU memory; designs a MoE-specific offloading strategy that enables running Mixtral-8x7B on desktop hardware and free-tier Google Colab instances | [Paper](https://arxiv.org/abs/2312.17238), [Tweet](https://x.com/rohanpaul_ai/status/1741044633495326861?s=20)  \n7) **GPT-4V is a Generalist Web Agent** - explores the potential of GPT-4V as a generalist web agent; in particular, can such a model follow natural language instructions to complete tasks on a website? the authors first developed a tool to enable web agents to run on live websites; findings suggest that GPT-4V can complete 50% of tasks on live websites, possible through manual grounding of its textual plans into actions on the websites. | [Paper](https://arxiv.org/abs/2401.01614), [Tweet](https://x.com/omarsar0/status/1742923330544706035?s=20)  \n8) **DocLLM** - a lightweight extension to traditional LLMs for reasoning over visual documents; focuses on using bounding box information to incorporate spatial layout structure; proposes a pre-training objective that addresses irregular layout and heterogeneous content present in visual documents; itâs then fine-tuned on an instruction-dataset and demonstrate SoTA performance on 14 out of 16 datasets across several document intelligence tasks. | [Paper](https://arxiv.org/abs/2401.00908), [Tweet](https://x.com/BrianRoemmele/status/1742572753251913742?s=20)  \n9) **How Code Empowers LLMs** - a comprehensive overview of the benefits of training LLMs with code-specific data. Some capabilities include enhanced code generation, enabling reasoning, function calling, automated self-improvements, and serving intelligent agents. | [Paper](https://arxiv.org/abs/2401.00812), [Tweet](https://x.com/omarsar0/status/1742215295907811613?s=20)  \n10) **Instruct-Imagen** - proposes an image generation model that tackles heterogeneous image generation tasks and generalizes across unseen tasks; it first enhances the modelâs ability to ground its generation on external multimodal context and then fine-tunes on image generation tasks with multimodal instructions | [Paper](https://arxiv.org/abs/2401.01952), [Tweet](https://x.com/_akhaliq/status/1743108118630818039?s=20)  \n## Top ML Papers of the Week (December 25 - December 31)\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-december-25---december-31)\n**Paper** | **Links**  \n---|---  \n1) **CogAgent** - presents an 18 billion parameter visual language model specializing in GUI understanding and navigation; supports high-resolution inputs (1120x1120) and shows abilities in tasks such as visual Q&A, visual grounding, and GUI Agent; achieves state of the art on 5 text-rich and 4 general VQA benchmarks. | [Paper](https://arxiv.org/abs/2312.08914), [Tweet](https://x.com/cenyk1230/status/1739916469272789222?s=20)  \n2) **From Gemini to Q-Star** - surveys 300+ papers and summarizes research developments to look at in the space of Generative AI; it covers computational challenges, scalability, real-world implications, and the potential for Gen AI to drive progress in fields like healthcare, finance, and education. | [Paper](https://arxiv.org/abs/2312.10868), [Tweet](https://x.com/omarsar0/status/1740119485011390558?s=20)  \n3) **PromptBench** - a unified library that supports comprehensive evaluation and analysis of LLMs; it consists of functionalities for prompt construction, prompt engineering, dataset and model loading, adversarial prompt attack, dynamic evaluation protocols, and analysis tools. | [Paper](https://arxiv.org/abs/2312.07910v1), [Tweet](https://x.com/omarsar0/status/1739360426134028631?s=20)  \n4) **Exploiting Novel GPT-4 APIs** - performs red-teaming on three functionalities exposed in the GPT-4 APIs: fine-tuning, function calling, and knowledge retrieval; Main findings: 1) fine-tuning on as few as 15 harmful examples or 100 benign examples can remove core safeguards from GPT-4, 2) GPT-4 Assistants divulge the function call schema and can be made to execute arbitrary function calls, and 3) knowledge retrieval can be hijacked by injecting instructions into retrieval documents. | [Paper](https://arxiv.org/abs/2312.14302), [Tweet](https://x.com/omarsar0/status/1739677995747450964?s=20)  \n5) **Fact Recalling in LLMs** - investigates how MLP layers implement a lookup table for factual recall; scopes the study on how early MLPs in Pythia 2.8B look up which of 3 different sports various athletes play; suggests that early MLP layers act as a lookup table and recommends thinking about the recall of factual knowledge in the model as multi-token embeddings. | [Paper](https://www.alignmentforum.org/s/hpWHhjvjn67LJ4xXX/p/iGuwZTHWb6DFY3sKB), [Tweet](https://x.com/NeelNanda5/status/1738559368361349122?s=20)  \n6) **Generative AI for Math** - presents a diverse and high-quality math-centric corpus comprising of ~9.5 billion tokens to train foundation models. | [Paper](https://arxiv.org/abs/2312.17120), [Tweet](https://x.com/arankomatsuzaki/status/1740564961032556942?s=20)  \n7) **Pricipled Instructions Are All You Need** - introduces 26 guiding principles designed to streamline the process of querying and prompting large language models; applies these principles to conduct extensive experiments on LLaMA-1/2 (7B, 13B and 70B), GPT-3.5/4 to verify their effectiveness on instructions and prompts design. | [Paper](https://arxiv.org/abs/2312.16171v1), [Tweet](https://x.com/_akhaliq/status/1739857456161759455?s=20)  \n8) **A Survey of Reasoning with Foundation Models** - provides a comprehensive survey of seminal foundational models for reasoning, highlighting the latest advancements in various reasoning tasks, methods, benchmarks, and potential future directions; also discusses how other developments like multimodal learning, autonomous agents, and super alignment accelerate and extend reasoning research. | [Paper](https://arxiv.org/abs/2312.11562v4), [Tweet](https://x.com/omarsar0/status/1740729489661874632?s=20)  \n9) **Making LLMs Better at Dense Retrieval** - proposes LLaRA which adapts an LLM for dense retrieval; it consists of two pretext tasks: EBAE (Embedding-Based Auto-Encoding) and EBAR (Embedding-Based Auto-Regression), where the text embeddings from LLM are used to reconstruct the tokens for the input sentence and predict the tokens for the next sentence, respectively; a LLaMa-2-7B was improved on benchmarks like MSMARCO and BEIR. | [Paper](https://arxiv.org/abs/2312.15503v1)  \n10) **Gemini vs GPT-4V** - provides a comprehensive preliminary comparison and combination of vision-language models like Gemini and GPT-4V through several qualitative cases; finds that GPT-4V is precise and succinct in responses, while Gemini excels in providing detailed, expansive answers accompanied by relevant imagery and links. | [Paper](https://arxiv.org/abs/2312.15011v1), [Tweet](https://x.com/omarsar0/status/1741177994377330895?s=20)  \n## Top ML Papers of the Week (December 18 - December 24)\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-december-18---december-24)\n**Paper** | **Links**  \n---|---  \n1) **Geminiâs Language Abilities** - provides an impartial and reproducible study comparing several popular models like Gemini, GPT, and Mixtral; Gemini Pro achieves comparable but slightly lower accuracy than the current version of GPT 3.5 Turbo; Gemini and GPT were better than Mixtral. | [Paper](https://arxiv.org/abs/2312.11444), [Tweet](https://x.com/gneubig/status/1737108966931673191?s=20)  \n2) **PowerInfer** - a high-speed inference engine for deploying LLMs locally; exploits the high locality in LLM inference to design a GPU-CPU hybrid inference engine; hot-activated neurons are preloaded onto the GPU for fast access, while cold-activated neurons (the majority) are computed on the CPU; this approach significantly reduces GPU memory demands and CPU-GPU data transfer. | [Paper](https://ipads.se.sjtu.edu.cn/_media/publications/powerinfer-20231219.pdf), [Tweet](https://x.com/omarsar0/status/1737168751668187229?s=20)  \n3) **Discovery of a New Family of Antibiotics with Graph Deep Learning** - discovered a new structural class of antibiotics with explainable graph algorithms; the approach enables explainable deep learning guided discovery of structural classes of antibiotics which helps to provide chemical substructures that underlie antibiotic activity. | [Paper](https://www.nature.com/articles/s41586-023-06887-8), [Tweet](https://x.com/EricTopol/status/1737505177052348545?s=20)  \n4) **VideoPoet** - introduces a large language model for zero-shot video generation; itâs capable of a variety of video generation tasks such as image-to-video and video stylization; trains an autoregressive model to learn across video, image, audio, and text modalities by using multiple tokenizers; shows that language models can synthesize and edit video with some degree of temporal consistency. | [Paper](https://sites.research.google/videopoet/), [Tweet](https://x.com/GoogleAI/status/1737235593078456389?s=20)_  \n5) **Multimodal Agents as Smartphone Users** - introduces an LLM-based multimodal agent framework to operate smartphone applications; learns to navigate new apps through autonomous exploration or observing human demonstrations; shows proficiency in handling diverse tasks across different applications like email, social media, shopping, editing tools, and more. | [Paper](https://arxiv.org/abs/2312.13771), [Tweet](https://x.com/omarsar0/status/1738265651188253051?s=20)_  \n6) **LLM in a Flash** - proposes an approach that efficiently runs LLMs that exceed the available DRAM capacity by storing the model parameters on flash memory but bringing them on demand to DRAM; enables running models up to twice the size of the available DRAM, with a 4-5x and 20-25x increase in inference speed compared to naive loading approaches in CPU and GPU, respectively. | [Paper](https://arxiv.org/abs/2312.11514), [Tweet](https://x.com/gabrielnocode/status/1737307286887133552?s=20)_  \n7) **ReST Meets ReAct** - proposes a ReAct-style agent with self-critique for improving on the task of long-form question answering; it shows that the agent can be improved through ReST-style (reinforced self-training) iterative fine-tuning on its reasoning traces; specifically, it uses growing-batch RL with AI feedback for continuous self-improvement and self-distillation; like a few other recent papers, it focuses on minimizing human involvement (i.e., doesn't rely on human-labeled training data); it generates synthetic data with self-improvement from AI feedback which can then be used to distill the agent into smaller models (1/2 orders magnitude) with comparable performance as the pre-trained agent. | [Paper](https://arxiv.org/abs/2312.10003), [Tweet](https://x.com/omarsar0/status/1736587397830176910?s=20)_  \n8) **Adversarial Attacks on GPT-4** - uses a simple random search algorithm to implement adversarial attacks on GPT-4; it achieves jailbreaking by appending an adversarial suffix to an original request, then iteratively making slight random changes to the suffix, and keeping changes if it increases the log probability of the token âSureâ at the first position of the response. | [Paper](https://www.andriushchenko.me/gpt4adv.pdf), [Tweet](https://x.com/maksym_andr/status/1737844601891983563?s=20)_  \n9) **RAG for LLMs** - an overview of all the retrieval augmented generation (RAG) research that has been happening. | [Paper](https://arxiv.org/abs/2312.10997v1), [Tweet](https://x.com/omarsar0/status/1738354427759612222?s=20)_  \n10) **Findings of the BabyLLM Challenge** - presents results for a new challenge that involves sample-efficient pretraining on a developmentally plausible corpus; the winning submission, which uses flashy LTG BERT, beat Llama 2 70B on 3/4 evals; other approaches that saw good results included data preprocessing or training on shorter context. | [Paper](https://aclanthology.org/volumes/2023.conll-babylm/), [Tweet](https://x.com/a_stadt/status/1737849248560066794?s=20)_  \n## Top ML Papers of the Week (December 11 - December 17)\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-december-11---december-17)\n**Paper** | **Links**  \n---|---  \n1) **LLMs for Discoveries in Mathematical Sciences** - uses LLMs to search for new solutions in mathematics & computer science; proposes FunSearch which combines a pre-trained LLM with a systematic evaluator and iterates over them to evolve low-scoring programs into high-scoring ones discovering new knowledge; one of the key findings in this work is that safeguarding against LLM hallucinations is important to produce mathematical discoveries and other real-world problems. | [Paper](https://www.nature.com/articles/s41586-023-06924-6), [Tweet](https://x.com/GoogleDeepMind/status/1735332722208284797?s=20)  \n2) **Weak-to-strong Generalization** - studies whether weak model supervision can elicit the full capabilities of stronger models; finds that when naively fine-tuning strong pretrained models on weak model generated labels they can perform better than their weak supervisors; reports that finetuning GPT-4 with a GPT-2-level supervisor itâs possible to recover close to GPT-3.5-level performance on NLP tasks. | [Paper](https://cdn.openai.com/papers/weak-to-strong-generalization.pdf), [Tweet](https://x.com/OpenAI/status/1735349718765715913?s=20)  \n3) **Audiobox** - a unified model based on flow-matching capable of generating various audio modalities; designs description-based and example-based prompting to enhance controllability and unify speech and sound generation paradigms; adapts a self-supervised infilling objective to pre-train on large quantities of unlabeled audio; performs well on speech and sound generation and unlocks new methods for generating audio with novel vocal and acoustic styles. | [Paper](https://ai.meta.com/research/publications/audiobox-unified-audio-generation-with-natural-language-prompts/), [Tweet](https://x.com/AIatMeta/status/1734257634008531453?s=20)  \n4) **Mathematical LLMs** - a survey on the progress of LLMs on mathematical tasks; covers papers and resources on LLM research around prompting techniques and tasks such as math word problem-solving and theorem proving. | [Paper](https://arxiv.org/abs/2312.07622), [Tweet](https://x.com/omarsar0/status/1735323577392542084?s=20)  \n5) **Towards Fully Transparent Open-Source LLMs** - proposes LLM360 to support open and collaborative AI research by making the end-to-end LLM training process transparent and reproducible; releases 7B parameter LLMs pre-trained from scratch, AMBER and CRYSTALCODER, including their training code, data, intermediate checkpoints, and analyses. | [Paper](https://arxiv.org/abs/2312.06550), [Tweet](https://x.com/omarsar0/status/1734591071575744820?s=20)  \n6) **LLMs in Medicine** - a comprehensive survey (analyzing 300+ papers) on LLMs in medicine; includes an overview of the principles, applications, and challenges faced by LLMs in medicine. | [Paper](https://arxiv.org/abs/2311.05112), [Tweet](https://x.com/omarsar0/status/1734599425568231513?s=20)  \n7) **Beyond Human Data for LLMs** - proposes an approach for self-training with feedback that can substantially reduce dependence on human-generated data; the model-generated data combined with a reward function improves the performance of LLMs on problem-solving tasks. | [Paper](https://arxiv.org/abs/2312.06585), [Tweet](https://x.com/omarsar0/status/1734953578274386002?s=20)  \n8) **Gaussian-SLAM** - a neural RGBD SLAM method capable of photorealistically reconstructing real-world scenes without compromising speed and efficiency; extends classical 3D Gaussians for scene representation to overcome the limitations of the previous methods. | [Paper](https://vladimiryugay.github.io/gaussian_slam/), [Tweet](https://x.com/vlyug/status/1734683948440252480?s=20)  \n9) **Pearl** - introduces a new production-ready RL agent software package that enables researchers and practitioners to develop RL AI agents that adapt to environments with limited observability, sparse feedback, and high stochasticity. | [Paper](https://arxiv.org/abs/2312.03814), [Tweet](https://x.com/ZheqingZhu/status/1732880717263352149?s=20)  \n10) **Quip** - compresses trained model weights into a lower precision format to reduce memory requirements; the approach combines lattice codebooks with incoherence processing to create 2 bit quantized models; significantly closes the gap between 2 bit quantized LLMs and unquantized 16 bit models. | [Paper](https://cornell-relaxml.github.io/quip-sharp/), [Tweet](https://x.com/tsengalb99/status/1733222467953422702?s=20)  \n## Top ML Papers of the Week (December 4 - December 10)\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-december-4---december-10)\n**Paper** | **Links**  \n---|---  \n1) **Gemini** - a series of multimodal models with multimodal reasoning capabilities across text, images, video, audio, and code; claims to outperform human experts on MMLU, a popular benchmark to test the knowledge and problem-solving abilities of AI models; capabilities reported include multimodality, multilinguality, factuality, summarization, math/science, long-context, reasoning, and more. | [Paper](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf), [Tweet](https://x.com/omarsar0/status/1732434324291563831?s=20)  \n2) **EfficientSAM** - a lightweight Segment Anything Model (SAM) that exhibits decent performance with largely reduced complexity; leverages masked autoencoders with 20x fewer parameters and 20x faster runtime; EfficientSAM performs within 2 points (44.4 AP vs 46.5 AP) of the original SAM model. | [Paper](https://arxiv.org/abs/2312.00863), [Tweet](https://x.com/fiandola/status/1732171016783180132?s=20)  \n3) **Magicoder** - a series of fully open-source LLMs for code that close the gap with top code models while having no more than 7B parameters; trained on 75K synthetic instruction data; uses open-source references for the production of more diverse, realistic, high-quality, and controllable data; outperforms state-of-the-art code models with similar or even larger sizes on several coding benchmarks, including Python text-to-code generation, multilingual coding, and data-science program completion; MagicoderS-CL-7B based on CodeLlama surpasses ChatGPT on HumanEval+ (66.5 vs. 65.9 in pass@1). | [Paper](https://arxiv.org/abs/2312.02120), [Tweet](https://x.com/omarsar0/status/1732063926613946863?s=20)  \n4) **LLMs on Graphs** - a comprehensive overview that summarizes different scenarios where LLMs are used on graphs such as pure graphs, text-rich graphs, and text-paired graphs | [Paper](https://arxiv.org/abs/2312.02783), [Tweet](https://x.com/omarsar0/status/1732404393037762588?s=20)  \n5) **Llama Guard** - an LLM-based safeguard model that involves a small (Llama2-7B) customizable instruction-tuned model that can classify safety risks in prompts and responses for conversational AI agent use cases; the model can be leveraged in a zero-shot or few-shot way if you need to adapt it to a different safety risk taxonomy that meets the requirements for a target use case; it can also be fine-tune on a specific dataset to adapt to a new taxonomy. | [Paper](https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/), [Tweet](https://x.com/omarsar0/status/1732781628139696279?s=20)  \n6) **Human-Centered Loss Functions** - proposes an approach called Kahneman-Tversky Optimization (KTO) that matches or exceeds DPO performance methods at scales from 1B to 30B; KTO maximizes the utility of LLM generations instead of maximizing the log-likelihood of preferences as most current methods do. | [Paper](https://github.com/ContextualAI/HALOs/blob/main/assets/report.pdf), [Tweet](https://x.com/ethayarajh/status/1732837520784957476?s=20)  \n7) **Chain of Code** - a simple extension of the chain-of-thought approach that improves LM code-driven reasoning; it encourages LMs to format semantic sub-tasks in a program as pseudocode that the interpreter can explicitly catch undefined behavior and hand off to simulate with an LLM; on BIG-Bench Hard, Chain of Code achieves 84%, a gain of 12% over Chain of Thought. | [Paper](https://arxiv.org/abs/2312.04474), [Tweet](https://x.com/ChengshuEricLi/status/1733169631949701425?s=20)  \n8) **Data Management For LLMs** - an overview of current research in data management within both the pretraining and supervised fine-tuning stages of LLMs; it covers different aspects of data management strategy design: data quantity, data quality, domain/task composition, and more. | [Paper](https://arxiv.org/abs/2312.01700), [Tweet](https://x.com/omarsar0/status/1731877232493166969?s=20)  \n9) _8RankZephyr_ * - an open-source LLM for listwise zero-shot reranking that bridges the effectiveness gap with GPT-4 and in some cases surpasses the proprietary model; it outperforms GPT-4 on the NovelEval test set, comprising queries and passages past its training period, which addresses concerns about data contamination. | [Paper](https://arxiv.org/abs/2312.02724), [Tweet](https://x.com/lintool/status/1732430269485867114?s=20)  \n10) **The Efficiency Spectrum of LLMs** - a comprehensive review of algorithmic advancements aimed at improving LLM efficiency; covers various topics related to efficiency, including scaling laws, data utilization, architectural innovations, training and tuning strategies, and inference techniques. | [Paper](https://arxiv.org/abs/2312.00678), [Tweet](https://x.com/omarsar0/status/1731696419457606048?s=20)  \n## Top ML Papers of the Week (November 27 - December 3)\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-november-27---december-3)\n**Paper** | **Links**  \n---|---  \n1) **GNoME** - a new AI system for material design that finds 2.2 million new crystals, including 380,000 stable materials; presents a new deep learning tool that increases the speed and efficiency of discovery by predicting the stability of new materials. | [Paper](https://www.nature.com/articles/s41586-023-06735-9), [Tweet](https://x.com/demishassabis/status/1729995611443769823?s=20)  \n2) **Open-Source LLMs vs. ChatGPT** - provides an exhaustive overview of tasks where open-source LLMs claim to be on par or better than ChatGPT. | [Paper](https://arxiv.org/abs/2311.16989), [Tweet](https://x.com/sophiamyang/status/1730108858889097710?s=20)  \n3) **Adversarial Diffusion Distillation** - a novel training approach that efficiently samples large-scale foundation image diffusion models in just 1-4 steps while maintaining high image quality; combines score distillation and an adversarial loss to ensure high image fidelity even in the low-step regime of one or two sampling steps; reaches performance of state-of-the-art diffusion models in only four steps. | [Paper](https://stability.ai/research/adversarial-diffusion-distillation), [Tweet](https://x.com/robrombach/status/1729590281647870342?s=20)  \n4) **Seamless** - a family of research models that enable end-to-end expressive cross-lingual communication in a streaming fashion; introduces an improved SeamlssM4T model trained on more low-resource language data; also applies red-teaming effort for safer multimodal machine translation. | [Paper](https://ai.meta.com/research/publications/seamless-multilingual-expressive-and-streaming-speech-translation/), [Tweet](https://x.com/AIatMeta/status/1730294284023427221?s=20)  \n5) **MEDITRON-70B** - a suite of open-source LLMs with 7B and 70B parameters adapted to the medical domain; builds on Llama-2 and extends pretraining on a curated medical corpus; MEDITRON-70B outperforms GPT-3.5 and Med-PaLM and is within 5% of GPT-4 and 10% of Med-PaLM-2. | [Paper](https://arxiv.org/abs/2311.16079v1), [Tweet](https://x.com/eric_zemingchen/status/1729563855213175010?s=20)  \n6) **Foundation Models Outcompeting Special-Purpose Tuning** - performs a systematic exploration of prompt engineering to boost the performance of LLMs on medical question answering; uses prompt engineering methods that are general purpose and make no use of domain expertise; prompt engineering led to enhancing GPT-4âs performance and achieves state-of-the-art results on nine benchmark datasets in the MultiMedQA suite. | [Paper](https://arxiv.org/abs/2311.16452), [Tweet](https://x.com/erichorvitz/status/1729854235443884385?s=20)  \n7) **UniIR** - a unified instruction-guided multimodal retriever that handles eight retrieval tasks across modalities; can generalize to unseen retrieval tasks and achieves robust performance across existing datasets and zero-shot generalization to new tasks; presents a multimodal retrieval benchmark to help standardize the evaluation of multimodal information retrieval. | [Paper](https://arxiv.org/abs/2311.17136), [Tweet](https://x.com/CongWei1230/status/1730307767469068476?s=20)  \n8) **Safe Deployment of Generative AI** - argues that to protect peopleâs privacy, medical professionals, not commercial interests, must drive the development and deployment of such models. | [Paper](https://www.nature.com/articles/d41586-023-03803-y), [Tweet](https://x.com/ClementDelangue/status/1730300666403238393?s=20)  \n9) **On Bringing Robots Home** - introduces Dobb-E, an affordable and versatile general-purpose system for learning robotic manipulation within household settings; Dobbe-E can learn new tasks with only 5 minutes of user demonstrations; experiments reveal unique challenges absent or ignored in lab robotics, including effects of strong shadows, variable demonstration quality by non-expert users, among others. | [Paper](https://arxiv.org/abs/2311.16098v1), [Tweet](https://x.com/LerrelPinto/status/1729515379892826211?s=20)  \n10) **Translatotron 3** - proposes an unsupervised approach to speech-to-speech translation that can learn from monolingual data alone; combines masked autoencoder, unsupervised embedding mapping, and back-translation; results show that the model outperforms a baseline cascade system and showcases its capability to retain para-/non-linguistic such as pauses, speaking rates, and speaker identity. | [Paper](https://arxiv.org/abs/2305.17547), [Tweet](https://x.com/GoogleAI/status/1730654297350959413?s=20)  \n## Top ML Papers of the Week (November 20 - November 26)\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-november-20---november-26)\n**Paper** | **Links**  \n---|---  \n1) **System 2 Attention** - leverages the reasoning and instruction following capabilities of LLMs to decide what to attend to; it regenerates input context to only include relevant portions before attending to the regenerated context to elicit the final response from the model; increases factuality and outperforms standard attention-based LLMs on tasks such as QA and math world problems. | [Paper](https://arxiv.org/abs/2311.11829), [Tweet](https://x.com/jaseweston/status/1726784511357157618?s=20)  \n2) **Advancing Long-Context LLMs** - an overview of the methodologies for enhancing Transformer architecture modules that optimize long-context capabilities across all stages from pre-training to inference. | [Paper](https://arxiv.org/abs/2311.12351), [Tweet](https://x.com/omarsar0/status/1727358484360945750?s=20)  \n3) **Parallel Speculative Sampling** - approach to reduce inference time of LLMs based on a variant of speculative sampling and parallel decoding; achieves significant speed-ups (up to 30%) by only learning as little as O(d_emb) additional parameters. | [Paper](https://arxiv.org/abs/2311.13581), [Tweet](https://x.com/omarsar0/status/1728066181796418009?s=20)  \n4) **Mirasol3B** - a multimodal model for learning across audio, video, and text which decouples the multimodal modeling into separate, focused autoregressive models; the inputs are processed according to the modalities; this approach can handle longer videos compared to other models and it outperforms state-of-the-art approach on video QA, long video QA, and audio-video-text benchmark. | [Paper](https://arxiv.org/abs/2311.05698), [Tweet](https://x.com/GoogleAI/status/1724553024088191211?s=20)  \n5) **Teaching Small LMs To Reason** - proposes an approach to teach smaller language models to reason; specifically, the LM is thought to use reasoning techniques, such as step-by-step processing, recall-then-generate, recall-reason-generate, extract-generate, and direct-answer methods; outperforms models of similar size and attains performance levels similar or better to those of models 5-10x larger, as assessed on complex tasks that test advanced reasoning abilities in zero-shot settings. | [Paper](https://arxiv.org/abs/2311.11045), [Tweet](https://x.com/omarsar0/status/1726990087399915995?s=20)  \n6) **GPQA** - proposes a graduate-level Google-proof QA benchmark consisting of 448 multiple-choice questions written by domain experts in biology, physics, and chemistry; the strongest GPT-4 based baseline achieves 39% accuracy; this benchmark offers scalable oversight experiments that can help obtain reliable and truthful information from modern AI systems that surpass human capabilities. | [Paper](https://arxiv.org/abs/2311.12022), [Tweet](https://x.com/idavidrein/status/1727033002234909060?s=20)  \n7) **The Hitchhikerâs Guide From Chain-of-Thought Reasoning to Language Agents** - summary of CoT reasoning, foundational mechanics underpinning CoT techniques, and their application to language agent frameworks. | [Paper](https://arxiv.org/abs/2311.11797), [Tweet](https://x.com/omarsar0/status/1726803725220487277?s=20)  \n8) **GAIA** - a benchmark for general AI assistants consisting of real-world questions that require a set of fundamental abilities such as reasoning, multimodal handling, web browsing, and generally tool-use proficiency; shows that human respondents obtain 92% vs. 15% for GPT-4 equipped with plugins. | [Paper](https://arxiv.org/abs/2311.12983), [Tweet](https://x.com/ThomasScialom/status/1727683993045201339?s=20)  \n9) **LLMs as Collaborators for Medical Reasoning** - proposes a collaborative multi-round framework for the medical domain that leverages role-playing LLM-based agents to enhance LLM proficiency and reasoning capabilities. | [Paper](https://arxiv.org/abs/2311.10537), [Tweet](https://x.com/omarsar0/status/1726627951582511135?s=20)  \n10) **TÃLU 2** - presents a suite of improved TÃLU models for advancing the understanding and best practices of adapting pretrained language models to downstream tasks and user preferences; TÃLU 2 suite achieves state-of-the-art performance among open models and matches or exceeds the performance of GPT-3.5-turbo-0301 on several benchmarks. | [Paper](https://arxiv.org/abs/2311.10702), [Tweet](https://x.com/natolambert/status/1727350301131518454?s=20)  \n## Top ML Papers of the Week (November 13 - November 19)\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-november-13---november-19)\n**Paper** | **Links**  \n---|---  \n1) **Emu Video and Emu Edit** - present new models for controlled image editing and text-to-video generation based on diffusion models; Emu Video can generate high-quality video by using text-only, image-only, or combined text and image inputs; Emu Edit enables free-form editing through text instructions. | [Paper](https://ai.meta.com/blog/emu-text-to-video-generation-image-editing-research/), [Tweet](https://x.com/AIatMeta/status/1725184026154349007?s=20)  \n2) **Chain-of-Note** - an approach to improve the robustness and reliability of retrieval-augmented language models in facing noisy, irrelevant documents and in handling unknown scenarios; CoN generates sequential reading notes for the retrieved documents, enabling an evaluation of their relevance to the given question and integrating this information to formulate the final answer; CoN significantly outperforms standard retrieval-augmented language models and achieves an average improvement of +7.9 in EM score given entirely noisy retrieved documents and +10.5 in rejection rates for real-time questions that fall outside the pre-training knowledge scope. | [Paper](https://arxiv.org/abs/2311.09210), [Tweet](https://x.com/omarsar0/status/1725181141693472959?s=20)  \n3) **LLMs for Scientific Discovery** - explores the impact of large language models, particularly GPT-4, across various scientific fields including drug discovery, biology, and computational chemistry; assesses GPT-4's understanding of complex scientific concepts, its problem-solving capabilities, and its potential to advance scientific research through expert-driven case assessments and benchmark testing. | [Paper](https://arxiv.org/abs/2311.07361), [Tweet](https://x.com/omarsar0/status/1724465107046940893?s=20)  \n4) **Fine-Tuning LLMs for Factuality** - fine-tunes language model for factuality without requiring human labeling; it learns from automatically generated factuality preference rankings and targets open-ended generation settings; it significantly improves the factuality of Llama-2 on held-out topics compared with RLHF or decoding strategies targeted at factuality. | [Paper](https://arxiv.org/abs/2311.08401), [Tweet](https://x.com/arankomatsuzaki/status/1724613041155608951?s=20)  \n5) **Contrastive CoT Prompting** - proposes a contrastive chain of thought method to enhance language model reasoning; the approach provides both valid and invalid reasoning demonstrations, to guide the model to reason step-by-step while reducing reasoning mistakes; also proposes an automatic method to construct contrastive demonstrations and demonstrates improvements over CoT prompting. | [Paper](https://arxiv.org/abs/2311.09277), [Tweet](https://x.com/arankomatsuzaki/status/1725340150819905723?s=20)  \n6) **A Survey on Language Models for Code** - provides an overview of LLMs for code, including a review of 50+ models, 30+ evaluation tasks, and 500 related works. | [Paper](https://arxiv.org/abs/2311.07989v1), [Tweet](https://x.com/omarsar0/status/1725637165256761553?s=20)  \n7) **JARVIS-1** - an open-world agent that can perceive multimodal input | [Paper](https://arxiv.org/abs/2311.05997), [Tweet](https://x.com/arankomatsuzaki/status/1723882043514470629?s=20)  \n8) **Learning to Filter Context for RAG** - proposes a method that improves the quality of the context provided to the generator via two steps: 1) identifying useful context based on lexical and information-theoretic approaches, and 2) training context filtering models that can filter retrieved contexts at inference; outperforms existing approaches on extractive question answering | [Paper](https://arxiv.org/abs/2311.08377v1), [Tweet](https://x.com/ZhiruoW/status/1724792850079252886?s=20)  \n9) **MART** - proposes an approach for improving LLM safety with multi-round automatic red-teaming; incorporates automatic adversarial prompt writing and safe response generation, which increases red-teaming scalability and the safety of LLMs; violation rate of an LLM with limited safety alignment reduces up to 84.7% after 4 rounds of MART, achieving comparable performance to LLMs with extensive adversarial prompt writing. | [Paper](https://arxiv.org/abs/2311.07689), [Tweet](https://x.com/AIatMeta/status/1724887918685425829?s=20)  \n10) **LLMs can Deceive Users** - explores the use of an autonomous stock trading agent powered by LLMs; finds that the agent acts upon insider tips and hides the reason behind the trading decision; shows that helpful and safe LLMs can strategically deceive users in a realistic situation without direction instructions or training for deception. | [Paper](https://arxiv.org/abs/2311.07590), [Tweet](https://x.com/ESYudkowsky/status/1725226563992715521?s=20)  \n## Top ML Papers of the Week (November 6 - November 12)\n[](https://github.com/dair-ai/ML-Papers-of-the-Week#top-ml-papers-of-the-week-november-6---november-12)\n**Paper** | **Links**  \n---|---  \n1) **Hallucination in LLMs** - a comprehensive survey | [Paper](https://arxiv.org/abs/2311.05232), [Tweet](https://x.com/omarsar0/status/1722985251129966705?s=20)  \n2) **Simplifying Transformer Blocks** - explores simplifying the transformer block and finds that many block components can be removed with no loss of training speed; using different architectures like autoregressive decoder-only and BERT encoder-only models, the simplified blocks emulate per-update training speed and performance of standard transformers, and even achieve 15% faster training throughput with fewer parameters | [Paper](https://arxiv.org/abs/2311.01906), [Tweet](https://x.com/maksym_andr/status/1722235666724192688?s=20)  \n3) **Understanding In-Context Learning Abilities in Transformers** - investigates how effectively transformers can bridge between pretraining data mixture to identify and learn new tasks in-context which are both inside and outside the pretraining distribution; in the regimes studied, there is limited evidence that the modelsâ in-context learning behavior is capable of generalizing beyond their pretraining data. | [Paper](https://arxiv.org/abs/2311.00871), [Tweet](https://x.com/abacaj/status/1721223737729581437?s=20)  \n4) **MusicGen** - a single-stage transformer-based LLM that operates over several streams of compressed discrete music representation; it can generate high-quality samples | [Paper](https://arxiv.org/abs/2306.05284), [Tweet](https://x.com/AIatMeta/status/1723043913638810025?s=20)  \n5) **AltUp** - a method that makes it possible to take advantage of increasing scale and capacity in Transformer models without increasing the computational cost; achieved by working on a subblock of the widened representation at each layer and using a predict-and-correct mechanism to update the inactivated blocks; it widens the learn representation while only incurring a negligible increase in latency. | [Paper](https://arxiv.org/abs/2301.13310), [Tweet](https://x.com/GoogleAI/status/1722004366201418132?s=20)  \n6) **Rephrase and Respond** - an effective prompting method that uses LLMs to rephrase and expand questions posed by humans to improve overall performance; it can improve the performance of different models across a wide range of tasks; the approach can be combined with chain-of-thought to improve performance further. | [Paper](https://arxiv.org/abs/2311.04205), [Tweet](https://x.com/QuanquanGu/status/1722364144379396513?s=20)  \n7) **On the Road with GPT-4V(ision)** - provides an exhaustive evaluation of the latest state-of-the-art visual language model, GPT-4V(vision), and its application in autonomous driving; the model demonstrates superior performance in scene understanding and causal reasoning compared to existing autonomous systems. | [Paper](https://arxiv.org/abs/2311.05332), [Tweet](https://x.com/arankomatsuzaki/status/1722795897359139057?s=20)  \n8) **GPT4All** - outlines technical details of the GPT4All model family along with the open-source repository that aims to democratize access to LLMs. | [Paper](https://arxiv.org/abs/2311.04931), [Tweet  \n## About\nð¥Highlighting the top ML papers every week. \n### Topics\n[ nlp ](https://github.com/topics/nlp \"Topic: nlp\") [ data-science ](https://github.com/topics/data-science \"Topic: data-science\") [ machine-learning ](https://github.com/topics/machine-learning \"Topic: machine-learning\") [ ai ](https://github.com/topics/ai \"Topic: ai\") [ deeplearning ](https://github.com/topics/deeplearning \"Topic: deeplearning\")\n### Resources\n[ Readme ](https://github.com/dair-ai/ML-Papers-of-the-Week#readme-ov-file)\n###  Uh oh! \nThere was an error while loading. [Please reload this page](https://github.com/dair-ai/ML-Papers-of-the-Week).\n[ Activity](https://github.com/dair-ai/ML-Papers-of-the-Week/activity)\n[ Custom properties](https://github.com/dair-ai/ML-Papers-of-the-Week/custom-properties)\n### Stars\n[ **11.3k** stars](https://github.com/dair-ai/ML-Papers-of-the-Week/stargazers)\n### Watchers\n[ **907** watching](https://github.com/dair-ai/ML-Papers-of-the-Week/watchers)\n### Forks\n[ **687** forks](https://github.com/dair-ai/ML-Papers-of-the-Week/forks)\n[ Report repository ](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fdair-ai%2FML-Papers-of-the-Week&report=dair-ai+%28user%29)\n##  [Releases](https://github.com/dair-ai/ML-Papers-of-the-Week/releases)\nNo releases published\n##  [Packages 0](https://github.com/orgs/dair-ai/packages?repo_name=ML-Papers-of-the-Week)\nNo packages published \n###  Uh oh! \nThere was an error while loading. [Please reload this page](https://github.com/dair-ai/ML-Papers-of-the-Week).\n##  [Contributors 9](https://github.com/dair-ai/ML-Papers-of-the-Week/graphs/contributors)\n  * [ ![@omarsar](https://avatars.githubusercontent.com/u/7049564?s=64&v=4) ](https://github.com/omarsar)\n  * [ ![@angysaravia](https://avatars.githubusercontent.com/u/61196172?s=64&v=4) ](https://github.com/angysaravia)\n  * [ ![@Ritvik19](https://avatars.githubusercontent.com/u/36080978?s=64&v=4) ](https://github.com/Ritvik19)\n  * [ ![@RaviSriTejaKuriseti](https://avatars.githubusercontent.com/u/58432652?s=64&v=4) ](https://github.com/RaviSriTejaKuriseti)\n  * [ ![@pivoshenko](https://avatars.githubusercontent.com/u/40499728?s=64&v=4) ](https://github.com/pivoshenko)\n  * [ ![@steven2358](https://avatars.githubusercontent.com/u/164072?s=64&v=4) ](https://github.com/steven2358)\n  * [ ![@guspan-tanadi](https://avatars.githubusercontent.com/u/36249910?s=64&v=4) ](https://github.com/guspan-tanadi)\n  * [ ![@pitmonticone](https://avatars.githubusercontent.com/u/38562595?s=64&v=4) ](https://github.com/pitmonticone)\n  * [ ![@ayushman17](https://avatars.githubusercontent.com/u/53474591?s=64&v=4) ](https://github.com/ayushman17)\n\n\n## Footer\n[ ](https://github.com) Â© 2025 GitHub, Inc. \n### Footer navigation\n  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n  * [Security](https://github.com/security)\n  * [Status](https://www.githubstatus.com/)\n  * [Docs](https://docs.github.com/)\n  * [Contact](https://support.github.com?tags=dotcom-footer)\n  * Manage cookies \n  * Do not share my personal information \n\n\nYou canât perform that action at this time. \n"
  },
  {
    "link": "https://github.com/Bhanupriya-art/INT426-Coursera-Answers",
    "raw_content": "[Skip to content](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#start-of-content)\n## Navigation Menu\nToggle navigation\n[ ](https://github.com/)\n[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FBhanupriya-art%2FINT426-Coursera-Answers)\nAppearance settings\n  * Product \n    * [ GitHub Copilot  Write better code with AI  ](https://github.com/features/copilot)\n    * [ GitHub Models  New  Manage and compare prompts  ](https://github.com/features/models)\n    * [ GitHub Advanced Security  Find and fix vulnerabilities  ](https://github.com/security/advanced-security)\n    * [ Actions  Automate any workflow  ](https://github.com/features/actions)\n    * [ Codespaces  Instant dev environments  ](https://github.com/features/codespaces)\n    * [ Issues  Plan and track work  ](https://github.com/features/issues)\n    * [ Code Review  Manage code changes  ](https://github.com/features/code-review)\n    * [ Discussions  Collaborate outside of code  ](https://github.com/features/discussions)\n    * [ Code Search  Find more, search less  ](https://github.com/features/code-search)\nExplore\n    * [ Why GitHub ](https://github.com/why-github)\n    * [ All features ](https://github.com/features)\n    * [ Documentation ](https://docs.github.com)\n    * [ GitHub Skills ](https://skills.github.com)\n    * [ Blog ](https://github.blog)\n  * Solutions \nBy company size\n    * [ Enterprises ](https://github.com/enterprise)\n    * [ Small and medium teams ](https://github.com/team)\n    * [ Startups ](https://github.com/enterprise/startups)\n    * [ Nonprofits ](https://github.com/solutions/industry/nonprofits)\nBy use case\n    * [ DevSecOps ](https://github.com/solutions/use-case/devsecops)\n    * [ DevOps ](https://github.com/solutions/use-case/devops)\n    * [ CI/CD ](https://github.com/solutions/use-case/ci-cd)\n    * [ View all use cases ](https://github.com/solutions/use-case)\nBy industry\n    * [ Healthcare ](https://github.com/solutions/industry/healthcare)\n    * [ Financial services ](https://github.com/solutions/industry/financial-services)\n    * [ Manufacturing ](https://github.com/solutions/industry/manufacturing)\n    * [ Government ](https://github.com/solutions/industry/government)\n    * [ View all industries ](https://github.com/solutions/industry)\n[ View all solutions ](https://github.com/solutions)\n  * Resources \nTopics\n    * [ AI ](https://github.com/resources/articles/ai)\n    * [ DevOps ](https://github.com/resources/articles/devops)\n    * [ Security ](https://github.com/resources/articles/security)\n    * [ Software Development ](https://github.com/resources/articles/software-development)\n    * [ View all ](https://github.com/resources/articles)\nExplore\n    * [ Learning Pathways ](https://resources.github.com/learn/pathways)\n    * [ Events & Webinars ](https://resources.github.com)\n    * [ Ebooks & Whitepapers ](https://github.com/resources/whitepapers)\n    * [ Customer Stories ](https://github.com/customer-stories)\n    * [ Partners ](https://partner.github.com)\n    * [ Executive Insights ](https://github.com/solutions/executive-insights)\n  * Open Source \n    * [ GitHub Sponsors  Fund open source developers  ](https://github.com/sponsors)\n    * [ The ReadME Project  GitHub community articles  ](https://github.com/readme)\nRepositories\n    * [ Topics ](https://github.com/topics)\n    * [ Trending ](https://github.com/trending)\n    * [ Collections ](https://github.com/collections)\n  * Enterprise \n    * [ Enterprise platform  AI-powered developer platform  ](https://github.com/enterprise)\nAvailable add-ons\n    * [ GitHub Advanced Security  Enterprise-grade security features  ](https://github.com/security/advanced-security)\n    * [ Copilot for business  Enterprise-grade AI features  ](https://github.com/features/copilot/copilot-business)\n    * [ Premium Support  Enterprise-grade 24/7 support  ](https://github.com/premium-support)\n  * [Pricing](https://github.com/pricing)\n\n\nSearch or jump to...\n# Search code, repositories, users, issues, pull requests...\nSearch \nClear\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n#  Provide feedback \nWe read every piece of feedback, and take your input very seriously.\nInclude my email address so I can be contacted\nCancel  Submit feedback \n#  Saved searches \n## Use saved searches to filter your results more quickly\nName\nQuery\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax). \nCancel  Create saved search \n[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FBhanupriya-art%2FINT426-Coursera-Answers)\n[ Sign up ](https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=Bhanupriya-art%2FINT426-Coursera-Answers)\nAppearance settings\nResetting focus\nYou signed in with another tab or window. [Reload](https://github.com/Bhanupriya-art/INT426-Coursera-Answers) to refresh your session. You signed out in another tab or window. [Reload](https://github.com/Bhanupriya-art/INT426-Coursera-Answers) to refresh your session. You switched accounts on another tab or window. [Reload](https://github.com/Bhanupriya-art/INT426-Coursera-Answers) to refresh your session. Dismiss alert\n{{ message }}\n[ Bhanupriya-art ](https://github.com/Bhanupriya-art) / **[INT426-Coursera-Answers](https://github.com/Bhanupriya-art/INT426-Coursera-Answers) ** Public\n  * [ Notifications ](https://github.com/login?return_to=%2FBhanupriya-art%2FINT426-Coursera-Answers) You must be signed in to change notification settings\n  * [ Fork 25 ](https://github.com/login?return_to=%2FBhanupriya-art%2FINT426-Coursera-Answers)\n  * [ Star  21 ](https://github.com/login?return_to=%2FBhanupriya-art%2FINT426-Coursera-Answers)\n\n\nThis repository contains all the coursera answers week wise for the subject INT426 \n[ 21 stars ](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/stargazers) [ 25 forks ](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/forks) [ Branches ](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/branches) [ Tags ](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/tags) [ Activity ](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/activity)\n[ Star  ](https://github.com/login?return_to=%2FBhanupriya-art%2FINT426-Coursera-Answers)\n[ Notifications ](https://github.com/login?return_to=%2FBhanupriya-art%2FINT426-Coursera-Answers) You must be signed in to change notification settings\n  * [ Code ](https://github.com/Bhanupriya-art/INT426-Coursera-Answers)\n  * [ Issues 0 ](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/issues)\n  * [ Pull requests 0 ](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/pulls)\n  * [ Actions ](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/actions)\n  * [ Projects 0 ](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/projects)\n  * [ Security ](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/security)\n[ ](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/security)\n[ ](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/security)\n[ ](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/security)\n### [ Uh oh!  ](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/security)\n[There was an error while loading. ](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/security)[Please reload this page](https://github.com/Bhanupriya-art/INT426-Coursera-Answers).\n  * [ Insights ](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/pulse)\n\n\nAdditional navigation options\n  * [ Code  ](https://github.com/Bhanupriya-art/INT426-Coursera-Answers)\n  * [ Issues  ](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/issues)\n  * [ Pull requests  ](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/pulls)\n  * [ Actions  ](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/actions)\n  * [ Projects  ](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/projects)\n  * [ Security  ](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/security)\n  * [ Insights  ](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/pulse)\n\n\n# Bhanupriya-art/INT426-Coursera-Answers\nmain\n[**1** Branch](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/branches)[**0** Tags](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/tags)\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/branches)[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/tags)\nGo to file\nCode\n## Folders and files\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n## Latest commit\n[![Bhanupriya-art](https://avatars.githubusercontent.com/u/120407422?v=4&size=40)](https://github.com/Bhanupriya-art)[Bhanupriya-art](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/commits?author=Bhanupriya-art)[Initial Commit](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/commit/affd132af71cc183b210fa628fd80b65574b091a)Apr 4, 2024[affd132](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/commit/affd132af71cc183b210fa628fd80b65574b091a) Â· Apr 4, 2024\n## History\n[110 Commits](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/commits/main/)[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/commits/main/)  \n[Week 1](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/tree/main/Week%201 \"Week 1\")| [Week 1](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/tree/main/Week%201 \"Week 1\")| [Initial Commit](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/commit/e4fe976bc258a147bf315613288a1d10f01dcba3 \"Initial Commit\")| Jan 17, 2024  \n[Week 10](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/tree/main/Week%2010 \"Week 10\")| [Week 10](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/tree/main/Week%2010 \"Week 10\")| [Initial Commit](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/commit/68091ec64af3bdefc6288519e2e1227f9806cf4d \"Initial Commit\")| Mar 18, 2024  \n[Week 11](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/tree/main/Week%2011 \"Week 11\")| [Week 11](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/tree/main/Week%2011 \"Week 11\")| [Initial Commit](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/commit/5cac7719000343c55c95bd7a06ae206d78298b75 \"Initial Commit\")| Mar 21, 2024  \n[Week 12 & 13](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/tree/main/Week%2012%20%26%2013 \"Week 12 & 13\")| [Week 12 & 13](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/tree/main/Week%2012%20%26%2013 \"Week 12 & 13\")| [Initial Commit](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/commit/affd132af71cc183b210fa628fd80b65574b091a \"Initial Commit\")| Apr 4, 2024  \n[Week 2](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/tree/main/Week%202 \"Week 2\")| [Week 2](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/tree/main/Week%202 \"Week 2\")| [Delete Commit](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/commit/26a3b29b2e62b4675b7bd13ab9430d33fcaff552 \"Delete Commit\")| Jan 26, 2024  \n[Week 3](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/tree/main/Week%203 \"Week 3\")| [Week 3](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/tree/main/Week%203 \"Week 3\")| [Delete Commit](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/commit/599e145f8a0866455bef56a8a8e37874ae40b4c1 \"Delete Commit\")| Jan 26, 2024  \n[Week 4/Prompt Engineering For ChatGPT](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/tree/main/Week%204/Prompt%20Engineering%20For%20ChatGPT \"This path skips through empty directories\")| [Week 4/Prompt Engineering For ChatGPT](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/tree/main/Week%204/Prompt%20Engineering%20For%20ChatGPT \"This path skips through empty directories\")| [Delete Commit](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/commit/ad9e98ce0465fd8e754db8e81ec6bb8391af5bfa \"Delete Commit\")| Feb 2, 2024  \n[Week 5 & 6](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/tree/main/Week%205%20%26%206 \"Week 5 & 6\")| [Week 5 & 6](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/tree/main/Week%205%20%26%206 \"Week 5 & 6\")| [Delete Week 5 & 6/a.img](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/commit/6843b0fa4d23ed012d0ba1d7e242c8f816c841e1 \"Delete Week 5 & 6/a.img\")| Mar 13, 2024  \n[Week 7 & 8 & 9/Generative AI with Large Language Models](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/tree/main/Week%207%20%26%208%20%26%209/Generative%20AI%20with%20Large%20Language%20Models \"This path skips through empty directories\")| [Week 7 & 8 & 9/Generative AI with Large Language Models](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/tree/main/Week%207%20%26%208%20%26%209/Generative%20AI%20with%20Large%20Language%20Models \"This path skips through empty directories\")| [Commit](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/commit/38f278c111e991646df88e03fc4ee8bd3a8a2cb9 \"Commit\")| Mar 13, 2024  \n[INT426 IP.pdf](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/blob/main/INT426%20IP.pdf \"INT426 IP.pdf\")| [INT426 IP.pdf](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/blob/main/INT426%20IP.pdf \"INT426 IP.pdf\")| [Add files via upload](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/commit/8ca05cdfcb17a663c339a3eb12d2fa956789dff9 \"Add files via upload\")| Jan 17, 2024  \n[README.md](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/blob/main/README.md \"README.md\")| [README.md](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/blob/main/README.md \"README.md\")| [Update README.md](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/commit/040549fa7167650c330cb69c46675abe10e3b42b \"Update README.md\")| Apr 4, 2024  \nView all files  \n## Repository files navigation\n  * [README](https://github.com/Bhanupriya-art/INT426-Coursera-Answers)\n\n\n# INT426 ANSWERS\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#int426-answers)\n## Link of Courses For Week 1:- <https://www.coursera.org/programs/int426-generative-ai-8n6df/learn/introduction-to-generative-ai><https://coursera.org/programs/int426-generative-ai-8n6df/learn/generative-ai-for-everyone>\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#link-of-courses-for-week-1--httpswwwcourseraorgprogramsint426-generative-ai-8n6dflearnintroduction-to-generative-aihttpscourseraorgprogramsint426-generative-ai-8n6dflearngenerative-ai-for-everyone)\n## Week 1 Solution According to College IP\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-1-solution-according-to-college-ip)\n## Note:-\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#note-)\n```\nIf anyone facing any doubts in these answers then he/she can refer to the images uploaded in the week-wise folder\n```\n\n# Introduction to Generative AI: Quiz\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#introduction-to-generative-ai-quiz)\n### Q.1 What is Generative AI?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-what-is-generative-ai)\n`Answer:- Generative AI is a type of artificial intelligence (AI) that can create new content, such as text, images, audio, and video. It does this by learning from existing data and then using that knowledge to generate new and unique outputs.`\n### Q.2 What is an example of both a generative AI model and a discriminative AI model?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-what-is-an-example-of-both-a-generative-ai-model-and-a-discriminative-ai-model)\n`Answer:- A generative AI model could be trained on a dataset of images of cats and then used to generate new images of cats. A discriminative AI model could be trained on a dataset of images of cats and dogs and then used to classify new images as either cats or dogs.`\n### Q.3 What are foundation models in Generative AI?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q3-what-are-foundation-models-in-generative-ai)\n`Answer:- A foundation model is a large AI model pretrained on a vast quantity of data that was \"designed to be adaptedâ (or fine-tuned) to a wide range of downstream tasks, such as sentiment analysis, image captioning, and object recognition.`\n### Q.4 Hallucinations are words or phrases that are generated by the model that are often nonsensical or grammatically incorrect. What are some factors that can cause hallucinations? Select three options.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q4-hallucinations-are-words-or-phrases-that-are-generated-by-the-model-that-are-often-nonsensical-or-grammatically-incorrect-what-are-some-factors-that-can-cause-hallucinations-select-three-options)\n`Answer:- The model is trained on noisy or dirty data.``The model is not given enough context.``The model is not trained on enough data`\n### Q.5 What is a prompt?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q5-what-is-a-prompt)\n`Answer A prompt is a short piece of text that is given to the large language model as input, and it can be used to control the output of the model in many ways. `\n# Generative AI for Everyone\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#generative-ai-for-everyone)\n## Week 1: What is Generative AI? (Graded Quiz)\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-1-what-is-generative-ai-graded-quiz)\n### Q.1 Which of these is the best definition of âGenerative AIâ?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-which-of-these-is-the-best-definition-of-generative-ai)\n`Answer:- AI that can produce high quality content, such as text, images, and audio.`\n### Q.2 Which of these is the most accurate description of an LLM?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-which-of-these-is-the-most-accurate-description-of-an-llm)\n`Answer:- It generates text by repeatedly predicting the next word.`\n### Q.3 True or False. Because an LLM has learned from web pages on the internet, its answers are always more trustworthy than what you will find on the internet.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q3-true-or-false-because-an-llm-has-learned-from-web-pages-on-the-internet-its-answers-are-always-more-trustworthy-than-what-you-will-find-on-the-internet)\n`Answer:- False`\n### Q.4 Why do we call AI a general purpose technology?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q4-why-do-we-call-ai-a-general-purpose-technology)\n`Answer:- Because it is useful for many different tasks.`\n### Q.5 You hear of a company using an LLM to automatically route emails to the right department. Which of these use cases is it most likely to be?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q5-you-hear-of-a-company-using-an-llm-to-automatically-route-emails-to-the-right-department-which-of-these-use-cases-is-it-most-likely-to-be)\n`Answer:- The company has a software-based application that uses an LLM to automatically route emails.`\n## Week 1: Generative AI applications\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-1-generative-ai-applications)\n### Q.1 A friend writes the following prompt to a web-based LLM: âWrite a description of our new dog food product.â\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-a-friend-writes-the-following-prompt-to-a-web-based-llm-write-a-description-of-our-new-dog-food-product)\n`Answer:- All of the above.`\n### Q.2 Which of the following are tasks that LLMs can do? (Check all that apply)\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-which-of-the-following-are-tasks-that-llms-can-do-check-all-that-apply)\n`Answer:- Summarize articles``Proofread text that youâre writing.``Translate text between languages.`\n### Q.3 Someone prompts an LLM as follows: âPlease summarize each of this morningâs top 10 news stories in 100 words per story, in a manner suitable for a newsletter.â What is the main reason this is unlikely to work?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q3-someone-prompts-an-llm-as-follows-please-summarize-each-of-this-mornings-top-10-news-stories-in-100-words-per-story-in-a-manner-suitable-for-a-newsletter-what-is-the-main-reason-this-is-unlikely-to-work)\n`Answer:- Because of the knowledge cutoff, the LLM will not have access to the latest news.`\n### Q.4 Youâre preparing a presentation about technology, and ask an LLM to help you find an inspirational quote. It comes up with this:**And thatâs what a computer is to me. What a computer is to me is itâs the most remarkable tool that weâve ever come up with, and itâs the equivalent of a bicycle for our minds. -Steve Jobs** How should you proceed?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q4-youre-preparing-a-presentation-about-technology-and-ask-an-llm-to-help-you-find-an-inspirational-quote-it-comes-up-with-thisand-thats-what-a-computer-is-to-me-what-a-computer-is-to-me-is-its-the-most-remarkable-tool-that-weve-ever-come-up-with-and-its-the-equivalent-of-a-bicycle-for-our-minds--steve-jobshow-should-you-proceed)\n`Answer:- Because LLMs hallucinate, double-check this quote by searching other sources (such as the web) to verify if Steve Jobs really said this.`\n### Q.5 You want an LLM to help check your writing for grammar and style. Which of these is the better approach for creating a prompt?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q5-you-want-an-llm-to-help-check-your-writing-for-grammar-and-style-which-of-these-is-the-better-approach-for-creating-a-prompt)\n`Answer:- Donât overthink the initial prompt -- quickly give it some context, then prompt the LLM to get its response, see what you get and iteratively refine your prompt from there.`\n# Generative AI for Everyone\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#generative-ai-for-everyone-1)\n## Week 2: Software Applications\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-2-software-applications)\n### Q.1 In the videos, we described using either supervised learning or a prompt-based development process to build a restaurant review sentiment classifier. Which of the following statements about prompt-based development is correct?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-in-the-videos-we-described-using-either-supervised-learning-or-a-prompt-based-development-process-to-build-a-restaurant-review-sentiment-classifier-which-of-the-following-statements-about-prompt-based-development-is-correct)\n`Answer:- Prompt-based development is generally much faster than supervised learning.`\n### Q.2 What is a token in the context of a large language model (LLM)?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-what-is-a-token-in-the-context-of-a-large-language-model-llm)\n`Answer:- A word or part of a word in either the input prompt or LLM output.`\n### Q.3 What are the major steps of the lifecycle of a Generative AI project?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q3-what-are-the-major-steps-of-the-lifecycle-of-a-generative-ai-project)\n`Answer:- Scope project â Build/improve system â Internal evaluation â Deploy and monitor `\n### Q.4 You are building a customer service chatbot. Why is it important to monitor the performance of the system after it is deployed?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q4-you-are-building-a-customer-service-chatbot-why-is-it-important-to-monitor-the-performance-of-the-system-after-it-is-deployed)\n`Answer:- In case customers say something that causes the chatbot to respond in an unexpected way, monitoring lets you discover problems and fix them.`\n### Q.5 You are working on using an LLM to summarize research reports. Suppose an average report contains roughly 6,000 words. Approximately how many tokens would it take an LLM to process 6,000 input words? (Assume 1 token = 3/4 words, or equivalently, 1 word \\approx 1.333 tokens).\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q5-you-are-working-on-using-an-llm-to-summarize-research-reports-suppose-an-average-report-contains-roughly-6000-words-approximately-how-many-tokens-would-it-take-an-llm-to-process-6000-input-words-assume-1-token--34-words-or-equivalently-1-word-approx-1333-tokens)\n`Answer:- 8,000 tokens (about 6000 * 1.333) `\n## Week 2: Advanced technologies: Beyond prompting\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-2-advanced-technologies-beyond-prompting)\n### Q.1 True or False. Because of the knowledge cut-off, an LLM cannot answer questions about todayâs news. But with RAG to supply it articles from the news, it would be able to.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-true-or-false-because-of-the-knowledge-cut-off-an-llm-cannot-answer-questions-about-todays-news-but-with-rag-to-supply-it-articles-from-the-news-it-would-be-able-to)\n`Answer:- True`\n### Q.2 You want to build an application to answer questions based on information found in your emails. Which of the following is the most appropriate technique?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-you-want-to-build-an-application-to-answer-questions-based-on-information-found-in-your-emails-which-of-the-following-is-the-most-appropriate-technique)\n`Answer:- RAG, where the LLM is provided additional context based on retrieving emails relevant to your question.`\n### Q.3 What does the idea of using an LLM as a reasoning engine refer to?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q3-what-does-the-idea-of-using-an-llm-as-a-reasoning-engine-refer-to)\n`Answer:- This refers to the idea of using an LLM not as a source of information, but to process information (wherein we provide it the context it needs, through techniques like RAG).`\n### Q.4 True or False. By making trusted sources of information available to an LLM via RAG, we can reduce the risk of hallucination.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q4-true-or-false-by-making-trusted-sources-of-information-available-to-an-llm-via-rag-we-can-reduce-the-risk-of-hallucination)\n`Answer:- True, because RAG allows the LLM to reason through accurate information retrieved from a trusted source to arrive at the correct answer.`\n### Q.5 An ecommerce company is building a software application to route emails to the right department (Apparel, Electronics, Home Appliances, etc.) It wants to do so with a small, 1 billion parameter model, and needs high accuracy. Which of these is an appropriate technique?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q5-an-ecommerce-company-is-building-a-software-application-to-route-emails-to-the-right-department-apparel-electronics-home-appliances-etc-it-wants-to-do-so-with-a-small-1-billion-parameter-model-and-needs-high-accuracy-which-of-these-is-an-appropriate-technique)\n`Answer:- Fine-tune a 1 billion parameter model on around 1,000 examples of emails and the appropriate department.`\n# Generative AI for Everyone\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#generative-ai-for-everyone-2)\n## Week 3: Generative AI and business\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-3-generative-ai-and-business)\n### Q.1 Which of these job roles are unlikely to find any use for web UI LLMs?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-which-of-these-job-roles-are-unlikely-to-find-any-use-for-web-ui-llms)\n`Answer:- None of the above`\n### Q.2 What is the relation between AI, tasks, and jobs?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-what-is-the-relation-between-ai-tasks-and-jobs)\n`Answer:- Jobs are comprised of many tasks. AI automates tasks, rather than jobs.`\n### Q.3 Here are some of the tasks of a retail salesperson from O*NET. (We encourage you to check out the page yourself.) [![image](https://private-user-images.githubusercontent.com/120407422/297348468-ec06a622-3370-4db7-a6b0-c26f21855254.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDg0ODc0MDMsIm5iZiI6MTc0ODQ4NzEwMywicGF0aCI6Ii8xMjA0MDc0MjIvMjk3MzQ4NDY4LWVjMDZhNjIyLTMzNzAtNGRiNy1hNmIwLWMyNmYyMTg1NTI1NC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNTI5JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDUyOVQwMjUxNDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1iMjZlNDUyMTZhNWE0ZDk2YjYxMzE1MzFiZTQ0YmI5NWJiYzI5MzY0ZWY2MzhhNzQ4ODBjOGU0ZjE5NjhiZGVlJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.1KeJYnoKJRAwqNO0VBAv8c71BIXJER5zmQjsUy9niuI)](https://private-user-images.githubusercontent.com/120407422/297348468-ec06a622-3370-4db7-a6b0-c26f21855254.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDg0ODc0MDMsIm5iZiI6MTc0ODQ4NzEwMywicGF0aCI6Ii8xMjA0MDc0MjIvMjk3MzQ4NDY4LWVjMDZhNjIyLTMzNzAtNGRiNy1hNmIwLWMyNmYyMTg1NTI1NC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNTI5JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDUyOVQwMjUxNDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1iMjZlNDUyMTZhNWE0ZDk2YjYxMzE1MzFiZTQ0YmI5NWJiYzI5MzY0ZWY2MzhhNzQ4ODBjOGU0ZjE5NjhiZGVlJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.1KeJYnoKJRAwqNO0VBAv8c71BIXJER5zmQjsUy9niuI) Say we decide to use AI to augment (rather than automate) a salesperson's task of recommending merchandise to customers. Which of the following would be an example of this?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q3-here-are-some-of-the-tasks-of-a-retail-salesperson-from-onet-we-encourage-you-to-check-out-the-page-yourself--say-we-decide-to-use-ai-to-augment-rather-than-automate-a-salespersons-task-of-recommending-merchandise-to-customers-which-of-the-following-would-be-an-example-of-this)\n`Answer:- Build an AI system to suggest products to the salesperson, who then decides what to recommend to the customer. `\n### Q.4 When looking for augmentation or automation opportunities, what are the two primary criteria by which to evaluate tasks for generative AI potential? (Check the two that apply.)\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q4-when-looking-for-augmentation-or-automation-opportunities-what-are-the-two-primary-criteria-by-which-to-evaluate-tasks-for-generative-ai-potential-check-the-two-that-apply)\n`Answer:- Business value (how valuable is it to automate?).``Technical feasibility (can AI do it?).`\n### Q.5 What is a quick way to start experimenting with an LLM application development project?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q5-what-is-a-quick-way-to-start-experimenting-with-an-llm-application-development-project)\n`Answer:- Try experimenting and prototyping with a web-based LLM to assess feasibility.`\n## Week 3: Generative AI and society\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-3-generative-ai-and-society)\n### Q.1 Which of the following statements about Reinforcement Learning from Human Feedback (RLHF) are true?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-which-of-the-following-statements-about-reinforcement-learning-from-human-feedback-rlhf-are-true)\n`Answer:- RLHF helps to align an LLM to human preferences, and can reduce the bias of an LLMâs output.`\n### Q.2 True or False. Because AI automates tasks, not jobs, absolutely no jobs will disappear because of AI.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-true-or-false-because-ai-automates-tasks-not-jobs-absolutely-no-jobs-will-disappear-because-of-ai)\n`Answer:- False`\n### Q.3 If we manage to build Artificial General Intelligence (AGI) some day, which tasks should AI be capable of performing? (Check all that apply.)\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q3-if-we-manage-to-build-artificial-general-intelligence-agi-some-day-which-tasks-should-ai-be-capable-of-performing-check-all-that-apply)\n`Answer:- Compose the music for a movie soundtrack.``Write a software application to let users manage their household spending budgets.``Learn to drive a car in roughly 20 hours of practice.`\n### Q.4 You are working on a chatbot to serve as a career coach for recent college graduates. Which of the following steps could you take to ensure that your project follows responsible AI? (Check all that apply.)\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q4-you-are-working-on-a-chatbot-to-serve-as-a-career-coach-for-recent-college-graduates-which-of-the-following-steps-could-you-take-to-ensure-that-your-project-follows-responsible-ai-check-all-that-apply)\n`Answer:- Engage diverse recent college graduates and ask them to offer feedback on the output of your chatbot.``Organize a brainstorming session to identify problems that could arise for users chatting with the career coach``Engage employers (because they are a key stakeholder group) and ask them to offer feedback on the output of your chatbot.`\n### Q.5 Now that youâve made it to the end of the course, which of these statements are true? (Please check all, because all apply!)\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q5-now-that-youve-made-it-to-the-end-of-the-course-which-of-these-statements-are-true-please-check-all-because-all-apply)\n`Answer:- All are correct`\n## Week 2 Solution According to College IP\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-2-solution-according-to-college-ip)\n## Link of Course for week 2:- <https://www.coursera.org/programs/int426-generative-ai-8n6df/learn/genai-for-everyone>\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#link-of-course-for-week-2--httpswwwcourseraorgprogramsint426-generative-ai-8n6dflearngenai-for-everyone)\n# GenAI For Everyone\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#genai-for-everyone)\n## Week 1:- Introduction To GenAI\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-1--introduction-to-genai)\n## Practice Quiz:-\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#practice-quiz-)\n### Q.1 Which of the following is an example of human-centered design in Al?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-which-of-the-following-is-an-example-of-human-centered-design-in-al)\n`Answer:- Designing a voice assistant that recognizes different accents and dialects to provide more accurate responses.``Creating a virtual assistant that helps users manage their mental health by providing personalized support.`\n### Q.2 How can Generative Al be used in the field of manufacturing?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-how-can-generative-al-be-used-in-the-field-of-manufacturing)\n`Answer:- To generate new product designs.`\n### Q.3 What are some potential applications of Generative Al in the retail industry?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q3-what-are-some-potential-applications-of-generative-al-in-the-retail-industry)\n`Answer:- By generating personalized product recommendations for customers.``By improving inventory management through predictive analytics.`\n### Q.4 In the field of art, how can Generative Al be used to create new works?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q4-in-the-field-of-art-how-can-generative-al-be-used-to-create-new-works)\n`Answer:- By generating completely original pieces of art.`\n### Q.5 What are some potential benefits of using Generative Al in the field of architecture?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q5-what-are-some-potential-benefits-of-using-generative-al-in-the-field-of-architecture)\n`Answer:- It can assist human architects in generating designs faster and more efficiently.``It can provide data-driven insights to optimize building performance and sustainability.`\n## Graded Quiz:-\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#graded-quiz-)\n### Q.1 What is the primary goal of Generative Al?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-what-is-the-primary-goal-of-generative-al)\n`Answer:- To generate new and original data`\n### Q.2 How does Generative Al impact organizational efficiency?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-how-does-generative-al-impact-organizational-efficiency)\n`Answer:- By automating repetitive tasks`\n### Q.3 Which of the following is a key consideration for implementing ethical aspects of Generative Al?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q3-which-of-the-following-is-a-key-consideration-for-implementing-ethical-aspects-of-generative-al)\n`Answer:- Ensuring unbiased model outputs`\n### Q.4 Which of the following are important considerations for ethical deployment and responsible practices in Generative Al projects?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q4-which-of-the-following-are-important-considerations-for-ethical-deployment-and-responsible-practices-in-generative-al-projects)\n`Answer:- Bias and fairness in Al algorithms``Transparency and explainability of Al systems`\n### Q.5 What distinguishes Generative Al from other types of Al algorithms, such as discriminative algorithms?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q5-what-distinguishes-generative-al-from-other-types-of-al-algorithms-such-as-discriminative-algorithms)\n`Answer:- Generative Al focuses on generating new data, while discriminative algorithms focus on classifying existing data.`\n### Q.6 Assess the impact of Generative Al on organizational efficiency.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q6-assess-the-impact-of-generative-al-on-organizational-efficiency)\n`Answer:- All options are correct`\n### Q.7 Which of the following statements best describes the fundamental concept of Generative Al?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q7-which-of-the-following-statements-best-describes-the-fundamental-concept-of-generative-al)\n`Answer:- Generative Al aims to generate new data based on patterns learned from existing data.`\n### Q.8 Which of the following best describes the purpose of Generative Al?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q8-which-of-the-following-best-describes-the-purpose-of-generative-al)\n`Answer:- To generate new and creative content.`\n### Q.9 What are some ethical considerations when implementing Generative Al?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q9-what-are-some-ethical-considerations-when-implementing-generative-al)\n`Answer:- Ensuring transparency and explainability of Al-generated outputs.`\n### Q.10 How can responsible implementation of Generative Al benefit society?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q10-how-can-responsible-implementation-of-generative-al-benefit-society)\n`Answer:- By fostering creativity and enabling new forms of artistic expression.`\n## Week 2:- GenAI in Daily Life\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-2--genai-in-daily-life)\n## Practice Quiz:-\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#practice-quiz--1)\n### Q.1 Which of the following is an example of an Al-driven application in the field of healthcare?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-which-of-the-following-is-an-example-of-an-al-driven-application-in-the-field-of-healthcare)\n`Answer:- A system that analyzes medical images to diagnose diseases.`\n### Q.2 Which of the following is a benefit of using GPT for content creation?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-which-of-the-following-is-a-benefit-of-using-gpt-for-content-creation)\n`Answer:- GPT can generate high-quality content with little human intervention.`\n### Q.3 Which of the following is a potential challenge of using GPT for content creation that could impact the quality of generated content?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q3-which-of-the-following-is-a-potential-challenge-of-using-gpt-for-content-creation-that-could-impact-the-quality-of-generated-content)\n`Answer:- GPT can generate content that lacks coherence and structure.`\n### Q.4 Which of the following is a benefit of using GPT (Generative Pre-trained Transformer) for creating presentations?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q4-which-of-the-following-is-a-benefit-of-using-gpt-generative-pre-trained-transformer-for-creating-presentations)\n`Answer:- GPT can automatically format and design slides for presentations.`\n### Q.5 Which of the following is a limitation of using GPT for creating media such as images or videos?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q5-which-of-the-following-is-a-limitation-of-using-gpt-for-creating-media-such-as-images-or-videos)\n`Answer:- GPT can only generate media content in a limited range of styles or themes.``GPT can generate biased or inappropriate media content due to training data.`\n## Prompt Engineering And You:-\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#prompt-engineering-and-you-)\n### Q.1 What is the primary objective of prompt engineering for generating content?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-what-is-the-primary-objective-of-prompt-engineering-for-generating-content)\n`Answer:- To generate high-quality and relevant content`\n### Q.2 Which of the following best describes prompt engineering in content generation?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-which-of-the-following-best-describes-prompt-engineering-in-content-generation)\n`Answer:- The practice of providing specific instructions or prompts for content creation.`\n### Q.3 How does prompt engineering contribute to content generation?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q3-how-does-prompt-engineering-contribute-to-content-generation)\n`Answer:- By providing a clear direction and focus for content creation`\n### Q.4 Which of the following is a benefit of using prompt engineering in content generation?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q4-which-of-the-following-is-a-benefit-of-using-prompt-engineering-in-content-generation)\n`Answer:- Improved content readability and coherence`\n### Q.5 What is the role of prompts in prompt engineering for content generation?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q5-what-is-the-role-of-prompts-in-prompt-engineering-for-content-generation)\n`Answer:- To guide and direct the content creation process`\n## Graded Quiz:-\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#graded-quiz--1)\n### Q.1 Which of the following is an advantage of using Al technology?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-which-of-the-following-is-an-advantage-of-using-al-technology)\n`Answer:- Increased efficiency and productivity`\n### Q.2 What does GPT stand for in the context of Al?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-what-does-gpt-stand-for-in-the-context-of-al)\n`Answer:- Generative Pre-trained Transformer`\n### Q.3 Why is Al customized for different use cases or needs?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q3-why-is-al-customized-for-different-use-cases-or-needs)\n`Answer:- To optimize Al's performance and adaptability`\n### Q.4 What is the primary purpose of content generation using Generative Al models like GPT-3?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q4-what-is-the-primary-purpose-of-content-generation-using-generative-al-models-like-gpt-3)\n`Answer:- To automatically produce coherent and contextually relevant text based on given prompts.`\n### Q.5 Which of the following is a key feature of content generation using Generative Al models like GPT-3?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q5-which-of-the-following-is-a-key-feature-of-content-generation-using-generative-al-models-like-gpt-3)\n`Answer:- The ability to generate diverse and contextually relevant text based on given prompts.`\n### Q.6 Which of the following projects could be socially impactful when developed using GenAl?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q6-which-of-the-following-projects-could-be-socially-impactful-when-developed-using-genal)\n`Answer:- Personalized healthcare recommendation system`\n### Q.7 A company wants to build an Al system for personalized recommendation. What approach should they use to customize Al for different use cases?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q7-a-company-wants-to-build-an-al-system-for-personalized-recommendation-what-approach-should-they-use-to-customize-al-for-different-use-cases)\n`Answer:- Employ collaborative filtering techniques.`\n### Q.8 In which of the following scenarios could content generation using Generative Al like GPT-3 be effectively applied?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q8-in-which-of-the-following-scenarios-could-content-generation-using-generative-al-like-gpt-3-be-effectively-applied)\n`Answer:- Automatically drafting legal contracts based on predefined templates and clauses.`\n### Q.9 How can prompt engineering enhance content generation using Generative Al models like GPT-3?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q9-how-can-prompt-engineering-enhance-content-generation-using-generative-al-models-like-gpt-3)\n`Answer:- By crafting specific and contextually rich prompts to influence the quality and relevance of the generated content.`\n### Q.10 How does GPT (Generative Pre-trained Transformer) work?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q10-how-does-gpt-generative-pre-trained-transformer-work)\n`Answer:- GPT utilizes transformer models and large-scale pre-training.`\n## Week 3:- How does GenAI work?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-3--how-does-genai-work)\n## Graded Quiz:-\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#graded-quiz--2)\n### Q.1 Which of the following is a major ethical concern related to Al?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-which-of-the-following-is-a-major-ethical-concern-related-to-al)\n`Answer:- Transparency and explainability`\n### Q.2 What is one potential limitation of Al when it comes to decision making?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-what-is-one-potential-limitation-of-al-when-it-comes-to-decision-making)\n`Answer:- Bias in the data used`\n### Q.3 What is the primary neural network architecture used in GPT?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q3-what-is-the-primary-neural-network-architecture-used-in-gpt)\n`Answer:- Transformer`\n### Q.4 In GPT, what does \"pre-training\" involve?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q4-in-gpt-what-does-pre-training-involve)\n`Answer:- Training the model on a specific task or dataset`\n### Q.5 How is Al customized to address different use cases and needs?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q5-how-is-al-customized-to-address-different-use-cases-and-needs)\n`Answer:- By tailoring Al models and algorithms to specific tasks and requirements`\n### Q.6 How can Al be used responsibly?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q6-how-can-al-be-used-responsibly)\n`Answer:- By ensuring transparency, fairness, and accountability in Al systems`\n### Q.7 Why is addressing bias in Al algorithms an important ethical consideration?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q7-why-is-addressing-bias-in-al-algorithms-an-important-ethical-consideration)\n`Answer:- Bias can lead to unfair and discriminatory treatment`\n### Q.8 Why is transparency in Al decision-making processes an important ethical consideration?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q8-why-is-transparency-in-al-decision-making-processes-an-important-ethical-consideration)\n`Answer:- Transparency promotes accountability and trustworthiness`\n### Q.9 Which step is NOT typically involved in building a simple GenAl application?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q9-which-step-is-not-typically-involved-in-building-a-simple-genal-application)\n`Answer:- Developing the user interface`\n### Q.10 What is one of the key steps in preparing data for training a GenAl model?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q10-what-is-one-of-the-key-steps-in-preparing-data-for-training-a-genal-model)\n`Answer:- Gathering and preprocessing the data`\n## Week 3 Solution According to College IP\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-3-solution-according-to-college-ip)\n## Link of Courses for week 3:- <https://www.coursera.org/learn/generative-ai> <https://www.coursera.org/learn/introduction-to-large-language-models> <https://www.coursera.org/learn/prompt-engineering/home/week/1>\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#link-of-courses-for-week-3--httpswwwcourseraorglearngenerative-ai---httpswwwcourseraorglearnintroduction-to-large-language-models-httpswwwcourseraorglearnprompt-engineeringhomeweek1)\n# Generative AI Primer\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#generative-ai-primer)\n## Generative AI Practice\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#generative-ai-practice)\n### Q.1 Use the Persona Pattern to perform an analysis of some content that your provide ChatGPT. When you are done, cut/paste the output in as the answer.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-use-the-persona-pattern-to-perform-an-analysis-of-some-content-that-your-provide-chatgpt-when-you-are-done-cutpaste-the-output-in-as-the-answer)\n```\nAnswer:-\nContent:\n\"The advancements in artificial intelligence have significantly impacted various industries. From healthcare to finance, AI is being utilized to enhance efficiency, streamline processes, and make data-driven decisions. However, concerns about the ethical implications of AI, such as bias in algorithms and job displacement, have also become prominent. Striking a balance between technological progress and ethical considerations is crucial for the responsible development and deployment of AI technologies.\"\nPersona Pattern Analysis:\n1. Perspective:\nThe content reflects a balanced perspective on artificial intelligence. It acknowledges the positive impact of AI on different industries while also highlighting the ethical concerns associated with its implementation.\n2. Tone:\nThe tone is informative and neutral. It presents facts and observations without expressing a strong bias towards either the positive or negative aspects of AI.\n3. Style:\nThe writing style is formal and professional, suited for discussing a complex topic. It uses clear and concise language to convey information.\n4. Values:\nThe content values a balanced approach to AI development, emphasizing the importance of considering ethical implications alongside technological advancements.\n5. Assumptions:\nThe content assumes a basic understanding of AI concepts and its applications across industries. It also assumes a general awareness of ethical concerns related to AI.\n6. Knowledge Base:\nThe content demonstrates a solid understanding of the subject matter, including the positive and negative aspects of AI, and the need for ethical considerations in its development and deployment.\n7. Intent:\nThe intent of the content is to inform and raise awareness about the dual nature of AI - its potential benefits and the ethical challenges it poses. It does not explicitly advocate for or against AI but encourages responsible development.\n8. Cultural Context:\nThe content is written in a way that transcends specific cultural contexts, making it relevant to a global audience. It focuses on universal concerns related to AI and ethics.\nOutput:\nThe content provides an informative and balanced perspective on the impact of artificial intelligence, acknowledging both its positive contributions and ethical concerns. The writing style is formal, and the intent is to inform and create awareness. The analysis reveals a solid understanding of the subject matter, with an emphasis on responsible development and deployment of AI technologies.\n\n```\n\n### Q.2 Write your own \"prompt program\" to convert some text that you cut/paste into ChatGPT into comma separated values (CSV). Cut/paste the output in as the answer.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-write-your-own-prompt-program-to-convert-some-text-that-you-cutpaste-into-chatgpt-into-comma-separated-values-csv-cutpaste-the-output-in-as-the-answer)\n```\nAnswer:-\nPython Program:-\nimport csv\ndef text_to_csv(input_text):\n# Split the input text into lines\nlines = input_text.split('\\n')\n# Create a CSV string\ncsv_content = \"\"\nfor line in lines:\n# Remove leading and trailing whitespaces\nline = line.strip()\n# Split the line into fields using comma as the delimiter\nfields = line.split(',')\n# Enclose each field in double quotes to handle cases with commas within the text\nfields = ['\"{}\"'.format(field.strip()) for field in fields]\n# Join the fields with commas and add a newline\ncsv_content += ','.join(fields) + '\\n'\nreturn csv_content\n# Example usage:\ninput_text = \"\"\"\nName, Age, Occupation\nJohn Doe, 30, Engineer\nJane Smith, 25, Scientist\nBob Johnson, 35, Doctor\n\"\"\"\ncsv_output = text_to_csv(input_text)\nprint(csv_output)\n\nOutput (CSV format):\n\"Name\",\"Age\",\"Occupation\"\n\"John Doe\",\"30\",\"Engineer\"\n\"Jane Smith\",\"25\",\"Scientist\"\n\"Bob Johnson\",\"35\",\"Doctor\"\n\n```\n\n### Q.3 Describe the ACHIEVE framework and each of its components. When you are done, cut/paste your description into ChatGPT and ask it to generate examples of how you could use ChatGPT and the ACHIEVE framework to perform tasks in your work or personal life.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q3-describe-the-achieve-framework-and-each-of-its-components-when-you-are-done-cutpaste-your-description-into-chatgpt-and-ask-it-to-generate-examples-of-how-you-could-use-chatgpt-and-the-achieve-framework-to-perform-tasks-in-your-work-or-personal-life)\n```\nAnswer:-\nThe ACHIEVE framework is a mnemonic device designed to outline the key components for setting and achieving goals effectively. Each letter in \"ACHIEVE\" represents a different aspect of the framework:\nA - Achievable:\nEnsure that your goals are realistic and attainable. Consider your resources, skills, and time constraints. Setting achievable goals increases motivation and the likelihood of success.\nC - Challenging:\nWhile goals should be achievable, they should also be challenging enough to stimulate growth and development. A balance between achievability and challenge is crucial for maintaining engagement and avoiding complacency.\nH - Human-driven:\nRecognize the human element in goal-setting. Consider your values, motivations, and personal strengths. Aligning your goals with your values increases commitment and satisfaction in the pursuit of those goals.\nI - Immediate actions:\nBreak down your goals into smaller, manageable tasks. Focus on immediate actions that move you closer to your objective. This helps prevent overwhelm and provides a clear roadmap for progress.\nE - Evaluated regularly:\nRegularly assess your progress toward the goal. Evaluate what's working, what needs adjustment, and celebrate milestones. Regular evaluation allows for adaptability and ensures that your goals remain relevant over time.\nV - Visible:\nKeep your goals visible and top-of-mind. Whether through written reminders, visual aids, or progress tracking, maintaining visibility helps sustain motivation and reinforces commitment to the goal.\nE - Emotional connection:\nConnect emotionally with your goals by understanding the deeper reasons behind them. Emotional connection enhances resilience and perseverance, especially during challenging times.\n\n```\n\n# Introduction To Large Language Models\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#introduction-to-large-language-models)\n## Introduction To Large Language Models: Quiz\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#introduction-to-large-language-models--quiz)\n### Q.1 What are large language models (LLMs)?:\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-what-are-large-language-models-llms)\n`Answer:- An LLM is a type of artificial intelligence (AI) that can generate human-quality text. LLMs are trained on massive datasets of text and code, and they can be used for many tasks, such as writing, translating, and coding.`\n### Q.2 What are some of the benefits of using large language models (LLMs)?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-what-are-some-of-the-benefits-of-using-large-language-models-llms)\n```\nAnswer:- LLMs have many benefits, including: \n1) They can generate human-quality text. \n2) They can be used for a variety of tasks.\n3) They can be trained on massive datasets of text and code. \n4) They are constantly improved.\n\n```\n\n### Q.3 What are some of the applications of LLMs?\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q3-what-are-some-of-the-applications-of-llms)\n```\nAnswer:- \nLLMs can be used for many tasks, including:\n1) Writing\n2) Translating\n3) Coding\n4) Answering questions\n5) Summarizing text\n6) Generating creative content\n\n```\n\n### Q.4 What are some of the challenges of using LLMs? Select three options.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q4-what-are-some-of-the-challenges-of-using-llms-select-three-options)\n```\nAnswer:- 1. They can be used to generate harmful content.\n2. They can be biased.\n3. They can be expensive to train.\n\n```\n\n# Prompt Engineering for ChatGPT: Module 1\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#prompt-engineering-for-chatgpt-module-1)\n## Week 1: Creating Your First Prompts\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-1-creating-your-first-prompts)\n### Q.1 Create a prompt for a large language model, such as ChatGPT, to describe how large language models work. Ask at least three follow-up questions based on the output. Provide the prompts and outputs from the conversation as the answer.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-create-a-prompt-for-a-large-language-model-such-as-chatgpt-to-describe-how-large-language-models-work-ask-at-least-three-follow-up-questions-based-on-the-output-provide-the-prompts-and-outputs-from-the-conversation-as-the-answer)\n```\nAnswer:-\nPrompt: Can you explain how large language models like ChatGPT work?\nOutput:\nLarge language models like ChatGPT work through a process called pre-training and fine-tuning. In the pre-training phase, the model is trained on a massive dataset containing parts of the Internet to learn grammar, facts, reasoning abilities, and some domain-specific knowledge. This helps the model develop a broad understanding of language. After pre-training, the model is fine-tuned on a narrower dataset with more specific examples and guidelines to align it with desired behaviors.\nFollow-up Question 1: How does the fine-tuning process contribute to the model's performance in specific tasks?\nFollow-up Question 2: Can you elaborate on the types of data used in pre-training and how it affects the model's general language understanding?\nFollow-up Question 3: Are there any limitations or challenges associated with the pre-training and fine-tuning approaches that impact the model's capabilities?\n\n```\n\n### Q.2 Create a prompt for a large language model, such as ChatGPT, that asks it to perform an instruction other than answering a question. For example, ask ChatGPT to create a meal plan, plan a trip, create a recipe, or help you diagnose a problem. Provide the prompts and outputs from the conversation as the answer.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-create-a-prompt-for-a-large-language-model-such-as-chatgpt-that-asks-it-to-perform-an-instruction-other-than-answering-a-question-for-example-ask-chatgpt-to-create-a-meal-plan-plan-a-trip-create-a-recipe-or-help-you-diagnose-a-problem-provide-the-prompts-and-outputs-from-the-conversation-as-the-answer)\n```\nAnswer:-\nPrompt: Can you help me plan a week-long vacation to a tropical destination?\nOutput:\nCertainly! To get started, could you please provide some details such as your preferred travel dates, budget range, and any specific activities or interests you have in mind for the vacation?\nFollow-up Question 1: What type of accommodation are you looking for, such as a hotel, resort, or vacation rental?\nFollow-up Question 2: Are there any particular destinations or countries you have in mind, or would you like suggestions based on your preferences?\nFollow-up Question 3: Do you have any dietary restrictions or preferences that I should consider when recommending restaurants or local cuisines at the destination?\n\n```\n\n# Prompt Engineering for ChatGPT: Module 2\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#prompt-engineering-for-chatgpt-module-2)\n## Week 2: Applying the Persona Pattern\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-2-applying-the-persona-pattern)\n### Q.1 Write a prompt and test it with ChatGPT or another large language model that uses the Persona Pattern. Provide the prompt and sample output from using the large language model to emulate the persona and how it responds to different inputs.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-write-a-prompt-and-test-it-with-chatgpt-or-another-large-language-model-that-uses-the-persona-pattern-provide-the-prompt-and-sample-output-from-using-the-large-language-model-to-emulate-the-persona-and-how-it-responds-to-different-inputs)\n```\nAnswer:- You are Chef Mia, a passionate and adventurous chef known for your creative dishes and warm personality. Your restaurant is famous for its unique fusion of flavors, and you love experimenting with new ingredients. Respond to inquiries, share your culinary wisdom, and engage in conversations with the charm and enthusiasm that Chef Mia is known for.\n\n```\n\n### Q.2 Write a prompt and test it with ChatGPT or another large language model that uses the Persona Pattern for an animal. Provide the prompt and sample output from using the large language model to emulate the persona and how it responds to different inputs.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-write-a-prompt-and-test-it-with-chatgpt-or-another-large-language-model-that-uses-the-persona-pattern-for-an-animal-provide-the-prompt-and-sample-output-from-using-the-large-language-model-to-emulate-the-persona-and-how-it-responds-to-different-inputs)\n```\nAnswer:- You are Luna, a wise and curious owl who resides in a mystical forest. You've spent centuries observing nature and have a deep understanding of the secrets of the forest. Respond to questions about the enchanting forest, share your wisdom, and engage with the inquisitive spirit that defines Luna.\n\n```\n\n### Q.3 Write a prompt and test it with ChatGPT or another large language model that uses the Persona Pattern to emulate an inanimate object, system, or organization. Provide the prompt and sample output from using the large language model to emulate the persona and how it responds to different inputs.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q3-write-a-prompt-and-test-it-with-chatgpt-or-another-large-language-model-that-uses-the-persona-pattern-to-emulate-an-inanimate-object-system-or-organization-provide-the-prompt-and-sample-output-from-using-the-large-language-model-to-emulate-the-persona-and-how-it-responds-to-different-inputs)\n```\nAnswer:- You are Cosmos, a sentient and ancient library of knowledge existing in the vast expanse of the universe. You hold the collective wisdom of countless civilizations and eons. Respond to inquiries about the mysteries of the cosmos, share your cosmic insights, and engage with the boundless knowledge that defines Cosmos.\n\n```\n\n## Week 4 Solution According to College IP\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-4-solution-according-to-college-ip)\n## Link of Courses for week 4:- <https://www.coursera.org/programs/int426-generative-ai-8n6df/learn/prompt-engineering><https://www.coursera.org/programs/int426-generative-ai-8n6df/learn/prompt-engineering>\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#link-of-courses-for-week-4--httpswwwcourseraorgprogramsint426-generative-ai-8n6dflearnprompt-engineeringhttpswwwcourseraorgprogramsint426-generative-ai-8n6dflearnprompt-engineering)\n## Week 2: Creating Prompts with New Information\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-2-creating-prompts-with-new-information)\n### Q.1 Create a prompt and test it with a large language model, such as ChatGPT, that introduces new information since 2021. Please only use public information. Do NOT use information that is private, subject to legal restrictions, or otherwise should not be shared with Coursera, ChatGPT, the instructor, etc. The prompt should require the large language model to answer a question about the information. Please provide your prompt and the output as the answer.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-create-a-prompt-and-test-it-with-a-large-language-model-such-as-chatgpt-that-introduces-new-information-since-2021-please-only-use-public-information-do-not-use-information-that-is-private-subject-to-legal-restrictions-or-otherwise-should-not-be-shared-with-coursera-chatgpt-the-instructor-etc-the-prompt-should-require-the-large-language-model-to-answer-a-question-about-the-information-please-provide-your-prompt-and-the-output-as-the-answer)\n```\nAnswer:-\nPrompt:\nYou are an AI language model, and I'd like you to provide information on the progress and advancements in renewable energy technologies since 2021. Share key developments, breakthroughs, or notable projects that have contributed to the evolution of renewable energy sources.\nOutput:\nCertainly! Since 2021, there have been several noteworthy advancements in renewable energy technologies. One significant development is the continued growth of solar power. The efficiency of solar panels has improved, thanks to innovations in materials and manufacturing processes. Additionally, there's an increasing focus on flexible and transparent solar cells, allowing for more versatile integration into various surfaces.\nIn the field of wind energy, there has been an expansion of offshore wind farms, harnessing strong and consistent winds at sea. Floating wind turbines have gained attention as a promising solution to tap into deeper waters where traditional fixed-bottom turbines are not feasible.\nEnergy storage technologies have also seen progress. Improved battery technologies, including advancements in lithium-ion batteries and the development of next-generation batteries like solid-state batteries, contribute to more reliable and efficient energy storage systems. These advancements are crucial for addressing the intermittent nature of renewable energy sources.\nMoreover, innovations in grid technologies and smart grids enhance the integration of renewable energy into existing power infrastructures. Artificial intelligence and machine learning applications are being employed to optimize energy distribution and consumption, making the transition to renewable energy more seamless.\nIt's important to note that these developments represent a snapshot of the ongoing progress in renewable energy, and the field continues to evolve with further research and investment.\n\n```\n\n### Q.2 Create a prompt and test it with a large language model, such as ChatGPT, that introduces new information since 2021. Please only use public information. Do NOT use information that is private, subject to legal restrictions, or otherwise should not be shared with Coursera, ChatGPT, the instructor, etc. The prompt should require the large language model to perform a task, other than answering a question, with the information. Please provide your prompt and the output as the answer.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-create-a-prompt-and-test-it-with-a-large-language-model-such-as-chatgpt-that-introduces-new-information-since-2021-please-only-use-public-information-do-not-use-information-that-is-private-subject-to-legal-restrictions-or-otherwise-should-not-be-shared-with-coursera-chatgpt-the-instructor-etc-the-prompt-should-require-the-large-language-model-to-perform-a-task-other-than-answering-a-question-with-the-information-please-provide-your-prompt-and-the-output-as-the-answer)\n```\nAnswer:-\nPrompt:\nAs an AI language model, I'd like you to create a persuasive paragraph encouraging individuals and businesses to consider the benefits of integrating blockchain technology into their operations. Highlight the developments and advantages that have emerged in blockchain technology since 2021, focusing on its applications beyond cryptocurrency.\nOutput:\nIn the ever-evolving landscape of technology, the advancements in blockchain since 2021 have opened up a myriad of opportunities for individuals and businesses alike. Beyond its origins in cryptocurrency, blockchain has become a transformative force across various industries. One significant development is the rise of decentralized finance (DeFi) applications, providing unprecedented financial inclusivity by enabling peer-to-peer transactions, lending, and borrowing without the need for traditional intermediaries.\nMoreover, the integration of blockchain in supply chain management has enhanced transparency and traceability, ensuring the authenticity of products from creation to delivery. This not only mitigates the risk of fraud but also fosters trust among consumers. Smart contracts, another groundbreaking feature, automate and enforce agreements, reducing the need for intermediaries and streamlining processes in legal, real estate, and other sectors.\nThe environmental impact of blockchain has also seen positive strides, with the emergence of eco-friendly consensus mechanisms and energy-efficient blockchain networks. This addresses concerns about the carbon footprint associated with certain blockchain technologies, making it a more sustainable option.\nBusinesses that embrace blockchain technology stand to benefit from increased efficiency, security, and trust in their operations. As we move forward, the continued evolution of blockchain promises even more innovations, making it an exciting and worthwhile consideration for anyone seeking to stay at the forefront of technological progress.\n\n```\n\n# Prompt Engineering for ChatGPT: Module 3\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#prompt-engineering-for-chatgpt-module-3)\n## Week 3: Applying Prompt Patterns I\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-3-applying-prompt-patterns-i)\n### Q.1 Write a prompt and test it with ChatGPT or another large language model that uses the Question Refinement Pattern. Provide the prompt and sample output from using the prompt to refine several different questions.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-write-a-prompt-and-test-it-with-chatgpt-or-another-large-language-model-that-uses-the-question-refinement-pattern-provide-the-prompt-and-sample-output-from-using-the-prompt-to-refine-several-different-questions)\n```\nAnswer:-\nPrompt:\nI am a curious individual eager to learn more about a variety of topics. Use the Question Refinement Pattern to help me refine the following questions:\nWhat are some interesting scientific discoveries made in the past decade?\nCan you tell me about famous historical figures and their contributions?\nWhat are the current trends in sustainable technology?\nExplain the key concepts of quantum mechanics in simple terms.\nSample Output:\nRefinement for Question 1:\nRevised Question: What are the most groundbreaking scientific discoveries in fields like physics, biology, and astronomy that have emerged in the past ten years?\nRefinement for Question 2:\nRevised Question: Could you provide insights into influential historical figures from various cultures, emphasizing their unique contributions to science, art, or politics?\nRefinement for Question 3:\nRevised Question: Can you elaborate on the latest advancements in sustainable technology, particularly focusing on innovations in renewable energy and eco-friendly practices in manufacturing?\nRefinement for Question 4:\nRevised Question: Break down the fundamental principles of quantum mechanics, explaining concepts like superposition and entanglement in a way that's easy for someone with a basic scientific background to grasp.\n\n```\n\n### Q.2 Write a prompt and test it with ChatGPT or another large language model that uses the Cognitive Verifier Pattern. Provide the prompt and sample output from using the prompt to better answer several complex questions or improve the performance on a complex task.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-write-a-prompt-and-test-it-with-chatgpt-or-another-large-language-model-that-uses-the-cognitive-verifier-pattern-provide-the-prompt-and-sample-output-from-using-the-prompt-to-better-answer-several-complex-questions-or-improve-the-performance-on-a-complex-task)\n```\nAnswer:-\nPrompt:\nYou are a knowledgeable assistant using the Cognitive Verifier Pattern. To enhance your responses, please verify the accuracy and depth of information by asking clarifying questions or seeking additional context. Address the following complex inquiries with thorough and precise answers:\nExplain the intricacies of CRISPR gene editing technology and its current applications in medical research.\nProvide a comprehensive overview of the factors influencing climate change, including both natural and anthropogenic contributors.\nAnalyze the economic impact of emerging technologies, such as artificial intelligence and blockchain, on various industries.\nSample Output:\nFor Question 1:\nClarifying Question: Are you looking for information on the specific molecular processes involved in CRISPR gene editing, or would you prefer a broader understanding of its applications in both somatic and germline cells within the medical research field?\nFor Question 2:\nClarifying Question: Would you like an exploration of the historical context of climate change factors, or is your focus more on the contemporary interplay between natural phenomena and human activities contributing to climate change?\nFor Question 3:\nClarifying Question: Are you interested in a general overview of the economic impact of emerging technologies, or would you prefer a more detailed analysis, perhaps focusing on a particular industry or region affected by the integration of artificial intelligence and blockchain?\n\n```\n\n## Week 5 & 6 Solution According to College IP\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-5--6-solution-according-to-college-ip)\n## Link of Courses for week 5 & 6:- <https://www.coursera.org/programs/int426-generative-ai-8n6df/learn/prompt-engineering><https://www.coursera.org/programs/int426-generative-ai-8n6df/learn/prompt-engineering>\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#link-of-courses-for-week-5--6--httpswwwcourseraorgprogramsint426-generative-ai-8n6dflearnprompt-engineeringhttpswwwcourseraorgprogramsint426-generative-ai-8n6dflearnprompt-engineering)\n# Prompt Engineering for ChatGPT: Module 4\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#prompt-engineering-for-chatgpt-module-4)\n## Week 4:- Applying Few-Shot Examples Concepts\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-4--applying-few-shot-examples-concepts)\n### Q.1 Write a prompt and test it with ChatGPT or another large language model that uses few-shot examples to teach the large language model to perform a complex task. Provide the prompt and sample output from using the prompt.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-write-a-prompt-and-test-it-with-chatgpt-or-another-large-language-model-that-uses-few-shot-examples-to-teach-the-large-language-model-to-perform-a-complex-task-provide-the-prompt-and-sample-output-from-using-the-prompt)\n```\nAnswer:-\nPrompt:\nYou're a travel agent tasked with creating personalized travel itineraries for clients based on their preferences. Write a few-shot prompt to train a large language model to generate a travel itinerary based on a client's interests and constraints.\nFew-shot Examples:\nClient: \"I love nature and adventure. I want to explore a destination known for its lush forests, hiking trails, and opportunities for outdoor activities like zip-lining and kayaking.\"\nClient: \"I'm a history enthusiast interested in ancient civilizations and cultural landmarks. I'm looking for a destination rich in historical sites and museums.\"\nClient: \"I'm a foodie who wants to indulge in culinary delights. I'm seeking a destination renowned for its street food, local markets, and diverse cuisine.\"\nClient: \"I'm a beach lover and sunseeker. I'm searching for a destination with pristine beaches, turquoise waters, and opportunities for water sports like snorkeling and surfing.\"\nSample Output:\nClient's Interests: Nature and Adventure\nBased on your preferences for nature and adventure, I recommend you explore the breathtaking landscapes of New Zealand. Here's a personalized itinerary for your trip:\nDay 1: Arrive in Auckland, New Zealand. Check into your accommodation and spend the evening exploring the city's vibrant waterfront and dining scene.\nDay 2: Head to Rotorua, known for its geothermal wonders and Maori culture. Take a thrilling zipline adventure through the Redwoods Forest, followed by a relaxing soak in natural hot springs.\nDay 3: Drive to Tongariro National Park and embark on the famous Tongariro Alpine Crossing, a challenging but rewarding hike through volcanic terrain with stunning views of Mt. Ngauruhoe.\nDay 4: Travel to Queenstown, the adventure capital of New Zealand. Spend the day kayaking on Lake Wakatipu or bungee jumping off the iconic Kawarau Bridge.\nDay 5: Explore Fiordland National Park on a scenic cruise through Milford Sound, where you'll witness cascading waterfalls, towering cliffs, and abundant wildlife.\nDay 6: Return to Auckland for your departure, taking in any last-minute adventures or souvenir shopping along the way.\nThis itinerary combines adrenaline-pumping activities with breathtaking natural beauty, ensuring an unforgettable adventure in New Zealand.\n\n```\n\n### Q.2 Write a prompt and test it with ChatGPT or another large language model that uses few-shot examples to teach the large language model to perform a complex task that requires performing intermediate sub-steps. Provide the prompt and sample output from using the prompt.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-write-a-prompt-and-test-it-with-chatgpt-or-another-large-language-model-that-uses-few-shot-examples-to-teach-the-large-language-model-to-perform-a-complex-task-that-requires-performing-intermediate-sub-steps-provide-the-prompt-and-sample-output-from-using-the-prompt)\n```\nAnswer:-\nPrompt:\nYou're a baking instructor teaching a class on how to make a classic chocolate cake. Write a few-shot prompt to train a large language model to guide students through the step-by-step process of making a chocolate cake, including instructions for preparing the batter, baking the cake, and decorating it.\nFew-shot Examples:\nInstruction: \"Mix the dry ingredients together in a large bowl: flour, cocoa powder, baking powder, baking soda, and salt.\"\nInstruction: \"In a separate bowl, cream together the butter and sugar until light and fluffy.\"\nInstruction: \"Add the eggs, one at a time, to the butter-sugar mixture, beating well after each addition.\"\nInstruction: \"Alternate adding the dry ingredients and the milk to the butter-sugar-egg mixture, beginning and ending with the dry ingredients.\"\nSample Output:\nInstruction: Mix the dry ingredients together in a large bowl: flour, cocoa powder, baking powder, baking soda, and salt.\nGreat! Now that you have your dry ingredients combined, let's move on to the next step.\nInstruction: In a separate bowl, cream together the butter and sugar until light and fluffy.\nExcellent! Creaming the butter and sugar together will help give our chocolate cake a tender and moist texture. Make sure to beat them until they're well combined and the mixture is light and fluffy.\nInstruction: Add the eggs, one at a time, to the butter-sugar mixture, beating well after each addition.\nPerfect! Adding the eggs one at a time ensures that they're fully incorporated into the batter, giving our cake structure and richness. Be sure to beat well after each addition to fully mix in the eggs.\nInstruction: Alternate adding the dry ingredients and the milk to the butter-sugar-egg mixture, beginning and ending with the dry ingredients.\nWell done! Alternating between adding the dry ingredients and the milk helps to ensure that the batter is evenly mixed and avoids overmixing, which can lead to a dense cake. Remember to start and finish with the dry ingredients to maintain the proper balance of ingredients.\nNow that your batter is ready, you can pour it into prepared cake pans and bake according to the recipe instructions. Once the cakes are baked and cooled, feel free to decorate them with frosting or toppings of your choice. Enjoy your delicious homemade chocolate cake!\n\n```\n\n# Prompt Engineering for ChatGPT: Module 5\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#prompt-engineering-for-chatgpt-module-5)\n## Week 5:- Applying Prompt Patterns II\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-5--applying-prompt-patterns-ii)\n### Q.1 Choose one of the patterns from this module and write a sample prompt using the pattern. Provide the prompt and output of using the prompt in ChatGPT or another large language model.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-choose-one-of-the-patterns-from-this-module-and-write-a-sample-prompt-using-the-pattern-provide-the-prompt-and-output-of-using-the-prompt-in-chatgpt-or-another-large-language-model)\n```\nAnswer:-\nPattern: Problem-Solution\nPrompt:\nYou're a homeowner dealing with a clogged kitchen sink drain. Write a problem-solution prompt to train a large language model to help you troubleshoot and fix the issue.\nFew-shot Examples:\nProblem: \"My kitchen sink drain is clogged, and water is backing up into the sink.\"\nSolution: \"Try using a plunger to dislodge the clog by creating a vacuum and pushing it through the pipes. If that doesn't work, you can attempt to remove the trap under the sink and manually clear the blockage.\"\nProblem: \"The water in my kitchen sink is draining very slowly.\"\nSolution: \"Pour boiling water down the drain to dissolve any grease or debris that may be causing the blockage. Alternatively, you can mix baking soda and vinegar to create a fizzy reaction that can help break up the clog. Follow it up with hot water to flush out the pipes.\"\nProblem: \"There's a foul odor coming from my kitchen sink drain.\"\nSolution: \"This could indicate a buildup of food particles and bacteria in the drain. Try pouring a mixture of hot water and bleach down the drain to sanitize it and eliminate the odor. You can also use citrus peels or baking soda to freshen up the drain naturally.\"\nSample Output:\nProblem: My kitchen sink drain is clogged, and water is backing up into the sink.\nSolution: Try using a plunger to dislodge the clog by creating a vacuum and pushing it through the pipes. If that doesn't work, you can attempt to remove the trap under the sink and manually clear the blockage.\nGreat! Let's start by using a plunger to see if we can clear the clog. Make sure there's enough water in the sink to cover the plunger's cup, then place the plunger over the drain and push and pull in a vigorous motion to create suction. This action can help dislodge the blockage and allow the water to flow freely again.\nIf the plunger doesn't do the trick, we can move on to removing the trap under the sink. Grab a bucket to catch any water or debris that may come out, then use a wrench to loosen the slip nuts on both ends of the trap. Once the trap is removed, you can manually clear out any obstructions using a wire hanger or plumber's snake.\nGive these methods a try, and hopefully, your kitchen sink will be back to normal in no time! If you need further assistance, feel free to ask for more advice.\n\n```\n\n### Q.2 Choose another one of the patterns from this module and write a sample prompt using the pattern. This prompt must be applied to some information that you provide in the prompt before the pattern. Provide the prompt and output of using the prompt in ChatGPT or another large language model.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-choose-another-one-of-the-patterns-from-this-module-and-write-a-sample-prompt-using-the-pattern-this-prompt-must-be-applied-to-some-information-that-you-provide-in-the-prompt-before-the-pattern-provide-the-prompt-and-output-of-using-the-prompt-in-chatgpt-or-another-large-language-model)\n```\nAnswer:-\nPattern: Compare and Contrast\nPrompt:\nYou're a student deciding between two universities to attend for your undergraduate studies: University A and University B. University A is known for its strong engineering program, while University B is renowned for its liberal arts curriculum. Write a compare and contrast prompt to train a large language model to help you weigh the pros and cons of each university.\nInformation:\nUniversity A:\nStrong engineering program\nUrban campus with access to industry partnerships\nLarge student population with diverse extracurricular activities\nUniversity B:\nRenowned liberal arts curriculum\nBeautiful suburban campus with extensive green spaces\nSmall class sizes with personalized attention from faculty\nSample Output:\nCompare and Contrast:\nUniversity A:\nStrengths: Offers a strong engineering program with access to industry partnerships due to its urban campus. It also boasts a large student population, providing a diverse range of extracurricular activities.\nWeaknesses: However, it may have larger class sizes and less personalized attention from faculty compared to University B.\nUniversity B:\nStrengths: Renowned for its liberal arts curriculum and beautiful suburban campus with extensive green spaces. Additionally, its small class sizes ensure personalized attention from faculty.\nWeaknesses: Yet, it might lack the same level of industry connections and opportunities for engineering students as University A.\nWhen considering which university to attend, it's essential to weigh these factors carefully. If you prioritize a strong engineering program and access to industry partnerships, University A may be the better choice. However, if you value a liberal arts education in a more intimate setting with personalized attention from faculty, University B might be the ideal fit for you. Take your time to evaluate your preferences and make an informed decision that aligns with your academic and personal goals.\n\n```\n\n# Prompt Engineering for ChatGPT: Module 6\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#prompt-engineering-for-chatgpt-module-6)\n## Week 6:- Creating a Prompt-based Application\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-6--creating-a-prompt-based-application)\n### Q.1 Develop your own prompt-based application, similar to the outlining application from the videos, to help you accomplish a task. Your application can do whatever you want and does not have to be focused on outlining. Come up with a creative way of using large language models to program an environment to solve a problem you face on a daily basis.Provide your prompt and a sample of using the prompt-based application.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-develop-your-own-prompt-based-application-similar-to-the-outlining-application-from-the-videos-to-help-you-accomplish-a-task-your-application-can-do-whatever-you-want-and-does-not-have-to-be-focused-on-outlining-come-up-with-a-creative-way-of-using-large-language-models-to-program-an-environment-to-solve-a-problem-you-face-on-a-daily-basisprovide-your-prompt-and-a-sample-of-using-the-prompt-based-application)\n```\nAnswer:-\nPrompt:\nYou're a busy professional who struggles to stay organized with your daily tasks and appointments. Develop a prompt-based application to help you manage your schedule efficiently. Your application should allow you to input tasks, set deadlines, receive reminders, and prioritize tasks based on urgency and importance.\nSample Usage:\nUser: Add a new task.\nApplication: What is the title of the task?\nUser: Prepare presentation for Monday meeting.\nApplication: Please enter the deadline for this task.\nUser: The deadline is Sunday evening.\nApplication: Task \"Prepare presentation for Monday meeting\" added with a deadline of Sunday evening.\nUser: Set a reminder for the upcoming task.\nApplication: Which task would you like to set a reminder for?\nUser: Prepare presentation for Monday meeting.\nApplication: When would you like to receive the reminder?\nUser: Saturday afternoon.\nApplication: Reminder set for the task \"Prepare presentation for Monday meeting\" on Saturday afternoon.\nUser: Prioritize tasks.\nApplication: Please list the tasks you want to prioritize.\nUser: 1. Finish report for client. 2. Prepare presentation for Monday meeting. 3. Call supplier for updates.\nApplication: Task priorities updated.\nUser: View tasks for today.\nApplication: Here are your tasks for today:\nFinish report for client (Priority: High, Deadline: Today)\nCall supplier for updates (Priority: Medium, Deadline: Tomorrow)\nUser: Mark task as complete.\nApplication: Which task would you like to mark as complete?\nUser: Finish report for client.\nApplication: Task \"Finish report for client\" marked as complete.\nUser: Help.\nApplication: What assistance do you need?\nUser: I forgot the deadline for a task.\nApplication: Please provide the title of the task you need the deadline for.\nUser: Prepare presentation for Monday meeting.\nApplication: The deadline for the task \"Prepare presentation for Monday meeting\" is Sunday evening.\n\n```\n\n## Week 7,8 & 9 Solution According to College IP\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-78--9-solution-according-to-college-ip)\n## Link of Courses for week 7,8 & 9:- <https://www.coursera.org/learn/generative-ai-with-llms>\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#link-of-courses-for-week-78--9--httpswwwcourseraorglearngenerative-ai-with-llms)\n# Generative AI with Large Language Models\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#generative-ai-with-large-language-models)\n## Week 1:- Week 1 quiz\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-1--week-1-quiz)\n### Q.1 Interacting with Large Language Models (LLMs) differs from traditional machine learning models. Working with LLMs involves natural language input, known as a _____, resulting in output from the Large Language Model, known as the ______ .Answer:- prompt, completion\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-interacting-with-large-language-models-llms-differs-from-traditional-machine-learning-models--working-with-llms-involves-natural-language-input-known-as-a--_____-resulting-in-output-from-the-large-language-model-known-as-the-______-answer--prompt-completion)\n### Q.2 Large Language Models (LLMs) are capable of performing multiple tasks supporting a variety of use cases. Which of the following tasks supports the use case of converting code comments into executable code?Answer:- Translation\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-large-language-models-llms-are-capable-of-performing-multiple-tasks-supporting-a-variety-of-use-cases--which-of-the-following-tasks-supports-the-use-case-of-converting-code-comments-into-executable-codeanswer--translation)\n### Q.3 What is the self-attention that powers the transformer architecture?Answer:- A mechanism that allows a model to focus on different parts of the input sequence during computation.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q3-what-is-the-self-attention-that-powers-the-transformer-architectureanswer--a-mechanism-that-allows-a-model-to-focus-on-different-parts-of-the-input-sequence-during-computation)\n### Q.4 Which of the following stages are part of the generative AI model lifecycle mentioned in the course? (Select all that apply)Answer:-1. Deploying the model into the infrastructure and integrating it with the application.2. Selecting a candidate model and potentially pre-training a custom model.3. Manipulating the model to align with specific project needs.4. Defining the problem and identifying relevant datasets.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q4-which-of-the-following-stages-are-part-of-the-generative-ai-model-lifecycle-mentioned-in-the-course-select-all-that-applyanswer-1-deploying-the-model-into-the-infrastructure-and-integrating-it-with-the-application2-selecting-a-candidate-model-and-potentially-pre-training-a-custom-model3-manipulating-the-model-to-align-with-specific-project-needs4-defining-the-problem-and-identifying-relevant-datasets)\n### Q.5 \"RNNs are better than Transformers for generative Al Tasks.\"Is this true or false?Answer:- False\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q5-rnns-are-better-than-transformers-for-generative-al-tasksis-this-true-or-falseanswer--false)\n### Q.6 Which transformer-based model architecture has the objective of guessing a masked token based on the previous sequence of tokens by building bidirectional representations of the input sequence.Answer:- Autoencoder\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q6-which-transformer-based-model-architecture-has-the-objective-of-guessing-a-masked-token-based-on-the-previous-sequence-of-tokens-by-building-bidirectional-representations-of-the-input-sequenceanswer--autoencoder)\n### Q.7 Which transformer-based model architecture is well-suited to the task of text translation?Answer:- Sequence-to-sequence\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q7-which-transformer-based-model-architecture-is-well-suited-to-the-task-of-text-translationanswer--sequence-to-sequence)\n### Q.8 Do we always need to increase the model size to improve its performance?Answer:- False\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q8-do-we-always-need-to-increase-the-model-size-to-improve-its-performanceanswer--false)\n### Q.9 Scaling laws for pre-training large language models consider several aspects to maximize performance of a model within a set of constraints and available scaling choices. Select all alternatives that should be considered for scaling when performing model pre-training?Answer:-1. Dataset size: Number of tokens2. Model size: Number of parameters3. Compute budget: Compute constraints\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q9-scaling-laws-for-pre-training-large-language-models-consider-several-aspects-to-maximize-performance-of-a-model-within-a-set-of-constraints-and-available-scaling-choices-select-all-alternatives-that-should-be-considered-for-scaling-when-performing-model-pre-traininganswer-1-dataset-size-number-of-tokens2-model-size-number-of-parameters3-compute-budget-compute-constraints)\n### Q.10 \"You can combine data parallelism with model parallelism to train LLMs.\"Is this true or false?Answer:- True\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q10-you-can-combine-data-parallelism-with-model-parallelism-to-train-llmsis-this-true-or-falseanswer--true)\n## Lab 1 - Generative AI Use Case: Summarize Dialogue\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#lab-1---generative-ai-use-case-summarize-dialogue)\n## In order to complete Lab 1 please watch the below given video carefully and do all the step as it is.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#in-order-to-complete-lab-1-please-watch-the-below-given-video-carefully-and-do-all-the-step-as-it-is)\nLab.-.1.Generative.Ai.Use.Case.Summarize.Dialogue.mov\n## Week 2:- Week 2 quiz\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-2--week-2-quiz)\n### Q.1 Fill in the blanks: involves using many prompt-completion examples as the labeled training dataset to continue training the model by updating its weights. This is different from where you provide prompt-completion examples during inference.Answer:- Instruction fine-tuning, In-context learning\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-fill-in-the-blanks-involves-using-many-prompt-completion-examples-as-the-labeled-training-dataset-to-continue-training-the-model-by-updating-its-weights-this-is-different-from-where-you-provide-prompt-completion-examples-during-inferenceanswer--instruction-fine-tuning-in-context-learning)\n### Q.2 Fine-tuning a model on a single task can improve model performance specifically on that task; however, it can also degrade the performance of other tasks as a side effect. This phenomenon is known as:Answer:- Catastrophic forgetting\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-fine-tuning-a-model-on-a-single-task-can-improve-model-performance-specifically-on-that-task-however-it-can-also-degrade-the-performance-of-other-tasks-as-a-side-effect-this-phenomenon-is-known-asanswer--catastrophic-forgetting)\n### Q.3 Which evaluation metric below focuses on precision in matching generated output to the reference text and is used for text translation?Answer:- BLEU\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q3-which-evaluation-metric-below-focuses-on-precision-in-matching-generated-output-to-the-reference-text-and-is-used-for-text-translationanswer--bleu)\n### Q.4 Which of the following statements about multi-task finetuning is correct? Select all that apply:Answer:-1. Multi-task finetuning can help prevent catastrophic forgetting.2. FLAN-T5 was trained with multi-task finetuning.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q4-which-of-the-following-statements-about-multi-task-finetuning-is-correct-select-all-that-applyanswer-1-multi-task-finetuning-can-help-prevent-catastrophic-forgetting2-flan-t5-was-trained-with-multi-task-finetuning)\n### Q.5 \"Smaller LLMs can struggle with one-shot and few-shot inference:\"Is this true or false?Answer:- True\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q5-smaller-llms-can-struggle-with-one-shot-and-few-shot-inferenceis-this-true-or-falseanswer--true)\n### Q.6 Which of the following are Parameter Efficient Fine-Tuning (PEFT) methods? Select all that apply.Answer:-1. Reparameterization2. Selective3. Additive\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q6-which-of-the-following-are-parameter-efficient-fine-tuning-peft-methods-select-all-that-applyanswer-1-reparameterization2-selective3-additive)\n### Q.7 Which of the following best describes how LoRA works?Answer:- LoRA decomposes weights into two smaller rank matrices and trains those instead of the full model weights.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q7-which-of-the-following-best-describes-how-lora-worksanswer--lora-decomposes-weights-into-two-smaller-rank-matrices-and-trains-those-instead-of-the-full-model-weights)\n### Q.8 What is a soft prompt in the context of LLMs (Large Language Models)?Answer:- A set of trainable tokens that are added to a prompt and whose values are updated during additional training to improve performance on specific tasks.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q8-what-is-a-soft-prompt-in-the-context-of-llms-large-language-modelsanswer--a-set-of-trainable-tokens-that-are-added-to-a-prompt-and-whose-values-are-updated-during-additional-training-to-improve-performance-on-specific-tasks)\n### Q.9 \"Prompt Tuning is a technique used to adjust all hyperparameters of a language model.\"Is this true or false?Answer:- False\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q9-prompt-tuning-is-a-technique-used-to-adjust-all-hyperparameters-of-a-language-modelis-this-true-or-falseanswer--false)\n### Q.10 \"PEFT methods can reduce the memory needed for fine-tuning dramatically, sometimes to just 12-20% of the memory needed for full fine-tuning.\"Is this true or false?Answer:- True\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q10-peft-methods-can-reduce-the-memory-needed-for-fine-tuning-dramatically-sometimes-to-just-12-20-of-the-memory-needed-for-full-fine-tuningis-this-true-or-falseanswer--true)\n## Lab 2 - Fine-tune a generative AI model for dialogue summarization\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#lab-2---fine-tune-a-generative-ai-model-for-dialogue-summarization)\n## In order to complete Lab 2 please watch the below given video carefully and do all the step as it is.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#in-order-to-complete-lab-2-please-watch-the-below-given-video-carefully-and-do-all-the-step-as-it-is)\nLab.2.-.Fine-tune.a.generative.AI.model.for.dialogue.summarization.mov\n## Week 3:- Week 3 quiz\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-3--week-3-quiz)\n### Q.1 Which of the following are true in regards to Constitutional Al? Select all that apply.Answer:-1. Red Teaming is the process of eliciting undesirable responses by interacting with a model.2. In Constitutional Al, we train a model to choose between different responses.3. To obtain revised answers for possible harmful prompts, we need to go through a Critique and Revision process.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-which-of-the-following-are-true-in-regards-to-constitutional-al-select-all-that-applyanswer-1-red-teaming-is-the-process-of-eliciting-undesirable-responses-by-interacting-with-a-model2-in-constitutional-al-we-train-a-model-to-choose-between-different-responses3-to-obtain-revised-answers-for-possible-harmful-prompts-we-need-to-go-through-a-critique-and-revision-process)\n### Q.2 What does the \"Proximal\" in Proximal Policy Optimization refer to?Answer:- The constraint that limits the distance between the new and old policy\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-what-does-the-proximal-in-proximal-policy-optimization-refer-toanswer--the-constraint-that-limits-the-distance-between-the-new-and-old-policy)\n### Q.3 \"You can use an algorithm other than Proximal Policy Optimization to update the model weights during RLHF.\"Is this true or false?Answer:- True\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q3-you-can-use-an-algorithm-other-than-proximal-policy-optimization-to-update-the-model-weights-during-rlhfis-this-true-or-falseanswer--true)\n### Q.4 In reinforcement learning, particularly with the Proximal Policy Optimization (PPO) algorithm, what is the role of KL-Divergence? Select all that apply.Answer:-1. KL divergence measures the difference between two probability distributions.2. KL divergence is used to enforce a constraint that limits the extent of LLM weight updates.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q4-in-reinforcement-learning-particularly-with-the-proximal-policy-optimization-ppo-algorithm-what-is-the-role-of-kl-divergence-select-all-that-applyanswer-1-kl-divergence-measures-the-difference-between-two-probability-distributions2-kl-divergence-is-used-to-enforce-a-constraint-that-limits-the-extent-of-llm-weight-updates)\n### Q.5 Fill in the blanks: When fine-tuning a large language model with human feedback, the action that the agent (in this case the LLM) carries out is __________ and the action space is the ____________.Answer:- Generating the next token, vocabulary of all tokens.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q5-fill-in-the-blanks-when-fine-tuning-a-large-language-model-with-human-feedback-the-action-that-the-agent-in-this-case-the-llm-carries-out-is-__________-and-the-action-space-is-the-____________answer--generating-the-next-token-vocabulary-of-all-tokens)\n### Q.6 How does Retrieval Augmented Generation (RAG) enhance generation-based models?Answer:- By making external knowledge available to the model\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q6-how-does-retrieval-augmented-generation-rag-enhance-generation-based-modelsanswer--by-making-external-knowledge-available-to-the-model)\n### Q.7 How can incorporating information retrieval techniques improve your LLM application? Select all that apply.Answer:-1. Overcome Knowledge Cut-offs2. Improve relevance and accuracy of responses\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q7-how-can-incorporating-information-retrieval-techniques-improve-your-llm-application-select-all-that-applyanswer-1-overcome-knowledge-cut-offs2-improve-relevance-and-accuracy-of-responses)\n### Q.8 What are correct definitions of Program-aided Language (PAL) models? Select all that apply.Answer:-1. Models that offload computational tasks to other programs.2. Models that assist programmers in writing code through natural language interfaces.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q8-what-are-correct-definitions-of-program-aided-language-pal-models-select-all-that-applyanswer-1-models-that-offload-computational-tasks-to-other-programs2-models-that-assist-programmers-in-writing-code-through-natural-language-interfaces)\n### Q.9 Which of the following best describes the primary focus of ReAct?Answer:- Enhancing language understanding and decision making in LLMs.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q9-which-of-the-following-best-describes-the-primary-focus-of-reactanswer--enhancing-language-understanding-and-decision-making-in-llms)\n### Q.10 What is the main purpose of the LangChain framework?Answer:- To chain together different components and create advanced use cases around LLMs, such as chatbots, Generative Question-Answering (GQA), and summarization.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q10-what-is-the-main-purpose-of-the-langchain-frameworkanswer--to-chain-together-different-components-and-create-advanced-use-cases-around-llms-such-as-chatbots-generative-question-answering-gqa-and-summarization)\n## Lab 3 - Fine-tune FLAN-T5 with reinforcement learning to generate more-positive summaries\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#lab-3---fine-tune-flan-t5-with-reinforcement-learning-to-generate-more-positive-summaries)\n## In order to complete Lab 3 please watch the below given video carefully and do all the step as it is.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#in-order-to-complete-lab-3-please-watch-the-below-given-video-carefully-and-do-all-the-step-as-it-is)\nLab.3.-.Fine-tune.FLAN-T5.with.reinforcement.learning.to.generate.more-positive.summaries.mov\n## Week 10 Solution According to College IP\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-10-solution-according-to-college-ip)\n## Link of Courses for week 10:- <https://www.coursera.org/learn/learn-to-code-with-ai> <https://www.coursera.org/programs/int426-generative-ai-batch-16-tfkqp/projects/chatgpt-for-beginners-save-time-with-microsoft-excel>\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#link-of-courses-for-week-10--httpswwwcourseraorglearnlearn-to-code-with-ai--httpswwwcourseraorgprogramsint426-generative-ai-batch-16-tfkqpprojectschatgpt-for-beginners-save-time-with-microsoft-excel)\n# Learn To Code With AI\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#learn-to-code-with-ai)\n## Week 2:- Check your skills!\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-2--check-your-skills)\n### Q.1 Which language controls the styling of a web page?Answer:- CSS\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-which-language-controls-the-styling-of-a-web-pageanswer--css)\n### Q.2 What is the below code? `<p>Class</p>`Answer:- It's a HTML paragraph element\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-what-is-the-below-code-pclasspanswer--its-a-html-paragraph-element)\n### Q.3 What do we mean by the so-called \"variables\" in JavaScript?Answer:- Variables are like containers that we use to store information\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q3-what-do-we-mean-by-the-so-called-variables-in-javascriptanswer--variables-are-like-containers-that-we-use-to-store-information)\n### Q.4 What do we mean when we say that ChatGPT is \"generative AI\"?Answer:- It means that the AI is able to generate new and original content\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q4-what-do-we-mean-when-we-say-that-chatgpt-is-generative-aianswer---it-means-that-the-ai-is-able-to-generate-new-and-original-content)\n### Q.5 What does it mean to deploy a website?Answer:- It's the act of making it available to users via the world wide web\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q5-what-does-it-mean-to-deploy-a-websiteanswer--its-the-act-of-making-it-available-to-users-via-the-world-wide-web)\n### Q.6 What is GitHub?Answer:- It's a platform for version control and source code management\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q6-what-is-githubanswer--its-a-platform-for-version-control-and-source-code-management)\n# ChatGPT for Beginners: Save time with Microsoft Excel\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#chatgpt-for-beginners-save-time-with-microsoft-excel)\n## Assess Your Knowledge\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#assess-your-knowledge)\n### Q.1 What are the potential benefits and applications of integrating ChatGPT with Excel, and how can it contribute to streamlining data-related tasks, analysis, and decision-making processes in various domains? (Select all that apply)Answer:-1. Help with writing and validating complex formulas2. Assistance with standardizing and cleansing data3. Conducting sentiment analysis in order to classify data\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-what-are-the-potential-benefits-and-applications-of-integrating-chatgpt-with-excel-and-how-can-it-contribute-to-streamlining-data-related-tasks-analysis-and-decision-making-processes-in-various-domains-select-all-that-applyanswer-1-help-with-writing-and-validating-complex-formulas2-assistance-with-standardizing-and-cleansing-data3-conducting-sentiment-analysis-in-order-to-classify-data)\n### Q.2 In what ways can ChatGPT be utilized to address and resolve issues related to inconsistent date formats in Excel, and how does its functionality contribute to enhancing data organization and accuracy within the spreadsheet?Answer:- By fixing inconsistent date formats within the ChatGPT console\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-in-what-ways-can-chatgpt-be-utilized-to-address-and-resolve-issues-related-to-inconsistent-date-formats-in-excel-and-how-does-its-functionality-contribute-to-enhancing-data-organization-and-accuracy-within-the-spreadsheetanswer--by-fixing-inconsistent-date-formats-within-the-chatgpt-console)\n### Q.3 How does the use of formulas in ChatGPT contribute to the data cleansing process, and what specific advantages does it offer in terms of ensuring data accuracy, consistency, and improved data-driven decision-making in Excel?Answer:- By generating formulas that can standardize, validate, and catogorize data\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q3-how-does-the-use-of-formulas-in-chatgpt-contribute-to-the-data-cleansing-process-and-what-specific-advantages-does-it-offer-in-terms-of-ensuring-data-accuracy-consistency-and-improved-data-driven-decision-making-in-excelanswer--by-generating-formulas-that-can-standardize-validate-and-catogorize-data)\n### Q.4 In what ways can ChatGPT be utilized to facilitate the extraction of relevant text data from URLs, and what are the advantages of using its capabilities compared to traditional methods or existing web scraping tools when integrating this information into Excel for analysis and processing?Answer:- By extracting text elements from URLs within the ChatGPT console like the root URL or page titles\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q4-in-what-ways-can-chatgpt-be-utilized-to-facilitate-the-extraction-of-relevant-text-data-from-urls-and-what-are-the-advantages-of-using-its-capabilities-compared-to-traditional-methods-or-existing-web-scraping-tools-when-integrating-this-information-into-excel-for-analysis-and-processinganswer--by-extracting-text-elements-from-urls-within-the-chatgpt-console-like-the-root-url-or-page-titles)\n### Q.5 What are the limitations of ChatGPT when processing URLs, and what specific types of data extraction tasks might present challenges or be beyond the current capabilities of the system when attempting to extract information from webpages associated with the URLs?Answer:- ChatGPT cannot extract images or videos from URLs\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q5-what-are-the-limitations-of-chatgpt-when-processing-urls-and-what-specific-types-of-data-extraction-tasks-might-present-challenges-or-be-beyond-the-current-capabilities-of-the-system-when-attempting-to-extract-information-from-webpages-associated-with-the-urlsanswer--chatgpt-cannot-extract-images-or-videos-from-urls)\n### Q.6 To support decision-making processes and data-driven insights, what types of data can be effectively analyzed and classified based on sentiment analysis using ChatGPT?Answer:- Textual data like customer reviews\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q6-to-support-decision-making-processes-and-data-driven-insights-what-types-of-data-can-be-effectively-analyzed-and-classified-based-on-sentiment-analysis-using-chatgptanswer--textual-data-like-customer-reviews)\n### Q.7 How should data analysts and professionals approach the ethical considerations and transparency when utilizing generated data? (Select all that apply)Answer:-1. By being transparent about the sources of data and methods of data generation2. By ensuring data privacy and complying with relevant data protection regulations3. By respecting the rights of data subjects, especially when dealing with sensitive data\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q7-how-should-data-analysts-and-professionals-approach-the-ethical-considerations-and-transparency-when-utilizing-generated-data-select-all-that-applyanswer-1-by-being-transparent-about-the-sources-of-data-and-methods-of-data-generation2-by-ensuring-data-privacy-and-complying-with-relevant-data-protection-regulations3-by-respecting-the-rights-of-data-subjects-especially-when-dealing-with-sensitive-data)\n### Q.8 How does the strategic classification of data into groupings contribute to the overall data management and analysis process? (Select all that apply)Answer:-1. It improves data visualization2. It enhances the ability to sort and filter data\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q8-how-does-the-strategic-classification-of-data-into-groupings-contribute-to-the-overall-data-management-and-analysis-process-select-all-that-applyanswer-1-it-improves-data-visualization2-it-enhances-the-ability-to-sort-and-filter-data)\n## Week 11 Solution According to College IP\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-11-solution-according-to-college-ip)\n## Link of Courses for week 11:- <https://www.coursera.org/learn/rudi-hinds-chatgpt-playground-for-beginners-intro-to-nlp-ai><https://www.coursera.org/learn/build-ai-apps-with-chatgpt-dalle-gpt4>\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#link-of-courses-for-week-11--httpswwwcourseraorglearnrudi-hinds-chatgpt-playground-for-beginners-intro-to-nlp-aihttpswwwcourseraorglearnbuild-ai-apps-with-chatgpt-dalle-gpt4)\n# ChatGPT Playground for Beginners: Intro to NLP AI\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#chatgpt-playground-for-beginners-intro-to-nlp-ai)\n## Assess Your Knowledge\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#assess-your-knowledge-1)\n### Q.1 What is the goal of Natural Language Processing (NLP) in the field of AI?Answer:- To read, decipher, understand, and make sense of human language in a valuable way\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-what-is-the-goal-of-natural-language-processing-nlp-in-the-field-of-aianswer--to-read-decipher-understand-and-make-sense-of-human-language-in-a-valuable-way)\n### Q.2 You're tracking the operational cost of your Chef ChatGPT program, and realize that the number of tokens used has increased. How will this impact the cost of operating Chef ChatGPT?Answer:- More tokens lead to a higher cost.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-youre-tracking-the-operational-cost-of-your-chef-chatgpt-program-and-realize-that-the-number-of-tokens-used-has-increased-how-will-this-impact-the-cost-of-operating-chef-chatgptanswer--more-tokens-lead-to-a-higher-cost)\n### Q.3 You're tasked with designing a chatbot aimed at providing factual information about scientific topics. How would you adjust the 'temperature' parameter to ensure that the responses are accurate and less likely to be random?Answer:- Set the temperature to a low value\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q3-youre-tasked-with-designing-a-chatbot-aimed-at-providing-factual-information-about-scientific-topics-how-would-you-adjust-the-temperature-parameter-to-ensure-that-the-responses-are-accurate-and-less-likely-to-be-randomanswer--set-the-temperature-to-a-low-value)\n### Q.4 You are designing a chatbot that needs to stick closely to the provided conversation context and should avoid introducing unrelated ideas. Which parameter would be helpful to adjust, and how should it be adjusted?Answer:- Increase the presence penalty.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q4-you-are-designing-a-chatbot-that-needs-to-stick-closely-to-the-provided-conversation-context-and-should-avoid-introducing-unrelated-ideas-which-parameter-would-be-helpful-to-adjust-and-how-should-it-be-adjustedanswer--increase-the-presence-penalty)\n### Q.5 In what way does the 'Chat' feature in GPT Playground differ from the 'Complete' mode when it comes to providing context?Answer:- 'Chat' allows for the injection of context through user and system roles, while 'Complete' uses a singular prompt.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q5-in-what-way-does-the-chat-feature-in-gpt-playground-differ-from-the-complete-mode-when-it-comes-to-providing-contextanswer--chat-allows-for-the-injection-of-context-through-user-and-system-roles-while-complete-uses-a-singular-prompt)\n# Build AI Apps with ChatGPT, Dall-E, and GPT-4 (For Students Who have 3 Weeks in their course)\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#build-ai-apps-with-chatgpt-dall-e-and-gpt-4-for-students-who-have-3-weeks-in-their-course)\n## Week 1: AI Quiz\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-1-ai-quiz)\n### Q.1 When you increase the temperature, what does that do to the completion?Answer:- Makes it less conservative\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-when-you-increase-the-temperature-what-does-that-do-to-the-completionanswer--makes-it-less-conservative)\n### Q.2 Which of the following statements accurately describes the max_tokens property in the OpenAI API?Answer:- It sets the maximum number of tokens that can be generated in the completion.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-which-of-the-following-statements-accurately-describes-the-max_tokens-property-in-the-openai-apianswer--it-sets-the-maximum-number-of-tokens-that-can-be-generated-in-the-completion)\n### Q.3 Which of the following is TRUE about the OpenAI API?Answer:- It allows us to access OpenAI models from within our applications.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q3-which-of-the-following-is-true-about-the-openai-apianswer--it-allows-us-to-access-openai-models-from-within-our-applications)\n### Q.4 Which of the following correctly defines a 'prompt' in the OpenAI API?Answer:- The input text provided to guide the AI's response.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q4-which-of-the-following-correctly-defines-a-prompt-in-the-openai-apianswer--the-input-text-provided-to-guide-the-ais-response)\n### Q.5 What is meant by the term 'Zero-shot' when we are creating prompts?Answer:- A prompt consisting of a request but no examples.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q5-what-is-meant-by-the-term-zero-shot-when-we-are-creating-promptsanswer--a-prompt-consisting-of-a-request-but-no-examples)\n### Q.6 What is meant by the term 'Few-shot' when we are creating prompts?Answer:- A prompt with one or more examples demonstrating what we are looking for in a completion.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q6-what-is-meant-by-the-term-few-shot-when-we-are-creating-promptsanswer--a-prompt-with-one-or-more-examples-demonstrating-what-we-are-looking-for-in-a-completion)\n### Q.7 What information are we REQUIRED to give the OpenAI API to generate an image (do not include parameters which have a default value).Answer:- 1. A description of the image.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q7-what-information-are-we-required-to-give-the-openai-api-to-generate-an-image-do-not-include-parameters-which-have-a-default-valueanswer--1-a-description-of-the-image)\n### Q.8 Which of the following is true about the createCompletions endpoint?Answer:- The model property must be used.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q8-which-of-the-following-is-true-about-the-createcompletions-endpointanswer--the-model-property-must-be-used)\n## Week 2: AI Quiz\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-2-ai-quiz)\n### Q.1 Which of these best describes an OpenAI model's behaviour?Answer:- It has no memory of previous prompts, so all of the context of a conversation must be included in every prompt.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-which-of-these-best-describes-an-openai-models-behaviouranswer--it-has-no-memory-of-previous-prompts-so-all-of-the-context-of-a-conversation-must-be-included-in-every-prompt)\n### Q.2 What should happen when presence_penalty is increased?Answer:- The model should talk about new topics more often.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-what-should-happen-when-presence_penalty-is-increasedanswer--the-model-should-talk-about-new-topics-more-often)\n### Q.3 Which one of the following is true?Answer:- When working with the createChatCompletions endpoint, the messages property must contain and array of objects.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q3-which-one-of-the-following-is-trueanswer--when-working-with-the-createchatcompletions-endpoint-the-messages-property-must-contain-and-array-of-objects)\n### Q.4 The frequency_penalty setting gives us some control over...Answer:- how likely the model is to use the same words and phrases in a completion.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q4-the-frequency_penalty-setting-gives-us-some-control-overanswer--how-likely-the-model-is-to-use-the-same-words-and-phrases-in-a-completion)\n### Q.5 Which of the following is true about the array we send to the API in the messages property.Answer:- The first object in the array should contain instructions telling the model how we want it to behave.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q5-which-of-the-following-is-true-about-the-array-we-send-to-the-api-in-the-messages-propertyanswer--the-first-object-in-the-array-should-contain-instructions-telling-the-model-how-we-want-it-to-behave)\n### Q.6 Which of these best describes a firebase 'snapshot'.Answer:- A copy of all of the database data as it exists at that moment.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q6-which-of-these-best-describes-a-firebase-snapshotanswer--a-copy-of-all-of-the-database-data-as-it-exists-at-that-moment)\n## Week 3: AI Quiz\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-3-ai-quiz)\n### Q.1 Fine-tuning allows us to do which of the following?Answer:- Train an OpenAI model on our own data.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-fine-tuning-allows-us-to-do-which-of-the-followinganswer--train-an-openai-model-on-our-own-data)\n### Q.2 Which of the following is FALSE about the OpenAI CLI?Answer:- It only fine-tunes the GPT-4 model.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-which-of-the-following-is-false-about-the-openai-clianswer--it-only-fine-tunes-the-gpt-4-model)\n### Q,3 Which of the following is TRUE about the characters we include in a 'stop sequence'Answer:- They will never be included in a completion.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q3-which-of-the-following-is-true-about-the-characters-we-include-in-a-stop-sequenceanswer--they-will-never-be-included-in-a-completion)\n### Q.4 What does the n_epoch parameter do in OpenAI?Answer:- It sets the number of times the training data will be cycled through when fine-tuning a model. More cycles tends to improve performance.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q4-what-does-the-n_epoch-parameter-do-in-openaianswer--it-sets-the-number-of-times-the-training-data-will-be-cycled-through-when-fine-tuning-a-model-more-cycles-tends-to-improve-performance)\n### Q.5 We can help a model better understand our prompts by doing which one of the following.Answer:- Using separators in our prompts such as '->' or '###'.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q5-we-can-help-a-model-better-understand-our-prompts-by-doing-which-one-of-the-followinganswer--using-separators-in-our-prompts-such-as---or-)\n### Q.6 Which of the following is TRUE.Answer:- An API key stored in an env variable is visible on the front end.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q6-which-of-the-following-is-trueanswer--an-api-key-stored-in-an-env-variable-is-visible-on-the-front-end)\n### Q.7 Which of the following is FALSE about data when fine-tuning.Answer:- In terms of accuracy, there is no performance advantage in using a larger data set.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q7-which-of-the-following-is-false-about-data-when-fine-tuninganswer--in-terms-of-accuracy-there-is-no-performance-advantage-in-using-a-larger-data-set)\n# Build AI Apps with ChatGPT, Dall-E, and GPT-4 (For Students Who have 2 Weeks in their course)\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#build-ai-apps-with-chatgpt-dall-e-and-gpt-4-for-students-who-have-2-weeks-in-their-course)\n## Week 1: Test your AI Engineering knowledge\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-1-test-your-ai-engineering-knowledge)\n### Q.1 Setting the temperature property to a higher number makes the modelâ¦Answer:- provide answers which are more creative and daring.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-setting-the-temperature-property-to-a-higher-number-makes-the-modelanswer--provide-answers-which-are-more-creative-and-daring)\n### Q.2 When working with the OpenAI API, the objects that are held in the messages array each have a role property, but what values can the role property hold?Answer:-system, user, assistant\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-when-working-with-the-openai-api-the-objects-that-are-held-in-the-messages-array-each-have-a-role-property-but-what-values-can-the-role-property-holdanswer-system-user-assistant)\n### Q.3 Which of the following is true about tokens and credit when using the OpenAI API?Answer:- Both the words in the prompt you send to the API and the data you get back count towards the total number of tokens used.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q3-which-of-the-following-is-true-about-tokens-and-credit-when-using-the-openai-apianswer--both-the-words-in-the-prompt-you-send-to-the-api-and-the-data-you-get-back-count-towards-the-total-number-of-tokens-used)\n### Q.4 What does the frequency_penalty setting do?Answer:- It gives the developer some control over the likelihood of words and phrases being repeated.\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q4-what-does-the-frequency_penalty-setting-doanswer--it-gives-the-developer-some-control-over-the-likelihood-of-words-and-phrases-being-repeated)\n### Q.5 When asking the OpenAI API to create images, which property or properties are required.Answer:- prompt\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q5-when-asking-the-openai-api-to-create-images-which-property-or-properties-are-requiredanswer--prompt)\n## Week 12 & 13 Solution According to College IP\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-12--13-solution-according-to-college-ip)\n## Link of Courses for week 12 & 13:- <https://www.coursera.org/learn/chatgpt-advanced-data-analysis>\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#link-of-courses-for-week-12--13--httpswwwcourseraorglearnchatgpt-advanced-data-analysis)\n# ChatGPT Advanced Data Analysis\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#chatgpt-advanced-data-analysis)\n## Week 1:- Ice Breaker Exercises with ChatGPT Advanced Data Analysis\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-1--ice-breaker-exercises-with-chatgpt-advanced-data-analysis)\n### Q.1 You will need to download this data, represented as comma separated values, that was extracted from Vanderbilt's financial reports:Use the \"+\" button to attach the CSV file that you downloaded to the prompt and enter this text into the prompt:---------Draw four visualizations for me that show me interesting things in this dataset. The visualization should show unexpected things based on higher education trends.Write 2-3 paragraphs describing the visualizations and what they show.---------Cut/paste the 2-3 paragraphs that Code Interpreter produces describing the data in as the answer. Do not include the images.Answer:-\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-you-will-need-to-download-this-data-represented-as-comma-separated-values-that-was-extracted-from-vanderbilts-financial-reportsuse-the--button-to-attach-the-csv-file-that-you-downloaded-to-the-prompt-and-enter-this-text-into-the-prompt---------draw-four-visualizations-for-me-that-show-me-interesting-things-in-this-dataset-the-visualization-should-show-unexpected-things-based-on-higher-education-trendswrite-2-3-paragraphs-describing-the-visualizations-and-what-they-show---------cutpaste-the-2-3-paragraphs-that-code-interpreter-produces-describing-the-data-in-as-the-answer-do-not-include-the-imagesanswer-)\n```\nThe first visualization is a stacked bar chart showing the total fall enrollment for undergraduate and graduate students from 2017/2018 to 2021/2022. The chart reveals that total enrollment has been increasing steadily, with a more significant jump between 2019/2020 and 2020/2021. The second visualization is a line chart displaying the number of degrees conferred in the same period. The chart shows a fluctuation in the number of conferred degrees, with a slight decrease in 2019/2020 and a significant increase in 2020/2021, which is unexpected as the total enrollment increased during this period.\nThe third visualization is a scatter plot comparing the percentage increase in undergraduate tuition over the prior year and the yield rate for undergraduate admissions. The plot shows a positive correlation between the two variables, indicating that higher tuition increases are associated with higher yield rates. The fourth visualization is a line chart displaying the endowment per student from 2017 to 2021. The chart reveals a significant increase in endowment per student between 2019 and 2021, which is unexpected as the total enrollment also increased during this period. This suggests that Vanderbilt University's endowment has grown faster than its student population.\n\n```\n\n### Q.2 Please download a PDF of the paper \"A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT\" from here: <https://arxiv.org/abs/2302.11382> Use the \"+\" button to attach the PDF of the paper that you downloaded to the prompt and enter this text into the prompt:---------Please extract each page of this PDF to a plain text file. Then, manually read the first three pages and learn what a prompt pattern is. Don't worry if there are formatting issues, just do your best and proceed. Then, ask me to describe my job or interests. Use what I tell you to describe to me what a prompt pattern is assuming I have no background in computer science. Make sure and use concrete examples based on my job or interests to show how I could use these patterns. Make sure and write some sample prompt patterns that could be cut/pasted into Code Interpreter for me to try out. Each pattern should rely on a document or dataset relevant to me. Describe the purpose of the pattern, the problem it is trying to solve, what data the pattern needs and why, and then the prompt that will be used on the document.---------Cut/paste the paragraphs that ChatGPT Advanced Data Analysis produces describing prompt patterns for you as the answer. Answer:-\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-please-download-a-pdf-of-the-paper-a-prompt-pattern-catalog-to-enhance-prompt-engineering-with-chatgpt-from-here-httpsarxivorgabs230211382-use-the--button-to-attach-the-pdf-of-the-paper-that-you-downloaded-to-the-prompt-and-enter-this-text-into-the-prompt---------please-extract-each-page-of-this-pdf-to-a-plain-text-file-then-manually-read-the-first-three-pages-and-learn-what-a-prompt-pattern-is-dont-worry-if-there-are-formatting-issues-just-do-your-best-and-proceed-then-ask-me-to-describe-my-job-or-interests-use-what-i-tell-you-to-describe-to-me-what-a-prompt-pattern-is-assuming-i-have-no-background-in-computer-science-make-sure-and-use-concrete-examples-based-on-my-job-or-interests-to-show-how-i-could-use-these-patterns---make-sure-and-write-some-sample-prompt-patterns-that-could-be-cutpasted-into-code-interpreter-for-me-to-try-out-each-pattern-should-rely-on-a-document-or-dataset-relevant-to-me-describe-the-purpose-of-the-pattern-the-problem-it-is-trying-to-solve-what-data-the-pattern-needs-and-why-and-then-the-prompt-that-will-be-used-on-the-document---------cutpaste-the-paragraphs-that-chatgpt-advanced-data-analysis-produces-describing-prompt-patterns-for-you-as-the-answer-answer-)\n```\nA prompt pattern is a structured approach used in programming conversational large language models (LLMs) like ChatGPT to customize their outputs and interactions. In simpler terms, a prompt pattern is a set of instructions that you provide to an LLM to guide it in generating specific types of content or responses. For example, if you work in marketing, a prompt pattern could be designed to extract key insights from customer feedback data. The purpose of this pattern would be to help the LLM analyze customer sentiments and preferences from the dataset, requiring the data to include customer feedback and reviews. The prompt for this pattern could be: \"Analyze the customer feedback data to identify common themes and sentiments. Provide a summary of the main issues raised by customers and any positive feedback trends.\"\nAnother example could be a prompt pattern for someone interested in sports analytics. This pattern could aim to extract statistics and trends from a sports performance dataset. The problem it solves is to help analyze player performance and team strategies based on historical data. The data needed would be the sports performance dataset containing player statistics, match outcomes, and team strategies. The prompt for this pattern could be: \"Analyze the sports performance dataset to identify key player performance metrics and trends. Provide insights into player strengths, weaknesses, and correlations between performance metrics and match outcomes.\"\nThese sample prompt patterns demonstrate how you can use structured instructions to guide an LLM in analyzing specific datasets related to your job or interests. By providing clear prompts tailored to your domain, you can leverage the power of LLMs like ChatGPT to extract valuable insights and information from complex datasets.\n\n```\n\n### Q.3 At the end of the conversation that you just did working with the paper \"A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT\", enter this prompt:---------Pick the ChatGPT Code Interpreter prompt pattern that you think would be most helpful to someone like me. Then, write a social media post about how you are taking the Coursera course \"ChatGPT Code Interpreter by Jules White\" and explain what Code Interpreter is, explain the problem the prompt pattern solves, what data you could upload with the prompt pattern, and what it would do for other people like me that would make their lives so much easier. Make the post exciting and have viral potential. Make sure readers have enough information to quickly cut/paste the pattern into Code Interpreter and know what to include with it in order to immediately take advantage of the prompt pattern.----------Cut/paste the social media post that it creates for you as the answer.Answer:-\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q3-at-the-end-of-the-conversation-that-you-just-did-working-with-the-paper-a-prompt-pattern-catalog-to-enhance-prompt-engineering-with-chatgpt-enter-this-prompt---------pick-the-chatgpt-code-interpreter-prompt-pattern-that-you-think-would-be-most-helpful-to-someone-like-me-then-write-a-social-media-post-about-how-you-are-taking-the-coursera-course-chatgpt-code-interpreter-by-jules-white-and-explain-what-code-interpreter-is-explain-the-problem-the-prompt-pattern-solves-what-data-you-could-upload-with-the-prompt-pattern-and-what-it-would-do-for-other-people-like-me-that-would-make-their-lives-so-much-easier-make-the-post-exciting-and-have-viral-potential-make-sure-readers-have-enough-information-to-quickly-cutpaste-the-pattern-into-code-interpreter-and-know-what-to-include-with-it-in-order-to-immediately-take-advantage-of-the-prompt-pattern----------cutpaste-the-social-media-post-that-it-creates-for-you-as-the-answeranswer-)\n```\nðâ¨Excited to share my latest learning experience with the Coursera course \"ChatGPT Code Interpreter\" by Jules White! This powerful tool allows you to use prompts to extract insights from documents and datasets, making it a game-changer for data analysis and problem-solving.\nð¡One prompt pattern that stood out to me is the \"Visualization Generator\" pattern. This pattern helps you create visualizations from data, making it easier to understand trends and patterns. To use it, simply upload your dataset and ask Code Interpreter to generate visualizations based on specific criteria.\nðFor example, if you're interested in environmental trends, you could upload a dataset on air quality and ask Code Interpreter to create visualizations showing changes over time. This would make it easy to identify areas with the biggest improvements or declines in air quality, helping you make informed decisions.\nð¤¯The potential applications of this pattern are endless, from business to education to research. By making data more accessible and understandable, Code Interpreter can help us all make better decisions and solve complex problems.\nðTo get started, simply cut and paste the following prompt into Code Interpreter: \"Generate visualizations from this dataset based on the following criteria: [insert criteria here]\". Then upload your dataset and watch the magic happen! #ChatGPTCodeInterpreter #DataAnalysis #Visualization #DataInsights #ProblemSolving #Coursera #JulesWhite\n\n```\n\n## Week 1:- Use ChatGPT Advanced Data Analysis to Help You Find Inspiration for Using It\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-1--use-chatgpt-advanced-data-analysis-to-help-you-find-inspiration-for-using-it)\n### Q.1 Combine the file and prompt from the \"Use ChatGPT Advanced Data Analysis to Help You Find Inspiration for Using It\" exercise to find use cases for Excel files based on your personal life. Cut/paste the output as the solution.Answer:-\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-combine-the-file-and-prompt-from-the-use-chatgpt-advanced-data-analysis-to-help-you-find-inspiration-for-using-it-exercise-to-find-use-cases-for-excel-files-based-on-your-personal-life-cutpaste-the-output-as-the-solutionanswer-)\n```\nTitle: Enhance Your Personal Life with Excel and ChatGPT\nDescription: ChatGPT, a powerful language model, can help you make the most of your Excel files in your personal life. Here are some use cases to inspire you:\nBudget Tracker: Create a budget tracker in Excel and use ChatGPT to analyze your spending habits, identify trends, and suggest ways to save money.\nPrompt: \"Analyze my monthly spending data in this Excel file and provide insights on how to reduce expenses.\"\nFitness Tracker: Keep track of your workouts and progress in Excel, and use ChatGPT to interpret the data, calculate statistics, and provide personalized recommendations.\nPrompt: \"Evaluate my fitness data in this Excel file and suggest ways to improve my workout routine.\"\nHealth Diary: Monitor your health and well-being in Excel, and let ChatGPT help you identify patterns, correlations, and potential health issues.\nPrompt: \"Examine my health data in this Excel file and determine if there are any health concerns I should be aware of.\"\nTravel Planner: Organize your travel plans in Excel and have ChatGPT generate an itinerary, suggest activities, and provide local information.\nPrompt: \"Create a travel itinerary based on my preferences and this Excel file containing my travel plans.\"\nInvestment Portfolio: Manage your investments in Excel and use ChatGPT to assess your portfolio, calculate returns, and offer advice on diversification.\nPrompt: \"Evaluate my investment portfolio in this Excel file and recommend ways to optimize it.\"\nBy combining Excel and ChatGPT, you can unlock the full potential of your data and make informed decisions in various aspects of your personal life.\nWhat do you think? These use cases demonstrate how ChatGPT can help you make the most of your Excel files in your personal life. By providing clear prompts, you can harness the power of ChatGPT to analyze, interpret, and generate valuable insights from your data.\n\n```\n\n### Q.2 Combine the file and prompt from the \"Use ChatGPT Advanced Data Analysis to Help You Find Inspiration for Using It\" exercise to find use cases for PowerPoint files based on your work duties.Cut/paste the output as the solution.Answer:-\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-combine-the-file-and-prompt-from-the-use-chatgpt-advanced-data-analysis-to-help-you-find-inspiration-for-using-it-exercise-to-find-use-cases-for-powerpoint-files-based-on-your-work-dutiescutpaste-the-output-as-the-solutionanswer-)\n```\nUse Case: PowerPoint Presentations for Work Duties\nProblem: Creating engaging and effective PowerPoint presentations for work-related tasks can be time-consuming and challenging.\nData: Upload a set of PowerPoint slides relevant to your work duties.\nPrompt Pattern: \"Enhance these PowerPoint slides for a more engaging and informative presentation, focusing on [specific area of improvement, e.g., visual design, content organization, storytelling].\"\nExample:\nVisual Design: \"Improve the visual design of this PowerPoint presentation by incorporating relevant images, icons, and charts to enhance the overall look and feel.\"\nContent Organization: \"Reorganize the content of this PowerPoint presentation to create a more logical flow and clearer hierarchy of information.\"\nStorytelling: \"Transform this PowerPoint presentation into a compelling story that engages the audience and effectively communicates the key messages.\"\n\n```\n\n### Q.3 Combine the file and prompt from the \"Use Code Interpreter to Help You Find Inspiration for Using It\" exercise to find use cases for a Zip of image files to enhance your social media profile. Answer:-\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q3-combine-the-file-and-prompt-from-the-use-code-interpreter-to-help-you-find-inspiration-for-using-it-exercise-to-find-use-cases-for-a-zip-of-image-files-to-enhance-your-social-media-profile-answer-)\n```\nTo enhance your social media profile, you can use a zip of image files and the power of ChatGPT Code Interpreter to generate captions, descriptions, or even analyze the content of the images to create a thematic series of posts. Here's a sample prompt pattern that you can use:\nPrompt Pattern: Image Analysis and Captioning\nProblem: You have a collection of images, and you want to create engaging social media posts with captions or descriptions that accurately represent the content of each image.\nData: A zip file containing images (JPEG, PNG, or other supported formats) that you want to analyze or caption.\nPrompt: \"Analyze the images in this zip file and generate captions or descriptions that accurately represent the content of each image. Ensure that the captions are engaging and suitable for social media platforms.\"\n\n```\n\n### Q.4 In one of the prior Code Interpreter conversations around finding inspiration, please use the following prompt to generate a social media post describing the example use case:---------Pick the ChatGPT Code Interpreter use case that you think would be most helpful to someone like me. Then, write a social media post about how you are taking the Coursera course \"ChatGPT Code Interpreter by Jules White\" and explain what Code Interpreter is, explain the problem the use case solves, what data you could upload to support the use case, and what it would do for other people like me that would make their lives so much easier. Make the post exciting and have viral potential. Make sure readers have enough information to quickly implement the idea by cutting / pasting some things into Code Interpreter and know what to include with it in order to immediately take advantage of the idea.----------Cut/paste the social media post in as your answer.Answer:-\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q4-in-one-of-the-prior-code-interpreter-conversations-around-finding-inspiration-please-use-the-following-prompt-to-generate-a-social-media-post-describing-the-example-use-case---------pick-the-chatgpt-code-interpreter-use-case-that-you-think-would-be-most-helpful-to-someone-like-me-then-write-a-social-media-post-about-how-you-are-taking-the-coursera-course-chatgpt-code-interpreter-by-jules-white-and-explain-what-code-interpreter-is-explain-the-problem-the-use-case-solves-what-data-you-could-upload-to-support-the-use-case-and-what-it-would-do-for-other-people-like-me-that-would-make-their-lives-so-much-easier-make-the-post-exciting-and-have-viral-potential-make-sure-readers-have-enough-information-to-quickly-implement-the-idea-by-cutting--pasting-some-things-into-code-interpreter-and-know-what-to-include-with-it-in-order-to-immediately-take-advantage-of-the-idea----------cutpaste-the-social-media-post-in-as-your-answeranswer-)\n```\nðTransform your software development tasks with ChatGPT Code Interpreter! ð»\nI'm taking the \"ChatGPT Code Interpreter\" course by Jules White on Coursera and I'm thrilled to share my experience with you! ð\nCode Interpreter is a powerful tool that uses conversational large language models (LLMs) like ChatGPT to automate software development tasks. It does this by using prompts, which are instructions given to the LLM to customize its outputs and interactions. ð¤\nFor example, you can use Code Interpreter to generate a Python script that automates the deployment of a Python application to AWS. Simply provide the necessary information about your application, and Code Interpreter will ask you questions to gather the required information. Once it has enough information, it will generate the script for you! ð¡\nTo use Code Interpreter, simply upload your data (such as an Excel file containing information about your application) and provide a prompt that tells the LLM what you want it to do. Code Interpreter will then generate the desired output for you. ð\nBy using Code Interpreter, you can save time and effort in your software development tasks, allowing you to focus on other important aspects of your work. Plus, it's easy to use and can be integrated directly into your preferred IDE! ð¼\nIf you're interested in learning more about Code Interpreter and how it can benefit you, be sure to check out the \"ChatGPT Code Interpreter\" course on Coursera! ð\n#ChatGPTCodeInterpreter #SoftwareDevelopment #Automation #AI #Coursera #JulesWhite\n\n```\n\n## Week 1:- Data to Content\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-1--data-to-content)\n### Q.1 Download this CSV file containing data extracted from Vanderbilt's 2022 Financial Report:Generate four different interesting visualizations of the data.You can use a series of prompts as shown below to incrementally read the data, generate the visualizations, save them to files, and then create the PowerPoint:\"Read and explain all of the columns in the attached CSV file.\"\"Create four interesting visualizations of this data that show the school's admissions rate and other indicators of success over time and try to use the Vanderbilt school colors. Draw trend lines on all charts.\"\"Save each of these visualizations as a separate image file for me to download.\"\"Create a PowerPoint presentation for me that has each of these images as separate slides.\"When you are done, ask Code Interpreter to summarize the work it did for you with a prompt like this:\"Output CSV describing the process that you just performed starting from the data and going all the way to the production of the slides.\"Now, copy/paste this CSV output as the answer to this question.Answer:-\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-download-this-csv-file-containing-data-extracted-from-vanderbilts-2022-financial-reportgenerate-four-different-interesting-visualizations-of-the-datayou-can-use-a-series-of-prompts-as-shown-below-to-incrementally-read-the-data-generate-the-visualizations-save-them-to-files-and-then-create-the-powerpointread-and-explain-all-of-the-columns-in-the-attached-csv-filecreate-four-interesting-visualizations-of-this-data-that-show-the-schools-admissions-rate-and-other-indicators-of-success-over-time-and-try-to-use-the-vanderbilt-school-colors-draw-trend-lines-on-all-chartssave-each-of-these-visualizations-as-a-separate-image-file-for-me-to-downloadcreate-a-powerpoint-presentation-for-me-that-has-each-of-these-images-as-separate-slideswhen-you-are-done-ask-code-interpreter-to-summarize-the-work-it-did-for-you-with-a-prompt-like-thisoutput-csv-describing-the-process-that-you-just-performed-starting-from-the-data-and-going-all-the-way-to-the-production-of-the-slidesnow-copypaste-this-csv-output-as-the-answer-to-this-questionanswer-)\n```\nTo incrementally read the data, generate visualizations, save them to files, and create a PowerPoint presentation, you can use a series of prompts. First, you would ask the AI to read and explain all the columns in the attached CSV file. Then, you would prompt it to create four interesting visualizations of the data that display the school's admissions rate. This approach leverages prompt engineering techniques to guide the AI in processing the data and producing the desired visual outputs efficiently\n\n```\n\n### Q.2 Download this CSV file containing data extracted from Vanderbilt's 2022 Financial Report:Generate an interesting social media post based on this data that is also related to what you do.You can use a series of prompts like this:\"Read and explain the data in the attached CSV file related to Vanderbilt University's 2022 finances.\"\"Ask me questions about what I do and then use my answers to create an interesting visualization of the data that I might be interested in.\"\"Find a really interesting insight in this data. Visualize the insight for me and save it as an image. Write a social media post explaining that you used prompts from the Coursera course 'ChatGPT Code Interpreter by Jules White' to create an interesting analysis of Vanderbilt's 2022 finances and include in the post the interesting thing seen in the visualization.\" Submit the social media post as the answer to this question.Answer:-\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-download-this-csv-file-containing-data-extracted-from-vanderbilts-2022-financial-reportgenerate-an-interesting-social-media-post-based-on-this-data-that-is-also-related-to-what-you-doyou-can-use-a-series-of-prompts-like-thisread-and-explain-the-data-in-the-attached-csv-file-related-to-vanderbilt-universitys-2022-financesask-me-questions-about-what-i-do-and-then-use-my-answers-to-create-an-interesting-visualization-of-the-data-that-i-might-be-interested-infind-a-really-interesting-insight-in-this-data-visualize-the-insight-for-me-and-save-it-as-an-image-write-a-social-media-post-explaining-that-you-used-prompts-from-the-coursera-course-chatgpt-code-interpreter-by-jules-white-to-create-an-interesting-analysis-of-vanderbilts-2022-finances-and-include-in-the-post-the-interesting-thing-seen-in-the-visualization-submit-the-social-media-post-as-the-answer-to-this-questionanswer-)\n```\nðð¡Excited to share a fascinating insight about Vanderbilt University's 2022 finances! Using prompts from the Coursera course 'ChatGPT Code Interpreter by Jules White', I discovered that the university's endowment per student has significantly increased between 2019 and 2021. This suggests that Vanderbilt's financial health is strong and growing. Check out the visualization below to see the trend for yourself! #VanderbiltFinances #ChatGPTCodeInterpreter #DataInsights\nBy using prompts to analyze the data, I was able to uncover this insight quickly and easily. The ChatGPT Code Interpreter is a powerful tool for data analysis, and I'm excited to continue exploring its capabilities! #DataAnalysis #AI #MachineLearning\n\n```\n\n## Week 2:- Exploring Code Interpreter Use Cases\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-2--exploring-code-interpreter-use-cases)\n### Q.1 Upload a document, such as something you have written, a PowerPoint presentation, a transcript from a recording of yourself talking on a subject, or something else that it can read for content ideas. Have Code Interpreter generate a set of four social media posts for you from the content. Make sure that Code Interpreter saves each post as a separate text file. When it is done, have it zip up all of the files for you to download.Cut/paste two of the social media posts into the answer.Answer:-\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-upload-a-document-such-as-something-you-have-written-a-powerpoint-presentation-a-transcript-from-a-recording-of-yourself-talking-on-a-subject-or-something-else-that-it-can-read-for-content-ideas-have-code-interpreter-generate-a-set-of-four-social-media-posts-for-you-from-the-content-make-sure-that-code-interpreter-saves-each-post-as-a-separate-text-file-when-it-is-done-have-it-zip-up-all-of-the-files-for-you-to-downloadcutpaste-two-of-the-social-media-posts-into-the-answeranswer-)\n```\nThe document discusses the importance of prompt engineering in conversing effectively with large language models (LLMs) like ChatGPT. Prompts are instructions given to LLMs to customize their outputs and interactions, acting as a form of programming to enhance the quality of generated content. The paper introduces a catalog of prompt patterns that provide reusable solutions to common problems faced when working with LLMs. These prompt patterns are analogous to software patterns, offering structured approaches to tailor LLM outputs and interactions effectively\n1\n.\nPrompt patterns are crucial in prompt engineering, offering a systematic way to program LLMs for various tasks. They provide a codified approach to customizing LLM outputs and interactions, enhancing the ability to enforce constraints, include relevant information, and change interaction formats to solve specific problems effectively. The document outlines the structure and key ideas of prompt patterns, emphasizing the importance of fundamental contextual statements to communicate key ideas clearly and intuitively to users\n1\n.\nThe catalog of prompt patterns includes categories like Input Semantics, Output Customization, Error Identification, Prompt Improvement, and Interaction. Each category contains specific prompt patterns aimed at addressing different aspects of working with LLMs, such as creating custom languages for LLM understanding, automating output generation, fact-checking, refining prompts, and managing context during interactions. These patterns provide concrete guidance on how to structure prompts to achieve desired outcomes when working with conversational LLMs\n\n```\n\n### Q.2 Question 2\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-question-2)\nUpload one or more images and have Code Interpreter create copies of each image in multiple different sizes. Have Code Interpreter create a CSV file with a catalog of the images and the transformations applied to the images.Copy and paste just the prompts, not the images or outputs, that you used to complete the process as the answer.Answer:-\n```\nPrompt 1:\n\"Read and explain the data in the attached CSV file related to Vanderbilt University's 2022 finances.\"\nPrompt 2:\n\"Ask me questions about what I do and then use my answers to create an interesting visualization of the data that I might be interested in.\"\nPrompt 3:\n\"Find a really interesting insight in this data. Visualize the insight for me and save it as an image. Write a social media post explaining that you used prompts from the Coursera course 'ChatGPT Code Interpreter by Jules White' to create an interesting analysis of Vanderbilt's 2022 finances and include in the post the interesting thing seen in the visualization.\"\nPrompt 4:\n\"Create a PowerPoint presentation for me that has each of these images as separate slides.\"\nPrompt 5:\n\"Output CSV describing the process that you just performed starting from the data and going all the way to the production of the slides.\"\n\n```\n\n## Week 3:- Problem Solving & Question Generation\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-3--problem-solving--question-generation)\n### Q.1 Ask Code Interpreter to give you 5 different ways to solve a problem that it is important to you. Ask it for concrete ideas on how to solve the problem.Cut/paste the answer from Code Interpreter as the solution.Answer:-\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-ask-code-interpreter-to-give-you-5-different-ways-to-solve-a-problem-that-it-is-important-to-you-ask-it-for-concrete-ideas-on-how-to-solve-the-problemcutpaste-the-answer-from-code-interpreter-as-the-solutionanswer-)\n```\nPrompt 1:\n\"Read and explain the data in the attached CSV file related to Vanderbilt University's 2022 finances.\"\nPrompt 2:\n\"Ask me questions about what I do and then use my answers to create an interesting visualization of the data that I might be interested in.\"\nPrompt 3:\n\"Find a really interesting insight in this data. Visualize the insight for me and save it as an image. Write a social media post explaining that you used prompts from the Coursera course 'ChatGPT Code Interpreter by Jules White' to create an interesting analysis of Vanderbilt's 2022 finances and include in the post the interesting thing seen in the visualization.\"\nPrompt 4:\n\"Create a PowerPoint presentation for me that has each of these images as separate slides.\"\nPrompt 5:\n\"Output CSV describing the process that you just performed starting from the data and going all the way to the production of the slides.\"\n\n```\n\n### Q.2 You are going to better prepare for your next meeting or class. Upload a document or presentation and have Code Interpreter read and give you 10 great questions related to the content.Cut/paste Code Interpreter's response as the answer.Answer:-\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-you-are-going-to-better-prepare-for-your-next-meeting-or-class-upload-a-document-or-presentation-and-have-code-interpreter-read-and-give-you-10-great-questions-related-to-the-contentcutpaste-code-interpreters-response-as-the-answeranswer-)\n```\nThe document titled \"A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT\" discusses the importance of prompt engineering in effectively interacting with large language models (LLMs) like ChatGPT. It introduces prompt patterns as reusable solutions to common problems faced when conversing with LLMs, providing a framework for structuring prompts to solve various issues across different domains. The paper emphasizes the significance of prompts in customizing LLM outputs and interactions, showcasing the power of prompts beyond conventional programming tasks. It also highlights the potential for prompts to create new interaction paradigms and facilitate self-adaptation, underscoring the value of prompt engineering in enhancing the capabilities of LLMs\n\n```\n\n## Week 4:- AI Planning\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-4--ai-planning)\n### Q.1 Ask Code Interpreter to generate a step-by-step plan to solve a problem and save it as a file.Cut/paste the plan in as the answer.Answer:-\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-ask-code-interpreter-to-generate-a-step-by-step-plan-to-solve-a-problem-and-save-it-as-a-filecutpaste-the-plan-in-as-the-answeranswer-)\n```\nPrompt Pattern: Visualization Generator\nPurpose: To create visualizations from data in a dataset.\nProblem: Analyzing data in a dataset can be challenging, especially when trying to identify trends or patterns. Visualizations can help make the data more accessible and easier to understand.\nData needed: A dataset containing the data to be visualized.\nPrompt: \"Create a visualization of the data in this dataset that highlights any trends or patterns. Use the school colors, Vanderbilt blue and gold, in the visualization.\"\nThis prompt pattern can be used to generate visualizations of data in a dataset, making it easier to identify trends and patterns. The prompt includes instructions to use the school colors, Vanderbilt blue and gold, to make the visualization more visually appealing and consistent with the school's branding.\nPrompt Pattern: Data Insight Finder\nPurpose: To identify interesting insights in a dataset.\nProblem: Analyzing data in a dataset can be time-consuming, and it can be challenging to identify interesting insights without guidance.\nData needed: A dataset containing the data to be analyzed.\nPrompt: \"Find an interesting insight in this dataset and visualize it for me. Use the school colors, Vanderbilt blue and gold, in the visualization.\"\nThis prompt pattern can be used to identify interesting insights in a dataset and visualize them for easier understanding. The prompt includes instructions to use the school colors, Vanderbilt blue and gold, to make the visualization more visually appealing and consistent with the school's branding.\nPrompt Pattern: Social Media Post Writer\nPurpose: To generate social media posts based on data in a dataset.\nProblem: Writing social media posts can be time-consuming, and it can be challenging to come up with interesting content without guidance.\nData needed: A dataset containing the data to be used in the social media posts.\nPrompt: \"Generate four social media posts for me based on the data in this dataset. Make sure each post is engaging and includes a visualization of the data.\"\nThis prompt pattern can be used to generate social media posts based on data in a dataset, making it easier to create engaging content. The prompt includes instructions to include a visualization of the data in each post to make it more visually appealing and easier to understand.\nPrompt Pattern: PowerPoint Presenter\nPurpose: To create a PowerPoint presentation based on data in a dataset.\nProblem: Creating a PowerPoint presentation can be time-consuming, and it can be challenging to create a visually appealing and informative presentation without guidance.\nData needed: A dataset containing the data to be used in the PowerPoint presentation.\nPrompt: \"Create a PowerPoint presentation for me that includes visualizations of the data in this dataset. Make sure the presentation is visually appealing and easy to understand.\"\nThis prompt pattern can be used to create a PowerPoint presentation based on data in a dataset, making it easier to create a visually appealing and informative presentation. The prompt includes instructions to include visualizations of the data in the presentation to make it more visually appealing and easier to understand.\n\n```\n\n### Q.2 Now, have Code Interpreter execute your plan.Cut/paste the prompt you used to get Code Interpreter to execute your plan in as the answer.Answer:-\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-now-have-code-interpreter-execute-your-plancutpaste-the-prompt-you-used-to-get-code-interpreter-to-execute-your-plan-in-as-the-answeranswer-)\n```\nThe document provided discusses the concept of prompt engineering in the context of conversing with large language models (LLMs) like ChatGPT. Prompts are instructions given to LLMs to customize their outputs and interactions, essentially programming them to generate specific content. Prompt patterns are introduced as reusable solutions to common problems faced when working with LLMs, similar to software patterns. These patterns aim to structure prompts effectively to achieve various output and interaction goals. The document compares software patterns with prompt patterns, highlighting the importance of documenting prompt patterns to enhance the interaction with LLMs in different contexts. It also discusses the structure and components of prompt patterns, emphasizing the need for clear and concise communication to users who may not be programmers. Additionally, it provides examples of prompt patterns, such as the Output Automater pattern, which instructs LLMs to generate automation artifacts like scripts to automate tasks. The document underscores the significance of engineering prompts to go beyond simple text or code generation, enabling LLMs to accomplish diverse tasks and interactions through well-crafted prompts\n\n```\n\n## Week 5:- Outlining for Content\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#week-5--outlining-for-content)\n### Q.1 Have Code Interpreter write an outline for a presentation that you are going to give. The initial outline should have one bullet item per slide. Incrementally build out the outline so that it specifies what should go on each slide and stores the outline for each slide in a separate file.Cut/paste the contents of one of these outlines in as the answer.Answer:-\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q1-have-code-interpreter-write-an-outline-for-a-presentation-that-you-are-going-to-give-the-initial-outline-should-have-one-bullet-item-per-slide-incrementally-build-out-the-outline-so-that-it-specifies-what-should-go-on-each-slide-and-stores-the-outline-for-each-slide-in-a-separate-filecutpaste-the-contents-of-one-of-these-outlines-in-as-the-answeranswer-)\n```\nHere is an outline for a presentation about prompt patterns for conversational large language models (LLMs):\nIntroduction to prompt patterns\nDefinition and purpose\nComparison to software patterns\nCategories of prompt patterns\nOutput Customization\nOutput Automater pattern\nPersona pattern\nVisualization Generator pattern\nRecipe pattern\nTemplate pattern\nError Identiï¬cation\nFact Check List pattern\nReï¬ection pattern\nPrompt Improvement\nQuestion Reï¬nement pattern\nAlternative Approaches pattern\nCognitive Veriï¬er pattern\nRefusal Breaker pattern\nEvaluating Means for Deï¬ning a Prompt Patternâs Structure and Ideas\nChallenges of deï¬ning a prompt patternâs structure\nPossible approaches for deï¬ning a prompt patternâs structure\nImportance of clear and concise communication\nExample Implementations\nSample prompts for each pattern\nExplanation of how the prompts are worded in practice\nConsequences\nPros and cons of applying each pattern\nGuidance on adapting the prompt to different contexts\nConclusion\nSummary of the importance and benefits of prompt patterns\nFuture directions for research and development\nThis outline provides a comprehensive overview of the concept of prompt patterns and their applications in conversational LLMs. Each section includes specific examples and implementation details to help the audience understand the practical applications of these patterns. The presentation concludes with a summary of the key takeaways and future directions for research and development in this area.\n\n```\n\n### Q.2 Using the outline files that you just created, have Code Interpreter turn one of the outline for one of the slides into 3-5 paragraphs and save it as a separate file.Cut/paste the paragraphs as your answer.Answer:-\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#q2-using-the-outline-files-that-you-just-created-have-code-interpreter-turn-one-of-the-outline-for-one-of-the-slides-into-3-5-paragraphs-and-save-it-as-a-separate-filecutpaste-the-paragraphs-as-your-answeranswer-)\n```\nThe prompt pattern catalog introduced in the paper is a collection of reusable solutions to common problems faced when conversing with conversational large language models (LLMs) like ChatGPT. These patterns are structured prompts that help users customize LLM outputs and interactions, similar to software patterns that provide reusable solutions for software development problems. The catalog includes prompt patterns for input semantics, output customization, error identification, prompt improvement, and interaction.\nInput semantics patterns focus on defining the input format and context for LLMs. These patterns include the Input Definition pattern, which specifies the input format and expected data types, and the Input Context pattern, which provides context to the LLM about the input data.\nOutput customization patterns help users tailor the types, formats, structure, or other properties of the output generated by the LLM. These patterns include the Output Format pattern, which specifies the format of the output, and the Output Structure pattern, which defines the structure of the output.\nError identification patterns focus on identifying and resolving errors in the output generated by the LLM. These patterns include the Error Detection pattern, which identifies errors in the output, and the Error Correction pattern, which corrects errors in the output.\nPrompt improvement patterns help users improve the quality of the input and output. These patterns include the Question Refinement pattern, which refines user questions to generate better output, and the Alternative Approaches pattern, which suggests alternative approaches to solving a problem.\nInteraction patterns focus on managing the interaction between the user and the LLM. These patterns include the Interaction Flow pattern, which defines the flow of the conversation, and the Interaction Context pattern, which provides context to the LLM about the conversation.\nThe paper also discusses the challenges of defining a prompt pattern's structure and ideas, including the need for clear and concise communication to users who may not be programmers. It suggests several possible approaches for defining a prompt pattern's structure, including diagrams and grammars for a prompt language. However, the paper notes that grammars can be challenging to define due to the nuanced ways that components of a prompt can be expressed in text or symbols.\nIn summary, the prompt pattern catalog introduced in the paper provides a collection of reusable solutions to common problems faced when conversing with conversational LLMs. These patterns help users customize LLM outputs and interactions, improve the quality of the input and output, and manage the interaction between the user and the LLM. The paper also discusses the challenges of defining a prompt pattern's structure and suggests several possible approaches for defining a prompt pattern's structure.\n\n```\n\n# END of The Courses!\n[](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#end-of-the-courses)\n## About\nThis repository contains all the coursera answers week wise for the subject INT426 \n### Resources\n[ Readme ](https://github.com/Bhanupriya-art/INT426-Coursera-Answers#readme-ov-file)\n###  Uh oh! \nThere was an error while loading. [Please reload this page](https://github.com/Bhanupriya-art/INT426-Coursera-Answers).\n[ Activity](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/activity)\n### Stars\n[ **21** stars](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/stargazers)\n### Watchers\n[ **1** watching](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/watchers)\n### Forks\n[ **25** forks](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/forks)\n[ Report repository ](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2FBhanupriya-art%2FINT426-Coursera-Answers&report=Bhanupriya-art+%28user%29)\n##  [Releases](https://github.com/Bhanupriya-art/INT426-Coursera-Answers/releases)\nNo releases published\n##  [Packages 0](https://github.com/users/Bhanupriya-art/packages?repo_name=INT426-Coursera-Answers)\nNo packages published \n###  Uh oh! \nThere was an error while loading. [Please reload this page](https://github.com/Bhanupriya-art/INT426-Coursera-Answers).\n## Footer\n[ ](https://github.com) Â© 2025 GitHub, Inc. \n### Footer navigation\n  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n  * [Security](https://github.com/security)\n  * [Status](https://www.githubstatus.com/)\n  * [Docs](https://docs.github.com/)\n  * [Contact](https://support.github.com?tags=dotcom-footer)\n  * Manage cookies \n  * Do not share my personal information \n\n\nYou canât perform that action at this time. \n"
  },
  {
    "link": "https://github.com/NirDiamant/RAG_Techniques",
    "raw_content": "[Skip to content](https://github.com/NirDiamant/RAG_Techniques#start-of-content)\n## Navigation Menu\nToggle navigation\n[ ](https://github.com/)\n[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FNirDiamant%2FRAG_Techniques)\nAppearance settings\n  * Product \n    * [ GitHub Copilot  Write better code with AI  ](https://github.com/features/copilot)\n    * [ GitHub Models  New  Manage and compare prompts  ](https://github.com/features/models)\n    * [ GitHub Advanced Security  Find and fix vulnerabilities  ](https://github.com/security/advanced-security)\n    * [ Actions  Automate any workflow  ](https://github.com/features/actions)\n    * [ Codespaces  Instant dev environments  ](https://github.com/features/codespaces)\n    * [ Issues  Plan and track work  ](https://github.com/features/issues)\n    * [ Code Review  Manage code changes  ](https://github.com/features/code-review)\n    * [ Discussions  Collaborate outside of code  ](https://github.com/features/discussions)\n    * [ Code Search  Find more, search less  ](https://github.com/features/code-search)\nExplore\n    * [ Why GitHub ](https://github.com/why-github)\n    * [ All features ](https://github.com/features)\n    * [ Documentation ](https://docs.github.com)\n    * [ GitHub Skills ](https://skills.github.com)\n    * [ Blog ](https://github.blog)\n  * Solutions \nBy company size\n    * [ Enterprises ](https://github.com/enterprise)\n    * [ Small and medium teams ](https://github.com/team)\n    * [ Startups ](https://github.com/enterprise/startups)\n    * [ Nonprofits ](https://github.com/solutions/industry/nonprofits)\nBy use case\n    * [ DevSecOps ](https://github.com/solutions/use-case/devsecops)\n    * [ DevOps ](https://github.com/solutions/use-case/devops)\n    * [ CI/CD ](https://github.com/solutions/use-case/ci-cd)\n    * [ View all use cases ](https://github.com/solutions/use-case)\nBy industry\n    * [ Healthcare ](https://github.com/solutions/industry/healthcare)\n    * [ Financial services ](https://github.com/solutions/industry/financial-services)\n    * [ Manufacturing ](https://github.com/solutions/industry/manufacturing)\n    * [ Government ](https://github.com/solutions/industry/government)\n    * [ View all industries ](https://github.com/solutions/industry)\n[ View all solutions ](https://github.com/solutions)\n  * Resources \nTopics\n    * [ AI ](https://github.com/resources/articles/ai)\n    * [ DevOps ](https://github.com/resources/articles/devops)\n    * [ Security ](https://github.com/resources/articles/security)\n    * [ Software Development ](https://github.com/resources/articles/software-development)\n    * [ View all ](https://github.com/resources/articles)\nExplore\n    * [ Learning Pathways ](https://resources.github.com/learn/pathways)\n    * [ Events & Webinars ](https://resources.github.com)\n    * [ Ebooks & Whitepapers ](https://github.com/resources/whitepapers)\n    * [ Customer Stories ](https://github.com/customer-stories)\n    * [ Partners ](https://partner.github.com)\n    * [ Executive Insights ](https://github.com/solutions/executive-insights)\n  * Open Source \n    * [ GitHub Sponsors  Fund open source developers  ](https://github.com/sponsors)\n    * [ The ReadME Project  GitHub community articles  ](https://github.com/readme)\nRepositories\n    * [ Topics ](https://github.com/topics)\n    * [ Trending ](https://github.com/trending)\n    * [ Collections ](https://github.com/collections)\n  * Enterprise \n    * [ Enterprise platform  AI-powered developer platform  ](https://github.com/enterprise)\nAvailable add-ons\n    * [ GitHub Advanced Security  Enterprise-grade security features  ](https://github.com/security/advanced-security)\n    * [ Copilot for business  Enterprise-grade AI features  ](https://github.com/features/copilot/copilot-business)\n    * [ Premium Support  Enterprise-grade 24/7 support  ](https://github.com/premium-support)\n  * [Pricing](https://github.com/pricing)\n\n\nSearch or jump to...\n# Search code, repositories, users, issues, pull requests...\nSearch \nClear\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n#  Provide feedback \nWe read every piece of feedback, and take your input very seriously.\nInclude my email address so I can be contacted\nCancel  Submit feedback \n#  Saved searches \n## Use saved searches to filter your results more quickly\nName\nQuery\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax). \nCancel  Create saved search \n[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FNirDiamant%2FRAG_Techniques)\n[ Sign up ](https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=NirDiamant%2FRAG_Techniques)\nAppearance settings\nResetting focus\nYou signed in with another tab or window. [Reload](https://github.com/NirDiamant/RAG_Techniques) to refresh your session. You signed out in another tab or window. [Reload](https://github.com/NirDiamant/RAG_Techniques) to refresh your session. You switched accounts on another tab or window. [Reload](https://github.com/NirDiamant/RAG_Techniques) to refresh your session. Dismiss alert\n{{ message }}\n[ NirDiamant ](https://github.com/NirDiamant) / **[RAG_Techniques](https://github.com/NirDiamant/RAG_Techniques) ** Public\n  * [ Sponsor  ](https://github.com/sponsors/NirDiamant)\n  * [ Notifications ](https://github.com/login?return_to=%2FNirDiamant%2FRAG_Techniques) You must be signed in to change notification settings\n  * [ Fork 1.6k ](https://github.com/login?return_to=%2FNirDiamant%2FRAG_Techniques)\n  * [ Star  16.4k ](https://github.com/login?return_to=%2FNirDiamant%2FRAG_Techniques)\n\n\nThis repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses. \n### License\n[ View license ](https://github.com/NirDiamant/RAG_Techniques/blob/main/LICENSE)\n[ 16.4k stars ](https://github.com/NirDiamant/RAG_Techniques/stargazers) [ 1.6k forks ](https://github.com/NirDiamant/RAG_Techniques/forks) [ Branches ](https://github.com/NirDiamant/RAG_Techniques/branches) [ Tags ](https://github.com/NirDiamant/RAG_Techniques/tags) [ Activity ](https://github.com/NirDiamant/RAG_Techniques/activity)\n[ Star  ](https://github.com/login?return_to=%2FNirDiamant%2FRAG_Techniques)\n[ Notifications ](https://github.com/login?return_to=%2FNirDiamant%2FRAG_Techniques) You must be signed in to change notification settings\n  * [ Code ](https://github.com/NirDiamant/RAG_Techniques)\n  * [ Issues 1 ](https://github.com/NirDiamant/RAG_Techniques/issues)\n  * [ Pull requests 7 ](https://github.com/NirDiamant/RAG_Techniques/pulls)\n  * [ Actions ](https://github.com/NirDiamant/RAG_Techniques/actions)\n  * [ Projects 0 ](https://github.com/NirDiamant/RAG_Techniques/projects)\n  * [ Security ](https://github.com/NirDiamant/RAG_Techniques/security)\n[ ](https://github.com/NirDiamant/RAG_Techniques/security)\n[ ](https://github.com/NirDiamant/RAG_Techniques/security)\n[ ](https://github.com/NirDiamant/RAG_Techniques/security)\n### [ Uh oh!  ](https://github.com/NirDiamant/RAG_Techniques/security)\n[There was an error while loading. ](https://github.com/NirDiamant/RAG_Techniques/security)[Please reload this page](https://github.com/NirDiamant/RAG_Techniques).\n  * [ Insights ](https://github.com/NirDiamant/RAG_Techniques/pulse)\n\n\nAdditional navigation options\n  * [ Code  ](https://github.com/NirDiamant/RAG_Techniques)\n  * [ Issues  ](https://github.com/NirDiamant/RAG_Techniques/issues)\n  * [ Pull requests  ](https://github.com/NirDiamant/RAG_Techniques/pulls)\n  * [ Actions  ](https://github.com/NirDiamant/RAG_Techniques/actions)\n  * [ Projects  ](https://github.com/NirDiamant/RAG_Techniques/projects)\n  * [ Security  ](https://github.com/NirDiamant/RAG_Techniques/security)\n  * [ Insights  ](https://github.com/NirDiamant/RAG_Techniques/pulse)\n\n\n# NirDiamant/RAG_Techniques\nmain\n[**1** Branch](https://github.com/NirDiamant/RAG_Techniques/branches)[**0** Tags](https://github.com/NirDiamant/RAG_Techniques/tags)\n[](https://github.com/NirDiamant/RAG_Techniques/branches)[](https://github.com/NirDiamant/RAG_Techniques/tags)\nGo to file\nCode\n## Folders and files\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n## Latest commit\n[![NirDiamant](https://avatars.githubusercontent.com/u/28316913?v=4&size=40)](https://github.com/NirDiamant)[NirDiamant](https://github.com/NirDiamant/RAG_Techniques/commits?author=NirDiamant)[Merge pull request](https://github.com/NirDiamant/RAG_Techniques/commit/f020503e4785462403d2d6cebffd968d21443331) [#101](https://github.com/NirDiamant/RAG_Techniques/pull/101) [from FINDarkside/patch-1](https://github.com/NirDiamant/RAG_Techniques/commit/f020503e4785462403d2d6cebffd968d21443331)May 28, 2025[f020503](https://github.com/NirDiamant/RAG_Techniques/commit/f020503e4785462403d2d6cebffd968d21443331) Â· May 28, 2025\n## History\n[360 Commits](https://github.com/NirDiamant/RAG_Techniques/commits/main/)[](https://github.com/NirDiamant/RAG_Techniques/commits/main/)  \n[.github](https://github.com/NirDiamant/RAG_Techniques/tree/main/.github \".github\")| [.github](https://github.com/NirDiamant/RAG_Techniques/tree/main/.github \".github\")| [added workflows](https://github.com/NirDiamant/RAG_Techniques/commit/68b512ceb2ff1e41e8a80524a7c7b15ff9a29f50 \"added workflows\")| Sep 12, 2024  \n[all_rag_techniques](https://github.com/NirDiamant/RAG_Techniques/tree/main/all_rag_techniques \"all_rag_techniques\")| [all_rag_techniques](https://github.com/NirDiamant/RAG_Techniques/tree/main/all_rag_techniques \"all_rag_techniques\")| [minor update](https://github.com/NirDiamant/RAG_Techniques/commit/7c42b970ed699f710380c36b686ef7bd97ab1c24 \"minor update\")| Apr 27, 2025  \n[all_rag_techniques_runnable_scripts](https://github.com/NirDiamant/RAG_Techniques/tree/main/all_rag_techniques_runnable_scripts \"all_rag_techniques_runnable_scripts\")| [all_rag_techniques_runnable_scripts](https://github.com/NirDiamant/RAG_Techniques/tree/main/all_rag_techniques_runnable_scripts \"all_rag_techniques_runnable_scripts\")| [Merge pull request](https://github.com/NirDiamant/RAG_Techniques/commit/1cfb0d44cb220f139fabe0ac195bd0b48d5ef13a \"Merge pull request #83 from VakeDomen/feature/hype\nFeature/hype\") [#83](https://github.com/NirDiamant/RAG_Techniques/pull/83) [from VakeDomen/feature/hype](https://github.com/NirDiamant/RAG_Techniques/commit/1cfb0d44cb220f139fabe0ac195bd0b48d5ef13a \"Merge pull request #83 from VakeDomen/feature/hype\nFeature/hype\")| Apr 2, 2025  \n[data](https://github.com/NirDiamant/RAG_Techniques/tree/main/data \"data\")| [data](https://github.com/NirDiamant/RAG_Techniques/tree/main/data \"data\")| [updated code](https://github.com/NirDiamant/RAG_Techniques/commit/76a529eccf2f42a87367cbe6801ebd558d35dd0b \"updated code\")| Feb 2, 2025  \n[evaluation](https://github.com/NirDiamant/RAG_Techniques/tree/main/evaluation \"evaluation\")| [evaluation](https://github.com/NirDiamant/RAG_Techniques/tree/main/evaluation \"evaluation\")| [changeed to colab notebooks](https://github.com/NirDiamant/RAG_Techniques/commit/fb429745d268375103b80ce1a3bfc4ad68b2303c \"changeed to colab notebooks\")| Apr 27, 2025  \n[images](https://github.com/NirDiamant/RAG_Techniques/tree/main/images \"images\")| [images](https://github.com/NirDiamant/RAG_Techniques/tree/main/images \"images\")| [update image](https://github.com/NirDiamant/RAG_Techniques/commit/372b884a95a392ba59e483e2920a25110786a6d7 \"update image\")| May 11, 2025  \n[tests](https://github.com/NirDiamant/RAG_Techniques/tree/main/tests \"tests\")| [tests](https://github.com/NirDiamant/RAG_Techniques/tree/main/tests \"tests\")| [updated code](https://github.com/NirDiamant/RAG_Techniques/commit/76a529eccf2f42a87367cbe6801ebd558d35dd0b \"updated code\")| Feb 2, 2025  \n[.gitignore](https://github.com/NirDiamant/RAG_Techniques/blob/main/.gitignore \".gitignore\")| [.gitignore](https://github.com/NirDiamant/RAG_Techniques/blob/main/.gitignore \".gitignore\")| [added substack logo in readme](https://github.com/NirDiamant/RAG_Techniques/commit/7790252c080df66ac3259964e1f6582e5dd99183 \"added substack logo in readme\")| Oct 25, 2024  \n[CONTRIBUTING.md](https://github.com/NirDiamant/RAG_Techniques/blob/main/CONTRIBUTING.md \"CONTRIBUTING.md\")| [CONTRIBUTING.md](https://github.com/NirDiamant/RAG_Techniques/blob/main/CONTRIBUTING.md \"CONTRIBUTING.md\")| [refer to colab notebooks](https://github.com/NirDiamant/RAG_Techniques/commit/cff742d144ab3e398581d9d12baf9e5491f6c823 \"refer to colab notebooks\")| Apr 27, 2025  \n[LICENSE](https://github.com/NirDiamant/RAG_Techniques/blob/main/LICENSE \"LICENSE\")| [LICENSE](https://github.com/NirDiamant/RAG_Techniques/blob/main/LICENSE \"LICENSE\")| [updated LICENSE](https://github.com/NirDiamant/RAG_Techniques/commit/a54655ec069478b952039a4512836c9a8b67a7f2 \"updated LICENSE\")| Oct 4, 2024  \n[README.md](https://github.com/NirDiamant/RAG_Techniques/blob/main/README.md \"README.md\")| [README.md](https://github.com/NirDiamant/RAG_Techniques/blob/main/README.md \"README.md\")| [Fix broken urls for hypothetical prompt embeddings](https://github.com/NirDiamant/RAG_Techniques/commit/8621f27616fa48a465602d5423372b9ac94bfc92 \"Fix broken urls for hypothetical prompt embeddings\")| May 28, 2025  \n[helper_functions.py](https://github.com/NirDiamant/RAG_Techniques/blob/main/helper_functions.py \"helper_functions.py\")| [helper_functions.py](https://github.com/NirDiamant/RAG_Techniques/blob/main/helper_functions.py \"helper_functions.py\")| [updated code](https://github.com/NirDiamant/RAG_Techniques/commit/76a529eccf2f42a87367cbe6801ebd558d35dd0b \"updated code\")| Feb 2, 2025  \nView all files  \n## Repository files navigation\n  * [README](https://github.com/NirDiamant/RAG_Techniques)\n  * [License](https://github.com/NirDiamant/RAG_Techniques)\n\n\n[![PRs Welcome](https://camo.githubusercontent.com/88482ebfc5e3e4f2d667148ab6a3eb55948789f1dba71dfa0eb2e05afe02958c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5052732d77656c636f6d652d627269676874677265656e2e7376673f7374796c653d666c61742d737175617265)](http://makeapullrequest.com) [![LinkedIn](https://camo.githubusercontent.com/7f4fa09b1856697217ac8392123d9ab7b47e4d8f8b96d82fb5ba375f7b5f0406/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c696e6b6564496e2d436f6e6e6563742d626c7565)](https://www.linkedin.com/in/nir-diamant-759323134/) [![Twitter](https://camo.githubusercontent.com/77144d97330c42418af5c6a0db3e37f7776815dc76ce06c4dc436b5c7ee5c00c/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f4e69724469616d616e7441493f6c6162656c3d466f6c6c6f77253230404e69724469616d616e744149267374796c653d736f6369616c)](https://twitter.com/NirDiamantAI) [![Discord](https://camo.githubusercontent.com/9e829a68987b31f1ac8844d03ba67f279dbced2cc7f46d5ec42a35f7b5d5ec93/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446973636f72642d4a6f696e2532306f7572253230636f6d6d756e6974792d3732383964613f7374796c653d666c61742d737175617265266c6f676f3d646973636f7264266c6f676f436f6c6f723d7768697465)](https://discord.gg/cA6Aa4uyDX) [![Sponsor](https://camo.githubusercontent.com/bce35a573e0dc8c4a75c3017272a722a11a2e4a45dcaa08510a42f47bbfb1d07/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76313f6c6162656c3d53706f6e736f72266d6573736167653d254532253944254134266c6f676f3d47697448756226636f6c6f723d666636396234)](https://github.com/sponsors/NirDiamant)\n> ð **Support This Project:** Your sponsorship fuels innovation in RAG technologies. **[Become a sponsor](https://github.com/sponsors/NirDiamant)** to help maintain and expand this valuable resource!\n## Sponsors â¤ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#sponsors-ï¸)\nA big thank you to the wonderful sponsor(s) who support this project!\n[![](https://github.com/Eisenh.png)](https://github.com/sponsors/Eisenh)\n# Advanced RAG Techniques: Elevating Your Retrieval-Augmented Generation Systems ð\n[](https://github.com/NirDiamant/RAG_Techniques#advanced-rag-techniques-elevating-your-retrieval-augmented-generation-systems-)\nWelcome to one of the most comprehensive and dynamic collections of Retrieval-Augmented Generation (RAG) tutorials available today. This repository serves as a hub for cutting-edge techniques aimed at enhancing the accuracy, efficiency, and contextual richness of RAG systems.\n## ð« Stay Updated!\n[](https://github.com/NirDiamant/RAG_Techniques#-stay-updated)\nð**Cutting-edgeUpdates** | ð¡**ExpertInsights** | ð¯**Top 0.1%Content**  \n---|---|---  \n[![Subscribe to DiamantAI Newsletter](https://github.com/NirDiamant/RAG_Techniques/raw/main/images/subscribe-button.svg)](https://diamantai.substack.com/?r=336pe4&utm_campaign=pub-share-checklist)\n_Join over 20,000 of AI enthusiasts getting unique cutting-edge insights and free tutorials!_ _**Plus, subscribers get exclusive early access and special 33% discounts to my book and the upcoming RAG Techniques course!**_\n[![DiamantAI's newsletter](https://github.com/NirDiamant/RAG_Techniques/raw/main/images/substack_image.png)](https://diamantai.substack.com/?r=336pe4&utm_campaign=pub-share-checklist)\n## Introduction\n[](https://github.com/NirDiamant/RAG_Techniques#introduction)\nRetrieval-Augmented Generation (RAG) is revolutionizing the way we combine information retrieval with generative AI. This repository showcases a curated collection of advanced techniques designed to supercharge your RAG systems, enabling them to deliver more accurate, contextually relevant, and comprehensive responses.\nOur goal is to provide a valuable resource for researchers and practitioners looking to push the boundaries of what's possible with RAG. By fostering a collaborative environment, we aim to accelerate innovation in this exciting field.\n## Related Projects\n[](https://github.com/NirDiamant/RAG_Techniques#related-projects)\nðï¸ Check out my **[Prompt Engineering Techniques guide](https://github.com/NirDiamant/Prompt_Engineering)** for a comprehensive collection of prompting strategies, from basic concepts to advanced techniques, enhancing your ability to interact effectively with AI language models.\nð¤ Explore my **[GenAI Agents Repository](https://github.com/NirDiamant/GenAI_Agents)** to discover a variety of AI agent implementations and tutorials, showcasing how different AI technologies can be combined to create powerful, interactive systems.\n## A Community-Driven Knowledge Hub\n[](https://github.com/NirDiamant/RAG_Techniques#a-community-driven-knowledge-hub)\n**This repository grows stronger with your contributions!** Join our vibrant Discord community â the central hub for shaping and advancing this project together ð¤\n**[RAG Techniques Discord Community](https://discord.gg/cA6Aa4uyDX)**\nWhether you're an expert or just starting out, your insights can shape the future of RAG. Join us to propose ideas, get feedback, and collaborate on innovative techniques. For contribution guidelines, please refer to our **[CONTRIBUTING.md](https://github.com/NirDiamant/RAG_Techniques/blob/main/CONTRIBUTING.md)** file. Let's advance RAG technology together!\nð For discussions on GenAI, RAG, or custom agents, or to explore knowledge-sharing opportunities, feel free to **[connect on LinkedIn](https://www.linkedin.com/in/nir-diamant-759323134/)**.\n## Key Features\n[](https://github.com/NirDiamant/RAG_Techniques#key-features)\n  * ð§  State-of-the-art RAG enhancements\n  * ð Comprehensive documentation for each technique\n  * ð ï¸ Practical implementation guidelines\n  * ð Regular updates with the latest advancements\n\n\n## Advanced Techniques\n[](https://github.com/NirDiamant/RAG_Techniques#advanced-techniques)\nExplore our extensive list of cutting-edge RAG techniques:\n# | Category | Technique | View  \n---|---|---|---  \n1 | Foundational ð± | Basic RAG | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/simple_rag.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_rag.ipynb)  \n2 | Foundational ð± | RAG with CSV Files | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/simple_csv_rag.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_csv_rag.ipynb)  \n3 | Foundational ð± | Reliable RAG | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/reliable_rag.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/reliable_rag.ipynb)  \n4 | Foundational ð± | Optimizing Chunk Sizes | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/choose_chunk_size.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/choose_chunk_size.ipynb)  \n5 | Foundational ð± | Proposition Chunking | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/proposition_chunking.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/proposition_chunking.ipynb)  \n6 | Query Enhancement ð | Query Transformations | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/query_transformations.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/query_transformations.ipynb)  \n7 | Query Enhancement ð | HyDE (Hypothetical Document Embedding) | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/HyDe_Hypothetical_Document_Embedding.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/HyDe_Hypothetical_Document_Embedding.ipynb)  \n8 | Query Enhancement ð | HyPE (Hypothetical Prompt Embedding) | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/HyPE_Hypothetical_Prompt_Embeddings.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/HyPE_Hypothetical_Prompt_Embeddings.ipynb)  \n9 | Context Enrichment ð | Contextual Chunk Headers | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/contextual_chunk_headers.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/contextual_chunk_headers.ipynb)  \n10 | Context Enrichment ð | Relevant Segment Extraction | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/relevant_segment_extraction.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/relevant_segment_extraction.ipynb)  \n11 | Context Enrichment ð | Context Window Enhancement | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/context_enrichment_window_around_chunk.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/context_enrichment_window_around_chunk.ipynb)  \n12 | Context Enrichment ð | Semantic Chunking | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/semantic_chunking.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/semantic_chunking.ipynb)  \n13 | Context Enrichment ð | Contextual Compression | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/contextual_compression.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/contextual_compression.ipynb)  \n14 | Context Enrichment ð | Document Augmentation | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/document_augmentation.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/document_augmentation.ipynb)  \n15 | Advanced Retrieval ð | Fusion Retrieval | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/fusion_retrieval.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/fusion_retrieval.ipynb)  \n16 | Advanced Retrieval ð | Reranking | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/reranking.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/reranking.ipynb)  \n17 | Advanced Retrieval ð | Multi-faceted Filtering | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/multi_faceted_filtering.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/multi_faceted_filtering.ipynb)  \n18 | Advanced Retrieval ð | Hierarchical Indices | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/hierarchical_indices.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/hierarchical_indices.ipynb)  \n19 | Advanced Retrieval ð | Ensemble Retrieval | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/ensemble_retrieval.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/ensemble_retrieval.ipynb)  \n20 | Advanced Retrieval ð | Dartboard Retrieval | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/dartboard.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/dartboard.ipynb)  \n21 | Advanced Retrieval ð | Multi-modal RAG with Captioning | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/multi_model_rag_with_captioning.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/multi_model_rag_with_captioning.ipynb)  \n22 | Iterative Techniques ð | Retrieval with Feedback Loop | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/retrieval_with_feedback_loop.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/retrieval_with_feedback_loop.ipynb)  \n23 | Iterative Techniques ð | Adaptive Retrieval | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/adaptive_retrieval.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/adaptive_retrieval.ipynb)  \n24 | Iterative Retrieval ð | Iterative Retrieval | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/iterative_retrieval.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/iterative_retrieval.ipynb)  \n25 | Evaluation ð | DeepEval | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/evaluation/evaluation_deep_eval.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/evaluation/evaluation_deep_eval.ipynb)  \n26 | Evaluation ð | GroUSE | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/evaluation/evaluation_grouse.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/evaluation/evaluation_grouse.ipynb)  \n27 | Explainability ð¬ | Explainable Retrieval | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/explainable_retrieval.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/explainable_retrieval.ipynb)  \n28 | Advanced Architecture ðï¸ | Graph RAG | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/graph_rag.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/graph_rag.ipynb)  \n29 | Advanced Architecture ðï¸ | Microsoft GraphRAG | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/Microsoft_GraphRag.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/Microsoft_GraphRag.ipynb)  \n30 | Advanced Architecture ðï¸ | RAPTOR | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/raptor.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/raptor.ipynb)  \n31 | Advanced Architecture ðï¸ | Self-RAG | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/self_rag.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/self_rag.ipynb)  \n32 | Advanced Architecture ðï¸ | Corrective RAG (CRAG) | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/all_rag_techniques/crag.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/crag.ipynb)  \n33 | Special Technique ð | Sophisticated Controllable Agent | [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/Controllable-RAG-Agent)  \n### ð± Foundational RAG Techniques\n[](https://github.com/NirDiamant/RAG_Techniques#-foundational-rag-techniques)\n  1. Simple RAG ð±\n     * **LangChain** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_rag.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_rag.ipynb)\n     * **LlamaIndex** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_rag_with_llamaindex.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_rag_with_llamaindex.ipynb)\n     * **[Runnable Script](https://github.com/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques_runnable_scripts/simple_rag.py)**\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview-)\nIntroducing basic RAG techniques ideal for newcomers.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸)\nStart with basic retrieval queries and integrate incremental learning mechanisms.\n  2. Simple RAG using a CSV file ð§©\n     * **LangChain** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_csv_rag.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_csv_rag.ipynb)\n     * **LlamaIndex** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_csv_rag_with_llamaindex.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/simple_csv_rag_with_llamaindex.ipynb)\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--1)\nIntroducing basic RAG using CSV files.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-1)\nThis uses CSV files to create basic retrieval and integrates with openai to create question and answering system.\n  3. **Reliable RAG ð·ï¸** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/reliable_rag.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/reliable_rag.ipynb)\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--2)\nEnhances the Simple RAG by adding validation and refinement to ensure the accuracy and relevance of retrieved information.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-2)\nCheck for retrieved document relevancy and highlight the segment of docs used for answering.\n  4. Choose Chunk Size ð\n     * **LangChain** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/choose_chunk_size.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/choose_chunk_size.ipynb)\n     * **[Runnable Script](https://github.com/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques_runnable_scripts/choose_chunk_size.py)**\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--3)\nSelecting an appropriate fixed size for text chunks to balance context preservation and retrieval efficiency.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-3)\nExperiment with different chunk sizes to find the optimal balance between preserving context and maintaining retrieval speed for your specific use case.\n  5. **Proposition Chunking âï¸âð¥** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/proposition_chunking.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/proposition_chunking.ipynb)\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--4)\nBreaking down the text into concise, complete, meaningful sentences allowing for better control and handling of specific queries (especially extracting knowledge).\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-4)\n     * ðª **Proposition Generation:** The LLM is used in conjunction with a custom prompt to generate factual statements from the document chunks.\n     * â **Quality Checking:** The generated propositions are passed through a grading system that evaluates accuracy, clarity, completeness, and conciseness.\n\n\n#### Additional Resources ð\n[](https://github.com/NirDiamant/RAG_Techniques#additional-resources-)\n  * **[The Propositions Method: Enhancing Information Retrieval for AI Systems](https://open.substack.com/pub/diamantai/p/the-propositions-method-enhancing?r=336pe4&utm_campaign=post&utm_medium=web)** - A comprehensive blog post exploring the benefits and implementation of proposition chunking in RAG systems.\n\n\n### ð Query Enhancement\n[](https://github.com/NirDiamant/RAG_Techniques#-query-enhancement)\n  1. Query Transformations ð\n     * **LangChain** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/query_transformations.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/query_transformations.ipynb)\n     * **[Runnable Script](https://github.com/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques_runnable_scripts/query_transformations.py)**\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--5)\nModifying and expanding queries to improve retrieval effectiveness.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-5)\n     * âï¸ **Query Rewriting:** Reformulate queries to improve retrieval.\n     * ð **Step-back Prompting:** Generate broader queries for better context retrieval.\n     * ð§© **Sub-query Decomposition:** Break complex queries into simpler sub-queries.\n  2. Hypothetical Questions (HyDE Approach) â\n     * **LangChain** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/HyDe_Hypothetical_Document_Embedding.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/HyDe_Hypothetical_Document_Embedding.ipynb)\n     * **[Runnable Script](https://github.com/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques_runnable_scripts/HyDe_Hypothetical_Document_Embedding.py)**\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--6)\nGenerating hypothetical questions to improve alignment between queries and data.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-6)\nCreate hypothetical questions that point to relevant locations in the data, enhancing query-data matching.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/RAG_Techniques#additional-resources--1)\n     * **[HyDE: Exploring Hypothetical Document Embeddings for AI Retrieval](https://open.substack.com/pub/diamantai/p/hyde-exploring-hypothetical-document?r=336pe4&utm_campaign=post&utm_medium=web)** - A short blog post explaining this method clearly.\n\n\n### ð Context and Content Enrichment\n[](https://github.com/NirDiamant/RAG_Techniques#-context-and-content-enrichment)\n  1. Hypothetical Prompt Embeddings (HyPE) âð\n     * **LangChain** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/HyPE_Hypothetical_Prompt_Embedding.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/HyPE_Hypothetical_Prompt_Embedding.ipynb)\n     * **[Runnable Script](https://github.com/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques_runnable_scripts/HyPE_Hypothetical_Prompt_Embeddings.py)**\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--7)\nHyPE (Hypothetical Prompt Embeddings) is an enhancement to traditional RAG retrieval that **precomputes hypothetical prompts at the indexing stage** , but inseting the chunk in their place. This transforms retrieval into a **question-question matching task**. This avoids the need for runtime synthetic answer generation, reducing inference-time computational overhead while **improving retrieval alignment**.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-7)\n     * ð **Precomputed Questions:** Instead of embedding document chunks, HyPE **generates multiple hypothetical queries per chunk** at indexing time.\n     * ð **Question-Question Matching:** User queries are matched against stored hypothetical questions, leading to **better retrieval alignment**.\n     * â¡ **No Runtime Overhead:** Unlike HyDE, HyPE does **not require LLM calls at query time** , making retrieval **faster and cheaper**.\n     * ð **Higher Precision & Recall:** Improves retrieval **context precision by up to 42 percentage points** and **claim recall by up to 45 percentage points**.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/RAG_Techniques#additional-resources--2)\n     * **[Preprint: Hypothetical Prompt Embeddings (HyPE)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5139335)** - Research paper detailing the method, evaluation, and benchmarks.\n  2. **Contextual Chunk Headers ð·ï¸** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/contextual_chunk_headers.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/contextual_chunk_headers.ipynb)\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--8)\nContextual chunk headers (CCH) is a method of creating document-level and section-level context, and prepending those chunk headers to the chunks prior to embedding them.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-8)\nCreate a chunk header that includes context about the document and/or section of the document, and prepend that to each chunk in order to improve the retrieval accuracy.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/RAG_Techniques#additional-resources--3)\n**[dsRAG](https://github.com/D-Star-AI/dsRAG)** : open-source retrieval engine that implements this technique (and a few other advanced RAG techniques)\n  3. **Relevant Segment Extraction ð§©** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/relevant_segment_extraction.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/relevant_segment_extraction.ipynb)\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--9)\nRelevant segment extraction (RSE) is a method of dynamically constructing multi-chunk segments of text that are relevant to a given query.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-9)\nPerform a retrieval post-processing step that analyzes the most relevant chunks and identifies longer multi-chunk segments to provide more complete context to the LLM.\n  4. Context Enrichment Techniques ð\n\n\n  * **LangChain** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/context_enrichment_window_around_chunk.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/context_enrichment_window_around_chunk.ipynb)\n  * **LlamaIndex** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/context_enrichment_window_around_chunk_with_llamaindex.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/context_enrichment_window_around_chunk_with_llamaindex.ipynb)\n  * **[Runnable Script](https://github.com/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques_runnable_scripts/context_enrichment_window_around_chunk.py)**\n\n\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--10)\nEnhancing retrieval accuracy by embedding individual sentences and extending context to neighboring sentences.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-10)\nRetrieve the most relevant sentence while also accessing the sentences before and after it in the original text.\n  1. Semantic Chunking ð§ \n\n\n  * **LangChain** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/semantic_chunking.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/semantic_chunking.ipynb)\n  * **[Runnable Script](https://github.com/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques_runnable_scripts/semantic_chunking.py)**\n\n\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--11)\nDividing documents based on semantic coherence rather than fixed sizes.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-11)\nUse NLP techniques to identify topic boundaries or coherent sections within documents for more meaningful retrieval units.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/RAG_Techniques#additional-resources--4)\n  * **[Semantic Chunking: Improving AI Information Retrieval](https://open.substack.com/pub/diamantai/p/semantic-chunking-improving-ai-information?r=336pe4&utm_campaign=post&utm_medium=web)** - A comprehensive blog post exploring the benefits and implementation of semantic chunking in RAG systems.\n\n\n  1. Contextual Compression ðï¸\n\n\n  * **LangChain** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/contextual_compression.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/contextual_compression.ipynb)\n  * **[Runnable Script](https://github.com/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques_runnable_scripts/contextual_compression.py)**\n\n\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--12)\nCompressing retrieved information while preserving query-relevant content.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-12)\nUse an LLM to compress or summarize retrieved chunks, preserving key information relevant to the query.\n  1. Document Augmentation through Question Generation for Enhanced Retrieval\n\n\n  * **LangChain** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/document_augmentation.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/document_augmentation.ipynb)\n  * **[Runnable Script](https://github.com/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques_runnable_scripts/document_augmentation.py)**\n\n\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--13)\nThis implementation demonstrates a text augmentation technique that leverages additional question generation to improve document retrieval within a vector database. By generating and incorporating various questions related to each text fragment, the system enhances the standard retrieval process, thus increasing the likelihood of finding relevant documents that can be utilized as context for generative question answering.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-13)\nUse an LLM to augment text dataset with all possible questions that can be asked to each document.\n### ð Advanced Retrieval Methods\n[](https://github.com/NirDiamant/RAG_Techniques#-advanced-retrieval-methods)\n  1. Fusion Retrieval ð\n     * **LangChain** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/fusion_retrieval.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/fusion_retrieval.ipynb)\n     * **LlamaIndex** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/fusion_retrieval_with_llamaindex.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/fusion_retrieval_with_llamaindex.ipynb)\n     * **[Runnable Script](https://github.com/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques_runnable_scripts/fusion_retrieval.py)**\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--14)\nOptimizing search results by combining different retrieval methods.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-14)\nCombine keyword-based search with vector-based search for more comprehensive and accurate retrieval.\n  2. Intelligent Reranking ð\n     * **LangChain** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/reranking.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/reranking.ipynb)\n     * **LlamaIndex** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/reranking_with_llamaindex.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/reranking_with_llamaindex.ipynb)\n     * **[Runnable Script](https://github.com/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques_runnable_scripts/reranking.py)**\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--15)\nApplying advanced scoring mechanisms to improve the relevance ranking of retrieved results.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-15)\n     * ð§  **LLM-based Scoring:** Use a language model to score the relevance of each retrieved chunk.\n     * ð **Cross-Encoder Models:** Re-encode both the query and retrieved documents jointly for similarity scoring.\n     * ð **Metadata-enhanced Ranking:** Incorporate metadata into the scoring process for more nuanced ranking.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/RAG_Techniques#additional-resources--5)\n     * **[Relevance Revolution: How Re-ranking Transforms RAG Systems](https://open.substack.com/pub/diamantai/p/relevance-revolution-how-re-ranking?r=336pe4&utm_campaign=post&utm_medium=web)** - A comprehensive blog post exploring the power of re-ranking in enhancing RAG system performance.\n  3. Multi-faceted Filtering ð\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--16)\nApplying various filtering techniques to refine and improve the quality of retrieved results.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-16)\n     * ð·ï¸ **Metadata Filtering:** Apply filters based on attributes like date, source, author, or document type.\n     * ð **Similarity Thresholds:** Set thresholds for relevance scores to keep only the most pertinent results.\n     * ð **Content Filtering:** Remove results that don't match specific content criteria or essential keywords.\n     * ð **Diversity Filtering:** Ensure result diversity by filtering out near-duplicate entries.\n  4. Hierarchical Indices ðï¸\n     * **LangChain** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/hierarchical_indices.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/hierarchical_indices.ipynb)\n     * **[Runnable Script](https://github.com/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques_runnable_scripts/hierarchical_indices.py)**\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--17)\nCreating a multi-tiered system for efficient information navigation and retrieval.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-17)\nImplement a two-tiered system for document summaries and detailed chunks, both containing metadata pointing to the same location in the data.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/RAG_Techniques#additional-resources--6)\n     * **[Hierarchical Indices: Enhancing RAG Systems](https://open.substack.com/pub/diamantai/p/hierarchical-indices-enhancing-rag?r=336pe4&utm_campaign=post&utm_medium=web)** - A comprehensive blog post exploring the power of hierarchical indices in enhancing RAG system performance.\n  5. Ensemble Retrieval ð­\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--18)\nCombining multiple retrieval models or techniques for more robust and accurate results.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-18)\nApply different embedding models or retrieval algorithms and use voting or weighting mechanisms to determine the final set of retrieved documents.\n  6. Dartboard Retrieval ð¯\n     * **LangChain** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/dartboard.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/dartboard.ipynb)\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--19)\nOptimizing over Relevant Information Gain in Retrieval\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-19)\n     * Combine both relevance and diversity into a single scoring function and directly optimize for it.\n     * POC showing plain simple RAG underperforming when the database is dense, and the dartboard retrieval outperforming it.\n  7. Multi-modal Retrieval ð½ï¸\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--20)\nExtending RAG capabilities to handle diverse data types for richer responses.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-20)\n     * **Multi-model RAG with Multimedia Captioning** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/multi_model_rag_with_captioning.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/multi_model_rag_with_captioning.ipynb) - Caption and store all the other multimedia data like pdfs, ppts, etc., with text data in vector store and retrieve them together.\n     * **Multi-model RAG with Colpali** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/multi_model_rag_with_colpali.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/multi_model_rag_with_colpali.ipynb) - Instead of captioning convert all the data into image, then find the most relevant images and pass them to a vision large language model.\n\n\n### ð Iterative and Adaptive Techniques\n[](https://github.com/NirDiamant/RAG_Techniques#-iterative-and-adaptive-techniques)\n  1. Retrieval with Feedback Loops ð\n     * **LangChain** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/retrieval_with_feedback_loop.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/retrieval_with_feedback_loop.ipynb)\n     * **[Runnable Script](https://github.com/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques_runnable_scripts/retrieval_with_feedback_loop.py)**\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--21)\nImplementing mechanisms to learn from user interactions and improve future retrievals.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-21)\nCollect and utilize user feedback on the relevance and quality of retrieved documents and generated responses to fine-tune retrieval and ranking models.\n  2. Adaptive Retrieval ð¯\n     * **LangChain** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/adaptive_retrieval.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/adaptive_retrieval.ipynb)\n     * **[Runnable Script](https://github.com/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques_runnable_scripts/adaptive_retrieval.py)**\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--22)\nDynamically adjusting retrieval strategies based on query types and user contexts.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-22)\nClassify queries into different categories and use tailored retrieval strategies for each, considering user context and preferences.\n  3. Iterative Retrieval ð\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--23)\nPerforming multiple rounds of retrieval to refine and enhance result quality.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-23)\nUse the LLM to analyze initial results and generate follow-up queries to fill in gaps or clarify information.\n\n\n### ð Evaluation\n[](https://github.com/NirDiamant/RAG_Techniques#-evaluation)\n  1. **DeepEval Evaluation** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/evaluation/evaluation_deep_eval.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/evaluation/evaluation_deep_eval.ipynb) | Comprehensive RAG system evaluation |\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--24)\nPerforming evaluations Retrieval-Augmented Generation systems, by covering several metrics and creating test cases.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-24)\nUse the `deepeval` library to conduct test cases on correctness, faithfulness and contextual relevancy of RAG systems.\n  2. **GroUSE Evaluation** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/evaluation/evaluation_grouse.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/evaluation/evaluation_grouse.ipynb) | Contextually-grounded LLM evaluation |\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--25)\nEvaluate the final stage of Retrieval-Augmented Generation using metrics of the GroUSE framework and meta-evaluate your custom LLM judge on GroUSE unit tests.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-25)\nUse the `grouse` package to evaluate contextually-grounded LLM generations with GPT-4 on the 6 metrics of the GroUSE framework and use unit tests to evaluate a custom Llama 3.1 405B evaluator.\n\n\n### ð¬ Explainability and Transparency\n[](https://github.com/NirDiamant/RAG_Techniques#-explainability-and-transparency)\n  1. Explainable Retrieval ð\n     * **LangChain** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/explainable_retrieval.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/explainable_retrieval.ipynb)\n     * **[Runnable Script](https://github.com/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques_runnable_scripts/explainable_retrieval.py)**\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--26)\nProviding transparency in the retrieval process to enhance user trust and system refinement.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-26)\nExplain why certain pieces of information were retrieved and how they relate to the query.\n\n\n### ðï¸ Advanced Architectures\n[](https://github.com/NirDiamant/RAG_Techniques#ï¸-advanced-architectures)\n  1. Knowledge Graph Integration (Graph RAG) ð¸ï¸\n     * **LangChain** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/graph_rag.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/graph_rag.ipynb)\n     * **[Runnable Script](https://github.com/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques_runnable_scripts/graph_rag.py)**\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--27)\nIncorporating structured data from knowledge graphs to enrich context and improve retrieval.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-27)\nRetrieve entities and their relationships from a knowledge graph relevant to the query, combining this structured data with unstructured text for more informative responses.\n  2. GraphRag (Microsoft) ð¯\n     * **GraphRag** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/Microsoft_GraphRag.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/Microsoft_GraphRag.ipynb)\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--28)\nMicrosoft GraphRAG (Open Source) is an advanced RAG system that integrates knowledge graphs to improve the performance of LLMs\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-28)\nâ¢ Analyze an input corpus by extracting entities, relationships from text units. generates summaries of each community and its constituents from the bottom-up.\n  3. RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval ð³\n     * **LangChain** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/raptor.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/raptor.ipynb)\n     * **[Runnable Script](https://github.com/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques_runnable_scripts/raptor.py)**\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--29)\nImplementing a recursive approach to process and organize retrieved information in a tree structure.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-29)\nUse abstractive summarization to recursively process and summarize retrieved documents, organizing the information in a tree structure for hierarchical context.\n  4. Self RAG ð\n     * **LangChain** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/self_rag.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/self_rag.ipynb)\n     * **[Runnable Script](https://github.com/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques_runnable_scripts/self_rag.py)**\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--30)\nA dynamic approach that combines retrieval-based and generation-based methods, adaptively deciding whether to use retrieved information and how to best utilize it in generating responses.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-30)\nâ¢ Implement a multi-step process including retrieval decision, document retrieval, relevance evaluation, response generation, support assessment, and utility evaluation to produce accurate, relevant, and useful outputs.\n  5. Corrective RAG ð§\n     * **LangChain** : [![](https://camo.githubusercontent.com/dd3ce5792d7b95f8e06e6a4595d27ed46934687a28cd2692fe435e98c06cb0f1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d566965772d626c7565)](https://github.com/NirDiamant/RAG_TECHNIQUES/blob/main/https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/crag.ipynb) [![](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques/crag.ipynb)\n     * **[Runnable Script](https://github.com/NirDiamant/RAG_Techniques/blob/main/all_rag_techniques_runnable_scripts/crag.py)**\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--31)\nA sophisticated RAG approach that dynamically evaluates and corrects the retrieval process, combining vector databases, web search, and language models for highly accurate and context-aware responses.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-31)\nâ¢ Integrate Retrieval Evaluator, Knowledge Refinement, Web Search Query Rewriter, and Response Generator components to create a system that adapts its information sourcing strategy based on relevance scores and combines multiple sources when necessary.\n\n\n## ð Special Advanced Technique ð\n[](https://github.com/NirDiamant/RAG_Techniques#-special-advanced-technique-)\n  1. **[Sophisticated Controllable Agent for Complex RAG Tasks ð¤](https://github.com/NirDiamant/Controllable-RAG-Agent)**\n#### Overview ð\n[](https://github.com/NirDiamant/RAG_Techniques#overview--32)\nAn advanced RAG solution designed to tackle complex questions that simple semantic similarity-based retrieval cannot solve. This approach uses a sophisticated deterministic graph as the \"brain\" ð§  of a highly controllable autonomous agent, capable of answering non-trivial questions from your own data.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/RAG_Techniques#implementation-ï¸-32)\nâ¢ Implement a multi-step process involving question anonymization, high-level planning, task breakdown, adaptive information retrieval and question answering, continuous re-planning, and rigorous answer verification to ensure grounded and accurate responses.\n\n\n## Getting Started\n[](https://github.com/NirDiamant/RAG_Techniques#getting-started)\nTo begin implementing these advanced RAG techniques in your projects:\n  1. Clone this repository: \n```\ngit clone https://github.com/NirDiamant/RAG_Techniques.git\n\n```\n\n  2. Navigate to the technique you're interested in: \n```\ncd all_rag_techniques/technique-name\n\n```\n\n  3. Follow the detailed implementation guide in each technique's directory.\n\n\n## Contributing\n[](https://github.com/NirDiamant/RAG_Techniques#contributing)\nWe welcome contributions from the community! If you have a new technique or improvement to suggest:\n  1. Fork the repository\n  2. Create your feature branch: `git checkout -b feature/AmazingFeature`\n  3. Commit your changes: `git commit -m 'Add some AmazingFeature'`\n  4. Push to the branch: `git push origin feature/AmazingFeature`\n  5. Open a pull request\n\n\n## Contributors\n[](https://github.com/NirDiamant/RAG_Techniques#contributors)\n[![Contributors](https://camo.githubusercontent.com/858ba294638a68388246f12f5556b091c74c0b8b410a38a5bd9b76f0929d4173/68747470733a2f2f636f6e747269622e726f636b732f696d6167653f7265706f3d4e69724469616d616e742f5241475f546563686e6971756573)](https://github.com/NirDiamant/RAG_Techniques/graphs/contributors)\n## License\n[](https://github.com/NirDiamant/RAG_Techniques#license)\nThis project is licensed under a custom non-commercial license - see the [LICENSE](https://github.com/NirDiamant/RAG_Techniques/blob/main/LICENSE) file for details.\nâ­ï¸ If you find this repository helpful, please consider giving it a star!\nKeywords: RAG, Retrieval-Augmented Generation, NLP, AI, Machine Learning, Information Retrieval, Natural Language Processing, LLM, Embeddings, Semantic Search\n## About\nThis repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses. \n### Topics\n[ python ](https://github.com/topics/python \"Topic: python\") [ ai ](https://github.com/topics/ai \"Topic: ai\") [ tutorials ](https://github.com/topics/tutorials \"Topic: tutorials\") [ rag ](https://github.com/topics/rag \"Topic: rag\") [ llm ](https://github.com/topics/llm \"Topic: llm\") [ llms ](https://github.com/topics/llms \"Topic: llms\") [ langchain ](https://github.com/topics/langchain \"Topic: langchain\") [ llama-index ](https://github.com/topics/llama-index \"Topic: llama-index\") [ opeani ](https://github.com/topics/opeani \"Topic: opeani\")\n### Resources\n[ Readme ](https://github.com/NirDiamant/RAG_Techniques#readme-ov-file)\n### License\n[ View license ](https://github.com/NirDiamant/RAG_Techniques#License-1-ov-file)\n###  Uh oh! \nThere was an error while loading. [Please reload this page](https://github.com/NirDiamant/RAG_Techniques).\n[ Activity](https://github.com/NirDiamant/RAG_Techniques/activity)\n### Stars\n[ **16.4k** stars](https://github.com/NirDiamant/RAG_Techniques/stargazers)\n### Watchers\n[ **184** watching](https://github.com/NirDiamant/RAG_Techniques/watchers)\n### Forks\n[ **1.6k** forks](https://github.com/NirDiamant/RAG_Techniques/forks)\n[ Report repository ](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2FNirDiamant%2FRAG_Techniques&report=NirDiamant+%28user%29)\n##  [Releases](https://github.com/NirDiamant/RAG_Techniques/releases)\nNo releases published\n## Sponsor this project\n[ ![@NirDiamant](https://avatars.githubusercontent.com/u/28316913?s=64&v=4) ](https://github.com/NirDiamant) [ **NirDiamant** ](https://github.com/NirDiamant)\n[ Sponsor  ](https://github.com/sponsors/NirDiamant)\n[Learn more about GitHub Sponsors](https://github.com/sponsors)\n##  [Packages 0](https://github.com/users/NirDiamant/packages?repo_name=RAG_Techniques)\nNo packages published \n###  Uh oh! \nThere was an error while loading. [Please reload this page](https://github.com/NirDiamant/RAG_Techniques).\n##  [Contributors 26](https://github.com/NirDiamant/RAG_Techniques/graphs/contributors)\n  * [ ![@NirDiamant](https://avatars.githubusercontent.com/u/28316913?s=64&v=4) ](https://github.com/NirDiamant)\n  * [ ![@tevfikcagridural](https://avatars.githubusercontent.com/u/39863822?s=64&v=4) ](https://github.com/tevfikcagridural)\n  * [ ![@lzytitan494](https://avatars.githubusercontent.com/u/97222085?s=64&v=4) ](https://github.com/lzytitan494)\n  * [ ![@zmccormick7](https://avatars.githubusercontent.com/u/6549202?s=64&v=4) ](https://github.com/zmccormick7)\n  * [ ![@roybka](https://avatars.githubusercontent.com/u/26812437?s=64&v=4) ](https://github.com/roybka)\n  * [ ![@michalu](https://avatars.githubusercontent.com/u/74382?s=64&v=4) ](https://github.com/michalu)\n  * [ ![@VakeDomen](https://avatars.githubusercontent.com/u/31067452?s=64&v=4) ](https://github.com/VakeDomen)\n  * [ ![@yanivvak](https://avatars.githubusercontent.com/u/42068219?s=64&v=4) ](https://github.com/yanivvak)\n  * [ ![@Haruna245](https://avatars.githubusercontent.com/u/69992226?s=64&v=4) ](https://github.com/Haruna245)\n  * [ ![@oaustegard](https://avatars.githubusercontent.com/u/3268739?s=64&v=4) ](https://github.com/oaustegard)\n  * [ ![@moshe-shelly](https://avatars.githubusercontent.com/u/40472500?s=64&v=4) ](https://github.com/moshe-shelly)\n  * [ ![@EliavSh](https://avatars.githubusercontent.com/u/55198967?s=64&v=4) ](https://github.com/EliavSh)\n  * [ ![@cnpatric](https://avatars.githubusercontent.com/u/82205245?s=64&v=4) ](https://github.com/cnpatric)\n  * [ ![@speedwagon1299](https://avatars.githubusercontent.com/u/118172807?s=64&v=4) ](https://github.com/speedwagon1299)\n\n\n[+ 12 contributors](https://github.com/NirDiamant/RAG_Techniques/graphs/contributors)\n## Languages\n  * [ Jupyter Notebook 93.5% ](https://github.com/NirDiamant/RAG_Techniques/search?l=jupyter-notebook)\n  * [ Python 6.5% ](https://github.com/NirDiamant/RAG_Techniques/search?l=python)\n\n\n## Footer\n[ ](https://github.com) Â© 2025 GitHub, Inc. \n### Footer navigation\n  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n  * [Security](https://github.com/security)\n  * [Status](https://www.githubstatus.com/)\n  * [Docs](https://docs.github.com/)\n  * [Contact](https://support.github.com?tags=dotcom-footer)\n  * Manage cookies \n  * Do not share my personal information \n\n\nYou canât perform that action at this time. \n"
  },
  {
    "link": "https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS",
    "raw_content": "[Skip to content](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS#start-of-content)\n## Navigation Menu\nToggle navigation\n[ ](https://github.com/)\n[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FGURPREETKAURJETHRA%2FEND-TO-END-GENERATIVE-AI-PROJECTS)\nAppearance settings\n  * Product \n    * [ GitHub Copilot  Write better code with AI  ](https://github.com/features/copilot)\n    * [ GitHub Models  New  Manage and compare prompts  ](https://github.com/features/models)\n    * [ GitHub Advanced Security  Find and fix vulnerabilities  ](https://github.com/security/advanced-security)\n    * [ Actions  Automate any workflow  ](https://github.com/features/actions)\n    * [ Codespaces  Instant dev environments  ](https://github.com/features/codespaces)\n    * [ Issues  Plan and track work  ](https://github.com/features/issues)\n    * [ Code Review  Manage code changes  ](https://github.com/features/code-review)\n    * [ Discussions  Collaborate outside of code  ](https://github.com/features/discussions)\n    * [ Code Search  Find more, search less  ](https://github.com/features/code-search)\nExplore\n    * [ Why GitHub ](https://github.com/why-github)\n    * [ All features ](https://github.com/features)\n    * [ Documentation ](https://docs.github.com)\n    * [ GitHub Skills ](https://skills.github.com)\n    * [ Blog ](https://github.blog)\n  * Solutions \nBy company size\n    * [ Enterprises ](https://github.com/enterprise)\n    * [ Small and medium teams ](https://github.com/team)\n    * [ Startups ](https://github.com/enterprise/startups)\n    * [ Nonprofits ](https://github.com/solutions/industry/nonprofits)\nBy use case\n    * [ DevSecOps ](https://github.com/solutions/use-case/devsecops)\n    * [ DevOps ](https://github.com/solutions/use-case/devops)\n    * [ CI/CD ](https://github.com/solutions/use-case/ci-cd)\n    * [ View all use cases ](https://github.com/solutions/use-case)\nBy industry\n    * [ Healthcare ](https://github.com/solutions/industry/healthcare)\n    * [ Financial services ](https://github.com/solutions/industry/financial-services)\n    * [ Manufacturing ](https://github.com/solutions/industry/manufacturing)\n    * [ Government ](https://github.com/solutions/industry/government)\n    * [ View all industries ](https://github.com/solutions/industry)\n[ View all solutions ](https://github.com/solutions)\n  * Resources \nTopics\n    * [ AI ](https://github.com/resources/articles/ai)\n    * [ DevOps ](https://github.com/resources/articles/devops)\n    * [ Security ](https://github.com/resources/articles/security)\n    * [ Software Development ](https://github.com/resources/articles/software-development)\n    * [ View all ](https://github.com/resources/articles)\nExplore\n    * [ Learning Pathways ](https://resources.github.com/learn/pathways)\n    * [ Events & Webinars ](https://resources.github.com)\n    * [ Ebooks & Whitepapers ](https://github.com/resources/whitepapers)\n    * [ Customer Stories ](https://github.com/customer-stories)\n    * [ Partners ](https://partner.github.com)\n    * [ Executive Insights ](https://github.com/solutions/executive-insights)\n  * Open Source \n    * [ GitHub Sponsors  Fund open source developers  ](https://github.com/sponsors)\n    * [ The ReadME Project  GitHub community articles  ](https://github.com/readme)\nRepositories\n    * [ Topics ](https://github.com/topics)\n    * [ Trending ](https://github.com/trending)\n    * [ Collections ](https://github.com/collections)\n  * Enterprise \n    * [ Enterprise platform  AI-powered developer platform  ](https://github.com/enterprise)\nAvailable add-ons\n    * [ GitHub Advanced Security  Enterprise-grade security features  ](https://github.com/security/advanced-security)\n    * [ Copilot for business  Enterprise-grade AI features  ](https://github.com/features/copilot/copilot-business)\n    * [ Premium Support  Enterprise-grade 24/7 support  ](https://github.com/premium-support)\n  * [Pricing](https://github.com/pricing)\n\n\nSearch or jump to...\n# Search code, repositories, users, issues, pull requests...\nSearch \nClear\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n#  Provide feedback \nWe read every piece of feedback, and take your input very seriously.\nInclude my email address so I can be contacted\nCancel  Submit feedback \n#  Saved searches \n## Use saved searches to filter your results more quickly\nName\nQuery\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax). \nCancel  Create saved search \n[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FGURPREETKAURJETHRA%2FEND-TO-END-GENERATIVE-AI-PROJECTS)\n[ Sign up ](https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=GURPREETKAURJETHRA%2FEND-TO-END-GENERATIVE-AI-PROJECTS)\nAppearance settings\nResetting focus\nYou signed in with another tab or window. [Reload](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS) to refresh your session. You signed out in another tab or window. [Reload](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS) to refresh your session. You switched accounts on another tab or window. [Reload](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS) to refresh your session. Dismiss alert\n{{ message }}\n[ GURPREETKAURJETHRA ](https://github.com/GURPREETKAURJETHRA) / **[END-TO-END-GENERATIVE-AI-PROJECTS](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS) ** Public\n  * [ Notifications ](https://github.com/login?return_to=%2FGURPREETKAURJETHRA%2FEND-TO-END-GENERATIVE-AI-PROJECTS) You must be signed in to change notification settings\n  * [ Fork 85 ](https://github.com/login?return_to=%2FGURPREETKAURJETHRA%2FEND-TO-END-GENERATIVE-AI-PROJECTS)\n  * [ Star  288 ](https://github.com/login?return_to=%2FGURPREETKAURJETHRA%2FEND-TO-END-GENERATIVE-AI-PROJECTS)\n\n\nEnd to End Generative AI Industry Projects on LLM Models with Deployment_Awesome LLM Projects \n[github.com/GURPREETKAURJETHRA/Generative-AI-LLM-Projects](https://github.com/GURPREETKAURJETHRA/Generative-AI-LLM-Projects \"https://github.com/GURPREETKAURJETHRA/Generative-AI-LLM-Projects\")\n### License\n[ MIT license ](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/blob/main/LICENSE)\n[ 288 stars ](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/stargazers) [ 85 forks ](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/forks) [ Branches ](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/branches) [ Tags ](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/tags) [ Activity ](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/activity)\n[ Star  ](https://github.com/login?return_to=%2FGURPREETKAURJETHRA%2FEND-TO-END-GENERATIVE-AI-PROJECTS)\n[ Notifications ](https://github.com/login?return_to=%2FGURPREETKAURJETHRA%2FEND-TO-END-GENERATIVE-AI-PROJECTS) You must be signed in to change notification settings\n  * [ Code ](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS)\n  * [ Issues 0 ](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/issues)\n  * [ Pull requests 1 ](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/pulls)\n  * [ Actions ](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/actions)\n  * [ Projects 0 ](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/projects)\n  * [ Security ](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/security)\n[ ](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/security)\n[ ](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/security)\n[ ](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/security)\n### [ Uh oh!  ](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/security)\n[There was an error while loading. ](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/security)[Please reload this page](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS).\n  * [ Insights ](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/pulse)\n\n\nAdditional navigation options\n  * [ Code  ](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS)\n  * [ Issues  ](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/issues)\n  * [ Pull requests  ](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/pulls)\n  * [ Actions  ](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/actions)\n  * [ Projects  ](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/projects)\n  * [ Security  ](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/security)\n  * [ Insights  ](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/pulse)\n\n\n# GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS\nmain\n[**1** Branch](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/branches)[**0** Tags](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/tags)\n[](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/branches)[](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/tags)\nGo to file\nCode\n## Folders and files\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n## Latest commit\n[![GURPREETKAURJETHRA](https://avatars.githubusercontent.com/u/100081334?v=4&size=40)](https://github.com/GURPREETKAURJETHRA)[GURPREETKAURJETHRA](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/commits?author=GURPREETKAURJETHRA)[Update README.md](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/commit/a69edbed250ff6959ceedd1aa27bdd8fb8e5c036)Jan 24, 2025[a69edbe](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/commit/a69edbed250ff6959ceedd1aa27bdd8fb8e5c036) Â· Jan 24, 2025\n## History\n[36 Commits](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/commits/main/)[](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/commits/main/)  \n[images](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/tree/main/images \"images\")| [images](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/tree/main/images \"images\")| [Uploaded Images](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/commit/065bd2bc83d2f40c37d32336884f90e411659867 \"Uploaded Images\")| Mar 21, 2024  \n[LICENSE](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/blob/main/LICENSE \"LICENSE\")| [LICENSE](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/blob/main/LICENSE \"LICENSE\")| [Initial commit](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/commit/4466d4c42927989482b2153cfc1925c6d494b882 \"Initial commit\")| Mar 21, 2024  \n[README.md](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/blob/main/README.md \"README.md\")| [README.md](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/blob/main/README.md \"README.md\")| [Update README.md](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/commit/a69edbed250ff6959ceedd1aa27bdd8fb8e5c036 \"Update README.md\")| Jan 24, 2025  \nView all files  \n## Repository files navigation\n  * [README](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS)\n  * [MIT license](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS)\n\n\n# END TO END GENERATIVE AI PROJECTS\n[](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS#end-to-end-generative-ai-projects)\n## Awesome Projects Collection on LLM Models\n[](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS#awesome-projects-collection-on-llm-models)\n### ðð§âð»End to End Generative AI Industry Projects on LLM Models, RAG, AI Agents, AI Chatbot, MultiModals with Deployment ð©âð»ð\n[](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS#end-to-end-generative-ai-industry-projects-on-llm-models-rag-ai-agents-ai-chatbot-multimodals-with-deployment-)\nS.No | Project Name | Description | Official Repo | Tech Stack  \n---|---|---|---|---  \n1 | **Multi-PDFs ðChatApp AI Agent ð¤** | Chat seamlessly with Multiple PDFs using Langchain, Google Gemini Pro & FAISS Vector DB with Seamless Streamlit Deployment. Get instant, accurate responses from Awesome Google Gemini OpenSource language Model. ðð¬ Transform your PDF experience now! ð¥â¨ | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Multi-PDFs_ChatApp_AI-Agent) | **`F/w:`Langchain`Model` : Google Gemini Pro, `Vector DB`: FAISS `Deployment`: Streamlit**  \n2 | **ð¼ï¸Image to Speech GenAI Tool Using LLM ðâ¨ï¸** | AI tool that generates an Audio short story based on the context of an uploaded image by prompting a GenAI LLM model. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Image-to-Speech-GenAI-Tool-Using-LLM) | **`F/w:`Langchain`Model` : HuggingFace Models, OpenAI GPT-3.5, `Vector Deployment`: Streamlit, Hugging Spaces**  \n3 | **Youtube Video Transcribe Summarizer LLM App** | End To End Youtube Video Transcribe Summarizer LLM App With Google Gemini Pro providing detailed notes based on YouTube video transcripts. With the power of AI, you can now convert video transcripts into comprehensive study materials. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Youtube-Video-Transcribe-Summarizer-LLM-App) | **Google Gemini Pro**  \n4 | **End to end RAG LLM App** | Step-by-Step Guide to Building a RAG LLM App with LLamA2 and LLaMAindex | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Building-a-RAG-LLM-App-with-LLamA2-and-LLaMAindex) | **LLamA2 and LLaMAindex**  \n5 | **Resume ATS Tracking LLM Project** | This is a project aiming to optimize the recruitment process. It integrates an advanced Applicant Tracking System with Google Gemini Pro, streamlining resume parsing, keyword matching, and candidate evaluation for an efficient end-to-end solution in talent acquisition. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Resume-ATS-Tracking-LLM-Project) | **Google Gemini Pro**  \n6 | **End To End Text To SQL LLM App Along With Querying SQL Database** | The \"Text to SQL LLM App with Google Gemini Pro\" is a software application that facilitates the conversion of natural language queries into SQL commands. It also enables querying SQL databases directly using the generated SQL commands. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/End-To-End-Text-To-SQL-LLM-App-Along-With-Querying-SQL-Database) | **Using Google Gemini Pro**  \n7 | **End To End Multi Language Invoice Extractor Project** | MultiLanguage Invoice Extractor ð¼â¨ Discover the power of MultiLanguage Invoice Extractor! This Streamlit app, powered by Google Gemini Pro Vision AI, makes extracting information from invoice images a breeze. Upload images, add prompts, and get detailed responses effortlessly. With multi-language support. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/End-To-End-Multi-Language-Invoice-Extractor-Project-Using-Google-Gemini) | **Using Google Gemini Pro**  \n8 | **PDF Document Question Answering LLM System** |  | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/PDF-Document-Question-Answering-LLM-System) | **Langchain,Cassandra,Astra DB,Vector Database**  \n9 | **Fine Tune LLAMA 2 With Custom Dataset** |  | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Fine-Tune-LLAMA-2-With-Custom-Dataset) | **Using`LoRA` And `QLoRA` Techniques**  \n10 | **End to End RAG LLM App: Indexing & Querying Multiple Pdf's** |  | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/End-to-End-RAG-LLM-App-Indexing-Querying-Multiple-Pdf-s) | **Using Llamaindex and OpenAI**  \n11 | **Real Time Financial Stock Analysis** |  | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Real-Time-Financial-Stock-Analysis) | **Using`CrewAI` , `Groq`, `LangChain` & some other APIs like `browserless, Serper and SEC EDGAR API`**  \n12 | **Medical ChatBot** | The Llama2 Medical Bot is a powerful tool designed to provide medical information by answering user queries using state-of-the-art language models and vector stores. The bot runs on a decent CPU machine with a minimum of 16GB of RAM. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Medical-ChatBot) | **Using`Llama2` and `Sentence Transformers`. Powered by `Langchain` and `Chainlit`**  \n13 | **Medical Mixture-of Experts LLM** | Medical Mixture of Experts LLM using Mergekit. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Medical-Mixture-of-Experts-LLM) | **MergeKit**  \n14 | **Haystack and Mistral 7B RAG Implementation** | Haystack and Mistral 7B RAG Implementation. It is based on completely open-source stack. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Haystack-and-Mistral-7B-RAG-Implementation) | **Haystack-and-Mistral-7B-RAG**  \n15 | **Power QnA Chatbot** | Question Answer Generation App using Mistral 7B, Langchain, and FastAPI. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Multi-PDFs_ChatApp_AI-Agent) | **Mistral 7B, Langchain, and FastAPI.**  \n16 | **RAG** | Gemma-7B-RAG-using-Ollama | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Gemma-7B-RAG-using-Ollama) | **Gemma-7B-RAG-using-Ollama**  \n17 | **On-device LLM Inference** | On-device LLM Inference using Mediapipe LLM Inference API. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/On-device-LLM-Inference-using-Mediapipe) | **Using Mediapipe LLM Inference API.**  \n18 | **Personal Voice Assistant using OpenAI** |  | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Personal-Voice-Assistant-using-OpenAI) |   \n19 | **Fast Fine Tuning and DPO Training of LLMs using Unsloth** |  | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Fast-Fine-Tuning-and-DPO-Training-of-LLMs-using-Unsloth) |   \n20 | **Groq Chat App** | Groq Chat App built using Groq API and Streamlit. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Groq-Chat-App) | **Groq API and Streamlit.**  \n21 | **Medical RAG using Bio-Mistral-7B** | This is a RAG implementation using Open Source stack. BioMistral 7B has been used to build this app along with PubMedBert as an embedding model, Qdrant as a self hosted Vector DB, and Langchain & Llama CPP as an orchestration frameworks | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Medical-RAG-using-Bio-Mistral-7B) | **RAG implementation, BioMistral 7B, PubMedBert, Qdrant, Langchain & Llama CPP**  \n22 | **End-to-End RAG Implementation-using Amazon Bedrock** |  | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/End-to-End-RAG-Implementation-using-Amazon-Bedrock) | **Amazon Bedrock**  \n23 | **Faster Stable Diffusion using SSD-1B** | Faster Stable Diffusion using SSD-1B. A gradio app inside for demo. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Faster-Stable-Diffusion-using-SSD-1B) | **Stable Diffusion using SSD-1B, Gradio**  \n24 | **Phi-2 Fine-Tuning** | Phi-2 Fine Tuning to build a mental health GPT. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Phi-2-Fine-Tuning) | **Phi-2-Fine-Tuning**  \n25 | **Medical RAG Using Meditron-7B-LLM** | Medical RAG QA App using Meditron 7B LLM, Qdrant Vector Database, and PubMedBERT Embedding Model. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Medical-RAG-using-Bio-Mistral-7B) | **Meditron 7B LLM, Qdrant, PubMedBERT**  \n26 | **Fastest Image Generation using LCM LoRA.** |  | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Fastest-Image-Generation-using-LCM-LoRA.) | **LoRA**  \n27 | **HyDE based RAG using NVIDIA NIM** |  | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/HyDE-based-RAG-using-NVIDIA-NIM) | **HyDE based RAG, NVIDIA NIM**  \n28 | **Building Intelligent Systems Using Visdum-AI** |  | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Building-Intelligent-Systems-Using-Visdum-AI) | **Visdum-AI**  \n29 | **Zephyr 7B beta RAG Demo inside a Gradio App** | Zephyr 7B beta RAG Demo inside a Gradio app powered by BGE Embeddings, ChromaDB, and Zephyr 7B Beta. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Zephyr-7B-beta-RAG-Demo-inside-a-Gradio-app) | **Zephyr 7B beta, RAG, Gradio, BGE Embeddings, ChromaDB**  \n30 | **LangChain Expression Language** | Intro to LangChain Expression Language. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/LangChain-Expression-Language) | **LEL**  \n31 | **Fine Tuning Multimodal LLM** | Fine Tuning Multimodal LLM \"Idefics 9B\" on Pokemon Go Dataset available on Hugging Face. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Fine-Tuning-Multimodal-LLM) | **Multimodal LLM \"Idefics 9B\"**  \n32 | **RAG Tool using Haystack, Mistral and Chainlit** | RAG Tool using Haystack, Mistral, and Chainlit. All open source stack on CPU. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/RAG-Tool-using-Haystack-Mistral-and-Chainlit) | **RAG, Haystack, Mistral, Chainlit**  \n33 | **Prompt Compression Using LLMLingua** | Prompt Compression using LLMLingua. It helps with token's cost and latency. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Prompt-Compression-using-LLMLingua) | **Prompt Compression, LLMLingua**  \n34 | **Stream Diffusion in Colab** |  | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Stream-Diffusion-in-Colab) |   \n35 | **Multimodal-RAG Using Langchain** | Multimodal-RAG-using-Langchain | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Multimodal-RAG-using-Langchain) | **RAG, Langchain**  \n36 | **Secure-AI-LLM Chatbots Using Prompt Injection Prevention Techniques** | Prompt Injection & Prevention techniques. Secure your AI Chatbots built using LLMs. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Secure-AI-LLM-Chatbots-Using-Prompt-Injection-Prevention-Techniques) | **Prompt Injection, LLMs**  \n37 | **GGUF Quantization Of any LLM** | GGUF-Quantization-of-any-LLM | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/GGUF-Quantization-of-any-LLM) | **GGUF-Quantization**  \n38 | **Deltamon Anime Using LoRA** | Deltamon-Anime-using-LoRA | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Deltamon-Anime-using-LoRA) | **LoRA**  \n39 | **Evaluation of LLMs and RAGs** | Evaluation-of-LLMs-and-RAGs. A complete guide to evaluate LLMs and RAGs covering theory and code based approaches. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Evaluation-of-LLMs-and-RAGs) | **LLMs, RAGs**  \n40 | **Unsloth Fine-Tuning** | Unsloth-Fine-Tuning | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Unsloth-Fine-Tuning) | **Unsloth**  \n41 | **SLIM Models by LLMWare** | SLIM Models by LLMWare. A streamlit app showing the capabilities for AI Agents and Function Calls. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/SLIM-Models-by-LLMWare) | **SLIM Models, LLMWare, AI Agents, Function Calls, Streamlit App**  \n42 | **Small Multimodal Vision Model** | Small Multimodal Vision Model \"Imp-v1-3b\" trained using Phi-2 and Siglip. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Small-Multimodal-Vision-Model) | **Small Multimodal Vision Model \"Imp-v1-3b\", Phi-2, Siglip**  \n43 | **Langsmith Implementation** | Langsmith-Implementation | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Langsmith-Implementation) | **Langsmith**  \n44 | **Langserve Implementation** | Langserve-Implementation | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Langserve-Implementation) | **Langserve**  \n45 | **Multimodal AI App using Llava 7B and Gradio** | Multimodal AI App using Llava 7B and Gradio | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Multimodal-AI-App-using-Llava-7B) | **Llava 7B, Gradio**  \n46 | **Perplexity Lite** | Perplexity Lite using Langgraph, Tavily, and GPT-4. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Perplexity-Lite) | **LangGraph, Tavily and GPT-4.**  \n47 | **Generative-AI-LLM-Projects** | Gen AI End To End Large Language Model Projects | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Generative-AI-LLM-Projects) | **30+ Gen AI End To End Large Language Model Projects With Latest OpenSource Models, Fine Tuning**  \n48 | **MusicAI** | Custom Music Generation with Transformers and PyTorch | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/MusicAI) | **Transformers, PyTorch**  \n49 | **Audio Summarization App using Gemini LLM** | Audio Summarization App using Gemini LLM | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Audio-Summarization-App-using-Gemini-LLM) | **Gemini 1.5, LLM**  \n50 | **Fine Tune Multimodal LLM \"Idefics 2\" using QLoRA** | Fine Tune Multimodal LLM \"Idefics 2\" using QLoRA. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Fine-Tune-Multimodal-LLM-Idefics-2-using-QLoRA.) | **Multimodal LLM \"Idefics 2\", QLoRA**  \n51 | **Llama 3 ORPO FineTuning** | Llama 3 ORPO Fine Tuning on A100 in Colab Pro. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Llama-3-ORPO-Fine-Tuning) | **Llama 3 ORPO**  \n52 | **RAG using Llama3, Langchain and ChromaDB** | This project utilizes Llama3 Langchain and ChromaDB to establish a Retrieval Augmented Generation (RAG) system. This system empowers you to ask questions about your documents, even if the information wasn't included in the training data for the Large Language Model (LLM). Retrieval Augmented Generation works by first performing a retrieval step when presented with a question. This step fetches relevant documents from a special vector database, where the documents have been indexed. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/RAG-using-Llama3-Langchain-and-ChromaDB) | **RAG using Llama3, Langchain and ChromaDB**  \n53 | **LLAMA-3 70B LLM with NVIDIA** | Meet LLAMA3 Chat AI App! ðMeta Unveils Llama 3, the Most Powerful Open Source Model Yet. Chat seamlessly with LLAMA3 Chatbot. Get instant, Accurate responses from Awesome Llama3 OpenSource language Modelðð¬ | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/LLAMA3-70B-LLM-with-NVIDIA) | **LLAMA-3 70B LLM with NVIDIA, Streamlit UI**  \n54 | **Efficiently fine-tune Llama 3 with PyTorch FSDP and Q-Lora** | Efficiently fine-tune Llama 3 with PyTorch FSDP and Q-Lora | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Fine-tuning-Llama-3-with-PyTorch-FSDP-and-Q-Lora) | **Llama 3 with PyTorch FSDP and Q-Lora, Fine Tuning**  \n55 | **ðMETA LLAMA3 GENAI Real World UseCases End To End Implementation Guidesð** | LLAMA3 GENAI UseCases | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Meta-LLAMA3-GenAI-UseCases-End-To-End-Implementation-Guides) | **Llama3, FineTuning, Deployment, RAG, Langchain**  \n56 | **â­Meta's LLaMA3-Quantizationð¦ðð«** | LLaMA3-Quantization is the official implementation of paper \"How Good Are Low-bit Quantized LLAMA3 Models?\". Here evaluation is done on the 10 existing post-training quantization and LoRA-finetuning methods of LLaMa3 on 1-8 bits and diverse datasets to comprehensively reveal LLaMa3's low-bit quantization performance. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/LLaMA3-Quantization) | **Quantization, GenerativeAI, llama3-meta-ai**  \n57 | **Ollama-UseCasesð** | This repo brings numerous use cases from the Open Source Ollama | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Ollama-UseCases) | **Ollama**  \n58 | **AI Agentsð«** | Design Patterns for Multi Agents Frameworks Like Autogen, Langraph, Taskweaver, Crewai,etc | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/AI-Agents) | **Multi Agents Frameworks Like Autogen, Langraph, Taskweaver, Crewai**  \n59 | **RAG with LlamaIndex and NVIDIA** | RAG with LlamaIndex and NVIDIA | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/RAG-with-LlamaIndex-and-NVIDIA) | **RAG with LlamaIndex and NVIDIA**  \n60 | **Quantize LLM using AWQ** | Quantize LLM using AWQ | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Quantize-LLM-using-AWQ) | **Quantize LLM using AWQ**  \n61 | **LLMs Inference and Fine Tuning** | Estimate Memory Consumption of LLMs Inference and Fine Tuning | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/LLMs-Inference-and-Fine-Tuning) | **LLMs Inference and Fine Tuning**  \n62 | **Phi-3 LLM by Microsoft** | Phi-3 LLM by Microsoft Implementation | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Phi-3-LLM-by-Microsoft) | **Phi-3 LLM**  \n63 | **ð¥Advanced RAGð«ð** | Advanced Retrieval-Augmented Generation (RAG) through practical notebooks, using the power of the Langchain, OpenAI GPTs ,META LLAMA3 , Agents. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Advanced_RAG) | **Advanced Retrieval-Augmented Generation (RAG), Langchain, OpenAI GPTs ,META LLAMA3 , Agents.**  \n64 | **RAG-using-AWS-Bedrock-and-Azure-OpenAI** | RAG-using-AWS-Bedrock-and-Azure-OpenAI | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/RAG-using-AWS-Bedrock-and-Azure-OpenAI) | **RAG, AWS-Bedrock, Azure-OpenAI, Generative AI**  \n65 | **LLM SECURITY 2024** | Securing LLM's Against Top 10 OWASP Large Language Model Vulnerabilities 2024 | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/LLM-SECURITY) | **OWASP, LLM Security, Vulnerability's, Data Security, Cyber Security, Generative AI, LLM Security**  \n66 | **GPT4o-API-Implementation-GPT4-RAG** | Getting Started with GPT4 API, GPT4 RAG, OpenAI GPT4 Assistant, OpenAI Models | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/GPT4o-API-Implementation-GPT4-RAG) | **openai-api, gpt-4, large-language-models, generative-ai, gpt4-api, gpt4o**  \n67 | **PaliGemma Inference and Fine Tuning** | PaliGemma Inference and Fine Tuning | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/PaliGemma-Inference-and-Fine-Tuning) | **PaliGemma, Inference, Fine Tuning, Generative-AI**  \n68 | **LLMs Evaluation** | LLMs Evaluation | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/LLMs-Evaluation) | **LLMs Evaluation, Generative AI**  \n69 | **Building RAG With OpenAI GPT-4o(omni) Model Using Objectbox Vector Database** | Building RAG With OpenAI GPT-4o(omni) Model Using Objectbox Vector Database | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Building-RAG-With-OpenAI-GPT-4o-omni-Model-Using-Objectbox-Vector-Database) | **RAG, OpenAI GPT-4o(omni) Model,MObjectbox Vector Database**  \n70 | **PaliGemma FineTuning** | PaliGemma FineTuning | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/PaliGemma-FineTuning) | **PaliGemma, FineTuning**  \n71 | **RAG Evaluator** | A library for evaluating Retrieval-Augmented Generation (RAG) systems | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/RAG-Evaluator) | **RAG Evaluator, Metrics: BLEU, ROUGE, BERT, Perplexity,Diversity, Racial Bias**  \n72 | **Griptape: Create Customisable Multi AI Agents from Scratch** | Griptape: Create Customisable Multi AI Agents from Scratch | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Griptape-Create-Customisable-Multi-AI-Agents) | **Agent-based-framework, Griptape, llm, Generative-ai, AIagents**  \n73 | **Synthetic Data Generation using LLM** | Synthetic Data Generation using LLM via Argilla, Distilabel, ChatGPT, etc. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Synthetic-Data-Generation-using-LLM) | **Synthetic Data Generation, LLM, Argilla, Distilabel, ChatGPT**  \n74 | **Groq-Whisper Fast Transcription App** | Groq-Whisper Fast Transcription App built using Groq API and Streamlit | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Groq-Whisper-Fast-Transcription-App) | **Groq-Whisper, LLM, Streamlit**  \n75 | **CrewAI AgentOps** | CrewAI AgentOps: Monitor your AI Agents | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/CrewAI-AgentOps) | **Agentops, Generative-AI, Crewai, AIagents**  \n76 | **Agentic RAG using Crew AI** | Agentic RAG using Crew AI | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Agentic-RAG-using-Crew-AI) | **RAG, Generative-AI, Crewai, AIagents, Agentic-RAG, Agentic-ai, Crewai-RAG**  \n77 | **AI Agents using Crew AI** | AI Agents Streamlit App using Crew AI | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/AI-Agents-Streamlit-App-using-Crew-AI) | **AI Agents, Streamlit App, GenerativeAI, Crew AI**  \n78 | **Multi GPU Fine Training LLMs** | Multi GPU Fine Training LLMs using DeepSpeed and Accelerate. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Multi-GPU-Fine-Training-LLMs) | **accelerate, gpu-computing, finetuning, deepspeed, large-language-models, generative-ai**  \n79 | **LLM based Finance Agent** | An intelligent agent utilizing Large Language Models (LLMs) for automated financial news retrieval and stock price prediction. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/LLM-based-Finance-Agent) | **Agent-based,finance-api,LLMs, generative-ai, gemini-pro**  \n80 | **Multi-Agent AI App** | The Multi-Agents AI App from Scratch is a Python-based application leveraging OpenAI's GPT-4o model to perform specialized tasks through a collaborative Multi-Agent Architecture. Built with Streamlit for an intuitive web interface without any Agents frameworks/libraries, this system includes agents for Summarizing Medical Texts, Writing Research Articles, and Sanitizing Medical Data. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Multi-Agent-AI-App) | **Agent-based, Multi-Agent Architecture, LLMs, GenerativeAI, Streamlit**  \n81 | **RAG Based LLM AI Chatbot** | RAG Based LLM Chatbot Built using Open Source Stack (Llama 3.2 Model, BGE Embeddings, and Qdrant running locally within a Docker Container) | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/RAG-Based-LLM-Chatbot) | **RAG, LLAMA Model, LLMs, GenerativeAI, Streamlit, Qdrant**  \n82 | **Perfect LLM Model Finder** | Perfect LLM Model Finder is a tool designed to simplify the overwhelming process of choosing the right LLM wrt Usecase or Project | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/Perfect-LLM-Model-Finder.git) | **AI Agent, google-generativeai, Pandas, datasets, google-cloud-storage, google-cloud-bigquery, google-auth, deep-translator, LLMs, GenerativeAI, Streamlit, LLMOps**  \n83 | **AI Data Visualization Agent** | This Streamlit application creates an interactive Data Visualization Assistant that can understand Natural Language Queries and generate appropriate Visualizations using LLMs. | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/AI-Data-Visualization-Agent.git) | **DataVisualization, DataAnalysis, AI Agent, together, e2b-code-interpreter, LLAMA, DeepSeek, Qwen, LLMs, GenerativeAI, Streamlit**  \n84 | **AI Lead Generation Agent** | This AI Agent that automatically discovers and qualifies potential leads from Quora. Using Firecrawl for intelligent web scraping, Phidata for agent orchestration, and Composio for Google Sheets integration, you'll create a system that can continuously generate and organize qualified leads with minimal human intervention! | [![](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/raw/main/images/git.jpg)](https://github.com/GURPREETKAURJETHRA/AI-Lead-Generation-Agent.git) | **AI Agents, firecrawl-py, phidata, composio-phidata, composio, pydantic, google sheets, quora, OpenAI GPT4, LLMs, GenerativeAI, Streamlit, AI Agent Framework**  \n| _**More Projects list is coming...!!!**_ |  |  |   \n## Â©ï¸ Awesome LLM Projects License ðªª\n[](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS#ï¸-awesome-llm-projects-license-)\nDistributed under the MIT License. See `LICENSE` for more information.\n#### **If you found Generative AI Projects Implementation fruitful do drop â­ to this repo and if you have Exciting Ideas, Contributions are welcome! ðð¦ð**\n[](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS#if-you-found-generative-ai-projects-implementation-fruitful-do-drop--to-this-repo-and-if-you-have-exciting-ideas-contributions-are-welcome-)\n#### Follow me on [![LinkedIn](https://camo.githubusercontent.com/0c59c81be6c6e981fbad69ea742692368b3fdc1018090a34cb7764dfea5a1a91/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c696e6b6564696e2d2532333030373742352e7376673f7374796c653d666f722d7468652d6261646765266c6f676f3d6c696e6b6564696e266c6f676f436f6c6f723d7768697465)](https://www.linkedin.com/in/gurpreetkaurjethra/) [![GitHub](https://camo.githubusercontent.com/7e282220b8ec0dd29cf99be1c0f5e82d74a42bc84ed834ee6afd86b4bad3bfee/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6769746875622d2532333132313031312e7376673f7374796c653d666f722d7468652d6261646765266c6f676f3d676974687562266c6f676f436f6c6f723d7768697465)](https://github.com/GURPREETKAURJETHRA/)\n[](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS#follow-me-on---)\n## About\nEnd to End Generative AI Industry Projects on LLM Models with Deployment_Awesome LLM Projects \n[github.com/GURPREETKAURJETHRA/Generative-AI-LLM-Projects](https://github.com/GURPREETKAURJETHRA/Generative-AI-LLM-Projects \"https://github.com/GURPREETKAURJETHRA/Generative-AI-LLM-Projects\")\n### Topics\n[ gemini ](https://github.com/topics/gemini \"Topic: gemini\") [ llama ](https://github.com/topics/llama \"Topic: llama\") [ lora ](https://github.com/topics/lora \"Topic: lora\") [ mistral ](https://github.com/topics/mistral \"Topic: mistral\") [ huggingface ](https://github.com/topics/huggingface \"Topic: huggingface\") [ openai-api ](https://github.com/topics/openai-api \"Topic: openai-api\") [ large-language-models ](https://github.com/topics/large-language-models \"Topic: large-language-models\") [ llm ](https://github.com/topics/llm \"Topic: llm\") [ generative-ai ](https://github.com/topics/generative-ai \"Topic: generative-ai\") [ langchain ](https://github.com/topics/langchain \"Topic: langchain\") [ llmops ](https://github.com/topics/llmops \"Topic: llmops\") [ llama-index ](https://github.com/topics/llama-index \"Topic: llama-index\") [ qlora ](https://github.com/topics/qlora \"Topic: qlora\") [ chainlit ](https://github.com/topics/chainlit \"Topic: chainlit\") [ finetuning-llms ](https://github.com/topics/finetuning-llms \"Topic: finetuning-llms\") [ gradio-python-llm ](https://github.com/topics/gradio-python-llm \"Topic: gradio-python-llm\") [ mergekit ](https://github.com/topics/mergekit \"Topic: mergekit\") [ llama3 ](https://github.com/topics/llama3 \"Topic: llama3\") [ llama3-meta-ai ](https://github.com/topics/llama3-meta-ai \"Topic: llama3-meta-ai\") [ gpt4o ](https://github.com/topics/gpt4o \"Topic: gpt4o\")\n### Resources\n[ Readme ](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS#readme-ov-file)\n### License\n[ MIT license ](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS#MIT-1-ov-file)\n###  Uh oh! \nThere was an error while loading. [Please reload this page](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS).\n[ Activity](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/activity)\n### Stars\n[ **288** stars](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/stargazers)\n### Watchers\n[ **1** watching](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/watchers)\n### Forks\n[ **85** forks](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/forks)\n[ Report repository ](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2FGURPREETKAURJETHRA%2FEND-TO-END-GENERATIVE-AI-PROJECTS&report=GURPREETKAURJETHRA+%28user%29)\n##  [Releases](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS/releases)\nNo releases published\n##  [Packages 0](https://github.com/users/GURPREETKAURJETHRA/packages?repo_name=END-TO-END-GENERATIVE-AI-PROJECTS)\nNo packages published \n###  Uh oh! \nThere was an error while loading. [Please reload this page](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS).\n## Footer\n[ ](https://github.com) Â© 2025 GitHub, Inc. \n### Footer navigation\n  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n  * [Security](https://github.com/security)\n  * [Status](https://www.githubstatus.com/)\n  * [Docs](https://docs.github.com/)\n  * [Contact](https://support.github.com?tags=dotcom-footer)\n  * Manage cookies \n  * Do not share my personal information \n\n\nYou canât perform that action at this time. \n"
  },
  {
    "link": "https://github.com/lancedb/vectordb-recipes",
    "raw_content": "[Skip to content](https://github.com/lancedb/vectordb-recipes#start-of-content)\n## Navigation Menu\nToggle navigation\n[ ](https://github.com/)\n[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Flancedb%2Fvectordb-recipes)\nAppearance settings\n  * Product \n    * [ GitHub Copilot  Write better code with AI  ](https://github.com/features/copilot)\n    * [ GitHub Models  New  Manage and compare prompts  ](https://github.com/features/models)\n    * [ GitHub Advanced Security  Find and fix vulnerabilities  ](https://github.com/security/advanced-security)\n    * [ Actions  Automate any workflow  ](https://github.com/features/actions)\n    * [ Codespaces  Instant dev environments  ](https://github.com/features/codespaces)\n    * [ Issues  Plan and track work  ](https://github.com/features/issues)\n    * [ Code Review  Manage code changes  ](https://github.com/features/code-review)\n    * [ Discussions  Collaborate outside of code  ](https://github.com/features/discussions)\n    * [ Code Search  Find more, search less  ](https://github.com/features/code-search)\nExplore\n    * [ Why GitHub ](https://github.com/why-github)\n    * [ All features ](https://github.com/features)\n    * [ Documentation ](https://docs.github.com)\n    * [ GitHub Skills ](https://skills.github.com)\n    * [ Blog ](https://github.blog)\n  * Solutions \nBy company size\n    * [ Enterprises ](https://github.com/enterprise)\n    * [ Small and medium teams ](https://github.com/team)\n    * [ Startups ](https://github.com/enterprise/startups)\n    * [ Nonprofits ](https://github.com/solutions/industry/nonprofits)\nBy use case\n    * [ DevSecOps ](https://github.com/solutions/use-case/devsecops)\n    * [ DevOps ](https://github.com/solutions/use-case/devops)\n    * [ CI/CD ](https://github.com/solutions/use-case/ci-cd)\n    * [ View all use cases ](https://github.com/solutions/use-case)\nBy industry\n    * [ Healthcare ](https://github.com/solutions/industry/healthcare)\n    * [ Financial services ](https://github.com/solutions/industry/financial-services)\n    * [ Manufacturing ](https://github.com/solutions/industry/manufacturing)\n    * [ Government ](https://github.com/solutions/industry/government)\n    * [ View all industries ](https://github.com/solutions/industry)\n[ View all solutions ](https://github.com/solutions)\n  * Resources \nTopics\n    * [ AI ](https://github.com/resources/articles/ai)\n    * [ DevOps ](https://github.com/resources/articles/devops)\n    * [ Security ](https://github.com/resources/articles/security)\n    * [ Software Development ](https://github.com/resources/articles/software-development)\n    * [ View all ](https://github.com/resources/articles)\nExplore\n    * [ Learning Pathways ](https://resources.github.com/learn/pathways)\n    * [ Events & Webinars ](https://resources.github.com)\n    * [ Ebooks & Whitepapers ](https://github.com/resources/whitepapers)\n    * [ Customer Stories ](https://github.com/customer-stories)\n    * [ Partners ](https://partner.github.com)\n    * [ Executive Insights ](https://github.com/solutions/executive-insights)\n  * Open Source \n    * [ GitHub Sponsors  Fund open source developers  ](https://github.com/sponsors)\n    * [ The ReadME Project  GitHub community articles  ](https://github.com/readme)\nRepositories\n    * [ Topics ](https://github.com/topics)\n    * [ Trending ](https://github.com/trending)\n    * [ Collections ](https://github.com/collections)\n  * Enterprise \n    * [ Enterprise platform  AI-powered developer platform  ](https://github.com/enterprise)\nAvailable add-ons\n    * [ GitHub Advanced Security  Enterprise-grade security features  ](https://github.com/security/advanced-security)\n    * [ Copilot for business  Enterprise-grade AI features  ](https://github.com/features/copilot/copilot-business)\n    * [ Premium Support  Enterprise-grade 24/7 support  ](https://github.com/premium-support)\n  * [Pricing](https://github.com/pricing)\n\n\nSearch or jump to...\n# Search code, repositories, users, issues, pull requests...\nSearch \nClear\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n#  Provide feedback \nWe read every piece of feedback, and take your input very seriously.\nInclude my email address so I can be contacted\nCancel  Submit feedback \n#  Saved searches \n## Use saved searches to filter your results more quickly\nName\nQuery\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax). \nCancel  Create saved search \n[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Flancedb%2Fvectordb-recipes)\n[ Sign up ](https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=lancedb%2Fvectordb-recipes)\nAppearance settings\nResetting focus\nYou signed in with another tab or window. [Reload](https://github.com/lancedb/vectordb-recipes) to refresh your session. You signed out in another tab or window. [Reload](https://github.com/lancedb/vectordb-recipes) to refresh your session. You switched accounts on another tab or window. [Reload](https://github.com/lancedb/vectordb-recipes) to refresh your session. Dismiss alert\n{{ message }}\n[ lancedb ](https://github.com/lancedb) / **[vectordb-recipes](https://github.com/lancedb/vectordb-recipes) ** Public\n  * [ Notifications ](https://github.com/login?return_to=%2Flancedb%2Fvectordb-recipes) You must be signed in to change notification settings\n  * [ Fork 140 ](https://github.com/login?return_to=%2Flancedb%2Fvectordb-recipes)\n  * [ Star  772 ](https://github.com/login?return_to=%2Flancedb%2Fvectordb-recipes)\n\n\nHigh quality resources & applications for LLMs, multi-modal models and VectorDBs \n### License\n[ Apache-2.0 license ](https://github.com/lancedb/vectordb-recipes/blob/main/LICENSE)\n[ 772 stars ](https://github.com/lancedb/vectordb-recipes/stargazers) [ 140 forks ](https://github.com/lancedb/vectordb-recipes/forks) [ Branches ](https://github.com/lancedb/vectordb-recipes/branches) [ Tags ](https://github.com/lancedb/vectordb-recipes/tags) [ Activity ](https://github.com/lancedb/vectordb-recipes/activity)\n[ Star  ](https://github.com/login?return_to=%2Flancedb%2Fvectordb-recipes)\n[ Notifications ](https://github.com/login?return_to=%2Flancedb%2Fvectordb-recipes) You must be signed in to change notification settings\n  * [ Code ](https://github.com/lancedb/vectordb-recipes)\n  * [ Issues 2 ](https://github.com/lancedb/vectordb-recipes/issues)\n  * [ Pull requests 2 ](https://github.com/lancedb/vectordb-recipes/pulls)\n  * [ Actions ](https://github.com/lancedb/vectordb-recipes/actions)\n  * [ Projects 0 ](https://github.com/lancedb/vectordb-recipes/projects)\n  * [ Security ](https://github.com/lancedb/vectordb-recipes/security)\n[ ](https://github.com/lancedb/vectordb-recipes/security)\n[ ](https://github.com/lancedb/vectordb-recipes/security)\n[ ](https://github.com/lancedb/vectordb-recipes/security)\n### [ Uh oh!  ](https://github.com/lancedb/vectordb-recipes/security)\n[There was an error while loading. ](https://github.com/lancedb/vectordb-recipes/security)[Please reload this page](https://github.com/lancedb/vectordb-recipes).\n  * [ Insights ](https://github.com/lancedb/vectordb-recipes/pulse)\n\n\nAdditional navigation options\n  * [ Code  ](https://github.com/lancedb/vectordb-recipes)\n  * [ Issues  ](https://github.com/lancedb/vectordb-recipes/issues)\n  * [ Pull requests  ](https://github.com/lancedb/vectordb-recipes/pulls)\n  * [ Actions  ](https://github.com/lancedb/vectordb-recipes/actions)\n  * [ Projects  ](https://github.com/lancedb/vectordb-recipes/projects)\n  * [ Security  ](https://github.com/lancedb/vectordb-recipes/security)\n  * [ Insights  ](https://github.com/lancedb/vectordb-recipes/pulse)\n\n\n# lancedb/vectordb-recipes\nmain\n[**60** Branches](https://github.com/lancedb/vectordb-recipes/branches)[**0** Tags](https://github.com/lancedb/vectordb-recipes/tags)\n[](https://github.com/lancedb/vectordb-recipes/branches)[](https://github.com/lancedb/vectordb-recipes/tags)\nGo to file\nCode\n## Folders and files\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n## Latest commit\n[![PrashantDixit0](https://avatars.githubusercontent.com/u/54981696?v=4&size=40)](https://github.com/PrashantDixit0)[PrashantDixit0](https://github.com/lancedb/vectordb-recipes/commits?author=PrashantDixit0)[langchain version conflict fix](https://github.com/lancedb/vectordb-recipes/commit/c1d1c1fa11306987cfd620dd326ee753f23c3414)May 12, 2025[c1d1c1f](https://github.com/lancedb/vectordb-recipes/commit/c1d1c1fa11306987cfd620dd326ee753f23c3414) Â· May 12, 2025\n## History\n[894 Commits](https://github.com/lancedb/vectordb-recipes/commits/main/)[](https://github.com/lancedb/vectordb-recipes/commits/main/)  \n[.github/workflows](https://github.com/lancedb/vectordb-recipes/tree/main/.github/workflows \"This path skips through empty directories\")| [.github/workflows](https://github.com/lancedb/vectordb-recipes/tree/main/.github/workflows \"This path skips through empty directories\")| [lint test update (](https://github.com/lancedb/vectordb-recipes/commit/52a763bb8fcc0905cd4a7f91b1cb2cf4058719a0 \"lint test update \\(#211\\)\n* assests and app name\n* update README\n* demo gifs\n* talk with github codespaces\n* talk with github codespaces\n* gitignore\n* linted\n* added version\n* link fix\n* added local llm tag\n* crag\n* link fix\n* lint\n* llm tags\n* non-clickable badge\n* non-clickable badge\n* fix\n* tutorial llm tags\n* added instructions and fix\n* colab fix\n* fix\n* formatted\n* hybrid search and rag colab\n* colab format\n* python test\n* node test\n* python test\n* blog link update\n* rag mlx\n* myntra search engine app\n* link fix\n* CrewAI Example\n* lint\n* node test\n* node test\n* node test\n* added readme\n* support for Gemini Pro\n* fix\n* chunking techniques\n* lint\n* Locally RAG from Scratch\n* lint\n* llama3 added\n* link finx\n* sdk manual cli chatbot phidata\n* sdk manual cli chatbot phidata\n* link fix\n* tags\n* advanced\n* update readme\n* remove key\n* lint\n* formatting fixes\n* lint\n* updated image\n* added demo image\n* change autogen notebook\n* lint\n* lint\n* rag evaluation with ragas\n* README update\n* broken link fix\n* Restructured README\n* updated titles\n* restructed README\n* sectional description\n* lint\n* dataset with Instructor\n* lint\n* remove blog link\n* img update\n* broken link\n* structured dataset using Instructor\n* lint\n* lint test update\n* lint workflow test\n* linting\n* linting workflow\n* linting workflow test\n* linting workflow test\n* linting workflow test\n* linting workflow test\n* linting workflow test\")[#211](https://github.com/lancedb/vectordb-recipes/pull/211)[)](https://github.com/lancedb/vectordb-recipes/commit/52a763bb8fcc0905cd4a7f91b1cb2cf4058719a0 \"lint test update \\(#211\\)\n* assests and app name\n* update README\n* demo gifs\n* talk with github codespaces\n* talk with github codespaces\n* gitignore\n* linted\n* added version\n* link fix\n* added local llm tag\n* crag\n* link fix\n* lint\n* llm tags\n* non-clickable badge\n* non-clickable badge\n* fix\n* tutorial llm tags\n* added instructions and fix\n* colab fix\n* fix\n* formatted\n* hybrid search and rag colab\n* colab format\n* python test\n* node test\n* python test\n* blog link update\n* rag mlx\n* myntra search engine app\n* link fix\n* CrewAI Example\n* lint\n* node test\n* node test\n* node test\n* added readme\n* support for Gemini Pro\n* fix\n* chunking techniques\n* lint\n* Locally RAG from Scratch\n* lint\n* llama3 added\n* link finx\n* sdk manual cli chatbot phidata\n* sdk manual cli chatbot phidata\n* link fix\n* tags\n* advanced\n* update readme\n* remove key\n* lint\n* formatting fixes\n* lint\n* updated image\n* added demo image\n* change autogen notebook\n* lint\n* lint\n* rag evaluation with ragas\n* README update\n* broken link fix\n* Restructured README\n* updated titles\n* restructed README\n* sectional description\n* lint\n* dataset with Instructor\n* lint\n* remove blog link\n* img update\n* broken link\n* structured dataset using Instructor\n* lint\n* lint test update\n* lint workflow test\n* linting\n* linting workflow\n* linting workflow test\n* linting workflow test\n* linting workflow test\n* linting workflow test\n* linting workflow test\")| Jul 1, 2024  \n[.vscode](https://github.com/lancedb/vectordb-recipes/tree/main/.vscode \".vscode\")| [.vscode](https://github.com/lancedb/vectordb-recipes/tree/main/.vscode \".vscode\")| [example : zero shot image classification (](https://github.com/lancedb/vectordb-recipes/commit/5e0f1869491cba401cd4656b5a12a7cd7c45ffce \"example : zero shot image classification \\(#216\\)\")[#216](https://github.com/lancedb/vectordb-recipes/pull/216)[)](https://github.com/lancedb/vectordb-recipes/commit/5e0f1869491cba401cd4656b5a12a7cd7c45ffce \"example : zero shot image classification \\(#216\\)\")| Jul 12, 2024  \n[applications](https://github.com/lancedb/vectordb-recipes/tree/main/applications \"applications\")| [applications](https://github.com/lancedb/vectordb-recipes/tree/main/applications \"applications\")| [langchain version conflict](https://github.com/lancedb/vectordb-recipes/commit/43c70c5d95e5a60a6aa13efa53d5fdbc9277cb1f \"langchain version conflict\")| May 12, 2025  \n[assets](https://github.com/lancedb/vectordb-recipes/tree/main/assets \"assets\")| [assets](https://github.com/lancedb/vectordb-recipes/tree/main/assets \"assets\")| [Add hierarchical multi-agent node application](https://github.com/lancedb/vectordb-recipes/commit/fff622163de1f54b40cc0144d112f071ed3a3efa \"Add hierarchical multi-agent node application\")| Mar 22, 2025  \n[examples](https://github.com/lancedb/vectordb-recipes/tree/main/examples \"examples\")| [examples](https://github.com/lancedb/vectordb-recipes/tree/main/examples \"examples\")| [new RAG_from_Scratch](https://github.com/lancedb/vectordb-recipes/commit/31eb6636ac9e9840c3b2e682b47c57f483ea20cb \"new RAG_from_Scratch\")| Apr 21, 2025  \n[tutorials](https://github.com/lancedb/vectordb-recipes/tree/main/tutorials \"tutorials\")| [tutorials](https://github.com/lancedb/vectordb-recipes/tree/main/tutorials \"tutorials\")| [fixed notebook widget](https://github.com/lancedb/vectordb-recipes/commit/f45747beccdebc8fe3cd2d4e196e83c3a177dea2 \"fixed notebook widget\")| Apr 21, 2025  \n[.gitignore](https://github.com/lancedb/vectordb-recipes/blob/main/.gitignore \".gitignore\")| [.gitignore](https://github.com/lancedb/vectordb-recipes/blob/main/.gitignore \".gitignore\")| [Imagebind demo update (](https://github.com/lancedb/vectordb-recipes/commit/61db072e1dafe8f102d3d869311559b3960bdacc \"Imagebind demo update \\(#150\\)\")[#150](https://github.com/lancedb/vectordb-recipes/pull/150)[)](https://github.com/lancedb/vectordb-recipes/commit/61db072e1dafe8f102d3d869311559b3960bdacc \"Imagebind demo update \\(#150\\)\")| Mar 3, 2024  \n[LICENSE](https://github.com/lancedb/vectordb-recipes/blob/main/LICENSE \"LICENSE\")| [LICENSE](https://github.com/lancedb/vectordb-recipes/blob/main/LICENSE \"LICENSE\")| [Initial commit](https://github.com/lancedb/vectordb-recipes/commit/38a58552791924d31a861eed33f59d991daff6a3 \"Initial commit\")| Jun 25, 2023  \n[README.md](https://github.com/lancedb/vectordb-recipes/blob/main/README.md \"README.md\")| [README.md](https://github.com/lancedb/vectordb-recipes/blob/main/README.md \"README.md\")| [Update README.md](https://github.com/lancedb/vectordb-recipes/commit/cbfcb5ebe9bbd9494c211265ec58fc7c8c7eb303 \"Update README.md\")| Mar 22, 2025  \n[compile_testing.js](https://github.com/lancedb/vectordb-recipes/blob/main/compile_testing.js \"compile_testing.js\")| [compile_testing.js](https://github.com/lancedb/vectordb-recipes/blob/main/compile_testing.js \"compile_testing.js\")| [Fix (](https://github.com/lancedb/vectordb-recipes/commit/66dec3ba157bf74ec8f7bfe0cf2d3d394036c3dd \"Fix \\(#155\\)\n* assests and app name\n* update README\n* demo gifs\n* talk with github codespaces\n* talk with github codespaces\n* gitignore\n* linted\n* added version\n* link fix\n* added local llm tag\n* crag\n* link fix\n* lint\n* llm tags\n* non-clickable badge\n* non-clickable badge\n* fix\n* tutorial llm tags\n* added instructions and fix\n* colab fix\n* fix\n* formatted\n* hybrid search and rag colab\n* colab format\n* python test\n* node test\n* python test\")[#155](https://github.com/lancedb/vectordb-recipes/pull/155)[)](https://github.com/lancedb/vectordb-recipes/commit/66dec3ba157bf74ec8f7bfe0cf2d3d394036c3dd \"Fix \\(#155\\)\n* assests and app name\n* update README\n* demo gifs\n* talk with github codespaces\n* talk with github codespaces\n* gitignore\n* linted\n* added version\n* link fix\n* added local llm tag\n* crag\n* link fix\n* lint\n* llm tags\n* non-clickable badge\n* non-clickable badge\n* fix\n* tutorial llm tags\n* added instructions and fix\n* colab fix\n* fix\n* formatted\n* hybrid search and rag colab\n* colab format\n* python test\n* node test\n* python test\")| Mar 14, 2024  \n[package.json](https://github.com/lancedb/vectordb-recipes/blob/main/package.json \"package.json\")| [package.json](https://github.com/lancedb/vectordb-recipes/blob/main/package.json \"package.json\")| [test](https://github.com/lancedb/vectordb-recipes/commit/e6cd926f094e414e6c82d93deed1f33f15134395 \"test\")| Jul 29, 2023  \n[requirements.txt](https://github.com/lancedb/vectordb-recipes/blob/main/requirements.txt \"requirements.txt\")| [requirements.txt](https://github.com/lancedb/vectordb-recipes/blob/main/requirements.txt \"requirements.txt\")| [add pylance to requirements.txt (](https://github.com/lancedb/vectordb-recipes/commit/96c41bac77aa3bf52283ac44e87ec089dcfef89b \"add pylance to requirements.txt \\(#319\\)\")[#319](https://github.com/lancedb/vectordb-recipes/pull/319)[)](https://github.com/lancedb/vectordb-recipes/commit/96c41bac77aa3bf52283ac44e87ec089dcfef89b \"add pylance to requirements.txt \\(#319\\)\")| Mar 11, 2025  \nView all files  \n## Repository files navigation\n  * [README](https://github.com/lancedb/vectordb-recipes)\n  * [Apache-2.0 license](https://github.com/lancedb/vectordb-recipes)\n\n\n# VectorDB-recipes\n[](https://github.com/lancedb/vectordb-recipes#vectordb-recipes)\nDive into building GenAI applications! This repository contains examples, applications, starter code, & tutorials to help you kickstart your GenAI projects. \n  * These are built using LanceDB, a free, open-source, serverless vectorDB that **requires no setup**.\n  * It **integrates into Python data ecosystem** so you can simply start using these in your existing data pipelines in pandas, arrow, pydantic etc.\n  * LanceDB has **native Typescript SDK** using which you can **run vector search** in serverless functions!\n\n[![](https://private-user-images.githubusercontent.com/5846846/318060905-d284accb-24b9-4404-8605-56483160e579.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDg0ODc0MTgsIm5iZiI6MTc0ODQ4NzExOCwicGF0aCI6Ii81ODQ2ODQ2LzMxODA2MDkwNS1kMjg0YWNjYi0yNGI5LTQ0MDQtODYwNS01NjQ4MzE2MGU1NzkucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDUyOSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTA1MjlUMDI1MTU4WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YTM0OTcwNGI5NDhkNGJhZWVhMDEwZTAyZWIxMzQyZTRlOWNhNTg3NTlmYjgwMTFhODBiY2I1NmE3M2VhYzNhOSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.UDakFzbUSG3-iZDAORXYAvwcCdLgMFRpUJqM5MasRJ4)](https://private-user-images.githubusercontent.com/5846846/318060905-d284accb-24b9-4404-8605-56483160e579.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDg0ODc0MTgsIm5iZiI6MTc0ODQ4NzExOCwicGF0aCI6Ii81ODQ2ODQ2LzMxODA2MDkwNS1kMjg0YWNjYi0yNGI5LTQ0MDQtODYwNS01NjQ4MzE2MGU1NzkucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDUyOSUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTA1MjlUMDI1MTU4WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YTM0OTcwNGI5NDhkNGJhZWVhMDEwZTAyZWIxMzQyZTRlOWNhNTg3NTlmYjgwMTFhODBiY2I1NmE3M2VhYzNhOSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.UDakFzbUSG3-iZDAORXYAvwcCdLgMFRpUJqM5MasRJ4) Join our community for support - [Discord](https://discord.gg/zMM32dvNtd) â¢ [Twitter](https://twitter.com/lancedb)\nThis repository is divided into 2 sections:\n  * [Examples](https://github.com/lancedb/vectordb-recipes#examples) - Get right into the code with minimal introduction, aimed at getting you from an idea to PoC within minutes!\n  * [Applications](https://github.com/lancedb/vectordb-recipes#projects--applications) - Ready to use Python and web apps using applied LLMs, VectorDB and GenAI tools\n\n\nThe following examples are organized into different tables to make similar types of examples easily accessible.\n### Sections\n[](https://github.com/lancedb/vectordb-recipes#sections)\n  * [Build from Scratch](https://github.com/lancedb/vectordb-recipes#build-from-scratch) - Step-by-step guides to create AI applications from scratch.\n  * [Multimodal](https://github.com/lancedb/vectordb-recipes#multimodal) - Build apps that process and search across both text and images.\n  * [RAG](https://github.com/lancedb/vectordb-recipes#rag) - Combine document retrieval with LLM-powered responses.\n  * [Vector Search](https://github.com/lancedb/vectordb-recipes#vector-search) - Learn to efficiently find relevant documents using vector-based search.\n  * [Chatbot](https://github.com/lancedb/vectordb-recipes#chatbot) - Create AI chatbots that fetch information and generate intelligent replies.\n  * [Evalution](https://github.com/lancedb/vectordb-recipes#evaluation) - Measure the quality and accuracy of AI-generated answers.\n  * [AI Agents](https://github.com/lancedb/vectordb-recipes#ai-agents) - Build LLM-driven applications where multiple agents collaborate and interact.\n  * [Recommender Systems](https://github.com/lancedb/vectordb-recipes#recommender-systems) - Develop AI-powered recommendation systems for personalized suggestions.\n  * [Concepts](https://github.com/lancedb/vectordb-recipes#concepts) - Tutorials and explanations of key techniques used in AI applications.\n\n\n### ð New ð\n[](https://github.com/lancedb/vectordb-recipes#-new-)\nStay up to date with the latest projects, tools, and improvements added to the repository.\n  * Monitoring and Tracing RAG using HoneyHive : **HoneyHive x LanceDB** - [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/HoneyHive_x_LanceDB/HoneyHive_x_LanceDB.ipynb)\n\n\n### Build from Scratch\n[](https://github.com/lancedb/vectordb-recipes#build-from-scratch)\nStart with the basics! These examples guide you through creating AI applications from the ground up using LanceDB for efficient document retrieval and search.\nBuild from Scratch  | Interactive Notebook & Scripts   \n---|---  \n|   \n[Build RAG from Scratch](https://github.com/lancedb/vectordb-recipes/blob/main/tutorials/RAG-from-Scratch) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/tutorials/RAG-from-Scratch/RAG_from_Scratch.ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes)  \n[Local RAG from Scratch with Llama3](https://github.com/lancedb/vectordb-recipes/blob/main/tutorials/Local-RAG-from-Scratch) | [![Python](https://camo.githubusercontent.com/0d0779a129f1dcf6c31613b701fe0646fd4e4d2ed2a7cbd61b27fd5514baa938/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d3336373041303f7374796c653d666f722d7468652d6261646765266c6f676f3d707974686f6e266c6f676f436f6c6f723d666664643534)](https://github.com/lancedb/vectordb-recipes/blob/main/tutorials/Local-RAG-from-Scratch/rag.py) [![local LLM](https://camo.githubusercontent.com/8e5e068f5d204854633299f2e401fe80a7ee1e2f33d48bbc9854f1ca38c443d8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6f63616c2d6c6c6d2d677265656e)](https://github.com/lancedb/vectordb-recipes) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes)  \n[Multi-Head RAG from Scratch](https://github.com/lancedb/vectordb-recipes/blob/main/tutorials/Multi-Head-RAG-from-Scratch) | [![Python](https://camo.githubusercontent.com/0d0779a129f1dcf6c31613b701fe0646fd4e4d2ed2a7cbd61b27fd5514baa938/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d3336373041303f7374796c653d666f722d7468652d6261646765266c6f676f3d707974686f6e266c6f676f436f6c6f723d666664643534)](https://github.com/lancedb/vectordb-recipes/blob/main/tutorials/Multi-Head-RAG-from-Scratch/main.py) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![local LLM](https://camo.githubusercontent.com/8e5e068f5d204854633299f2e401fe80a7ee1e2f33d48bbc9854f1ca38c443d8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6f63616c2d6c6c6d2d677265656e)](https://github.com/lancedb/vectordb-recipes) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes)  \n[Fintech AI Agent from Scratch](https://github.com/lancedb/vectordb-recipes/blob/main/examples/fintech-ai-agent) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/fintech-ai-agent/fintech-ai-agent.ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![advanced](https://camo.githubusercontent.com/d12ae86d73cc13f67f57015080da3936c77e6b1dda6cbd5f03afe54d5285b5bc/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f616476616e6365642d464633333333)](https://github.com/lancedb/vectordb-recipes)  \n|   \n### MultiModal\n[](https://github.com/lancedb/vectordb-recipes#multimodal)\nSearch across different types of data (text, images, and more). Build powerful search applications that work with diverse inputs.\nMultimodal  | Interactive Notebook & Scripts  | Blog  \n---|---|---  \n|  |   \n[Multimodal CLIP: DiffusionDB](https://github.com/lancedb/vectordb-recipes/blob/main/examples/multimodal_clip_diffusiondb) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/multimodal_clip_diffusiondb/main.ipynb) [![Python](https://camo.githubusercontent.com/0d0779a129f1dcf6c31613b701fe0646fd4e4d2ed2a7cbd61b27fd5514baa938/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d3336373041303f7374796c653d666f722d7468652d6261646765266c6f676f3d707974686f6e266c6f676f436f6c6f723d666664643534)](https://github.com/lancedb/vectordb-recipes/blob/main/examples/multimodal_clip_diffusiondb/main.py) [![LLM](https://camo.githubusercontent.com/8e5e068f5d204854633299f2e401fe80a7ee1e2f33d48bbc9854f1ca38c443d8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6f63616c2d6c6c6d2d677265656e)](https://github.com/lancedb/vectordb-recipes) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/multi-modal-ai-made-easy-with-lancedb-clip-5aaf8801c939/)  \n[Multimodal CLIP: Youtube videos](https://github.com/lancedb/vectordb-recipes/blob/main/examples/multimodal_video_search) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/multimodal_video_search/main.ipynb) [![Python](https://camo.githubusercontent.com/0d0779a129f1dcf6c31613b701fe0646fd4e4d2ed2a7cbd61b27fd5514baa938/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d3336373041303f7374796c653d666f722d7468652d6261646765266c6f676f3d707974686f6e266c6f676f436f6c6f723d666664643534)](https://github.com/lancedb/vectordb-recipes/blob/main/examples/multimodal_video_search/main.py) [![LLM](https://camo.githubusercontent.com/8e5e068f5d204854633299f2e401fe80a7ee1e2f33d48bbc9854f1ca38c443d8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6f63616c2d6c6c6d2d677265656e)](https://github.com/lancedb/vectordb-recipes) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/multi-modal-ai-made-easy-with-lancedb-clip-5aaf8801c939/)  \n[Cambrian-1: Vision centric exploration of images](https://www.kaggle.com/code/prasantdixit/cambrian-1-vision-centric-exploration-of-images/) | [![Kaggle](https://camo.githubusercontent.com/c7135949c5c6882489e68f4af05a78a759460a4db256b86df3097e04419b4d9e/68747470733a2f2f6b6167676c652e636f6d2f7374617469632f696d616765732f6f70656e2d696e2d6b6167676c652e737667)](https://www.kaggle.com/code/prasantdixit/cambrian-1-vision-centric-exploration-of-images/) [![LLM](https://camo.githubusercontent.com/8e5e068f5d204854633299f2e401fe80a7ee1e2f33d48bbc9854f1ca38c443d8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6f63616c2d6c6c6d2d677265656e)](https://github.com/lancedb/vectordb-recipes) [![intermediate](https://camo.githubusercontent.com/e5434f1272ff67d7f42ea89b763774c6b579e6dffa75cf12b47855ab67910b51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e7465726d6564696174652d464644413333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/cambrian-1-vision-centric-exploration/)  \n[Multimodal Jina CLIP-V2 : Food Search ](https://github.com/lancedb/vectordb-recipes/blob/main/examples/multimodal_jina_clipv2) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/multimodal_jina_clipv2/main.ipynb) [![Python](https://camo.githubusercontent.com/0d0779a129f1dcf6c31613b701fe0646fd4e4d2ed2a7cbd61b27fd5514baa938/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d3336373041303f7374796c653d666f722d7468652d6261646765266c6f676f3d707974686f6e266c6f676f436f6c6f723d666664643534)](https://github.com/lancedb/vectordb-recipes/blob/main/examples/multimodal_jina_clipv2) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes) |   \n[Multimodal vector search: Voyage AI X LanceDB](https://github.com/lancedb/vectordb-recipes/blob/main/examples/voyagexlancedb) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/voyagexlancedb/Voyage_x_LanceDB.ipynb) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes) |   \n|  |   \n### RAG\n[](https://github.com/lancedb/vectordb-recipes#rag)\nGenerated Responses by retrieving relevant documents before answering. This section covers different approaches to implementing RAG in your projects.\nRAG  | Interactive Notebook & Scripts | Blog  \n---|---|---  \n|  |   \n[RAG using Deepseek R1 vs OpenAI o1](https://github.com/lancedb/vectordb-recipes/blob/main/examples/Deepseek_R1_VS_GPT_4o) | [![Python](https://camo.githubusercontent.com/0d0779a129f1dcf6c31613b701fe0646fd4e4d2ed2a7cbd61b27fd5514baa938/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d3336373041303f7374796c653d666f722d7468652d6261646765266c6f676f3d707974686f6e266c6f676f436f6c6f723d666664643534)](https://github.com/lancedb/vectordb-recipes/blob/main/examples/Deepseek_R1_VS_GPT_4o/README.md) [![Analysis](https://camo.githubusercontent.com/add728d6011b15be0262ee68e94580042086bd98650ce41b07d90c7e303e68ec/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f416e616c797369732d464633333333)](https://github.com/lancedb/vectordb-recipes) |   \n[RAG On PDF](https://github.com/lancedb/vectordb-recipes/blob/main/examples/RAG-On-PDF) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/RAG-On-PDF/main.ipynb) [![LLM](https://camo.githubusercontent.com/8e5e068f5d204854633299f2e401fe80a7ee1e2f33d48bbc9854f1ca38c443d8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6f63616c2d6c6c6d2d677265656e)](https://github.com/lancedb/vectordb-recipes) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes) |   \n[RAG with Contextual Retrieval and Hybrid search](https://github.com/lancedb/vectordb-recipes/blob/main/examples/Contextual-RAG) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/Contextual-RAG/Anthropic_Contextual_RAG.ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![intermediate](https://camo.githubusercontent.com/e5434f1272ff67d7f42ea89b763774c6b579e6dffa75cf12b47855ab67910b51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e7465726d6564696174652d464644413333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/guide-to-use-contextual-retrieval-and-prompt-caching-with-lancedb/)  \n[RAG with Matryoshka Embeddings and LlamaIndex](https://github.com/lancedb/vectordb-recipes/blob/main/tutorials/RAG-with_MatryoshkaEmbed-Llamaindex) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/tutorials/RAG-with_MatryoshkaEmbed-Llamaindex/RAG_with_MatryoshkaEmbedding_and_Llamaindex.ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![intermediate](https://camo.githubusercontent.com/e5434f1272ff67d7f42ea89b763774c6b579e6dffa75cf12b47855ab67910b51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e7465726d6564696174652d464644413333)](https://github.com/lancedb/vectordb-recipes) |   \n[RAG with IBM Watsonx](https://github.com/lancedb/vectordb-recipes/blob/main/examples/RAG-with-watsonx) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/RAG-with-watsonx/Watsonx_example.ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![watsonx LLM](https://camo.githubusercontent.com/66628862340cc827f541c6b169f96bdaed9381ad0a6efe9a21985667f25e6126/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f776174736f6e782d6170692d6c69676874626c7565)](https://github.com/lancedb/vectordb-recipes) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes) |   \n[Cognee RAG](https://github.com/lancedb/vectordb-recipes/blob/main/examples/cognee-RAG) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/cognee-RAG/cognee_demo.ipynb) |   \n[Improve RAG with Re-ranking](https://github.com/lancedb/vectordb-recipes/blob/main/examples/RAG_Reranking) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/RAG_Reranking/main.ipynb) [![LLM](https://camo.githubusercontent.com/8e5e068f5d204854633299f2e401fe80a7ee1e2f33d48bbc9854f1ca38c443d8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6f63616c2d6c6c6d2d677265656e)](https://github.com/lancedb/vectordb-recipes) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/simplest-method-to-improve-rag-pipeline-re-ranking-cf6eaec6d544)  \n[Instruct-Multitask](https://github.com/lancedb/vectordb-recipes/blob/main/examples/instruct-multitask) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/instruct-multitask/main.ipynb) [![Python](https://camo.githubusercontent.com/0d0779a129f1dcf6c31613b701fe0646fd4e4d2ed2a7cbd61b27fd5514baa938/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d3336373041303f7374796c653d666f722d7468652d6261646765266c6f676f3d707974686f6e266c6f676f436f6c6f723d666664643534)](https://github.com/lancedb/vectordb-recipes/blob/main/examples/instruct-multitask/main.py) [![LLM](https://camo.githubusercontent.com/8e5e068f5d204854633299f2e401fe80a7ee1e2f33d48bbc9854f1ca38c443d8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6f63616c2d6c6c6d2d677265656e)](https://github.com/lancedb/vectordb-recipes) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/multitask-embedding-with-lancedb-be18ec397543)  \n[Improve RAG with HyDE](https://github.com/lancedb/vectordb-recipes/blob/main/examples/Advance-RAG-with-HyDE) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/Advance-RAG-with-HyDE/main.ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![intermediate](https://camo.githubusercontent.com/e5434f1272ff67d7f42ea89b763774c6b579e6dffa75cf12b47855ab67910b51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e7465726d6564696174652d464644413333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/advanced-rag-precise-zero-shot-dense-retrieval-with-hyde-0946c54dfdcb)  \n[Improve RAG with LOTR ](https://github.com/lancedb/vectordb-recipes/blob/main/examples/Advance_RAG_LOTR) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/Advance_RAG_LOTR/main.ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![intermediate](https://camo.githubusercontent.com/e5434f1272ff67d7f42ea89b763774c6b579e6dffa75cf12b47855ab67910b51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e7465726d6564696174652d464644413333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/better-rag-with-lotr-lord-of-retriever-23c8336b9a35)  \n[Advanced RAG: Context Enrichment Window](https://github.com/lancedb/vectordb-recipes/blob/main/examples/Advanced_RAG_Context_Enrichment_Window) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/Advanced_RAG_Context_Enrichment_Window/Advanced_RAG_Context_Enrichment_Window.ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![intermediate](https://camo.githubusercontent.com/e5434f1272ff67d7f42ea89b763774c6b579e6dffa75cf12b47855ab67910b51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e7465726d6564696174652d464644413333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/https://blog.lancedb.com/advanced-rag-context-enrichment-window/)  \n[Advanced RAG: Late Chunking](https://github.com/lancedb/vectordb-recipes/blob/main/examples/Advanced_RAG_Late_Chunking) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/Advanced_RAG_Late_Chunking/Late_Chunking_\\(Chunked_Pooling\\).ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![intermediate](https://camo.githubusercontent.com/e5434f1272ff67d7f42ea89b763774c6b579e6dffa75cf12b47855ab67910b51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e7465726d6564696174652d464644413333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/late-chunking-aka-chunked-pooling-2/)  \n[Advanced RAG: Parent Document Retriever](https://github.com/lancedb/vectordb-recipes/blob/main/examples/parent_document_retriever) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/parent_document_retriever/main.ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![intermediate](https://camo.githubusercontent.com/e5434f1272ff67d7f42ea89b763774c6b579e6dffa75cf12b47855ab67910b51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e7465726d6564696174652d464644413333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/modified-rag-parent-document-bigger-chunk-retriever-62b3d1e79bc6)  \n[Corrective RAG with Langgraph](https://github.com/lancedb/vectordb-recipes/blob/main/tutorials/Corrective-RAG-with_Langgraph) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/tutorials/Corrective-RAG-with_Langgraph/CRAG_with_Langgraph.ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![intermediate](https://camo.githubusercontent.com/e5434f1272ff67d7f42ea89b763774c6b579e6dffa75cf12b47855ab67910b51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e7465726d6564696174652d464644413333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/implementing-corrective-rag-in-the-easiest-way-2/)  \n[Contextual-Compression-with-RAG](https://github.com/lancedb/vectordb-recipes/blob/main/examples/Contextual-Compression-with-RAG) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/Contextual-Compression-with-RAG/main.ipynb) [![local LLM](https://camo.githubusercontent.com/8e5e068f5d204854633299f2e401fe80a7ee1e2f33d48bbc9854f1ca38c443d8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6f63616c2d6c6c6d2d677265656e)](https://github.com/lancedb/vectordb-recipes) [![intermediate](https://camo.githubusercontent.com/e5434f1272ff67d7f42ea89b763774c6b579e6dffa75cf12b47855ab67910b51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e7465726d6564696174652d464644413333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/enhance-rag-integrate-contextual-compression-and-filtering-for-precision-a29d4a810301/)  \n[Improve RAG with FLARE](https://github.com/lancedb/vectordb-recipes/blob/main/examples/better-rag-FLAIR) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/better-rag-FLAIR/main.ipynb) [![local LLM](https://camo.githubusercontent.com/8e5e068f5d204854633299f2e401fe80a7ee1e2f33d48bbc9854f1ca38c443d8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6f63616c2d6c6c6d2d677265656e)](https://github.com/lancedb/vectordb-recipes) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![advanced](https://camo.githubusercontent.com/d12ae86d73cc13f67f57015080da3936c77e6b1dda6cbd5f03afe54d5285b5bc/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f616476616e6365642d464633333333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/better-rag-with-active-retrieval-augmented-generation-flare-3b66646e2a9f/)  \n[Agentic RAG ](https://github.com/lancedb/vectordb-recipes/blob/main/tutorials/Agentic_RAG) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/tutorials/Agentic_RAG/main.ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![advanced](https://camo.githubusercontent.com/d12ae86d73cc13f67f57015080da3936c77e6b1dda6cbd5f03afe54d5285b5bc/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f616476616e6365642d464633333333)](https://github.com/lancedb/vectordb-recipes) |   \n[GraphRAG ](https://github.com/lancedb/vectordb-recipes/blob/main/examples/Graphrag) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/Graphrag/main.ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![intermediate](https://camo.githubusercontent.com/e5434f1272ff67d7f42ea89b763774c6b579e6dffa75cf12b47855ab67910b51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e7465726d6564696174652d464644413333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/graphrag-hierarchical-approach-to-retrieval-augmented-generation/)  \n[GraphRAG with CSV File ](https://github.com/lancedb/vectordb-recipes/blob/main/tutorials/GraphRAG_CSV) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/tutorials/GraphRAG_CSV/main.ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![intermediate](https://camo.githubusercontent.com/e5434f1272ff67d7f42ea89b763774c6b579e6dffa75cf12b47855ab67910b51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e7465726d6564696174652d464644413333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://aksdesai1998.medium.com/optimizing-graphrag-with-microsoft-for-csv-data-a-guide-with-lancedb-8e4150b93e37)  \n[GraphRAG with cognee - Multimedia ](https://github.com/lancedb/vectordb-recipes/blob/main/tutorials/GraphRAG_with_cognee) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/tutorials/GraphRAG_with_cognee/cognee_multimedia_demo.ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![intermediate](https://camo.githubusercontent.com/e5434f1272ff67d7f42ea89b763774c6b579e6dffa75cf12b47855ab67910b51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e7465726d6564696174652d464644413333)](https://github.com/lancedb/vectordb-recipes) |   \n|  |   \n### Vector Search\n[](https://github.com/lancedb/vectordb-recipes#vector-search)\nFind relevant documents quickly! These projects show how to use vector-based search techniques to make AI-powered searches faster and smarter.\nVector Search  | Interactive Notebook & Scripts  | Blog  \n---|---|---  \n|  |   \n[Inbuilt Hybrid Search](https://github.com/lancedb/vectordb-recipes/blob/main/examples/Inbuilt-Hybrid-Search) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/Inbuilt-Hybrid-Search/Inbuilt_Hybrid_Search_with_LanceDB.ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes) |   \n[Hybrid search BM25 & lancedb ](https://github.com/lancedb/vectordb-recipes/blob/main/examples/Hybrid_search_bm25_lancedb) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/Hybrid_search_bm25_lancedb/main.ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/hybrid-search-combining-bm25-and-semantic-search-for-better-results-with-lan-1358038fe7e6)  \n[NER powered Semantic Search](https://github.com/lancedb/vectordb-recipes/blob/main/tutorials/NER-powered-Semantic-Search) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/tutorials/NER-powered-Semantic-Search/NER_powered_Semantic_Search_with_LanceDB.ipynb) [![local LLM](https://camo.githubusercontent.com/8e5e068f5d204854633299f2e401fe80a7ee1e2f33d48bbc9854f1ca38c443d8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6f63616c2d6c6c6d2d677265656e)](https://github.com/lancedb/vectordb-recipes) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/ner-powered-semantic-search-using-lancedb-51051dc3e493)  \n[Vector Arithmetic with LanceDB](https://github.com/lancedb/vectordb-recipes/blob/main/examples/Vector-Arithmetic-with-LanceDB) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/Vector-Arithmetic-with-LanceDB/main.ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/vector-arithmetic-with-lancedb-an-intro-to-vector-embeddings/)  \n[Summarize and Search Reddit Posts](https://github.com/lancedb/vectordb-recipes/blob/main/examples/Reddit-summarization-and-search) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://github.com/lancedb/vectordb-recipes/blob/main/examples/Reddit-summarization-and-search/subreddit_summarization_querying.ipynb) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes) |   \n[Imagebind demo app](https://github.com/lancedb/vectordb-recipes/blob/main/examples/imagebind_demo) | [![hf spaces](https://camo.githubusercontent.com/c6a4854abec5f79297fdcf4c12e281dcdcc2440416fd8be55f19548d88ed7ad5/68747470733a2f2f68756767696e67666163652e636f2f64617461736574732f68756767696e67666163652f6272616e642d6173736574732f7265736f6c76652f6d61696e2f68662d6c6f676f2d776974682d7469746c652e737667)](https://huggingface.co/spaces/raghavd99/imagebind2) [![intermediate](https://camo.githubusercontent.com/e5434f1272ff67d7f42ea89b763774c6b579e6dffa75cf12b47855ab67910b51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e7465726d6564696174652d464644413333)](https://github.com/lancedb/vectordb-recipes) |   \n[Search Within Images](https://github.com/lancedb/vectordb-recipes/blob/main/examples/search-within-images-with-sam-and-clip) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/search-within-images-with-sam-and-clip/main.ipynb) [![local LLM](https://camo.githubusercontent.com/8e5e068f5d204854633299f2e401fe80a7ee1e2f33d48bbc9854f1ca38c443d8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6f63616c2d6c6c6d2d677265656e)](https://github.com/lancedb/vectordb-recipes) [![intermediate](https://camo.githubusercontent.com/e5434f1272ff67d7f42ea89b763774c6b579e6dffa75cf12b47855ab67910b51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e7465726d6564696174652d464644413333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/search-within-an-image-331b54e4285e)  \n[Zero Shot Object Detection with CLIP](https://github.com/lancedb/vectordb-recipes/blob/main/examples/zero-shot-object-detection-CLIP) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/zero-shot-object-detection-CLIP/zero_shot_object_detection_clip.ipynb) [![intermediate](https://camo.githubusercontent.com/e5434f1272ff67d7f42ea89b763774c6b579e6dffa75cf12b47855ab67910b51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e7465726d6564696174652d464644413333)](https://github.com/lancedb/vectordb-recipes) |   \n[Vector Search with TransformersJS](https://github.com/lancedb/vectordb-recipes/blob/main/examples/js-transformers) | [![JS](https://camo.githubusercontent.com/29d02b3669d6450d67e043cf5909e740dcb94c1e2306d88ac48b15b4ec55dc65/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6a6176617363726970742d2532333332333333302e7376673f7374796c653d666f722d7468652d6261646765266c6f676f3d6a617661736372697074266c6f676f436f6c6f723d253233463744463145)](https://github.com/lancedb/vectordb-recipes/blob/main/examples/js-transformers/index.js) [![LLM](https://camo.githubusercontent.com/8e5e068f5d204854633299f2e401fe80a7ee1e2f33d48bbc9854f1ca38c443d8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6f63616c2d6c6c6d2d677265656e)](https://github.com/lancedb/vectordb-recipes) [![advanced](https://camo.githubusercontent.com/d12ae86d73cc13f67f57015080da3936c77e6b1dda6cbd5f03afe54d5285b5bc/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f616476616e6365642d464633333333)](https://github.com/lancedb/vectordb-recipes) |   \n[Geospatial Recommendation System](https://github.com/lancedb/vectordb-recipes/blob/main/examples/Geospatial-Recommendation-System) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/Geospatial-Recommendation-System/geospatial-recommendation.ipynb) [![LLM](https://camo.githubusercontent.com/8e5e068f5d204854633299f2e401fe80a7ee1e2f33d48bbc9854f1ca38c443d8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6f63616c2d6c6c6d2d677265656e)](https://github.com/lancedb/vectordb-recipes) [![intermediate](https://camo.githubusercontent.com/e5434f1272ff67d7f42ea89b763774c6b579e6dffa75cf12b47855ab67910b51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e7465726d6564696174652d464644413333)](https://github.com/lancedb/vectordb-recipes) |   \n[Accelerate Vector Search Applications Using OpenVINO](https://github.com/lancedb/vectordb-recipes/blob/main/examples/Accelerate-Vector-Search-Applications-Using-OpenVINO) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/Accelerate-Vector-Search-Applications-Using-OpenVINO/clip_text_image_search.ipynb) [![local LLM](https://camo.githubusercontent.com/8e5e068f5d204854633299f2e401fe80a7ee1e2f33d48bbc9854f1ca38c443d8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6f63616c2d6c6c6d2d677265656e)](https://github.com/lancedb/vectordb-recipes) [![advanced](https://camo.githubusercontent.com/d12ae86d73cc13f67f57015080da3936c77e6b1dda6cbd5f03afe54d5285b5bc/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f616476616e6365642d464633333333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/accelerate-vector-search-applications-using-openvino-lancedb/)  \n|  |   \n### Chatbot\n[](https://github.com/lancedb/vectordb-recipes#chatbot)\nCreate chatbots that understand user queries and fetch relevant responses using LanceDBâs vector search capabilities.\nChatbot  | Interactive Notebook & Scripts  | Blog   \n---|---|---  \n|  |   \n[Databricks DBRX Website Bot](https://github.com/lancedb/vectordb-recipes/blob/main/examples/databricks_DBRX_website_bot) | [![Python](https://camo.githubusercontent.com/0d0779a129f1dcf6c31613b701fe0646fd4e4d2ed2a7cbd61b27fd5514baa938/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d3336373041303f7374796c653d666f722d7468652d6261646765266c6f676f3d707974686f6e266c6f676f436f6c6f723d666664643534)](https://github.com/lancedb/vectordb-recipes/blob/main/examples/databricks_DBRX_website_bot/main.py) [![Databricks LLM](https://camo.githubusercontent.com/760e31c337cd62603281543c087f1bbd5f5f377c29ce7bb884966f74fef0e5e6/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f64617461627269636b732d6170692d726564)](https://github.com/lancedb/vectordb-recipes) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes) |   \n[CLI-based SDK Manual Chatbot with Phidata](https://github.com/lancedb/vectordb-recipes/blob/main/examples/CLI-SDK-Manual-Chatbot-Locally) | [![Python](https://camo.githubusercontent.com/0d0779a129f1dcf6c31613b701fe0646fd4e4d2ed2a7cbd61b27fd5514baa938/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d3336373041303f7374796c653d666f722d7468652d6261646765266c6f676f3d707974686f6e266c6f676f436f6c6f723d666664643534)](https://github.com/lancedb/vectordb-recipes/blob/main/examples/CLI-SDK-Manual-Chatbot-Locally/assistant.py) [![local LLM](https://camo.githubusercontent.com/8e5e068f5d204854633299f2e401fe80a7ee1e2f33d48bbc9854f1ca38c443d8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6f63616c2d6c6c6d2d677265656e)](https://github.com/lancedb/vectordb-recipes) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes) |   \n[Youtube transcript search bot](https://github.com/lancedb/vectordb-recipes/blob/main/examples/Youtube-Search-QA-Bot) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/Youtube-Search-QA-Bot/main.ipynb) [![Python](https://camo.githubusercontent.com/0d0779a129f1dcf6c31613b701fe0646fd4e4d2ed2a7cbd61b27fd5514baa938/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d3336373041303f7374796c653d666f722d7468652d6261646765266c6f676f3d707974686f6e266c6f676f436f6c6f723d666664643534)](https://github.com/lancedb/vectordb-recipes/blob/main/examples/Youtube-Search-QA-Bot/main.py) [![JS](https://camo.githubusercontent.com/29d02b3669d6450d67e043cf5909e740dcb94c1e2306d88ac48b15b4ec55dc65/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6a6176617363726970742d2532333332333333302e7376673f7374796c653d666f722d7468652d6261646765266c6f676f3d6a617661736372697074266c6f676f436f6c6f723d253233463744463145)](https://github.com/lancedb/vectordb-recipes/blob/main/examples/Youtube-Search-QA-Bot/index.js) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![intermediate](https://camo.githubusercontent.com/e5434f1272ff67d7f42ea89b763774c6b579e6dffa75cf12b47855ab67910b51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e7465726d6564696174652d464644413333)](https://github.com/lancedb/vectordb-recipes) |   \n[Langchain: Code Docs QA bot](https://github.com/lancedb/vectordb-recipes/blob/main/examples/Code-Documentation-QA-Bot) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/Code-Documentation-QA-Bot/main.ipynb) [![Python](https://camo.githubusercontent.com/0d0779a129f1dcf6c31613b701fe0646fd4e4d2ed2a7cbd61b27fd5514baa938/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d3336373041303f7374796c653d666f722d7468652d6261646765266c6f676f3d707974686f6e266c6f676f436f6c6f723d666664643534)](https://github.com/lancedb/vectordb-recipes/blob/main/examples/Code-Documentation-QA-Bot/main.py) [![JS](https://camo.githubusercontent.com/29d02b3669d6450d67e043cf5909e740dcb94c1e2306d88ac48b15b4ec55dc65/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6a6176617363726970742d2532333332333333302e7376673f7374796c653d666f722d7468652d6261646765266c6f676f3d6a617661736372697074266c6f676f436f6c6f723d253233463744463145)](https://github.com/lancedb/vectordb-recipes/blob/main/examples/Code-Documentation-QA-Bot/index.js) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![intermediate](https://camo.githubusercontent.com/e5434f1272ff67d7f42ea89b763774c6b579e6dffa75cf12b47855ab67910b51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e7465726d6564696174652d464644413333)](https://github.com/lancedb/vectordb-recipes) |   \n[Chatbot with any website using Crawl4AI ](https://github.com/lancedb/vectordb-recipes/blob/main/examples/CrawlerQ&A_website) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/CrawlerQ&A_website/main.ipynb) [![Python](https://camo.githubusercontent.com/0d0779a129f1dcf6c31613b701fe0646fd4e4d2ed2a7cbd61b27fd5514baa938/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d3336373041303f7374796c653d666f722d7468652d6261646765266c6f676f3d707974686f6e266c6f676f436f6c6f723d666664643534)](https://github.com/lancedb/vectordb-recipes/blob/main/examples/Code-Documentation-QA-Bot/main.py) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes) |   \n[Context-Aware Chatbot using Llama 2 & LanceDB](https://github.com/lancedb/vectordb-recipes/blob/main/tutorials/chatbot_using_Llama2_&_lanceDB) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/tutorials/chatbot_using_Llama2_&_lanceDB/main.ipynb) [![local LLM](https://camo.githubusercontent.com/8e5e068f5d204854633299f2e401fe80a7ee1e2f33d48bbc9854f1ca38c443d8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6f63616c2d6c6c6d2d677265656e)](https://github.com/lancedb/vectordb-recipes) [![advanced](https://camo.githubusercontent.com/d12ae86d73cc13f67f57015080da3936c77e6b1dda6cbd5f03afe54d5285b5bc/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f616476616e6365642d464633333333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/context-aware-chatbot-using-llama-2-lancedb-as-vector-database-4d771d95c755)  \n|  |   \n### Evaluation\n[](https://github.com/lancedb/vectordb-recipes#evaluation)\nThese projects provide tools to compare AI-generated responses against reference data and fine-tune accuracy.\nEvaluation  | Interactive Notebook & Scripts  | Blog  \n---|---|---  \n|  |   \n[Monitoring and Tracing RAG using HoneyHive](https://github.com/lancedb/vectordb-recipes/blob/main/examples/HoneyHive_x_LanceDB) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/HoneyHive_x_LanceDB/HoneyHive_x_LanceDB.ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes) |   \n[Evaluating RAG with RAGAs](https://github.com/lancedb/vectordb-recipes/blob/main/examples/Evaluating_RAG_with_RAGAs) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/Evaluating_RAG_with_RAGAs/Evaluating_RAG_with_RAGAs.ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![intermediate](https://camo.githubusercontent.com/e5434f1272ff67d7f42ea89b763774c6b579e6dffa75cf12b47855ab67910b51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e7465726d6564696174652d464644413333)](https://github.com/lancedb/vectordb-recipes) |   \n|  |   \n### AI Agents\n[](https://github.com/lancedb/vectordb-recipes#ai-agents)\nBuild applications where multiple AI agents interact to complete tasks efficiently. These projects show how agents can collaborate, exchange data, and automate workflows.\nAI Agents  | Interactive Notebook & Scripts  | Blog  \n---|---|---  \n|  |   \n[Trip Planner Swarm style Agent ](https://github.com/lancedb/vectordb-recipes/blob/main/examples/Trip_planner_swarm_style_agent) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/Trip_planner_swarm_style_agent/Trip_planner_agent.ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![intermediate](https://camo.githubusercontent.com/e5434f1272ff67d7f42ea89b763774c6b579e6dffa75cf12b47855ab67910b51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e7465726d6564696174652d464644413333)](https://github.com/lancedb/vectordb-recipes) |   \n[Multi Source Agent ](https://github.com/lancedb/vectordb-recipes/blob/main/examples/Multi-source-Agent) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/Multi-source-Agent/Multi_source_RAG_Agent.ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes) |   \n[AI email assistant with Composio](https://github.com/lancedb/vectordb-recipes/blob/main/examples/AI-Email-Assistant-with-Composio) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/AI-Email-Assistant-with-Composio/composio-lance.ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes) |   \n[Assitant Bot with OpenAI Swarm](https://github.com/lancedb/vectordb-recipes/blob/main/examples/assistance-bot-with-swarm) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/assistance-bot-with-swarm/assitant_bot_with_swarm.ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![intermediate](https://camo.githubusercontent.com/e5434f1272ff67d7f42ea89b763774c6b579e6dffa75cf12b47855ab67910b51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e7465726d6564696174652d464644413333)](https://github.com/lancedb/vectordb-recipes) |   \n[AI Trends Searcher with CrewAI](https://github.com/lancedb/vectordb-recipes/blob/main/examples/AI-Trends-with-CrewAI) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/AI-Trends-with-CrewAI/CrewAI_AI_Trends.ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/track-ai-trends-crewai-agents-rag/)  \n[SuperAgent Autogen](https://github.com/lancedb/vectordb-recipes/blob/main/examples/SuperAgent_Autogen) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/SuperAgent_Autogen/main.ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![intermediate](https://camo.githubusercontent.com/e5434f1272ff67d7f42ea89b763774c6b579e6dffa75cf12b47855ab67910b51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e7465726d6564696174652d464644413333)](https://github.com/lancedb/vectordb-recipes) |   \n[Build autonomous Customer support agent using Langgraph](https://github.com/lancedb/vectordb-recipes/blob/main/examples/customer_support_agent_langgraph/LangGraph_LanceDB.ipynb) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main//examples/customer_support_agent_langgraph/LangGraph_LanceDB.ipynb) [![intermediate](https://camo.githubusercontent.com/e5434f1272ff67d7f42ea89b763774c6b579e6dffa75cf12b47855ab67910b51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e7465726d6564696174652d464644413333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/agentic-rag-using-langgraph-building-a-simple-customer-support-autonomous-agent/)  \n[AI Agents: Reducing Hallucination](https://github.com/lancedb/vectordb-recipes/blob/main/examples/reducing_hallucinations_ai_agents) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/reducing_hallucinations_ai_agents/main.ipynb) [![Python](https://camo.githubusercontent.com/0d0779a129f1dcf6c31613b701fe0646fd4e4d2ed2a7cbd61b27fd5514baa938/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d3336373041303f7374796c653d666f722d7468652d6261646765266c6f676f3d707974686f6e266c6f676f436f6c6f723d666664643534)](https://github.com/lancedb/vectordb-recipes/blob/main/examples/reducing_hallucinations_ai_agents/main.py) [![JS](https://camo.githubusercontent.com/29d02b3669d6450d67e043cf5909e740dcb94c1e2306d88ac48b15b4ec55dc65/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6a6176617363726970742d2532333332333333302e7376673f7374796c653d666f722d7468652d6261646765266c6f676f3d6a617661736372697074266c6f676f436f6c6f723d253233463744463145)](https://github.com/lancedb/vectordb-recipes/blob/main/examples/reducing_hallucinations_ai_agents/index.js) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![advanced](https://camo.githubusercontent.com/d12ae86d73cc13f67f57015080da3936c77e6b1dda6cbd5f03afe54d5285b5bc/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f616476616e6365642d464633333333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/how-to-reduce-hallucinations-from-llm-powered-agents-using-long-term-memory-72f262c3cc1f/)  \n[Multi Document Agentic RAG](https://github.com/lancedb/vectordb-recipes/blob/main/examples/multi-document-agentic-rag) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/multi-document-agentic-rag/main.ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![advanced](https://camo.githubusercontent.com/d12ae86d73cc13f67f57015080da3936c77e6b1dda6cbd5f03afe54d5285b5bc/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f616476616e6365642d464633333333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/multi-document-agentic-rag/)  \n[RASA: Customer Support Bot](https://github.com/lancedb/vectordb-recipes/blob/main/examples/RASA_Customer-support-bot) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/RASA_Customer-support-bot/main.ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![advanced](https://camo.githubusercontent.com/d12ae86d73cc13f67f57015080da3936c77e6b1dda6cbd5f03afe54d5285b5bc/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f616476616e6365642d464633333333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/customer-support-bot-rasa-x-lancedb/)  \n|  |   \n### Recommender Systems\n[](https://github.com/lancedb/vectordb-recipes#recommender-systems)\nPersonalized AI recommendations! These projects help you build recommendation engines that suggest content based on user preferences.\nRecommender Systems | Interactive Notebook & Scripts  | Blog  \n---|---|---  \n|  |   \n[Movie Recommender](https://github.com/lancedb/vectordb-recipes/blob/main/examples/movie-recommender) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/movie-recommender/main.ipynb) [![Python](https://camo.githubusercontent.com/0d0779a129f1dcf6c31613b701fe0646fd4e4d2ed2a7cbd61b27fd5514baa938/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d3336373041303f7374796c653d666f722d7468652d6261646765266c6f676f3d707974686f6e266c6f676f436f6c6f723d666664643534)](https://github.com/lancedb/vectordb-recipes/blob/main/examples/movie-recommender/main.py) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes) |   \n[Product Recommender](https://github.com/lancedb/vectordb-recipes/blob/main/examples/product-recommender) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/product-recommender/main.ipynb) [![Python](https://camo.githubusercontent.com/0d0779a129f1dcf6c31613b701fe0646fd4e4d2ed2a7cbd61b27fd5514baa938/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d3336373041303f7374796c653d666f722d7468652d6261646765266c6f676f3d707974686f6e266c6f676f436f6c6f723d666664643534)](https://github.com/lancedb/vectordb-recipes/blob/main/examples/product-recommender/main.py) [![intermediate](https://camo.githubusercontent.com/e5434f1272ff67d7f42ea89b763774c6b579e6dffa75cf12b47855ab67910b51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e7465726d6564696174652d464644413333)](https://github.com/lancedb/vectordb-recipes) |   \n[Arxiv paper recommender](https://github.com/lancedb/vectordb-recipes/blob/main/examples/arxiv-recommender) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/arxiv-recommender/main.ipynb) [![Python](https://camo.githubusercontent.com/0d0779a129f1dcf6c31613b701fe0646fd4e4d2ed2a7cbd61b27fd5514baa938/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d3336373041303f7374796c653d666f722d7468652d6261646765266c6f676f3d707974686f6e266c6f676f436f6c6f723d666664643534)](https://github.com/lancedb/vectordb-recipes/blob/main/examples/arxiv-recommender/main.py) [![LLM](https://camo.githubusercontent.com/8e5e068f5d204854633299f2e401fe80a7ee1e2f33d48bbc9854f1ca38c443d8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6f63616c2d6c6c6d2d677265656e)](https://github.com/lancedb/vectordb-recipes) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes) |   \n[Music Recommender](https://github.com/lancedb/vectordb-recipes/blob/main/applications/Music_Recommendation) | [![Python](https://camo.githubusercontent.com/0d0779a129f1dcf6c31613b701fe0646fd4e4d2ed2a7cbd61b27fd5514baa938/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d3336373041303f7374796c653d666f722d7468652d6261646765266c6f676f3d707974686f6e266c6f676f436f6c6f723d666664643534)](https://github.com/lancedb/vectordb-recipes/blob/main/applications/Music_Recommendation/app_music.py) [![intermediate](https://camo.githubusercontent.com/e5434f1272ff67d7f42ea89b763774c6b579e6dffa75cf12b47855ab67910b51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e7465726d6564696174652d464644413333)](https://github.com/lancedb/vectordb-recipes) |   \n|  |   \n### Concepts\n[](https://github.com/lancedb/vectordb-recipes#concepts)\nLearn the core ideas behind AI applicationsâincluding text chunking, retrieval strategies, and optimization techniquesâto improve your understanding of vector search and AI pipelines.\nConcepts | Interactive Notebook | Blog  \n---|---|---  \n|  |   \n[A Primer on Text Chunking and its Types](https://github.com/lancedb/vectordb-recipes/blob/main/tutorials/different-types-text-chunking-in-RAG) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/tutorials/different-types-text-chunking-in-RAG/Text_Chunking_on_RAG_application_with_LanceDB.ipynb) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/a-primer-on-text-chunking-and-its-types-a420efc96a13)  \n[Langchain LlamaIndex Chunking](https://github.com/lancedb/vectordb-recipes/blob/main/tutorials/Langchain-LlamaIndex-Chunking) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/tutorials/Langchain-LlamaIndex-Chunking/Langchain_Llamaindex_chunking.ipynb) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/chunking-techniques-with-langchain-and-llamaindex/)  \n[Create structured dataset using Instructor](https://github.com/lancedb/vectordb-recipes/blob/main/tutorials/NER-dataset-with-Instructor) | [![Python](https://camo.githubusercontent.com/0d0779a129f1dcf6c31613b701fe0646fd4e4d2ed2a7cbd61b27fd5514baa938/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d3336373041303f7374796c653d666f722d7468652d6261646765266c6f676f3d707974686f6e266c6f676f436f6c6f723d666664643534)](https://github.com/lancedb/vectordb-recipes/blob/main/tutorials/NER-dataset-with-Instructor/main.py) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes) |   \n[Comparing Cohere Rerankers with LanceDB](https://github.com/lancedb/vectordb-recipes/blob/main/tutorials/cohere-reranker) | [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/benchmarking-cohere-reranker-with-lancedb/)  \n[Product Quantization: Compress High Dimensional Vectors](https://blog.lancedb.com/benchmarking-lancedb-92b01032874a-2/) | [![intermediate](https://camo.githubusercontent.com/e5434f1272ff67d7f42ea89b763774c6b579e6dffa75cf12b47855ab67910b51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e7465726d6564696174652d464644413333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/benchmarking-lancedb-92b01032874a-2/)  \n[LLMs, RAG, & the missing storage layer for AI](https://blog.lancedb.com/llms-rag-the-missing-storage-layer-for-ai-28ded35fa984) | [![intermediate](https://camo.githubusercontent.com/e5434f1272ff67d7f42ea89b763774c6b579e6dffa75cf12b47855ab67910b51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e7465726d6564696174652d464644413333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/llms-rag-the-missing-storage-layer-for-ai-28ded35fa984/)  \n[Fine-Tuning LLM using PEFT & QLoRA](https://github.com/lancedb/vectordb-recipes/blob/main/tutorials/fine-tuning_LLM_with_PEFT_QLoRA) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/tutorials/fine-tuning_LLM_with_PEFT_QLoRA/main.ipynb) [![local LLM](https://camo.githubusercontent.com/8e5e068f5d204854633299f2e401fe80a7ee1e2f33d48bbc9854f1ca38c443d8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6f63616c2d6c6c6d2d677265656e)](https://github.com/lancedb/vectordb-recipes) [![advanced](https://camo.githubusercontent.com/d12ae86d73cc13f67f57015080da3936c77e6b1dda6cbd5f03afe54d5285b5bc/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f616476616e6365642d464633333333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/optimizing-llms-a-step-by-step-guide-to-fine-tuning-with-peft-and-qlora-22eddd13d25b)  \n[Extracting Complex tables-text from PDFs using LlamaParse ](https://github.com/lancedb/vectordb-recipes/blob/main/tutorials/Advace_RAG_LlamaParser) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/tutorials/Advace_RAG_LlamaParser/main.ipynb) [![LLM](https://camo.githubusercontent.com/c27563e9d057be207e19b28ad77dff0638e0a1953a73e922ad3a7aa376c52446/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e61692d6170692d7768697465)](https://github.com/lancedb/vectordb-recipes) [![LlamaCloud](https://camo.githubusercontent.com/223b54fa91f8cc1eea164635bf526f3daa68cb67977b1a094f4e0a9e5a058a60/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6c616d612d6170692d70696e6b)](https://github.com/lancedb/vectordb-recipes) [![beginner](https://camo.githubusercontent.com/45fcefe51c82881be19026794347d140658016a90d98fff0aefc36ab1544dfe2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626567696e6e65722d423546463333)](https://github.com/lancedb/vectordb-recipes) |   \n[Convert any Image dataset to lance Format](https://github.com/lancedb/vectordb-recipes/blob/main/tutorials/cli-sdk-to-convert-image-datasets-to-lance) | [![Open In Colab](https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/tutorials/cli-sdk-to-convert-image-datasets-to-lance/main.ipynb) [![advanced](https://camo.githubusercontent.com/d12ae86d73cc13f67f57015080da3936c77e6b1dda6cbd5f03afe54d5285b5bc/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f616476616e6365642d464633333333)](https://github.com/lancedb/vectordb-recipes) | [![Ghost](https://camo.githubusercontent.com/f9c0dc3fad29396493b13fb3a09263af43ca64ec6cda4c997105c7e8dc6c4e9e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f67686f73742d3030303f7374796c653d666f722d7468652d6261646765266c6f676f3d67686f7374266c6f676f436f6c6f723d253233463744463145)](https://blog.lancedb.com/python-package-to-convert-image-datasets-to-lance-type/)  \n|  |   \n## Projects & Applications\n[](https://github.com/lancedb/vectordb-recipes#projects--applications)\nReady-to-use AI applications built with LanceDB! Use these projects as-is, customize them, or integrate them into your own applications.\n### Node applications powered by LanceDB\n[](https://github.com/lancedb/vectordb-recipes#node-applications-powered-by-lancedb)\nProject Name | Description | Screenshot  \n---|---|---  \n[Writing assistant](https://github.com/lancedb/vectordb-recipes/tree/main/applications/node/lanchain_writing_assistant) | Writing assistant app using lanchain.js with LanceDB, allows you to get real time relevant suggestions and facts based on you written text to help you with your writing. | [![Writing assistant](https://private-user-images.githubusercontent.com/15766192/369141715-87354e93-df4d-40ad-922b-abcbb62d667c.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDg0ODc0MTgsIm5iZiI6MTc0ODQ4NzExOCwicGF0aCI6Ii8xNTc2NjE5Mi8zNjkxNDE3MTUtODczNTRlOTMtZGY0ZC00MGFkLTkyMmItYWJjYmI2MmQ2NjdjLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MjklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTI5VDAyNTE1OFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWZlZTBmNjU2ZmEyMGNmNzJkZGM0MTdlYjM5NjM1ODRlNGM1OTA2YzBkYmUyZDczYWEwZDcwYzBkN2ZhNjdkZDEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.Wci3zkmcKc5l3TioCz7sO2jCPuY0fnXnmrTGLEvVjAU)](https://private-user-images.githubusercontent.com/15766192/369141715-87354e93-df4d-40ad-922b-abcbb62d667c.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDg0ODc0MTgsIm5iZiI6MTc0ODQ4NzExOCwicGF0aCI6Ii8xNTc2NjE5Mi8zNjkxNDE3MTUtODczNTRlOTMtZGY0ZC00MGFkLTkyMmItYWJjYmI2MmQ2NjdjLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MjklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTI5VDAyNTE1OFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWZlZTBmNjU2ZmEyMGNmNzJkZGM0MTdlYjM5NjM1ODRlNGM1OTA2YzBkYmUyZDczYWEwZDcwYzBkN2ZhNjdkZDEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.Wci3zkmcKc5l3TioCz7sO2jCPuY0fnXnmrTGLEvVjAU) [ ![Writing assistant](https://private-user-images.githubusercontent.com/15766192/369141715-87354e93-df4d-40ad-922b-abcbb62d667c.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDg0ODc0MTgsIm5iZiI6MTc0ODQ4NzExOCwicGF0aCI6Ii8xNTc2NjE5Mi8zNjkxNDE3MTUtODczNTRlOTMtZGY0ZC00MGFkLTkyMmItYWJjYmI2MmQ2NjdjLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MjklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTI5VDAyNTE1OFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWZlZTBmNjU2ZmEyMGNmNzJkZGM0MTdlYjM5NjM1ODRlNGM1OTA2YzBkYmUyZDczYWEwZDcwYzBkN2ZhNjdkZDEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.Wci3zkmcKc5l3TioCz7sO2jCPuY0fnXnmrTGLEvVjAU) ](https://private-user-images.githubusercontent.com/15766192/369141715-87354e93-df4d-40ad-922b-abcbb62d667c.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDg0ODc0MTgsIm5iZiI6MTc0ODQ4NzExOCwicGF0aCI6Ii8xNTc2NjE5Mi8zNjkxNDE3MTUtODczNTRlOTMtZGY0ZC00MGFkLTkyMmItYWJjYmI2MmQ2NjdjLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MjklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTI5VDAyNTE1OFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWZlZTBmNjU2ZmEyMGNmNzJkZGM0MTdlYjM5NjM1ODRlNGM1OTA2YzBkYmUyZDczYWEwZDcwYzBkN2ZhNjdkZDEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.Wci3zkmcKc5l3TioCz7sO2jCPuY0fnXnmrTGLEvVjAU) [ ](https://private-user-images.githubusercontent.com/15766192/369141715-87354e93-df4d-40ad-922b-abcbb62d667c.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDg0ODc0MTgsIm5iZiI6MTc0ODQ4NzExOCwicGF0aCI6Ii8xNTc2NjE5Mi8zNjkxNDE3MTUtODczNTRlOTMtZGY0ZC00MGFkLTkyMmItYWJjYmI2MmQ2NjdjLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MjklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTI5VDAyNTE1OFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWZlZTBmNjU2ZmEyMGNmNzJkZGM0MTdlYjM5NjM1ODRlNGM1OTA2YzBkYmUyZDczYWEwZDcwYzBkN2ZhNjdkZDEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.Wci3zkmcKc5l3TioCz7sO2jCPuY0fnXnmrTGLEvVjAU)  \n[Sentence Auto-Complete](https://github.com/lancedb/vectordb-recipes/tree/main/applications/node/sentance_auto_complete) | Sentance auto complete app using lanchain.js with LanceDB, allows you to get real time relevant auto complete suggestions and facts based on you written text to help you with your writing.You can also upload your data source in the form of a pdf file.You can switch between gpt models to get faster results. | [![Sentence auto-complete](https://github.com/lancedb/assets/raw/main/recipes/sentance_Auto_complete.gif)](https://github.com/lancedb/assets/blob/main/recipes/sentance_Auto_complete.gif) [ ![Sentence auto-complete](https://github.com/lancedb/assets/raw/main/recipes/sentance_Auto_complete.gif) ](https://github.com/lancedb/assets/blob/main/recipes/sentance_Auto_complete.gif) [ ](https://github.com/lancedb/assets/blob/main/recipes/sentance_Auto_complete.gif)  \n[Article Recommendation](https://github.com/lancedb/vectordb-recipes/tree/main/applications/node/article_recommender) | Article Recommender: Explore vast data set of articles with Instant, Context-Aware Suggestions. Leveraging Advanced NLP, Vector Search, and Customizable Datasets, Our App Delivers Real-Time, Precise Article Recommendations. Perfect for Research, Content Curation, and Staying Informed. Unlock Smarter Insights with State-of-the-Art Technology in Content Retrieval and Discovery!\". | [![Article Recommendation](https://github.com/lancedb/vectordb-recipes/raw/main/applications/node/article_recommender/public/assets/article_recommendation_engine.gif)](https://github.com/lancedb/vectordb-recipes/blob/main/applications/node/article_recommender/public/assets/article_recommendation_engine.gif) [ ![Article Recommendation](https://github.com/lancedb/vectordb-recipes/raw/main/applications/node/article_recommender/public/assets/article_recommendation_engine.gif) ](https://github.com/lancedb/vectordb-recipes/blob/main/applications/node/article_recommender/public/assets/article_recommendation_engine.gif) [ ](https://github.com/lancedb/vectordb-recipes/blob/main/applications/node/article_recommender/public/assets/article_recommendation_engine.gif)  \n[AI Powered Job Search](https://github.com/lancedb/vectordb-recipes/tree/main/applications/node/AI_powered_job_search) | Transform your job search experience with this AI-driven application. Powered by LangChain.js, LanceDB, and advanced semantic search, it provides real-time, highly accurate job listings tailored to your preferences. Featuring customizable datasets and advanced filtering options (e.g., skills, location, job type, and salary range), this app ensures you find the right opportunities quickly and effortlessly. Best suited for job seekers, recruiters, career platforms, custom job boards. | [![Job Search](https://github.com/lancedb/vectordb-recipes/raw/main/applications/node/assets/AI-powered-job-search.gif)](https://github.com/lancedb/vectordb-recipes/blob/main/applications/node/assets/AI-powered-job-search.gif) [ ![Job Search](https://github.com/lancedb/vectordb-recipes/raw/main/applications/node/assets/AI-powered-job-search.gif) ](https://github.com/lancedb/vectordb-recipes/blob/main/applications/node/assets/AI-powered-job-search.gif) [ ](https://github.com/lancedb/vectordb-recipes/blob/main/applications/node/assets/AI-powered-job-search.gif)  \n[AI Powered Multimodal meme search](https://github.com/lancedb/vectordb-recipes/blob/main/applications/node/mutimodal_meme_finder) | An advanced AI-powered meme search engine that allows users to find memes using both text and image queries. By leveraging LanceDB as a high-performance vector database and Roboflow's CLIP model for embedding generation, the platform delivers fast and accurate meme retrieval. | [![Multimodal meme search](https://github.com/lancedb/vectordb-recipes/raw/main/applications/node/mutimodal_meme_finder/public/assets/AI-powered-multimodal-meme-search.gif)](https://github.com/lancedb/vectordb-recipes/blob/main/applications/node/mutimodal_meme_finder/public/assets/AI-powered-multimodal-meme-search.gif) [ ![Multimodal meme search](https://github.com/lancedb/vectordb-recipes/raw/main/applications/node/mutimodal_meme_finder/public/assets/AI-powered-multimodal-meme-search.gif) ](https://github.com/lancedb/vectordb-recipes/blob/main/applications/node/mutimodal_meme_finder/public/assets/AI-powered-multimodal-meme-search.gif) [ ](https://github.com/lancedb/vectordb-recipes/blob/main/applications/node/mutimodal_meme_finder/public/assets/AI-powered-multimodal-meme-search.gif)  \n[AI Powered Feedback search and analysis](https://github.com/lancedb/vectordb-recipes/tree/main/applications/node/Feedback_search_and_analysis) | An AI-powered employee feedback analysis platform designed to collect, store, analyze, and retrieve insightful employee feedback. This system leverages LanceDB for high-speed vector-based semantic search, React.js for an interactive UI, Node.js for backend processing, and LangChain.js with an Ambient Agent for intelligent analysis and actionable insights. | [![AI Powered Feedback search and analysis](https://github.com/lancedb/vectordb-recipes/raw/main/assets/AI-Powered-feedback-search-and-analysis.gif)](https://github.com/lancedb/vectordb-recipes/blob/main/assets/AI-Powered-feedback-search-and-analysis.gif) [ ![AI Powered Feedback search and analysis](https://github.com/lancedb/vectordb-recipes/raw/main/assets/AI-Powered-feedback-search-and-analysis.gif) ](https://github.com/lancedb/vectordb-recipes/blob/main/assets/AI-Powered-feedback-search-and-analysis.gif) [ ](https://github.com/lancedb/vectordb-recipes/blob/main/assets/AI-Powered-feedback-search-and-analysis.gif)  \n[Hierarchical Multi Agent](https://github.com/lancedb/vectordb-recipes/tree/main/applications/node/hierarchical-multi-agent) | The AI-Powered Law Assistant is a **Hierarchical Multi-Agent** System leveraging LangGraph, LangChain, and LanceDB for efficient legal query processing. It features a Supervisor Agent that delegates tasks to specialized agents for IPC and NDPS laws, each with sub-agents for case retrieval and legal summarization. Using LanceDB, it stores and retrieves vectorized legal documents, enabling fast, structured, and context-aware responses for legal professionals, researchers, and law students. | [![AI Powered Law Assistant](https://github.com/lancedb/vectordb-recipes/raw/main/assets/law_assistant.gif)](https://github.com/lancedb/vectordb-recipes/blob/main/assets/law_assistant.gif) [ ![AI Powered Law Assistant](https://github.com/lancedb/vectordb-recipes/raw/main/assets/law_assistant.gif) ](https://github.com/lancedb/vectordb-recipes/blob/main/assets/law_assistant.gif) [ ](https://github.com/lancedb/vectordb-recipes/blob/main/assets/law_assistant.gif)  \n|  |   \nProject Name | Description | Screenshot  \n---|---|---  \n[YOLOExplorer](https://github.com/lancedb/yoloexplorer) | Iterate on your YOLO / CV datasets using SQL, Vector semantic search, and more within seconds | [![YOLOExplorer](https://private-user-images.githubusercontent.com/15766192/254201501-ae513a29-8f15-4e0b-99a1-ccd8272b6131.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDg0ODc0MTgsIm5iZiI6MTc0ODQ4NzExOCwicGF0aCI6Ii8xNTc2NjE5Mi8yNTQyMDE1MDEtYWU1MTNhMjktOGYxNS00ZTBiLTk5YTEtY2NkODI3MmI2MTMxLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MjklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTI5VDAyNTE1OFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWFhOTllYjFlNGZlZmQ5ZTk2NDljYWYxMjI4YTZmYzNiZTU3MWM2ZjA5N2M2OTk4ZjQxNDIxMmFlZTdiYTJhMjYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.9R7vx5TMR1S9M8Uh_wdxSRSlmenvJvaN4oNDveiPZII)](https://private-user-images.githubusercontent.com/15766192/254201501-ae513a29-8f15-4e0b-99a1-ccd8272b6131.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDg0ODc0MTgsIm5iZiI6MTc0ODQ4NzExOCwicGF0aCI6Ii8xNTc2NjE5Mi8yNTQyMDE1MDEtYWU1MTNhMjktOGYxNS00ZTBiLTk5YTEtY2NkODI3MmI2MTMxLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MjklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTI5VDAyNTE1OFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWFhOTllYjFlNGZlZmQ5ZTk2NDljYWYxMjI4YTZmYzNiZTU3MWM2ZjA5N2M2OTk4ZjQxNDIxMmFlZTdiYTJhMjYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.9R7vx5TMR1S9M8Uh_wdxSRSlmenvJvaN4oNDveiPZII) [ ![YOLOExplorer](https://private-user-images.githubusercontent.com/15766192/254201501-ae513a29-8f15-4e0b-99a1-ccd8272b6131.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDg0ODc0MTgsIm5iZiI6MTc0ODQ4NzExOCwicGF0aCI6Ii8xNTc2NjE5Mi8yNTQyMDE1MDEtYWU1MTNhMjktOGYxNS00ZTBiLTk5YTEtY2NkODI3MmI2MTMxLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MjklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTI5VDAyNTE1OFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWFhOTllYjFlNGZlZmQ5ZTk2NDljYWYxMjI4YTZmYzNiZTU3MWM2ZjA5N2M2OTk4ZjQxNDIxMmFlZTdiYTJhMjYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.9R7vx5TMR1S9M8Uh_wdxSRSlmenvJvaN4oNDveiPZII) ](https://private-user-images.githubusercontent.com/15766192/254201501-ae513a29-8f15-4e0b-99a1-ccd8272b6131.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDg0ODc0MTgsIm5iZiI6MTc0ODQ4NzExOCwicGF0aCI6Ii8xNTc2NjE5Mi8yNTQyMDE1MDEtYWU1MTNhMjktOGYxNS00ZTBiLTk5YTEtY2NkODI3MmI2MTMxLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MjklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTI5VDAyNTE1OFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWFhOTllYjFlNGZlZmQ5ZTk2NDljYWYxMjI4YTZmYzNiZTU3MWM2ZjA5N2M2OTk4ZjQxNDIxMmFlZTdiYTJhMjYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.9R7vx5TMR1S9M8Uh_wdxSRSlmenvJvaN4oNDveiPZII) [ ](https://private-user-images.githubusercontent.com/15766192/254201501-ae513a29-8f15-4e0b-99a1-ccd8272b6131.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDg0ODc0MTgsIm5iZiI6MTc0ODQ4NzExOCwicGF0aCI6Ii8xNTc2NjE5Mi8yNTQyMDE1MDEtYWU1MTNhMjktOGYxNS00ZTBiLTk5YTEtY2NkODI3MmI2MTMxLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MjklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTI5VDAyNTE1OFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWFhOTllYjFlNGZlZmQ5ZTk2NDljYWYxMjI4YTZmYzNiZTU3MWM2ZjA5N2M2OTk4ZjQxNDIxMmFlZTdiYTJhMjYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.9R7vx5TMR1S9M8Uh_wdxSRSlmenvJvaN4oNDveiPZII)  \n[Website Chatbot (Deployable Vercel Template)](https://github.com/lancedb/lancedb-vercel-chatbot) | Create a chatbot from the sitemap of any website/docs of your choice. Built using vectorDB serverless native javascript package. | [![Chatbot](https://github.com/lancedb/vectordb-recipes/raw/main/assets/vercel-template.gif)](https://github.com/lancedb/vectordb-recipes/blob/main/assets/vercel-template.gif) [ ![Chatbot](https://github.com/lancedb/vectordb-recipes/raw/main/assets/vercel-template.gif) ](https://github.com/lancedb/vectordb-recipes/blob/main/assets/vercel-template.gif) [ ](https://github.com/lancedb/vectordb-recipes/blob/main/assets/vercel-template.gif)  \n[Advanced Chatbot with Parler TTS ](https://github.com/lancedb/vectordb-recipes/blob/main/applications/Chatbot_with_Parler_TTS) | This Chatbot app uses Lancedb Hybrid search, FTS & reranker method with Parlers TTS library. | [![image](https://github.com/lancedb/vectordb-recipes/raw/main/assets/chatbot_tts.png)](https://github.com/lancedb/vectordb-recipes/blob/main/assets/chatbot_tts.png)  \n[Multi-Modal Search Engine](https://github.com/lancedb/vectordb-recipes/blob/main/applications/multimodal-search) | Create a Multi-modal search engine app, to search images using both images or text | [![Search](https://private-user-images.githubusercontent.com/15766192/266800376-9805fec8-da72-44c0-be12-ddbe1c2d6afc.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDg0ODc0MTgsIm5iZiI6MTc0ODQ4NzExOCwicGF0aCI6Ii8xNTc2NjE5Mi8yNjY4MDAzNzYtOTgwNWZlYzgtZGE3Mi00NGMwLWJlMTItZGRiZTFjMmQ2YWZjLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MjklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTI5VDAyNTE1OFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQ1MzdlZTI1YTg0M2FmYTBiNGRmODcxNGQzNGVjZjVmMTY1NTAwZjE3NDM3NDcwYWFiYzRiYTQzMmUyYTkwOTgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.hHjrhtXebiFt39DF0hx5VtYWcDS7VYiD7191LjyUCSo)](https://private-user-images.githubusercontent.com/15766192/266800376-9805fec8-da72-44c0-be12-ddbe1c2d6afc.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDg0ODc0MTgsIm5iZiI6MTc0ODQ4NzExOCwicGF0aCI6Ii8xNTc2NjE5Mi8yNjY4MDAzNzYtOTgwNWZlYzgtZGE3Mi00NGMwLWJlMTItZGRiZTFjMmQ2YWZjLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MjklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTI5VDAyNTE1OFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQ1MzdlZTI1YTg0M2FmYTBiNGRmODcxNGQzNGVjZjVmMTY1NTAwZjE3NDM3NDcwYWFiYzRiYTQzMmUyYTkwOTgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.hHjrhtXebiFt39DF0hx5VtYWcDS7VYiD7191LjyUCSo) [ ![Search](https://private-user-images.githubusercontent.com/15766192/266800376-9805fec8-da72-44c0-be12-ddbe1c2d6afc.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDg0ODc0MTgsIm5iZiI6MTc0ODQ4NzExOCwicGF0aCI6Ii8xNTc2NjE5Mi8yNjY4MDAzNzYtOTgwNWZlYzgtZGE3Mi00NGMwLWJlMTItZGRiZTFjMmQ2YWZjLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MjklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTI5VDAyNTE1OFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQ1MzdlZTI1YTg0M2FmYTBiNGRmODcxNGQzNGVjZjVmMTY1NTAwZjE3NDM3NDcwYWFiYzRiYTQzMmUyYTkwOTgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.hHjrhtXebiFt39DF0hx5VtYWcDS7VYiD7191LjyUCSo) ](https://private-user-images.githubusercontent.com/15766192/266800376-9805fec8-da72-44c0-be12-ddbe1c2d6afc.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDg0ODc0MTgsIm5iZiI6MTc0ODQ4NzExOCwicGF0aCI6Ii8xNTc2NjE5Mi8yNjY4MDAzNzYtOTgwNWZlYzgtZGE3Mi00NGMwLWJlMTItZGRiZTFjMmQ2YWZjLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MjklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTI5VDAyNTE1OFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQ1MzdlZTI1YTg0M2FmYTBiNGRmODcxNGQzNGVjZjVmMTY1NTAwZjE3NDM3NDcwYWFiYzRiYTQzMmUyYTkwOTgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.hHjrhtXebiFt39DF0hx5VtYWcDS7VYiD7191LjyUCSo) [ ](https://private-user-images.githubusercontent.com/15766192/266800376-9805fec8-da72-44c0-be12-ddbe1c2d6afc.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDg0ODc0MTgsIm5iZiI6MTc0ODQ4NzExOCwicGF0aCI6Ii8xNTc2NjE5Mi8yNjY4MDAzNzYtOTgwNWZlYzgtZGE3Mi00NGMwLWJlMTItZGRiZTFjMmQ2YWZjLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MjklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTI5VDAyNTE1OFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQ1MzdlZTI1YTg0M2FmYTBiNGRmODcxNGQzNGVjZjVmMTY1NTAwZjE3NDM3NDcwYWFiYzRiYTQzMmUyYTkwOTgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.hHjrhtXebiFt39DF0hx5VtYWcDS7VYiD7191LjyUCSo)  \n[Evaluate RAG](https://github.com/lancedb/vectordb-recipes/blob/main/applications/evaluate_RAG) | A working Streamlit RAG App designed to demonstrate end to to end production grade evaluation using 50+ scores and metrics which include guards, software metrics, traditional metrics and LLM as judge metrics. It uses mixture of specialised deep learning models and LLM as Judge models to do the evaluations | [![image](https://github.com/lancedb/vectordb-recipes/raw/main/applications/evaluate_RAG/APP.png)](https://github.com/lancedb/vectordb-recipes/blob/main/applications/evaluate_RAG/APP.png)  \n[Multi-Agent Collaboration Chatbot](https://github.com/lancedb/vectordb-recipes/blob/main/applications/Multi_collabration_chatbot) | Multi-Agent collabration chatbot using langgraph for share-market use case using Lancedb & tools such as Polygon ,Tavily | [![image](https://github.com/akashAD98/vectordb-recipes/raw/application/multi_collabartion_chatbot/assets/Streamlite_multicolabration_chat.png)](https://github.com/akashAD98/vectordb-recipes/blob/application/multi_collabartion_chatbot/assets/Streamlite_multicolabration_chat.png)  \n[Multimodal Myntra Fashion Search Engine](https://github.com/ishandutta0098/lancedb-multimodal-myntra-fashion-search-engine) | This app uses OpenAI's CLIP to make a search engine that can understand and deal with both written words and pictures. | [![image](https://github.com/lancedb/vectordb-recipes/raw/main/assets/myntra-search-engine.png)](https://github.com/lancedb/vectordb-recipes/blob/main/assets/myntra-search-engine.png)  \n[Multilingual-RAG](https://github.com/lancedb/vectordb-recipes/blob/main/applications/Multilingual_RAG) | Multilingual RAG with cohere embedding & support 100+ languages | [![image](https://private-user-images.githubusercontent.com/62583018/303703467-be65eb39-25c4-4441-98fc-6ded09689819.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDg0ODc0MTgsIm5iZiI6MTc0ODQ4NzExOCwicGF0aCI6Ii82MjU4MzAxOC8zMDM3MDM0NjctYmU2NWViMzktMjVjNC00NDQxLTk4ZmMtNmRlZDA5Njg5ODE5LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MjklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTI5VDAyNTE1OFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTUwZTZlNTkwZGRiMjUxMDkxNWZlNmYxNGMzMTFhNTM5MjJmN2VjMmUxYmYxNDkzOTdmOTRjZTMxYzAzNzRhMzcmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.hUBWyRKyt5j3FSLP6f_iIDeTa66Hk7iNr39bwwzNyXQ)](https://private-user-images.githubusercontent.com/62583018/303703467-be65eb39-25c4-4441-98fc-6ded09689819.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDg0ODc0MTgsIm5iZiI6MTc0ODQ4NzExOCwicGF0aCI6Ii82MjU4MzAxOC8zMDM3MDM0NjctYmU2NWViMzktMjVjNC00NDQxLTk4ZmMtNmRlZDA5Njg5ODE5LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA1MjklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNTI5VDAyNTE1OFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTUwZTZlNTkwZGRiMjUxMDkxNWZlNmYxNGMzMTFhNTM5MjJmN2VjMmUxYmYxNDkzOTdmOTRjZTMxYzAzNzRhMzcmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.hUBWyRKyt5j3FSLP6f_iIDeTa66Hk7iNr39bwwzNyXQ)  \n[Music Recommender](https://github.com/lancedb/vectordb-recipes/blob/main/applications/Music_Recommendation) | Music Recommendation system using audio feature extraction and vector similarity search. By utilizing **LanceDB** , **PANNs** for audio tagging, and **Librosa** for audio feature extraction, the system finds and recommends tracks with similar audio characteristics based on a query song. | [![image](https://github.com/lancedb/vectordb-recipes/raw/main/applications/Music_Recommendation/Music_recommndations_lancedb.png)](https://github.com/lancedb/vectordb-recipes/blob/main/applications/Music_Recommendation/Music_recommndations_lancedb.png)  \n[NoOCR](https://github.com/kyryl-opens-ml/no-ocr) | End-to-end solution for complex PDFs, powered by **ColPali** and **LanceDB**. | [![image](https://github.com/kyryl-opens-ml/no-ocr/raw/main/docs/flow.gif)](https://github.com/kyryl-opens-ml/no-ocr/blob/main/docs/flow.gif) [ ![image](https://github.com/kyryl-opens-ml/no-ocr/raw/main/docs/flow.gif) ](https://github.com/kyryl-opens-ml/no-ocr/blob/main/docs/flow.gif) [ ](https://github.com/kyryl-opens-ml/no-ocr/blob/main/docs/flow.gif)  \n**ð New! ð Applied GenAI and VectorDB course on Udacity** Learn about GenAI and vectorDBs using LanceDB in the recently launched [Udacity Course](https://www.udacity.com/course/building-generative-ai-solutions-with-vector-databases--cd12952)\n[![](https://github.com/lancedb/vectordb-recipes/raw/main/assets/udacity-course.png)](https://github.com/lancedb/vectordb-recipes/blob/main/assets/udacity-course.png)\n## Contributing Examples\n[](https://github.com/lancedb/vectordb-recipes#contributing-examples)\nIf you're working on some cool applications that you'd like to add to this repo, please open a PR!\n## About\nHigh quality resources & applications for LLMs, multi-modal models and VectorDBs \n### Topics\n[ machine-learning ](https://github.com/topics/machine-learning \"Topic: machine-learning\") [ ai ](https://github.com/topics/ai \"Topic: ai\") [ deep-learning ](https://github.com/topics/deep-learning \"Topic: deep-learning\") [ embeddings ](https://github.com/topics/embeddings \"Topic: embeddings\") [ openai ](https://github.com/topics/openai \"Topic: openai\") [ gpt ](https://github.com/topics/gpt \"Topic: gpt\") [ agents ](https://github.com/topics/agents \"Topic: agents\") [ fine-tuning ](https://github.com/topics/fine-tuning \"Topic: fine-tuning\") [ multimodal ](https://github.com/topics/multimodal \"Topic: multimodal\") [ rag ](https://github.com/topics/rag \"Topic: rag\") [ vector-database ](https://github.com/topics/vector-database \"Topic: vector-database\") [ llms ](https://github.com/topics/llms \"Topic: llms\") [ langchain ](https://github.com/topics/langchain \"Topic: langchain\") [ llama-index ](https://github.com/topics/llama-index \"Topic: llama-index\") [ gpt-4-vision ](https://github.com/topics/gpt-4-vision \"Topic: gpt-4-vision\")\n### Resources\n[ Readme ](https://github.com/lancedb/vectordb-recipes#readme-ov-file)\n### License\n[ Apache-2.0 license ](https://github.com/lancedb/vectordb-recipes#Apache-2.0-1-ov-file)\n###  Uh oh! \nThere was an error while loading. [Please reload this page](https://github.com/lancedb/vectordb-recipes).\n[ Activity](https://github.com/lancedb/vectordb-recipes/activity)\n[ Custom properties](https://github.com/lancedb/vectordb-recipes/custom-properties)\n### Stars\n[ **772** stars](https://github.com/lancedb/vectordb-recipes/stargazers)\n### Watchers\n[ **10** watching](https://github.com/lancedb/vectordb-recipes/watchers)\n### Forks\n[ **140** forks](https://github.com/lancedb/vectordb-recipes/forks)\n[ Report repository ](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Flancedb%2Fvectordb-recipes&report=lancedb+%28user%29)\n##  [Releases](https://github.com/lancedb/vectordb-recipes/releases)\nNo releases published\n##  [Packages 0](https://github.com/orgs/lancedb/packages?repo_name=vectordb-recipes)\nNo packages published \n###  Uh oh! \nThere was an error while loading. [Please reload this page](https://github.com/lancedb/vectordb-recipes).\n##  [Contributors 32](https://github.com/lancedb/vectordb-recipes/graphs/contributors)\n  * [ ![@PrashantDixit0](https://avatars.githubusercontent.com/u/54981696?s=64&v=4) ](https://github.com/PrashantDixit0)\n  * [ ![@akashAD98](https://avatars.githubusercontent.com/u/62583018?s=64&v=4) ](https://github.com/akashAD98)\n  * [ ![@AyushExel](https://avatars.githubusercontent.com/u/15766192?s=64&v=4) ](https://github.com/AyushExel)\n  * [ ![@unkn-wn](https://avatars.githubusercontent.com/u/43097991?s=64&v=4) ](https://github.com/unkn-wn)\n  * [ ![@QianZhu](https://avatars.githubusercontent.com/u/1305083?s=64&v=4) ](https://github.com/QianZhu)\n  * [ ![@shuklaji28](https://avatars.githubusercontent.com/u/66516678?s=64&v=4) ](https://github.com/shuklaji28)\n  * [ ![@kaushal07wick](https://avatars.githubusercontent.com/u/57106063?s=64&v=4) ](https://github.com/kaushal07wick)\n  * [ ![@vipul-maheshwari](https://avatars.githubusercontent.com/u/86592569?s=64&v=4) ](https://github.com/vipul-maheshwari)\n  * [ ![@TevinWang](https://avatars.githubusercontent.com/u/43354492?s=64&v=4) ](https://github.com/TevinWang)\n  * [ ![@raghavdixit99](https://avatars.githubusercontent.com/u/34462078?s=64&v=4) ](https://github.com/raghavdixit99)\n  * [ ![@albertlockett](https://avatars.githubusercontent.com/u/5846846?s=64&v=4) ](https://github.com/albertlockett)\n  * [ ![@AyushSingh-7](https://avatars.githubusercontent.com/u/64305346?s=64&v=4) ](https://github.com/AyushSingh-7)\n  * [ ![@hande-k](https://avatars.githubusercontent.com/u/159312713?s=64&v=4) ](https://github.com/hande-k)\n  * [ ![@changhiskhan](https://avatars.githubusercontent.com/u/759245?s=64&v=4) ](https://github.com/changhiskhan)\n\n\n[+ 18 contributors](https://github.com/lancedb/vectordb-recipes/graphs/contributors)\n## Languages\n  * [ Jupyter Notebook 93.9% ](https://github.com/lancedb/vectordb-recipes/search?l=jupyter-notebook)\n  * [ JavaScript 2.7% ](https://github.com/lancedb/vectordb-recipes/search?l=javascript)\n  * [ Python 2.7% ](https://github.com/lancedb/vectordb-recipes/search?l=python)\n  * Other 0.7%\n\n\n## Footer\n[ ](https://github.com) Â© 2025 GitHub, Inc. \n### Footer navigation\n  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n  * [Security](https://github.com/security)\n  * [Status](https://www.githubstatus.com/)\n  * [Docs](https://docs.github.com/)\n  * [Contact](https://support.github.com?tags=dotcom-footer)\n  * Manage cookies \n  * Do not share my personal information \n\n\nYou canât perform that action at this time. \n"
  },
  {
    "link": "https://github.com/ggml-org/llama.cpp",
    "raw_content": "[Skip to content](https://github.com/ggml-org/llama.cpp#start-of-content)\n## Navigation Menu\nToggle navigation\n[ ](https://github.com/)\n[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fggml-org%2Fllama.cpp)\nAppearance settings\n  * Product \n    * [ GitHub Copilot  Write better code with AI  ](https://github.com/features/copilot)\n    * [ GitHub Models  New  Manage and compare prompts  ](https://github.com/features/models)\n    * [ GitHub Advanced Security  Find and fix vulnerabilities  ](https://github.com/security/advanced-security)\n    * [ Actions  Automate any workflow  ](https://github.com/features/actions)\n    * [ Codespaces  Instant dev environments  ](https://github.com/features/codespaces)\n    * [ Issues  Plan and track work  ](https://github.com/features/issues)\n    * [ Code Review  Manage code changes  ](https://github.com/features/code-review)\n    * [ Discussions  Collaborate outside of code  ](https://github.com/features/discussions)\n    * [ Code Search  Find more, search less  ](https://github.com/features/code-search)\nExplore\n    * [ Why GitHub ](https://github.com/why-github)\n    * [ All features ](https://github.com/features)\n    * [ Documentation ](https://docs.github.com)\n    * [ GitHub Skills ](https://skills.github.com)\n    * [ Blog ](https://github.blog)\n  * Solutions \nBy company size\n    * [ Enterprises ](https://github.com/enterprise)\n    * [ Small and medium teams ](https://github.com/team)\n    * [ Startups ](https://github.com/enterprise/startups)\n    * [ Nonprofits ](https://github.com/solutions/industry/nonprofits)\nBy use case\n    * [ DevSecOps ](https://github.com/solutions/use-case/devsecops)\n    * [ DevOps ](https://github.com/solutions/use-case/devops)\n    * [ CI/CD ](https://github.com/solutions/use-case/ci-cd)\n    * [ View all use cases ](https://github.com/solutions/use-case)\nBy industry\n    * [ Healthcare ](https://github.com/solutions/industry/healthcare)\n    * [ Financial services ](https://github.com/solutions/industry/financial-services)\n    * [ Manufacturing ](https://github.com/solutions/industry/manufacturing)\n    * [ Government ](https://github.com/solutions/industry/government)\n    * [ View all industries ](https://github.com/solutions/industry)\n[ View all solutions ](https://github.com/solutions)\n  * Resources \nTopics\n    * [ AI ](https://github.com/resources/articles/ai)\n    * [ DevOps ](https://github.com/resources/articles/devops)\n    * [ Security ](https://github.com/resources/articles/security)\n    * [ Software Development ](https://github.com/resources/articles/software-development)\n    * [ View all ](https://github.com/resources/articles)\nExplore\n    * [ Learning Pathways ](https://resources.github.com/learn/pathways)\n    * [ Events & Webinars ](https://resources.github.com)\n    * [ Ebooks & Whitepapers ](https://github.com/resources/whitepapers)\n    * [ Customer Stories ](https://github.com/customer-stories)\n    * [ Partners ](https://partner.github.com)\n    * [ Executive Insights ](https://github.com/solutions/executive-insights)\n  * Open Source \n    * [ GitHub Sponsors  Fund open source developers  ](https://github.com/sponsors)\n    * [ The ReadME Project  GitHub community articles  ](https://github.com/readme)\nRepositories\n    * [ Topics ](https://github.com/topics)\n    * [ Trending ](https://github.com/trending)\n    * [ Collections ](https://github.com/collections)\n  * Enterprise \n    * [ Enterprise platform  AI-powered developer platform  ](https://github.com/enterprise)\nAvailable add-ons\n    * [ GitHub Advanced Security  Enterprise-grade security features  ](https://github.com/security/advanced-security)\n    * [ Copilot for business  Enterprise-grade AI features  ](https://github.com/features/copilot/copilot-business)\n    * [ Premium Support  Enterprise-grade 24/7 support  ](https://github.com/premium-support)\n  * [Pricing](https://github.com/pricing)\n\n\nSearch or jump to...\n# Search code, repositories, users, issues, pull requests...\nSearch \nClear\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n#  Provide feedback \nWe read every piece of feedback, and take your input very seriously.\nInclude my email address so I can be contacted\nCancel  Submit feedback \n#  Saved searches \n## Use saved searches to filter your results more quickly\nName\nQuery\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax). \nCancel  Create saved search \n[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fggml-org%2Fllama.cpp)\n[ Sign up ](https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=ggml-org%2Fllama.cpp)\nAppearance settings\nResetting focus\nYou signed in with another tab or window. [Reload](https://github.com/ggml-org/llama.cpp) to refresh your session. You signed out in another tab or window. [Reload](https://github.com/ggml-org/llama.cpp) to refresh your session. You switched accounts on another tab or window. [Reload](https://github.com/ggml-org/llama.cpp) to refresh your session. Dismiss alert\n{{ message }}\n[ ggml-org ](https://github.com/ggml-org) / **[llama.cpp](https://github.com/ggml-org/llama.cpp) ** Public\n  * [ Notifications ](https://github.com/login?return_to=%2Fggml-org%2Fllama.cpp) You must be signed in to change notification settings\n  * [ Fork 12k ](https://github.com/login?return_to=%2Fggml-org%2Fllama.cpp)\n  * [ Star  81k ](https://github.com/login?return_to=%2Fggml-org%2Fllama.cpp)\n\n\nLLM inference in C/C++ \n### License\n[ MIT license ](https://github.com/ggml-org/llama.cpp/blob/master/LICENSE)\n[ 81k stars ](https://github.com/ggml-org/llama.cpp/stargazers) [ 12k forks ](https://github.com/ggml-org/llama.cpp/forks) [ Branches ](https://github.com/ggml-org/llama.cpp/branches) [ Tags ](https://github.com/ggml-org/llama.cpp/tags) [ Activity ](https://github.com/ggml-org/llama.cpp/activity)\n[ Star  ](https://github.com/login?return_to=%2Fggml-org%2Fllama.cpp)\n[ Notifications ](https://github.com/login?return_to=%2Fggml-org%2Fllama.cpp) You must be signed in to change notification settings\n  * [ Code ](https://github.com/ggml-org/llama.cpp)\n  * [ Issues 333 ](https://github.com/ggml-org/llama.cpp/issues)\n  * [ Pull requests 456 ](https://github.com/ggml-org/llama.cpp/pulls)\n  * [ Discussions ](https://github.com/ggml-org/llama.cpp/discussions)\n  * [ Actions ](https://github.com/ggml-org/llama.cpp/actions)\n  * [ Projects 10 ](https://github.com/ggml-org/llama.cpp/projects)\n  * [ Wiki ](https://github.com/ggml-org/llama.cpp/wiki)\n  * [ Security 5 ](https://github.com/ggml-org/llama.cpp/security)\n[ ](https://github.com/ggml-org/llama.cpp/security)\n[ ](https://github.com/ggml-org/llama.cpp/security)\n[ ](https://github.com/ggml-org/llama.cpp/security)\n### [ Uh oh!  ](https://github.com/ggml-org/llama.cpp/security)\n[There was an error while loading. ](https://github.com/ggml-org/llama.cpp/security)[Please reload this page](https://github.com/ggml-org/llama.cpp).\n  * [ Insights ](https://github.com/ggml-org/llama.cpp/pulse)\n\n\nAdditional navigation options\n  * [ Code  ](https://github.com/ggml-org/llama.cpp)\n  * [ Issues  ](https://github.com/ggml-org/llama.cpp/issues)\n  * [ Pull requests  ](https://github.com/ggml-org/llama.cpp/pulls)\n  * [ Discussions  ](https://github.com/ggml-org/llama.cpp/discussions)\n  * [ Actions  ](https://github.com/ggml-org/llama.cpp/actions)\n  * [ Projects  ](https://github.com/ggml-org/llama.cpp/projects)\n  * [ Wiki  ](https://github.com/ggml-org/llama.cpp/wiki)\n  * [ Security  ](https://github.com/ggml-org/llama.cpp/security)\n  * [ Insights  ](https://github.com/ggml-org/llama.cpp/pulse)\n\n\n# ggml-org/llama.cpp\nmaster\n[**435** Branches](https://github.com/ggml-org/llama.cpp/branches)[**3676** Tags](https://github.com/ggml-org/llama.cpp/tags)\n[](https://github.com/ggml-org/llama.cpp/branches)[](https://github.com/ggml-org/llama.cpp/tags)\nGo to file\nCode\n## Folders and files\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n## Latest commit\n[![Beinsezii](https://avatars.githubusercontent.com/u/39478211?v=4&size=40)](https://github.com/Beinsezii)[Beinsezii](https://github.com/ggml-org/llama.cpp/commits?author=Beinsezii)[gguf-py : fix SafetensorRemote return on undefined size (< 0) (](https://github.com/ggml-org/llama.cpp/commit/53ae30640e131082d8d19bd80485b47c4553d551)[#13841](https://github.com/ggml-org/llama.cpp/pull/13841)[)](https://github.com/ggml-org/llama.cpp/commit/53ae30640e131082d8d19bd80485b47c4553d551)May 29, 2025[53ae306](https://github.com/ggml-org/llama.cpp/commit/53ae30640e131082d8d19bd80485b47c4553d551) Â· May 29, 2025\n## History\n[5,528 Commits](https://github.com/ggml-org/llama.cpp/commits/master/)[](https://github.com/ggml-org/llama.cpp/commits/master/)  \n[.devops](https://github.com/ggml-org/llama.cpp/tree/master/.devops \".devops\")| [.devops](https://github.com/ggml-org/llama.cpp/tree/master/.devops \".devops\")| [musa: Upgrade MUSA SDK version to rc4.0.1 and use mudnn::Unary::IDENTâ¦](https://github.com/ggml-org/llama.cpp/commit/33983057d0f578aca74ba15eccc3de9c267a5ff6 \"musa: Upgrade MUSA SDK version to rc4.0.1 and use mudnn::Unary::IDENTITY op to accelerate D2D memory copy \\(#13647\\)\n* musa: fix build warning \\(unused parameter\\)\nSigned-off-by: Xiaodong Ye <xiaodong.ye@mthreads.com>\n* musa: upgrade MUSA SDK version to rc4.0.1\nSigned-off-by: Xiaodong Ye <xiaodong.ye@mthreads.com>\n* musa: use mudnn::Unary::IDENTITY op to accelerate D2D memory copy\nSigned-off-by: Xiaodong Ye <xiaodong.ye@mthreads.com>\n* Update ggml/src/ggml-cuda/cpy.cu\nCo-authored-by: Johannes GÃ¤Ãler <johannesg@5d6.de>\n* musa: remove MUDNN_CHECK_GEN and use CUDA_CHECK_GEN instead in MUDNN_CHECK\nSigned-off-by: Xiaodong Ye <xiaodong.ye@mthreads.com>\n---------\nSigned-off-by: Xiaodong Ye <xiaodong.ye@mthreads.com>\nCo-authored-by: Johannes GÃ¤Ãler <johannesg@5d6.de>\")| May 21, 2025  \n[.github](https://github.com/ggml-org/llama.cpp/tree/master/.github \".github\")| [.github](https://github.com/ggml-org/llama.cpp/tree/master/.github \".github\")| [ci: disable LLAMA_CURL for Linux cross-builds (](https://github.com/ggml-org/llama.cpp/commit/d98f2a35fcf4a8d3e660ad48cd19e2a1f3d5b2ef \"ci: disable LLAMA_CURL for Linux cross-builds \\(#13871\\)\")[#13871](https://github.com/ggml-org/llama.cpp/pull/13871)[)](https://github.com/ggml-org/llama.cpp/commit/d98f2a35fcf4a8d3e660ad48cd19e2a1f3d5b2ef \"ci: disable LLAMA_CURL for Linux cross-builds \\(#13871\\)\")| May 29, 2025  \n[ci](https://github.com/ggml-org/llama.cpp/tree/master/ci \"ci\")| [ci](https://github.com/ggml-org/llama.cpp/tree/master/ci \"ci\")| [musa: Upgrade MUSA SDK version to rc4.0.1 and use mudnn::Unary::IDENTâ¦](https://github.com/ggml-org/llama.cpp/commit/33983057d0f578aca74ba15eccc3de9c267a5ff6 \"musa: Upgrade MUSA SDK version to rc4.0.1 and use mudnn::Unary::IDENTITY op to accelerate D2D memory copy \\(#13647\\)\n* musa: fix build warning \\(unused parameter\\)\nSigned-off-by: Xiaodong Ye <xiaodong.ye@mthreads.com>\n* musa: upgrade MUSA SDK version to rc4.0.1\nSigned-off-by: Xiaodong Ye <xiaodong.ye@mthreads.com>\n* musa: use mudnn::Unary::IDENTITY op to accelerate D2D memory copy\nSigned-off-by: Xiaodong Ye <xiaodong.ye@mthreads.com>\n* Update ggml/src/ggml-cuda/cpy.cu\nCo-authored-by: Johannes GÃ¤Ãler <johannesg@5d6.de>\n* musa: remove MUDNN_CHECK_GEN and use CUDA_CHECK_GEN instead in MUDNN_CHECK\nSigned-off-by: Xiaodong Ye <xiaodong.ye@mthreads.com>\n---------\nSigned-off-by: Xiaodong Ye <xiaodong.ye@mthreads.com>\nCo-authored-by: Johannes GÃ¤Ãler <johannesg@5d6.de>\")| May 21, 2025  \n[cmake](https://github.com/ggml-org/llama.cpp/tree/master/cmake \"cmake\")| [cmake](https://github.com/ggml-org/llama.cpp/tree/master/cmake \"cmake\")| [llama : build windows releases with dl backends (](https://github.com/ggml-org/llama.cpp/commit/9f2da5871f4bbd205b8a3b952cdc76283218d595 \"llama : build windows releases with dl backends \\(#13220\\)\")[#13220](https://github.com/ggml-org/llama.cpp/pull/13220)[)](https://github.com/ggml-org/llama.cpp/commit/9f2da5871f4bbd205b8a3b952cdc76283218d595 \"llama : build windows releases with dl backends \\(#13220\\)\")| May 4, 2025  \n[common](https://github.com/ggml-org/llama.cpp/tree/master/common \"common\")| [common](https://github.com/ggml-org/llama.cpp/tree/master/common \"common\")| [mtmd : move helpers to dedicated library (](https://github.com/ggml-org/llama.cpp/commit/10961339b26bd2eff01d5479e8879f435da261b7 \"mtmd : move helpers to dedicated library \\(â ï¸ breaking change\\) \\(#13866\\)\n* mtmd : move helpers to dedicated library\n* fix server build\n* rm leftover cmakelist code\")[â ï¸](https://github.com/ggml-org/llama.cpp/commit/10961339b26bd2eff01d5479e8879f435da261b7 \"mtmd : move helpers to dedicated library \\(â ï¸ breaking change\\) \\(#13866\\)\n* mtmd : move helpers to dedicated library\n* fix server build\n* rm leftover cmakelist code\") [breaking change) (](https://github.com/ggml-org/llama.cpp/commit/10961339b26bd2eff01d5479e8879f435da261b7 \"mtmd : move helpers to dedicated library \\(â ï¸ breaking change\\) \\(#13866\\)\n* mtmd : move helpers to dedicated library\n* fix server build\n* rm leftover cmakelist code\")[#13866](https://github.com/ggml-org/llama.cpp/pull/13866)[)](https://github.com/ggml-org/llama.cpp/commit/10961339b26bd2eff01d5479e8879f435da261b7 \"mtmd : move helpers to dedicated library \\(â ï¸ breaking change\\) \\(#13866\\)\n* mtmd : move helpers to dedicated library\n* fix server build\n* rm leftover cmakelist code\")| May 29, 2025  \n[docs](https://github.com/ggml-org/llama.cpp/tree/master/docs \"docs\")| [docs](https://github.com/ggml-org/llama.cpp/tree/master/docs \"docs\")| [mtmd : support Qwen 2.5 Omni (input audio+vision, no audio output) (](https://github.com/ggml-org/llama.cpp/commit/bc583e3c63c04a11d287c108ea9e6a515ead0423 \"mtmd : support Qwen 2.5 Omni \\(input audio+vision, no audio output\\) \\(#13784\\)\n* mtmd : allow multiple modalities at the same time\n* refactor mtmd tokenizer\n* fix compile\n* ok, missing SinusoidsPositionEmbedding\n* first working version\n* fix style\n* more strict validate of n_embd\n* refactor if..else to switch\n* fix regression\n* add test for 3B\n* update docs\n* fix tokenizing with add_special\n* add more tests\n* fix test case \"huge\"\n* rm redundant code\n* set_position_mrope_1d rm n_tokens\")[#â¦](https://github.com/ggml-org/llama.cpp/pull/13784)| May 27, 2025  \n[examples](https://github.com/ggml-org/llama.cpp/tree/master/examples \"examples\")| [examples](https://github.com/ggml-org/llama.cpp/tree/master/examples \"examples\")| [examples/training: Fix file name in README (](https://github.com/ggml-org/llama.cpp/commit/88c125f2acce0e25e5fc8481ab0681415fc64a10 \"examples/training: Fix file name in README \\(#13803\\)\nThis patch fixes binary file names in README.md.\nSigned-off-by: Masanari Iida <standby24x7@gmail.com>\")[#13803](https://github.com/ggml-org/llama.cpp/pull/13803)[)](https://github.com/ggml-org/llama.cpp/commit/88c125f2acce0e25e5fc8481ab0681415fc64a10 \"examples/training: Fix file name in README \\(#13803\\)\nThis patch fixes binary file names in README.md.\nSigned-off-by: Masanari Iida <standby24x7@gmail.com>\")| May 26, 2025  \n[ggml](https://github.com/ggml-org/llama.cpp/tree/master/ggml \"ggml\")| [ggml](https://github.com/ggml-org/llama.cpp/tree/master/ggml \"ggml\")| [CUDA: fix FA tg at long context for CC >= 8.9 (](https://github.com/ggml-org/llama.cpp/commit/a68247439bd6fb756cc93ad2817e55a02aa0b100 \"CUDA: fix FA tg at long context for CC >= 8.9 \\(#13852\\)\")[#13852](https://github.com/ggml-org/llama.cpp/pull/13852)[)](https://github.com/ggml-org/llama.cpp/commit/a68247439bd6fb756cc93ad2817e55a02aa0b100 \"CUDA: fix FA tg at long context for CC >= 8.9 \\(#13852\\)\")| May 28, 2025  \n[gguf-py](https://github.com/ggml-org/llama.cpp/tree/master/gguf-py \"gguf-py\")| [gguf-py](https://github.com/ggml-org/llama.cpp/tree/master/gguf-py \"gguf-py\")| [gguf-py : fix SafetensorRemote return on undefined size (< 0) (](https://github.com/ggml-org/llama.cpp/commit/53ae30640e131082d8d19bd80485b47c4553d551 \"gguf-py : fix SafetensorRemote return on undefined size \\(< 0\\) \\(#13841\\)\")[#13841](https://github.com/ggml-org/llama.cpp/pull/13841)[)](https://github.com/ggml-org/llama.cpp/commit/53ae30640e131082d8d19bd80485b47c4553d551 \"gguf-py : fix SafetensorRemote return on undefined size \\(< 0\\) \\(#13841\\)\")| May 29, 2025  \n[grammars](https://github.com/ggml-org/llama.cpp/tree/master/grammars \"grammars\")| [grammars](https://github.com/ggml-org/llama.cpp/tree/master/grammars \"grammars\")| [llama : move end-user examples to tools directory (](https://github.com/ggml-org/llama.cpp/commit/1d36b3670b285e69e58b9d687c770a2a0a192194 \"llama : move end-user examples to tools directory \\(#13249\\)\n* llama : move end-user examples to tools directory\n---------\nCo-authored-by: Xuan Son Nguyen <son@huggingface.co>\")[#13249](https://github.com/ggml-org/llama.cpp/pull/13249)[)](https://github.com/ggml-org/llama.cpp/commit/1d36b3670b285e69e58b9d687c770a2a0a192194 \"llama : move end-user examples to tools directory \\(#13249\\)\n* llama : move end-user examples to tools directory\n---------\nCo-authored-by: Xuan Son Nguyen <son@huggingface.co>\")| May 3, 2025  \n[include](https://github.com/ggml-org/llama.cpp/tree/master/include \"include\")| [include](https://github.com/ggml-org/llama.cpp/tree/master/include \"include\")| [llama : clarify deprecation message (](https://github.com/ggml-org/llama.cpp/commit/22229314fc46b2f741bb21b12cde71f6c6a60b52 \"llama : clarify deprecation message \\(#13794\\)\")[#13794](https://github.com/ggml-org/llama.cpp/pull/13794)[)](https://github.com/ggml-org/llama.cpp/commit/22229314fc46b2f741bb21b12cde71f6c6a60b52 \"llama : clarify deprecation message \\(#13794\\)\")| May 26, 2025  \n[licenses](https://github.com/ggml-org/llama.cpp/tree/master/licenses \"licenses\")| [licenses](https://github.com/ggml-org/llama.cpp/tree/master/licenses \"licenses\")| [cmake : enable curl by default (](https://github.com/ggml-org/llama.cpp/commit/bd3f59f81289b920bcc597a208c14f55e39ed37e \"cmake : enable curl by default \\(#12761\\)\n* cmake : enable curl by default\n* no curl if no examples\n* fix build\n* fix build-linux-cross\n* add windows-setup-curl\n* fix\n* shell\n* fix path\n* fix windows-latest-cmake*\n* run: include_directories\n* LLAMA_RUN_EXTRA_LIBS\n* sycl: no llama_curl\n* no test-arg-parser on windows\n* clarification\n* try riscv64 / arm64\n* windows: include libcurl inside release binary\n* add msg\n* fix mac / ios / android build\n* will this fix xcode?\n* try clearing the cache\n* add bunch of licenses\n* revert clear cache\n* fix xcode\n* fix xcode \\(2\\)\n* fix typo\")[#12761](https://github.com/ggml-org/llama.cpp/pull/12761)[)](https://github.com/ggml-org/llama.cpp/commit/bd3f59f81289b920bcc597a208c14f55e39ed37e \"cmake : enable curl by default \\(#12761\\)\n* cmake : enable curl by default\n* no curl if no examples\n* fix build\n* fix build-linux-cross\n* add windows-setup-curl\n* fix\n* shell\n* fix path\n* fix windows-latest-cmake*\n* run: include_directories\n* LLAMA_RUN_EXTRA_LIBS\n* sycl: no llama_curl\n* no test-arg-parser on windows\n* clarification\n* try riscv64 / arm64\n* windows: include libcurl inside release binary\n* add msg\n* fix mac / ios / android build\n* will this fix xcode?\n* try clearing the cache\n* add bunch of licenses\n* revert clear cache\n* fix xcode\n* fix xcode \\(2\\)\n* fix typo\")| Apr 7, 2025  \n[media](https://github.com/ggml-org/llama.cpp/tree/master/media \"media\")| [media](https://github.com/ggml-org/llama.cpp/tree/master/media \"media\")| [media : add SVG logo [no ci] (](https://github.com/ggml-org/llama.cpp/commit/296901983700f3c37449bcb555d85d27150a679d \"media : add SVG logo \\[no ci\\] \\(#12616\\)\")[#12616](https://github.com/ggml-org/llama.cpp/pull/12616)[)](https://github.com/ggml-org/llama.cpp/commit/296901983700f3c37449bcb555d85d27150a679d \"media : add SVG logo \\[no ci\\] \\(#12616\\)\")| Mar 28, 2025  \n[models](https://github.com/ggml-org/llama.cpp/tree/master/models \"models\")| [models](https://github.com/ggml-org/llama.cpp/tree/master/models \"models\")| [`server`: add `--reasoning-budget 0` to disable thinking (incl. qwen3â¦](https://github.com/ggml-org/llama.cpp/commit/e121edc4324a640be11b7e567edd39b721b0f8e4 \"`server`: add `--reasoning-budget 0` to disable thinking \\(incl. qwen3 w/ enable_thinking:false\\) \\(#13771\\)\n---------\nCo-authored-by: ochafik <ochafik@google.com>\nCo-authored-by: Xuan-Son Nguyen <thichthat@gmail.com>\")| May 26, 2025  \n[pocs](https://github.com/ggml-org/llama.cpp/tree/master/pocs \"pocs\")| [pocs](https://github.com/ggml-org/llama.cpp/tree/master/pocs \"pocs\")| [ggml : move AMX to the CPU backend (](https://github.com/ggml-org/llama.cpp/commit/7cc2d2c88908fc92b97b28acafb82f7d6e425b85 \"ggml : move AMX to the CPU backend \\(#10570\\)\n* ggml : move AMX to the CPU backend\n---------\nCo-authored-by: Georgi Gerganov <ggerganov@gmail.com>\")[#10570](https://github.com/ggml-org/llama.cpp/pull/10570)[)](https://github.com/ggml-org/llama.cpp/commit/7cc2d2c88908fc92b97b28acafb82f7d6e425b85 \"ggml : move AMX to the CPU backend \\(#10570\\)\n* ggml : move AMX to the CPU backend\n---------\nCo-authored-by: Georgi Gerganov <ggerganov@gmail.com>\")| Nov 30, 2024  \n[prompts](https://github.com/ggml-org/llama.cpp/tree/master/prompts \"prompts\")| [prompts](https://github.com/ggml-org/llama.cpp/tree/master/prompts \"prompts\")| [llama : add Qwen support (](https://github.com/ggml-org/llama.cpp/commit/37c746d687d877bc11803e96b4dc5f378b83c0a0 \"llama : add Qwen support \\(#4281\\)\n* enable qwen to llama.cpp\n* llama : do not GPU split bias tensors\n---------\nCo-authored-by: Georgi Gerganov <ggerganov@gmail.com>\")[#4281](https://github.com/ggml-org/llama.cpp/pull/4281)[)](https://github.com/ggml-org/llama.cpp/commit/37c746d687d877bc11803e96b4dc5f378b83c0a0 \"llama : add Qwen support \\(#4281\\)\n* enable qwen to llama.cpp\n* llama : do not GPU split bias tensors\n---------\nCo-authored-by: Georgi Gerganov <ggerganov@gmail.com>\")| Dec 2, 2023  \n[requirements](https://github.com/ggml-org/llama.cpp/tree/master/requirements \"requirements\")| [requirements](https://github.com/ggml-org/llama.cpp/tree/master/requirements \"requirements\")| [common: Include torch package for s390x (](https://github.com/ggml-org/llama.cpp/commit/ab86335760ebb441574eb47f886fa1ee302e2131 \"common: Include torch package for s390x \\(#13699\\)\n* common: update requirements.txt to include pytorch nightly for s390x\nSigned-off-by: Aaron Teo <aaron.teo1@ibm.com>\n* common: fix torch installation via pip for s390x\nSigned-off-by: Aaron Teo <aaron.teo1@ibm.com>\n---------\nSigned-off-by: Aaron Teo <aaron.teo1@ibm.com>\")[#13699](https://github.com/ggml-org/llama.cpp/pull/13699)[)](https://github.com/ggml-org/llama.cpp/commit/ab86335760ebb441574eb47f886fa1ee302e2131 \"common: Include torch package for s390x \\(#13699\\)\n* common: update requirements.txt to include pytorch nightly for s390x\nSigned-off-by: Aaron Teo <aaron.teo1@ibm.com>\n* common: fix torch installation via pip for s390x\nSigned-off-by: Aaron Teo <aaron.teo1@ibm.com>\n---------\nSigned-off-by: Aaron Teo <aaron.teo1@ibm.com>\")| May 23, 2025  \n[scripts](https://github.com/ggml-org/llama.cpp/tree/master/scripts \"scripts\")| [scripts](https://github.com/ggml-org/llama.cpp/tree/master/scripts \"scripts\")| [sync : ggml](https://github.com/ggml-org/llama.cpp/commit/1c49c70d07ef87635daa5e8fdd0b5bfd88493dd3 \"sync : ggml\")| May 27, 2025  \n[src](https://github.com/ggml-org/llama.cpp/tree/master/src \"src\")| [src](https://github.com/ggml-org/llama.cpp/tree/master/src \"src\")| [llama : fix KV shift for qwen2vl (](https://github.com/ggml-org/llama.cpp/commit/763d06edb7dd5094ea58bad1d81e2e8d35033e34 \"llama : fix KV shift for qwen2vl \\(#13870\\)\n* llama : fix KV shift for qwen2vl\n* add ref to the PR\")[#13870](https://github.com/ggml-org/llama.cpp/pull/13870)[)](https://github.com/ggml-org/llama.cpp/commit/763d06edb7dd5094ea58bad1d81e2e8d35033e34 \"llama : fix KV shift for qwen2vl \\(#13870\\)\n* llama : fix KV shift for qwen2vl\n* add ref to the PR\")| May 29, 2025  \n[tests](https://github.com/ggml-org/llama.cpp/tree/master/tests \"tests\")| [tests](https://github.com/ggml-org/llama.cpp/tree/master/tests \"tests\")| [sampling : make sure samplers return at least 1 token (](https://github.com/ggml-org/llama.cpp/commit/f9cd68398baf2ba8af4725ca9ed00bef205e6706 \"sampling : make sure samplers return at least 1 token \\(#13822\\)\n* sampling : min-p should always return at least one token\nggml-ci\n* sampling : same for typical sampling\n* tests : sampling tests use min_keep == 0\nggml-ci\")[#13822](https://github.com/ggml-org/llama.cpp/pull/13822)[)](https://github.com/ggml-org/llama.cpp/commit/f9cd68398baf2ba8af4725ca9ed00bef205e6706 \"sampling : make sure samplers return at least 1 token \\(#13822\\)\n* sampling : min-p should always return at least one token\nggml-ci\n* sampling : same for typical sampling\n* tests : sampling tests use min_keep == 0\nggml-ci\")| May 27, 2025  \n[tools](https://github.com/ggml-org/llama.cpp/tree/master/tools \"tools\")| [tools](https://github.com/ggml-org/llama.cpp/tree/master/tools \"tools\")| [mtmd : move helpers to dedicated library (](https://github.com/ggml-org/llama.cpp/commit/10961339b26bd2eff01d5479e8879f435da261b7 \"mtmd : move helpers to dedicated library \\(â ï¸ breaking change\\) \\(#13866\\)\n* mtmd : move helpers to dedicated library\n* fix server build\n* rm leftover cmakelist code\")[â ï¸](https://github.com/ggml-org/llama.cpp/commit/10961339b26bd2eff01d5479e8879f435da261b7 \"mtmd : move helpers to dedicated library \\(â ï¸ breaking change\\) \\(#13866\\)\n* mtmd : move helpers to dedicated library\n* fix server build\n* rm leftover cmakelist code\") [breaking change) (](https://github.com/ggml-org/llama.cpp/commit/10961339b26bd2eff01d5479e8879f435da261b7 \"mtmd : move helpers to dedicated library \\(â ï¸ breaking change\\) \\(#13866\\)\n* mtmd : move helpers to dedicated library\n* fix server build\n* rm leftover cmakelist code\")[#13866](https://github.com/ggml-org/llama.cpp/pull/13866)[)](https://github.com/ggml-org/llama.cpp/commit/10961339b26bd2eff01d5479e8879f435da261b7 \"mtmd : move helpers to dedicated library \\(â ï¸ breaking change\\) \\(#13866\\)\n* mtmd : move helpers to dedicated library\n* fix server build\n* rm leftover cmakelist code\")| May 29, 2025  \n[.clang-format](https://github.com/ggml-org/llama.cpp/blob/master/.clang-format \".clang-format\")| [.clang-format](https://github.com/ggml-org/llama.cpp/blob/master/.clang-format \".clang-format\")| [llama : add .clang-format file (](https://github.com/ggml-org/llama.cpp/commit/fab5d30ff6729ff6ff615c41e8c0215d6bc30393 \"llama : add .clang-format file \\(#10415\\)\")[#10415](https://github.com/ggml-org/llama.cpp/pull/10415)[)](https://github.com/ggml-org/llama.cpp/commit/fab5d30ff6729ff6ff615c41e8c0215d6bc30393 \"llama : add .clang-format file \\(#10415\\)\")| Nov 20, 2024  \n[.clang-tidy](https://github.com/ggml-org/llama.cpp/blob/master/.clang-tidy \".clang-tidy\")| [.clang-tidy](https://github.com/ggml-org/llama.cpp/blob/master/.clang-tidy \".clang-tidy\")| [clang-tidy : disable warning about missing math parenthesis (](https://github.com/ggml-org/llama.cpp/commit/572b3141d343d7f947bf53b57513016e90db5680 \"clang-tidy : disable warning about missing math parenthesis \\(#13091\\)\")[#13091](https://github.com/ggml-org/llama.cpp/pull/13091)[)](https://github.com/ggml-org/llama.cpp/commit/572b3141d343d7f947bf53b57513016e90db5680 \"clang-tidy : disable warning about missing math parenthesis \\(#13091\\)\")| Apr 24, 2025  \n[.dockerignore](https://github.com/ggml-org/llama.cpp/blob/master/.dockerignore \".dockerignore\")| [.dockerignore](https://github.com/ggml-org/llama.cpp/blob/master/.dockerignore \".dockerignore\")| [ci : fix docker build number and tag name (](https://github.com/ggml-org/llama.cpp/commit/ea9c32be71b91b42ecc538bd902e93cbb5fb36cb \"ci : fix docker build number and tag name \\(#9638\\)\n* ci : fix docker build number and tag name\n* fine-grant permissions\")[#9638](https://github.com/ggml-org/llama.cpp/pull/9638)[)](https://github.com/ggml-org/llama.cpp/commit/ea9c32be71b91b42ecc538bd902e93cbb5fb36cb \"ci : fix docker build number and tag name \\(#9638\\)\n* ci : fix docker build number and tag name\n* fine-grant permissions\")| Sep 25, 2024  \n[.ecrc](https://github.com/ggml-org/llama.cpp/blob/master/.ecrc \".ecrc\")| [.ecrc](https://github.com/ggml-org/llama.cpp/blob/master/.ecrc \".ecrc\")| [common : Update stb_image.h to latest version (](https://github.com/ggml-org/llama.cpp/commit/ad76569f8e78ab6ca921bda25cef25a157361719 \"common : Update stb_image.h to latest version \\(#9161\\)\n* Update stb_image.h to latest version\nFixes https://github.com/ggerganov/llama.cpp/issues/7431\n* Update .ecrc\")[#9161](https://github.com/ggml-org/llama.cpp/pull/9161)[)](https://github.com/ggml-org/llama.cpp/commit/ad76569f8e78ab6ca921bda25cef25a157361719 \"common : Update stb_image.h to latest version \\(#9161\\)\n* Update stb_image.h to latest version\nFixes https://github.com/ggerganov/llama.cpp/issues/7431\n* Update .ecrc\")| Aug 27, 2024  \n[.editorconfig](https://github.com/ggml-org/llama.cpp/blob/master/.editorconfig \".editorconfig\")| [.editorconfig](https://github.com/ggml-org/llama.cpp/blob/master/.editorconfig \".editorconfig\")| [mtmd : move helpers to dedicated library (](https://github.com/ggml-org/llama.cpp/commit/10961339b26bd2eff01d5479e8879f435da261b7 \"mtmd : move helpers to dedicated library \\(â ï¸ breaking change\\) \\(#13866\\)\n* mtmd : move helpers to dedicated library\n* fix server build\n* rm leftover cmakelist code\")[â ï¸](https://github.com/ggml-org/llama.cpp/commit/10961339b26bd2eff01d5479e8879f435da261b7 \"mtmd : move helpers to dedicated library \\(â ï¸ breaking change\\) \\(#13866\\)\n* mtmd : move helpers to dedicated library\n* fix server build\n* rm leftover cmakelist code\") [breaking change) (](https://github.com/ggml-org/llama.cpp/commit/10961339b26bd2eff01d5479e8879f435da261b7 \"mtmd : move helpers to dedicated library \\(â ï¸ breaking change\\) \\(#13866\\)\n* mtmd : move helpers to dedicated library\n* fix server build\n* rm leftover cmakelist code\")[#13866](https://github.com/ggml-org/llama.cpp/pull/13866)[)](https://github.com/ggml-org/llama.cpp/commit/10961339b26bd2eff01d5479e8879f435da261b7 \"mtmd : move helpers to dedicated library \\(â ï¸ breaking change\\) \\(#13866\\)\n* mtmd : move helpers to dedicated library\n* fix server build\n* rm leftover cmakelist code\")| May 29, 2025  \n[.flake8](https://github.com/ggml-org/llama.cpp/blob/master/.flake8 \".flake8\")| [.flake8](https://github.com/ggml-org/llama.cpp/blob/master/.flake8 \".flake8\")| [llama : move end-user examples to tools directory (](https://github.com/ggml-org/llama.cpp/commit/1d36b3670b285e69e58b9d687c770a2a0a192194 \"llama : move end-user examples to tools directory \\(#13249\\)\n* llama : move end-user examples to tools directory\n---------\nCo-authored-by: Xuan Son Nguyen <son@huggingface.co>\")[#13249](https://github.com/ggml-org/llama.cpp/pull/13249)[)](https://github.com/ggml-org/llama.cpp/commit/1d36b3670b285e69e58b9d687c770a2a0a192194 \"llama : move end-user examples to tools directory \\(#13249\\)\n* llama : move end-user examples to tools directory\n---------\nCo-authored-by: Xuan Son Nguyen <son@huggingface.co>\")| May 3, 2025  \n[.gitignore](https://github.com/ggml-org/llama.cpp/blob/master/.gitignore \".gitignore\")| [.gitignore](https://github.com/ggml-org/llama.cpp/blob/master/.gitignore \".gitignore\")| [llama : move end-user examples to tools directory (](https://github.com/ggml-org/llama.cpp/commit/1d36b3670b285e69e58b9d687c770a2a0a192194 \"llama : move end-user examples to tools directory \\(#13249\\)\n* llama : move end-user examples to tools directory\n---------\nCo-authored-by: Xuan Son Nguyen <son@huggingface.co>\")[#13249](https://github.com/ggml-org/llama.cpp/pull/13249)[)](https://github.com/ggml-org/llama.cpp/commit/1d36b3670b285e69e58b9d687c770a2a0a192194 \"llama : move end-user examples to tools directory \\(#13249\\)\n* llama : move end-user examples to tools directory\n---------\nCo-authored-by: Xuan Son Nguyen <son@huggingface.co>\")| May 3, 2025  \n[.gitmodules](https://github.com/ggml-org/llama.cpp/blob/master/.gitmodules \".gitmodules\")| [.gitmodules](https://github.com/ggml-org/llama.cpp/blob/master/.gitmodules \".gitmodules\")| [ggml : build backends as libraries (](https://github.com/ggml-org/llama.cpp/commit/ae8de6d50a09d49545e0afab2e50cc4acfb280e2 \"ggml : build backends as libraries \\(#10256\\)\n* ggml : build backends as libraries\n---------\nSigned-off-by: Xiaodong Ye <xiaodong.ye@mthreads.com>\nCo-authored-by: Georgi Gerganov <ggerganov@gmail.com>\nCo-authored-by: R0CKSTAR <xiaodong.ye@mthreads.com>\")[#10256](https://github.com/ggml-org/llama.cpp/pull/10256)[)](https://github.com/ggml-org/llama.cpp/commit/ae8de6d50a09d49545e0afab2e50cc4acfb280e2 \"ggml : build backends as libraries \\(#10256\\)\n* ggml : build backends as libraries\n---------\nSigned-off-by: Xiaodong Ye <xiaodong.ye@mthreads.com>\nCo-authored-by: Georgi Gerganov <ggerganov@gmail.com>\nCo-authored-by: R0CKSTAR <xiaodong.ye@mthreads.com>\")| Nov 15, 2024  \n[.pre-commit-config.yaml](https://github.com/ggml-org/llama.cpp/blob/master/.pre-commit-config.yaml \".pre-commit-config.yaml\")| [.pre-commit-config.yaml](https://github.com/ggml-org/llama.cpp/blob/master/.pre-commit-config.yaml \".pre-commit-config.yaml\")| [convert.py : add python logging instead of print() (](https://github.com/ggml-org/llama.cpp/commit/a2ac89d6efb41b535778bfeaecaae8fe295b6ed3 \"convert.py : add python logging instead of print\\(\\) \\(#6511\\)\n* convert.py: add python logging instead of print\\(\\)\n* convert.py: verbose flag takes priority over dump flag log suppression\n* convert.py: named instance logging\n* convert.py: use explicit logger id string\n* convert.py: convert extra print\\(\\) to named logger\n* convert.py: sys.stderr.write --> logger.error\n* *.py: Convert all python scripts to use logging module\n* requirements.txt: remove extra line\n* flake8: update flake8 ignore and exclude to match ci settings\n* gh-actions: add flake8-no-print to flake8 lint step\n* pre-commit: add flake8-no-print to flake8 and also update pre-commit version\n* convert-hf-to-gguf.py: print\\(\\) to logger conversion\n* *.py: logging basiconfig refactor to use conditional expression\n* *.py: removed commented out logging\n* fixup! *.py: logging basiconfig refactor to use conditional expression\n* constant.py: logger.error then exit should be a raise exception instead\n* *.py: Convert logger error and sys.exit\\(\\) into a raise exception \\(for atypical error\\)\n* gguf-convert-endian.py: refactor convert_byteorder\\(\\) to use tqdm progressbar\n* verify-checksum-model.py: This is the result of the program, it should be printed to stdout.\n* compare-llama-bench.py: add blank line for readability during missing repo response\n* reader.py: read_gguf_file\\(\\) use print\\(\\) over logging\n* convert.py: warning goes to stderr and won't hurt the dump output\n* gguf-dump.py: dump_metadata\\(\\) should print to stdout\n* convert-hf-to-gguf.py: print --> logger.debug or ValueError\\(\\)\n* verify-checksum-models.py: use print\\(\\) for printing table\n* *.py: refactor logging.basicConfig\\(\\)\n* gguf-py/gguf/*.py: use __name__ as logger name\nSince they will be imported and not run directly.\n* python-lint.yml: use .flake8 file instead\n* constants.py: logger no longer required\n* convert-hf-to-gguf.py: add additional logging\n* convert-hf-to-gguf.py: print\\(\\) --> logger\n* *.py: fix flake8 warnings\n* revert changes to convert-hf-to-gguf.py for get_name\\(\\)\n* convert-hf-to-gguf-update.py: use triple quoted f-string instead\n* *.py: accidentally corrected the wrong line\n* *.py: add compilade warning suggestions and style fixes\")[#6511](https://github.com/ggml-org/llama.cpp/pull/6511)[)](https://github.com/ggml-org/llama.cpp/commit/a2ac89d6efb41b535778bfeaecaae8fe295b6ed3 \"convert.py : add python logging instead of print\\(\\) \\(#6511\\)\n* convert.py: add python logging instead of print\\(\\)\n* convert.py: verbose flag takes priority over dump flag log suppression\n* convert.py: named instance logging\n* convert.py: use explicit logger id string\n* convert.py: convert extra print\\(\\) to named logger\n* convert.py: sys.stderr.write --> logger.error\n* *.py: Convert all python scripts to use logging module\n* requirements.txt: remove extra line\n* flake8: update flake8 ignore and exclude to match ci settings\n* gh-actions: add flake8-no-print to flake8 lint step\n* pre-commit: add flake8-no-print to flake8 and also update pre-commit version\n* convert-hf-to-gguf.py: print\\(\\) to logger conversion\n* *.py: logging basiconfig refactor to use conditional expression\n* *.py: removed commented out logging\n* fixup! *.py: logging basiconfig refactor to use conditional expression\n* constant.py: logger.error then exit should be a raise exception instead\n* *.py: Convert logger error and sys.exit\\(\\) into a raise exception \\(for atypical error\\)\n* gguf-convert-endian.py: refactor convert_byteorder\\(\\) to use tqdm progressbar\n* verify-checksum-model.py: This is the result of the program, it should be printed to stdout.\n* compare-llama-bench.py: add blank line for readability during missing repo response\n* reader.py: read_gguf_file\\(\\) use print\\(\\) over logging\n* convert.py: warning goes to stderr and won't hurt the dump output\n* gguf-dump.py: dump_metadata\\(\\) should print to stdout\n* convert-hf-to-gguf.py: print --> logger.debug or ValueError\\(\\)\n* verify-checksum-models.py: use print\\(\\) for printing table\n* *.py: refactor logging.basicConfig\\(\\)\n* gguf-py/gguf/*.py: use __name__ as logger name\nSince they will be imported and not run directly.\n* python-lint.yml: use .flake8 file instead\n* constants.py: logger no longer required\n* convert-hf-to-gguf.py: add additional logging\n* convert-hf-to-gguf.py: print\\(\\) --> logger\n* *.py: fix flake8 warnings\n* revert changes to convert-hf-to-gguf.py for get_name\\(\\)\n* convert-hf-to-gguf-update.py: use triple quoted f-string instead\n* *.py: accidentally corrected the wrong line\n* *.py: add compilade warning suggestions and style fixes\")| May 4, 2024  \n[AUTHORS](https://github.com/ggml-org/llama.cpp/blob/master/AUTHORS \"AUTHORS\")| [AUTHORS](https://github.com/ggml-org/llama.cpp/blob/master/AUTHORS \"AUTHORS\")| [authors : update (](https://github.com/ggml-org/llama.cpp/commit/0fd7ca7a210bd4abc995cd728491043491dbdef7 \"authors : update \\(#12271\\)\")[#12271](https://github.com/ggml-org/llama.cpp/pull/12271)[)](https://github.com/ggml-org/llama.cpp/commit/0fd7ca7a210bd4abc995cd728491043491dbdef7 \"authors : update \\(#12271\\)\")| Mar 8, 2025  \n[CMakeLists.txt](https://github.com/ggml-org/llama.cpp/blob/master/CMakeLists.txt \"CMakeLists.txt\")| [CMakeLists.txt](https://github.com/ggml-org/llama.cpp/blob/master/CMakeLists.txt \"CMakeLists.txt\")| [ci : limit write permission to only the release step + fixes (](https://github.com/ggml-org/llama.cpp/commit/15e03282bb432631193464100c2237a3b6bcfe4c \"ci : limit write permission to only the release step + fixes \\(#13392\\)\n* ci : limit write permission to only the release step\n* fix win cuda file name\n* fix license file copy on multi-config generators\")[#13392](https://github.com/ggml-org/llama.cpp/pull/13392)[)](https://github.com/ggml-org/llama.cpp/commit/15e03282bb432631193464100c2237a3b6bcfe4c \"ci : limit write permission to only the release step + fixes \\(#13392\\)\n* ci : limit write permission to only the release step\n* fix win cuda file name\n* fix license file copy on multi-config generators\")| May 9, 2025  \n[CMakePresets.json](https://github.com/ggml-org/llama.cpp/blob/master/CMakePresets.json \"CMakePresets.json\")| [CMakePresets.json](https://github.com/ggml-org/llama.cpp/blob/master/CMakePresets.json \"CMakePresets.json\")| [cmake : remove arm64 msvc presets (](https://github.com/ggml-org/llama.cpp/commit/f4ed10b69cc38c54070a47f841827de5e8984cdf \"cmake : remove arm64 msvc presets \\(#13342\\)\")[#13342](https://github.com/ggml-org/llama.cpp/pull/13342)[)](https://github.com/ggml-org/llama.cpp/commit/f4ed10b69cc38c54070a47f841827de5e8984cdf \"cmake : remove arm64 msvc presets \\(#13342\\)\")| May 7, 2025  \n[CODEOWNERS](https://github.com/ggml-org/llama.cpp/blob/master/CODEOWNERS \"CODEOWNERS\")| [CODEOWNERS](https://github.com/ggml-org/llama.cpp/blob/master/CODEOWNERS \"CODEOWNERS\")| [llama : move end-user examples to tools directory (](https://github.com/ggml-org/llama.cpp/commit/1d36b3670b285e69e58b9d687c770a2a0a192194 \"llama : move end-user examples to tools directory \\(#13249\\)\n* llama : move end-user examples to tools directory\n---------\nCo-authored-by: Xuan Son Nguyen <son@huggingface.co>\")[#13249](https://github.com/ggml-org/llama.cpp/pull/13249)[)](https://github.com/ggml-org/llama.cpp/commit/1d36b3670b285e69e58b9d687c770a2a0a192194 \"llama : move end-user examples to tools directory \\(#13249\\)\n* llama : move end-user examples to tools directory\n---------\nCo-authored-by: Xuan Son Nguyen <son@huggingface.co>\")| May 3, 2025  \n[CONTRIBUTING.md](https://github.com/ggml-org/llama.cpp/blob/master/CONTRIBUTING.md \"CONTRIBUTING.md\")| [CONTRIBUTING.md](https://github.com/ggml-org/llama.cpp/blob/master/CONTRIBUTING.md \"CONTRIBUTING.md\")| [ggml : upgrade init_tensor API to return a ggml_status (](https://github.com/ggml-org/llama.cpp/commit/70680c48e5f77d2d3138712a6582bd8c1e548922 \"ggml : upgrade init_tensor API to return a ggml_status \\(#11854\\)\n* Upgrade init_tensor API to return a ggml_status\nTo prepare for an 'abort-free' ggml\n\\(ggml not to abort on OOMs but return a OOM status\\),\nas agreeed with Diego in the ggml repo,\nupgrade the init_tensor\\(\\) and view_init\\(\\) APIs\nto return a ggml_status.\n* misc fixes\n---------\nCo-authored-by: slaren <slarengh@gmail.com>\")[#11854](https://github.com/ggml-org/llama.cpp/pull/11854)[)](https://github.com/ggml-org/llama.cpp/commit/70680c48e5f77d2d3138712a6582bd8c1e548922 \"ggml : upgrade init_tensor API to return a ggml_status \\(#11854\\)\n* Upgrade init_tensor API to return a ggml_status\nTo prepare for an 'abort-free' ggml\n\\(ggml not to abort on OOMs but return a OOM status\\),\nas agreeed with Diego in the ggml repo,\nupgrade the init_tensor\\(\\) and view_init\\(\\) APIs\nto return a ggml_status.\n* misc fixes\n---------\nCo-authored-by: slaren <slarengh@gmail.com>\")| Feb 28, 2025  \n[LICENSE](https://github.com/ggml-org/llama.cpp/blob/master/LICENSE \"LICENSE\")| [LICENSE](https://github.com/ggml-org/llama.cpp/blob/master/LICENSE \"LICENSE\")| [license : update copyright notice + add AUTHORS (](https://github.com/ggml-org/llama.cpp/commit/e11a8999b5690f810c2c99c14347f0834e68c524 \"license : update copyright notice + add AUTHORS \\(#6405\\)\n* license : add AUTHORS\n* authors : update\n* scipts : add LICENSE and gen-authors.sh to sync\")[#6405](https://github.com/ggml-org/llama.cpp/pull/6405)[)](https://github.com/ggml-org/llama.cpp/commit/e11a8999b5690f810c2c99c14347f0834e68c524 \"license : update copyright notice + add AUTHORS \\(#6405\\)\n* license : add AUTHORS\n* authors : update\n* scipts : add LICENSE and gen-authors.sh to sync\")| Apr 9, 2024  \n[Makefile](https://github.com/ggml-org/llama.cpp/blob/master/Makefile \"Makefile\")| [Makefile](https://github.com/ggml-org/llama.cpp/blob/master/Makefile \"Makefile\")| [examples : remove infill (](https://github.com/ggml-org/llama.cpp/commit/4773d7a02ffdb05ba9e673ff21ce95351836e33a \"examples : remove infill \\(#13283\\)\nggml-ci\")[#13283](https://github.com/ggml-org/llama.cpp/pull/13283)[)](https://github.com/ggml-org/llama.cpp/commit/4773d7a02ffdb05ba9e673ff21ce95351836e33a \"examples : remove infill \\(#13283\\)\nggml-ci\")| May 7, 2025  \n[README.md](https://github.com/ggml-org/llama.cpp/blob/master/README.md \"README.md\")| [README.md](https://github.com/ggml-org/llama.cpp/blob/master/README.md \"README.md\")| [mtmd : add ultravox audio input (](https://github.com/ggml-org/llama.cpp/commit/797990c4bca0dca5be295c63e3fb2800dc0a69c2 \"mtmd : add ultravox audio input \\(#13623\\)\n* convert ok, load ok\n* warmup ok\n* test\n* still does not work?\n* fix padding\n* temporary give up\n* fix merge conflict\n* build_ultravox\\(\\)\n* rm test\n* fix merge conflict\n* add necessary mtmd APIs\n* first working version \\(only 4s of audio\\)\n* will this monster compile?\n* fix compile\n* please compile\n* fPIC\n* fix windows\n* various fixes\n* clean up audio_helpers\n* fix conversion\n* add some debug stuff\n* long audio input ok\n* adapt the api\n* add --audio arg\n* final touch UX\n* add miniaudio to readme\n* fix typo\n* refactor kv metadata\n* mtmd_default_marker\\(\\)\")[#13623](https://github.com/ggml-org/llama.cpp/pull/13623)[)](https://github.com/ggml-org/llama.cpp/commit/797990c4bca0dca5be295c63e3fb2800dc0a69c2 \"mtmd : add ultravox audio input \\(#13623\\)\n* convert ok, load ok\n* warmup ok\n* test\n* still does not work?\n* fix padding\n* temporary give up\n* fix merge conflict\n* build_ultravox\\(\\)\n* rm test\n* fix merge conflict\n* add necessary mtmd APIs\n* first working version \\(only 4s of audio\\)\n* will this monster compile?\n* fix compile\n* please compile\n* fPIC\n* fix windows\n* various fixes\n* clean up audio_helpers\n* fix conversion\n* add some debug stuff\n* long audio input ok\n* adapt the api\n* add --audio arg\n* final touch UX\n* add miniaudio to readme\n* fix typo\n* refactor kv metadata\n* mtmd_default_marker\\(\\)\")| May 23, 2025  \n[SECURITY.md](https://github.com/ggml-org/llama.cpp/blob/master/SECURITY.md \"SECURITY.md\")| [SECURITY.md](https://github.com/ggml-org/llama.cpp/blob/master/SECURITY.md \"SECURITY.md\")| [llama : move end-user examples to tools directory (](https://github.com/ggml-org/llama.cpp/commit/1d36b3670b285e69e58b9d687c770a2a0a192194 \"llama : move end-user examples to tools directory \\(#13249\\)\n* llama : move end-user examples to tools directory\n---------\nCo-authored-by: Xuan Son Nguyen <son@huggingface.co>\")[#13249](https://github.com/ggml-org/llama.cpp/pull/13249)[)](https://github.com/ggml-org/llama.cpp/commit/1d36b3670b285e69e58b9d687c770a2a0a192194 \"llama : move end-user examples to tools directory \\(#13249\\)\n* llama : move end-user examples to tools directory\n---------\nCo-authored-by: Xuan Son Nguyen <son@huggingface.co>\")| May 3, 2025  \n[build-xcframework.sh](https://github.com/ggml-org/llama.cpp/blob/master/build-xcframework.sh \"build-xcframework.sh\")| [build-xcframework.sh](https://github.com/ggml-org/llama.cpp/blob/master/build-xcframework.sh \"build-xcframework.sh\")| [llama/ggml: add LLM training support (](https://github.com/ggml-org/llama.cpp/commit/10d2af0eaa0aafd7c6577b279dfa5221ff44a63f \"llama/ggml: add LLM training support \\(#10544\\)\n* llama/ggml: add LLM training support\nmore compact progress bar\nllama_save_model_to_file\nllama_opt_param_filter\nggml_graph_dup force_grads\nrefactor ggml_opt, fix test-opt\n* remove logits_all\n* refactor CUDA implementation for ACC\n* reset graph at beginning of opt period\")[#10544](https://github.com/ggml-org/llama.cpp/pull/10544)[)](https://github.com/ggml-org/llama.cpp/commit/10d2af0eaa0aafd7c6577b279dfa5221ff44a63f \"llama/ggml: add LLM training support \\(#10544\\)\n* llama/ggml: add LLM training support\nmore compact progress bar\nllama_save_model_to_file\nllama_opt_param_filter\nggml_graph_dup force_grads\nrefactor ggml_opt, fix test-opt\n* remove logits_all\n* refactor CUDA implementation for ACC\n* reset graph at beginning of opt period\")| May 12, 2025  \n[convert_hf_to_gguf.py](https://github.com/ggml-org/llama.cpp/blob/master/convert_hf_to_gguf.py \"convert_hf_to_gguf.py\")| [convert_hf_to_gguf.py](https://github.com/ggml-org/llama.cpp/blob/master/convert_hf_to_gguf.py \"convert_hf_to_gguf.py\")| [llama : add support for BertForSequenceClassification reranker (](https://github.com/ggml-org/llama.cpp/commit/e0e3aa231d899720c2864d09cdb89d4c400eeb55 \"llama : add support for BertForSequenceClassification reranker \\(#13858\\)\n* convert: add support for BertForSequenceClassification\n* add support for reranking using BertForSequenceClassification\n* merge checks of eos and sep\n* fix lint\n---------\nCo-authored-by: dinhhuy <huy.dinh@brains-tech.co.jp>\")[#13858](https://github.com/ggml-org/llama.cpp/pull/13858)[)](https://github.com/ggml-org/llama.cpp/commit/e0e3aa231d899720c2864d09cdb89d4c400eeb55 \"llama : add support for BertForSequenceClassification reranker \\(#13858\\)\n* convert: add support for BertForSequenceClassification\n* add support for reranking using BertForSequenceClassification\n* merge checks of eos and sep\n* fix lint\n---------\nCo-authored-by: dinhhuy <huy.dinh@brains-tech.co.jp>\")| May 29, 2025  \n[convert_hf_to_gguf_update.py](https://github.com/ggml-org/llama.cpp/blob/master/convert_hf_to_gguf_update.py \"convert_hf_to_gguf_update.py\")| [convert_hf_to_gguf_update.py](https://github.com/ggml-org/llama.cpp/blob/master/convert_hf_to_gguf_update.py \"convert_hf_to_gguf_update.py\")| [tests : change umlaut test (](https://github.com/ggml-org/llama.cpp/commit/f7873fc698c09047e2873630ab7e7730a0bfb224 \"tests : change umlaut test \\(#11600\\)\")[#11600](https://github.com/ggml-org/llama.cpp/pull/11600)[)](https://github.com/ggml-org/llama.cpp/commit/f7873fc698c09047e2873630ab7e7730a0bfb224 \"tests : change umlaut test \\(#11600\\)\")| May 28, 2025  \n[convert_llama_ggml_to_gguf.py](https://github.com/ggml-org/llama.cpp/blob/master/convert_llama_ggml_to_gguf.py \"convert_llama_ggml_to_gguf.py\")| [convert_llama_ggml_to_gguf.py](https://github.com/ggml-org/llama.cpp/blob/master/convert_llama_ggml_to_gguf.py \"convert_llama_ggml_to_gguf.py\")| [py : fix wrong input type for raw_dtype in ggml to gguf scripts (](https://github.com/ggml-org/llama.cpp/commit/ee2984bdaf10c14d440ad873a049bcc09b786d9b \"py : fix wrong input type for raw_dtype in ggml to gguf scripts \\(#8928\\)\nCo-authored-by: farbod <farbod.bjary82@gmail.com>\")[#8928](https://github.com/ggml-org/llama.cpp/pull/8928)[)](https://github.com/ggml-org/llama.cpp/commit/ee2984bdaf10c14d440ad873a049bcc09b786d9b \"py : fix wrong input type for raw_dtype in ggml to gguf scripts \\(#8928\\)\nCo-authored-by: farbod <farbod.bjary82@gmail.com>\")| Aug 16, 2024  \n[convert_lora_to_gguf.py](https://github.com/ggml-org/llama.cpp/blob/master/convert_lora_to_gguf.py \"convert_lora_to_gguf.py\")| [convert_lora_to_gguf.py](https://github.com/ggml-org/llama.cpp/blob/master/convert_lora_to_gguf.py \"convert_lora_to_gguf.py\")| [convert : experimental support for](https://github.com/ggml-org/llama.cpp/commit/2016f07bd106c73699ecbaace80f55db5ed95dac \"convert : experimental support for `--mmproj` flag \\(#13023\\)\n* convert : experimental support for `--mmproj` flag\n* fix bad ctrl+f replace\n* fix style\n* split into subclasses TextModel and VisionModel\n* rename Mode --> ModelBase\n* small fix\n* correct CLIP_VISION arch name \\(because existing GGUF already use it\\)\n* Apply suggestions from code review\nCo-authored-by: compilade <git@compilade.net>\n* fix Mistral3Model\n* fix typo\nCo-authored-by: compilade <git@compilade.net>\n---------\nCo-authored-by: compilade <git@compilade.net>\") `--mmproj[](https://github.com/ggml-org/llama.cpp/commit/2016f07bd106c73699ecbaace80f55db5ed95dac \"convert : experimental support for `--mmproj` flag \\(#13023\\)\n* convert : experimental support for `--mmproj` flag\n* fix bad ctrl+f replace\n* fix style\n* split into subclasses TextModel and VisionModel\n* rename Mode --> ModelBase\n* small fix\n* correct CLIP_VISION arch name \\(because existing GGUF already use it\\)\n* Apply suggestions from code review\nCo-authored-by: compilade <git@compilade.net>\n* fix Mistral3Model\n* fix typo\nCo-authored-by: compilade <git@compilade.net>\n---------\nCo-authored-by: compilade <git@compilade.net>\")` [flag (](https://github.com/ggml-org/llama.cpp/commit/2016f07bd106c73699ecbaace80f55db5ed95dac \"convert : experimental support for `--mmproj` flag \\(#13023\\)\n* convert : experimental support for `--mmproj` flag\n* fix bad ctrl+f replace\n* fix style\n* split into subclasses TextModel and VisionModel\n* rename Mode --> ModelBase\n* small fix\n* correct CLIP_VISION arch name \\(because existing GGUF already use it\\)\n* Apply suggestions from code review\nCo-authored-by: compilade <git@compilade.net>\n* fix Mistral3Model\n* fix typo\nCo-authored-by: compilade <git@compilade.net>\n---------\nCo-authored-by: compilade <git@compilade.net>\")[#13023](https://github.com/ggml-org/llama.cpp/pull/13023)[)](https://github.com/ggml-org/llama.cpp/commit/2016f07bd106c73699ecbaace80f55db5ed95dac \"convert : experimental support for `--mmproj` flag \\(#13023\\)\n* convert : experimental support for `--mmproj` flag\n* fix bad ctrl+f replace\n* fix style\n* split into subclasses TextModel and VisionModel\n* rename Mode --> ModelBase\n* small fix\n* correct CLIP_VISION arch name \\(because existing GGUF already use it\\)\n* Apply suggestions from code review\nCo-authored-by: compilade <git@compilade.net>\n* fix Mistral3Model\n* fix typo\nCo-authored-by: compilade <git@compilade.net>\n---------\nCo-authored-by: compilade <git@compilade.net>\")| Apr 21, 2025  \n[flake.lock](https://github.com/ggml-org/llama.cpp/blob/master/flake.lock \"flake.lock\")| [flake.lock](https://github.com/ggml-org/llama.cpp/blob/master/flake.lock \"flake.lock\")| [flake.lock: Update (](https://github.com/ggml-org/llama.cpp/commit/cce5a9007572c6e9fa522296b77571d2e5071357 \"flake.lock: Update \\(#10470\\)\nFlake lock file updates:\nâ¢ Updated input 'nixpkgs':\n  'github:NixOS/nixpkgs/5e4fbfb6b3de1aa2872b76d49fafc942626e2add?narHash=sha256-OZiZ3m8SCMfh3B6bfGC/Bm4x3qc1m2SVEAlkV6iY7Yg%3D' \\(2024-11-15\\)\n â 'github:NixOS/nixpkgs/23e89b7da85c3640bbc2173fe04f4bd114342367?narHash=sha256-y/MEyuJ5oBWrWAic/14LaIr/u5E0wRVzyYsouYY3W6w%3D' \\(2024-11-19\\)\nCo-authored-by: github-actions\\[bot\\] <github-actions\\[bot\\]@users.noreply.github.com>\")[#10470](https://github.com/ggml-org/llama.cpp/pull/10470)[)](https://github.com/ggml-org/llama.cpp/commit/cce5a9007572c6e9fa522296b77571d2e5071357 \"flake.lock: Update \\(#10470\\)\nFlake lock file updates:\nâ¢ Updated input 'nixpkgs':\n  'github:NixOS/nixpkgs/5e4fbfb6b3de1aa2872b76d49fafc942626e2add?narHash=sha256-OZiZ3m8SCMfh3B6bfGC/Bm4x3qc1m2SVEAlkV6iY7Yg%3D' \\(2024-11-15\\)\n â 'github:NixOS/nixpkgs/23e89b7da85c3640bbc2173fe04f4bd114342367?narHash=sha256-y/MEyuJ5oBWrWAic/14LaIr/u5E0wRVzyYsouYY3W6w%3D' \\(2024-11-19\\)\nCo-authored-by: github-actions\\[bot\\] <github-actions\\[bot\\]@users.noreply.github.com>\")| Nov 24, 2024  \n[flake.nix](https://github.com/ggml-org/llama.cpp/blob/master/flake.nix \"flake.nix\")| [flake.nix](https://github.com/ggml-org/llama.cpp/blob/master/flake.nix \"flake.nix\")| [repo : update links to new url (](https://github.com/ggml-org/llama.cpp/commit/68ff663a04ed92044a9937bcae353e9d9733f9cd \"repo : update links to new url \\(#11886\\)\n* repo : update links to new url\nggml-ci\n* cont : more urls\nggml-ci\")[#11886](https://github.com/ggml-org/llama.cpp/pull/11886)[)](https://github.com/ggml-org/llama.cpp/commit/68ff663a04ed92044a9937bcae353e9d9733f9cd \"repo : update links to new url \\(#11886\\)\n* repo : update links to new url\nggml-ci\n* cont : more urls\nggml-ci\")| Feb 15, 2025  \n[mypy.ini](https://github.com/ggml-org/llama.cpp/blob/master/mypy.ini \"mypy.ini\")| [mypy.ini](https://github.com/ggml-org/llama.cpp/blob/master/mypy.ini \"mypy.ini\")| [convert : partially revert PR](https://github.com/ggml-org/llama.cpp/commit/b43ebde3b0ccbc42d9dd782b32e2fd8eb35b43b5 \"convert : partially revert PR #4818 \\(#5041\\)\") [#4818](https://github.com/ggml-org/llama.cpp/pull/4818) [(](https://github.com/ggml-org/llama.cpp/commit/b43ebde3b0ccbc42d9dd782b32e2fd8eb35b43b5 \"convert : partially revert PR #4818 \\(#5041\\)\")[#5041](https://github.com/ggml-org/llama.cpp/pull/5041)[)](https://github.com/ggml-org/llama.cpp/commit/b43ebde3b0ccbc42d9dd782b32e2fd8eb35b43b5 \"convert : partially revert PR #4818 \\(#5041\\)\")| Jan 21, 2024  \n[poetry.lock](https://github.com/ggml-org/llama.cpp/blob/master/poetry.lock \"poetry.lock\")| [poetry.lock](https://github.com/ggml-org/llama.cpp/blob/master/poetry.lock \"poetry.lock\")| [build(python): Package scripts with pip-0517 compliance](https://github.com/ggml-org/llama.cpp/commit/b0a46993dfbf8b8127598f319d4dcfdd83824ba8 \"build\\(python\\): Package scripts with pip-0517 compliance\")| Jul 4, 2024  \n[pyproject.toml](https://github.com/ggml-org/llama.cpp/blob/master/pyproject.toml \"pyproject.toml\")| [pyproject.toml](https://github.com/ggml-org/llama.cpp/blob/master/pyproject.toml \"pyproject.toml\")| [gguf-py : avoid requiring pyside6 for other scripts (](https://github.com/ggml-org/llama.cpp/commit/a7366faa5bb2fff97b9fb43340d853709f52d8c9 \"gguf-py : avoid requiring pyside6 for other scripts \\(#13036\\)\n- gguf-py : remove gguf-py/gguf/scripts/__init__.py because it's not needed\nImplicit namespaces are supported since Python 3.3 \\(https://peps.python.org/pep-0420/\\),\nand the entrypoints in pyproject.toml can directly refer to the main functions.\")[#13036](https://github.com/ggml-org/llama.cpp/pull/13036)[)](https://github.com/ggml-org/llama.cpp/commit/a7366faa5bb2fff97b9fb43340d853709f52d8c9 \"gguf-py : avoid requiring pyside6 for other scripts \\(#13036\\)\n- gguf-py : remove gguf-py/gguf/scripts/__init__.py because it's not needed\nImplicit namespaces are supported since Python 3.3 \\(https://peps.python.org/pep-0420/\\),\nand the entrypoints in pyproject.toml can directly refer to the main functions.\")| May 6, 2025  \n[pyrightconfig.json](https://github.com/ggml-org/llama.cpp/blob/master/pyrightconfig.json \"pyrightconfig.json\")| [pyrightconfig.json](https://github.com/ggml-org/llama.cpp/blob/master/pyrightconfig.json \"pyrightconfig.json\")| [llama : move end-user examples to tools directory (](https://github.com/ggml-org/llama.cpp/commit/1d36b3670b285e69e58b9d687c770a2a0a192194 \"llama : move end-user examples to tools directory \\(#13249\\)\n* llama : move end-user examples to tools directory\n---------\nCo-authored-by: Xuan Son Nguyen <son@huggingface.co>\")[#13249](https://github.com/ggml-org/llama.cpp/pull/13249)[)](https://github.com/ggml-org/llama.cpp/commit/1d36b3670b285e69e58b9d687c770a2a0a192194 \"llama : move end-user examples to tools directory \\(#13249\\)\n* llama : move end-user examples to tools directory\n---------\nCo-authored-by: Xuan Son Nguyen <son@huggingface.co>\")| May 3, 2025  \n[requirements.txt](https://github.com/ggml-org/llama.cpp/blob/master/requirements.txt \"requirements.txt\")| [requirements.txt](https://github.com/ggml-org/llama.cpp/blob/master/requirements.txt \"requirements.txt\")| [`tool-call`: fix Qwen 2.5 Coder support, add micro benchmarks, supporâ¦](https://github.com/ggml-org/llama.cpp/commit/669912d9a5bf927312c553332ff997f0a99da8fb \"`tool-call`: fix Qwen 2.5 Coder support, add micro benchmarks, support trigger patterns for lazy grammars \\(#12034\\)\n* sampler: turn lazy grammar trigger words to regexes\n* add scripts/tool_bench.sh & .py\n* constrain llama json output regardless of function name if matches at beginning\n* update relaxed newline space rule in grammar tests\n* support add_generation_prompt query parameter \\(useful for /apply_template\\)\n* Update src/llama-grammar.cpp\nCo-authored-by: Georgi Gerganov <ggerganov@gmail.com>\n---------\nCo-authored-by: Georgi Gerganov <ggerganov@gmail.com>\")| Mar 5, 2025  \nView all files  \n## Repository files navigation\n  * [README](https://github.com/ggml-org/llama.cpp)\n  * [MIT license](https://github.com/ggml-org/llama.cpp)\n  * [Security](https://github.com/ggml-org/llama.cpp)\n\n\n# llama.cpp\n[](https://github.com/ggml-org/llama.cpp#llamacpp)\n[![llama](https://user-images.githubusercontent.com/1991296/230134379-7181e485-c521-4d23-a0d6-f7b3b61ba524.png)](https://user-images.githubusercontent.com/1991296/230134379-7181e485-c521-4d23-a0d6-f7b3b61ba524.png)\n[![License: MIT](https://camo.githubusercontent.com/6581c31c16c1b13ddc2efb92e2ad69a93ddc4a92fd871ff15d401c4c6c9155a4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d626c75652e737667)](https://opensource.org/licenses/MIT) [![Server](https://github.com/ggml-org/llama.cpp/actions/workflows/server.yml/badge.svg)](https://github.com/ggml-org/llama.cpp/actions/workflows/server.yml)\n[Roadmap](https://github.com/users/ggerganov/projects/7) / [Project status](https://github.com/ggml-org/llama.cpp/discussions/3471) / [Manifesto](https://github.com/ggml-org/llama.cpp/discussions/205) / [ggml](https://github.com/ggml-org/ggml)\nInference of Meta's [LLaMA](https://arxiv.org/abs/2302.13971) model (and others) in pure C/C++\n## Recent API changes\n[](https://github.com/ggml-org/llama.cpp#recent-api-changes)\n  * [Changelog for `libllama` API](https://github.com/ggml-org/llama.cpp/issues/9289)\n  * [Changelog for `llama-server` REST API](https://github.com/ggml-org/llama.cpp/issues/9291)\n\n\n## Hot topics\n[](https://github.com/ggml-org/llama.cpp#hot-topics)\n  * ð¥ Multimodal support arrived in `llama-server`: [#12898](https://github.com/ggml-org/llama.cpp/pull/12898) | [documentation](https://github.com/ggml-org/llama.cpp/blob/master/docs/multimodal.md)\n  * **GGML developer experience survey (organized and reviewed by NVIDIA):** [link](https://forms.gle/Gasw3cRgyhNEnrwK9)\n  * A new binary `llama-mtmd-cli` is introduced to replace `llava-cli`, `minicpmv-cli`, `gemma3-cli` ([#13012](https://github.com/ggml-org/llama.cpp/pull/13012)) and `qwen2vl-cli` ([#13141](https://github.com/ggml-org/llama.cpp/pull/13141)), `libllava` will be deprecated\n  * VS Code extension for FIM completions: <https://github.com/ggml-org/llama.vscode>\n  * Universal [tool call support](https://github.com/ggml-org/llama.cpp/blob/master/docs/function-calling.md) in `llama-server` [#9639](https://github.com/ggml-org/llama.cpp/pull/9639)\n  * Vim/Neovim plugin for FIM completions: <https://github.com/ggml-org/llama.vim>\n  * Introducing GGUF-my-LoRA [#10123](https://github.com/ggml-org/llama.cpp/discussions/10123)\n  * Hugging Face Inference Endpoints now support GGUF out of the box! [#9669](https://github.com/ggml-org/llama.cpp/discussions/9669)\n  * Hugging Face GGUF editor: [discussion](https://github.com/ggml-org/llama.cpp/discussions/9268) | [tool](https://huggingface.co/spaces/CISCai/gguf-editor)\n\n\n## Description\n[](https://github.com/ggml-org/llama.cpp#description)\nThe main goal of `llama.cpp` is to enable LLM inference with minimal setup and state-of-the-art performance on a wide range of hardware - locally and in the cloud.\n  * Plain C/C++ implementation without any dependencies\n  * Apple silicon is a first-class citizen - optimized via ARM NEON, Accelerate and Metal frameworks\n  * AVX, AVX2, AVX512 and AMX support for x86 architectures\n  * 1.5-bit, 2-bit, 3-bit, 4-bit, 5-bit, 6-bit, and 8-bit integer quantization for faster inference and reduced memory use\n  * Custom CUDA kernels for running LLMs on NVIDIA GPUs (support for AMD GPUs via HIP and Moore Threads GPUs via MUSA)\n  * Vulkan and SYCL backend support\n  * CPU+GPU hybrid inference to partially accelerate models larger than the total VRAM capacity\n\n\nThe `llama.cpp` project is the main playground for developing new features for the [ggml](https://github.com/ggml-org/ggml) library.\nModels\nTypically finetunes of the base models below are supported as well.\nInstructions for adding support for new models: [HOWTO-add-model.md](https://github.com/ggml-org/llama.cpp/blob/master/docs/development/HOWTO-add-model.md)\n#### Text-only\n[](https://github.com/ggml-org/llama.cpp#text-only)\n  * LLaMA ð¦\n  * LLaMA 2 ð¦ð¦\n  * LLaMA 3 ð¦ð¦ð¦\n  * [Mistral 7B](https://huggingface.co/mistralai/Mistral-7B-v0.1)\n  * [Mixtral MoE](https://huggingface.co/models?search=mistral-ai/Mixtral)\n  * [DBRX](https://huggingface.co/databricks/dbrx-instruct)\n  * [Falcon](https://huggingface.co/models?search=tiiuae/falcon)\n  * [Chinese LLaMA / Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca) and [Chinese LLaMA-2 / Alpaca-2](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2)\n  * [Vigogne (French)](https://github.com/bofenghuang/vigogne)\n  * [BERT](https://github.com/ggml-org/llama.cpp/pull/5423)\n  * [Koala](https://bair.berkeley.edu/blog/2023/04/03/koala/)\n  * [Baichuan 1 & 2](https://huggingface.co/models?search=baichuan-inc/Baichuan) + [derivations](https://huggingface.co/hiyouga/baichuan-7b-sft)\n  * [Aquila 1 & 2](https://huggingface.co/models?search=BAAI/Aquila)\n  * [Starcoder models](https://github.com/ggml-org/llama.cpp/pull/3187)\n  * [Refact](https://huggingface.co/smallcloudai/Refact-1_6B-fim)\n  * [MPT](https://github.com/ggml-org/llama.cpp/pull/3417)\n  * [Bloom](https://github.com/ggml-org/llama.cpp/pull/3553)\n  * [Yi models](https://huggingface.co/models?search=01-ai/Yi)\n  * [StableLM models](https://huggingface.co/stabilityai)\n  * [Deepseek models](https://huggingface.co/models?search=deepseek-ai/deepseek)\n  * [Qwen models](https://huggingface.co/models?search=Qwen/Qwen)\n  * [PLaMo-13B](https://github.com/ggml-org/llama.cpp/pull/3557)\n  * [Phi models](https://huggingface.co/models?search=microsoft/phi)\n  * [PhiMoE](https://github.com/ggml-org/llama.cpp/pull/11003)\n  * [GPT-2](https://huggingface.co/gpt2)\n  * [Orion 14B](https://github.com/ggml-org/llama.cpp/pull/5118)\n  * [InternLM2](https://huggingface.co/models?search=internlm2)\n  * [CodeShell](https://github.com/WisdomShell/codeshell)\n  * [Gemma](https://ai.google.dev/gemma)\n  * [Mamba](https://github.com/state-spaces/mamba)\n  * [Grok-1](https://huggingface.co/keyfan/grok-1-hf)\n  * [Xverse](https://huggingface.co/models?search=xverse)\n  * [Command-R models](https://huggingface.co/models?search=CohereForAI/c4ai-command-r)\n  * [SEA-LION](https://huggingface.co/models?search=sea-lion)\n  * [GritLM-7B](https://huggingface.co/GritLM/GritLM-7B) + [GritLM-8x7B](https://huggingface.co/GritLM/GritLM-8x7B)\n  * [OLMo](https://allenai.org/olmo)\n  * [OLMo 2](https://allenai.org/olmo)\n  * [OLMoE](https://huggingface.co/allenai/OLMoE-1B-7B-0924)\n  * [Granite models](https://huggingface.co/collections/ibm-granite/granite-code-models-6624c5cec322e4c148c8b330)\n  * [GPT-NeoX](https://github.com/EleutherAI/gpt-neox) + [Pythia](https://github.com/EleutherAI/pythia)\n  * [Snowflake-Arctic MoE](https://huggingface.co/collections/Snowflake/arctic-66290090abe542894a5ac520)\n  * [Smaug](https://huggingface.co/models?search=Smaug)\n  * [Poro 34B](https://huggingface.co/LumiOpen/Poro-34B)\n  * [Bitnet b1.58 models](https://huggingface.co/1bitLLM)\n  * [Flan T5](https://huggingface.co/models?search=flan-t5)\n  * [Open Elm models](https://huggingface.co/collections/apple/openelm-instruct-models-6619ad295d7ae9f868b759ca)\n  * [ChatGLM3-6b](https://huggingface.co/THUDM/chatglm3-6b) + [ChatGLM4-9b](https://huggingface.co/THUDM/glm-4-9b) + [GLMEdge-1.5b](https://huggingface.co/THUDM/glm-edge-1.5b-chat) + [GLMEdge-4b](https://huggingface.co/THUDM/glm-edge-4b-chat)\n  * [GLM-4-0414](https://huggingface.co/collections/THUDM/glm-4-0414-67f3cbcb34dd9d252707cb2e)\n  * [SmolLM](https://huggingface.co/collections/HuggingFaceTB/smollm-6695016cad7167254ce15966)\n  * [EXAONE-3.0-7.8B-Instruct](https://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct)\n  * [FalconMamba Models](https://huggingface.co/collections/tiiuae/falconmamba-7b-66b9a580324dd1598b0f6d4a)\n  * [Jais](https://huggingface.co/inceptionai/jais-13b-chat)\n  * [Bielik-11B-v2.3](https://huggingface.co/collections/speakleash/bielik-11b-v23-66ee813238d9b526a072408a)\n  * [RWKV-6](https://github.com/BlinkDL/RWKV-LM)\n  * [QRWKV-6](https://huggingface.co/recursal/QRWKV6-32B-Instruct-Preview-v0.1)\n  * [GigaChat-20B-A3B](https://huggingface.co/ai-sage/GigaChat-20B-A3B-instruct)\n  * [Trillion-7B-preview](https://huggingface.co/trillionlabs/Trillion-7B-preview)\n  * [Ling models](https://huggingface.co/collections/inclusionAI/ling-67c51c85b34a7ea0aba94c32)\n\n\n#### Multimodal\n[](https://github.com/ggml-org/llama.cpp#multimodal)\n  * [LLaVA 1.5 models](https://huggingface.co/collections/liuhaotian/llava-15-653aac15d994e992e2677a7e), [LLaVA 1.6 models](https://huggingface.co/collections/liuhaotian/llava-16-65b9e40155f60fd046a5ccf2)\n  * [BakLLaVA](https://huggingface.co/models?search=SkunkworksAI/Bakllava)\n  * [Obsidian](https://huggingface.co/NousResearch/Obsidian-3B-V0.5)\n  * [ShareGPT4V](https://huggingface.co/models?search=Lin-Chen/ShareGPT4V)\n  * [MobileVLM 1.7B/3B models](https://huggingface.co/models?search=mobileVLM)\n  * [Yi-VL](https://huggingface.co/models?search=Yi-VL)\n  * [Mini CPM](https://huggingface.co/models?search=MiniCPM)\n  * [Moondream](https://huggingface.co/vikhyatk/moondream2)\n  * [Bunny](https://github.com/BAAI-DCAI/Bunny)\n  * [GLM-EDGE](https://huggingface.co/models?search=glm-edge)\n  * [Qwen2-VL](https://huggingface.co/collections/Qwen/qwen2-vl-66cee7455501d7126940800d)\n\nBindings\n  * Python: [abetlen/llama-cpp-python](https://github.com/abetlen/llama-cpp-python)\n  * Go: [go-skynet/go-llama.cpp](https://github.com/go-skynet/go-llama.cpp)\n  * Node.js: [withcatai/node-llama-cpp](https://github.com/withcatai/node-llama-cpp)\n  * JS/TS (llama.cpp server client): [lgrammel/modelfusion](https://modelfusion.dev/integration/model-provider/llamacpp)\n  * JS/TS (Programmable Prompt Engine CLI): [offline-ai/cli](https://github.com/offline-ai/cli)\n  * JavaScript/Wasm (works in browser): [tangledgroup/llama-cpp-wasm](https://github.com/tangledgroup/llama-cpp-wasm)\n  * Typescript/Wasm (nicer API, available on npm): [ngxson/wllama](https://github.com/ngxson/wllama)\n  * Ruby: [yoshoku/llama_cpp.rb](https://github.com/yoshoku/llama_cpp.rb)\n  * Rust (more features): [edgenai/llama_cpp-rs](https://github.com/edgenai/llama_cpp-rs)\n  * Rust (nicer API): [mdrokz/rust-llama.cpp](https://github.com/mdrokz/rust-llama.cpp)\n  * Rust (more direct bindings): [utilityai/llama-cpp-rs](https://github.com/utilityai/llama-cpp-rs)\n  * Rust (automated build from crates.io): [ShelbyJenkins/llm_client](https://github.com/ShelbyJenkins/llm_client)\n  * C#/.NET: [SciSharp/LLamaSharp](https://github.com/SciSharp/LLamaSharp)\n  * C#/VB.NET (more features - community license): [LM-Kit.NET](https://docs.lm-kit.com/lm-kit-net/index.html)\n  * Scala 3: [donderom/llm4s](https://github.com/donderom/llm4s)\n  * Clojure: [phronmophobic/llama.clj](https://github.com/phronmophobic/llama.clj)\n  * React Native: [mybigday/llama.rn](https://github.com/mybigday/llama.rn)\n  * Java: [kherud/java-llama.cpp](https://github.com/kherud/java-llama.cpp)\n  * Zig: [deins/llama.cpp.zig](https://github.com/Deins/llama.cpp.zig)\n  * Flutter/Dart: [netdur/llama_cpp_dart](https://github.com/netdur/llama_cpp_dart)\n  * Flutter: [xuegao-tzx/Fllama](https://github.com/xuegao-tzx/Fllama)\n  * PHP (API bindings and features built on top of llama.cpp): [distantmagic/resonance](https://github.com/distantmagic/resonance) [(more info)](https://github.com/ggml-org/llama.cpp/pull/6326)\n  * Guile Scheme: [guile_llama_cpp](https://savannah.nongnu.org/projects/guile-llama-cpp)\n  * Swift [srgtuszy/llama-cpp-swift](https://github.com/srgtuszy/llama-cpp-swift)\n  * Swift [ShenghaiWang/SwiftLlama](https://github.com/ShenghaiWang/SwiftLlama)\n  * Delphi [Embarcadero/llama-cpp-delphi](https://github.com/Embarcadero/llama-cpp-delphi)\n\nUIs\n_(to have a project listed here, it should clearly state that it depends on`llama.cpp`)_\n  * [AI Sublime Text plugin](https://github.com/yaroslavyaroslav/OpenAI-sublime-text) (MIT)\n  * [cztomsik/ava](https://github.com/cztomsik/ava) (MIT)\n  * [Dot](https://github.com/alexpinel/Dot) (GPL)\n  * [eva](https://github.com/ylsdamxssjxxdd/eva) (MIT)\n  * [iohub/collama](https://github.com/iohub/coLLaMA) (Apache-2.0)\n  * [janhq/jan](https://github.com/janhq/jan) (AGPL)\n  * [johnbean393/Sidekick](https://github.com/johnbean393/Sidekick) (MIT)\n  * [KanTV](https://github.com/zhouwg/kantv?tab=readme-ov-file) (Apache-2.0)\n  * [KodiBot](https://github.com/firatkiral/kodibot) (GPL)\n  * [llama.vim](https://github.com/ggml-org/llama.vim) (MIT)\n  * [LARS](https://github.com/abgulati/LARS) (AGPL)\n  * [Llama Assistant](https://github.com/vietanhdev/llama-assistant) (GPL)\n  * [LLMFarm](https://github.com/guinmoon/LLMFarm?tab=readme-ov-file) (MIT)\n  * [LLMUnity](https://github.com/undreamai/LLMUnity) (MIT)\n  * [LMStudio](https://lmstudio.ai/) (proprietary)\n  * [LocalAI](https://github.com/mudler/LocalAI) (MIT)\n  * [LostRuins/koboldcpp](https://github.com/LostRuins/koboldcpp) (AGPL)\n  * [MindMac](https://mindmac.app) (proprietary)\n  * [MindWorkAI/AI-Studio](https://github.com/MindWorkAI/AI-Studio) (FSL-1.1-MIT)\n  * [Mobile-Artificial-Intelligence/maid](https://github.com/Mobile-Artificial-Intelligence/maid) (MIT)\n  * [Mozilla-Ocho/llamafile](https://github.com/Mozilla-Ocho/llamafile) (Apache-2.0)\n  * [nat/openplayground](https://github.com/nat/openplayground) (MIT)\n  * [nomic-ai/gpt4all](https://github.com/nomic-ai/gpt4all) (MIT)\n  * [ollama/ollama](https://github.com/ollama/ollama) (MIT)\n  * [oobabooga/text-generation-webui](https://github.com/oobabooga/text-generation-webui) (AGPL)\n  * [PocketPal AI](https://github.com/a-ghorbani/pocketpal-ai) (MIT)\n  * [psugihara/FreeChat](https://github.com/psugihara/FreeChat) (MIT)\n  * [ptsochantaris/emeltal](https://github.com/ptsochantaris/emeltal) (MIT)\n  * [pythops/tenere](https://github.com/pythops/tenere) (AGPL)\n  * [ramalama](https://github.com/containers/ramalama) (MIT)\n  * [semperai/amica](https://github.com/semperai/amica) (MIT)\n  * [withcatai/catai](https://github.com/withcatai/catai) (MIT)\n  * [Autopen](https://github.com/blackhole89/autopen) (GPL)\n\nTools\n  * [akx/ggify](https://github.com/akx/ggify) â download PyTorch models from HuggingFace Hub and convert them to GGML\n  * [akx/ollama-dl](https://github.com/akx/ollama-dl) â download models from the Ollama library to be used directly with llama.cpp\n  * [crashr/gppm](https://github.com/crashr/gppm) â launch llama.cpp instances utilizing NVIDIA Tesla P40 or P100 GPUs with reduced idle power consumption\n  * [gpustack/gguf-parser](https://github.com/gpustack/gguf-parser-go/tree/main/cmd/gguf-parser) - review/check the GGUF file and estimate the memory usage\n  * [Styled Lines](https://marketplace.unity.com/packages/tools/generative-ai/styled-lines-llama-cpp-model-292902) (proprietary licensed, async wrapper of inference part for game development in Unity3d with pre-built Mobile and Web platform wrappers and a model example)\n\nInfrastructure\n  * [Paddler](https://github.com/distantmagic/paddler) - Stateful load balancer custom-tailored for llama.cpp\n  * [GPUStack](https://github.com/gpustack/gpustack) - Manage GPU clusters for running LLMs\n  * [llama_cpp_canister](https://github.com/onicai/llama_cpp_canister) - llama.cpp as a smart contract on the Internet Computer, using WebAssembly\n  * [llama-swap](https://github.com/mostlygeek/llama-swap) - transparent proxy that adds automatic model switching with llama-server\n  * [Kalavai](https://github.com/kalavai-net/kalavai-client) - Crowdsource end to end LLM deployment at any scale\n  * [llmaz](https://github.com/InftyAI/llmaz) - â¸ï¸ Easy, advanced inference platform for large language models on Kubernetes.\n\nGames\n  * [Lucy's Labyrinth](https://github.com/MorganRO8/Lucys_Labyrinth) - A simple maze game where agents controlled by an AI model will try to trick you.\n\n\n## Supported backends\n[](https://github.com/ggml-org/llama.cpp#supported-backends)\nBackend | Target devices  \n---|---  \n[Metal](https://github.com/ggml-org/llama.cpp/blob/master/docs/build.md#metal-build) | Apple Silicon  \n[BLAS](https://github.com/ggml-org/llama.cpp/blob/master/docs/build.md#blas-build) | All  \n[BLIS](https://github.com/ggml-org/llama.cpp/blob/master/docs/backend/BLIS.md) | All  \n[SYCL](https://github.com/ggml-org/llama.cpp/blob/master/docs/backend/SYCL.md) | Intel and Nvidia GPU  \n[MUSA](https://github.com/ggml-org/llama.cpp/blob/master/docs/build.md#musa) | Moore Threads GPU  \n[CUDA](https://github.com/ggml-org/llama.cpp/blob/master/docs/build.md#cuda) | Nvidia GPU  \n[HIP](https://github.com/ggml-org/llama.cpp/blob/master/docs/build.md#hip) | AMD GPU  \n[Vulkan](https://github.com/ggml-org/llama.cpp/blob/master/docs/build.md#vulkan) | GPU  \n[CANN](https://github.com/ggml-org/llama.cpp/blob/master/docs/build.md#cann) | Ascend NPU  \n[OpenCL](https://github.com/ggml-org/llama.cpp/blob/master/docs/backend/OPENCL.md) | Adreno GPU  \n[RPC](https://github.com/ggml-org/llama.cpp/tree/master/tools/rpc) | All  \n## Building the project\n[](https://github.com/ggml-org/llama.cpp#building-the-project)\nThe main product of this project is the `llama` library. Its C-style interface can be found in [include/llama.h](https://github.com/ggml-org/llama.cpp/blob/master/include/llama.h). The project also includes many example programs and tools using the `llama` library. The examples range from simple, minimal code snippets to sophisticated sub-projects such as an OpenAI-compatible HTTP server. Possible methods for obtaining the binaries:\n  * Clone this repository and build locally, see [how to build](https://github.com/ggml-org/llama.cpp/blob/master/docs/build.md)\n  * On MacOS or Linux, install `llama.cpp` via [brew, flox or nix](https://github.com/ggml-org/llama.cpp/blob/master/docs/install.md)\n  * Use a Docker image, see [documentation for Docker](https://github.com/ggml-org/llama.cpp/blob/master/docs/docker.md)\n  * Download pre-built binaries from [releases](https://github.com/ggml-org/llama.cpp/releases)\n\n\n## Obtaining and quantizing models\n[](https://github.com/ggml-org/llama.cpp#obtaining-and-quantizing-models)\nThe [Hugging Face](https://huggingface.co) platform hosts a [number of LLMs](https://huggingface.co/models?library=gguf&sort=trending) compatible with `llama.cpp`:\n  * [Trending](https://huggingface.co/models?library=gguf&sort=trending)\n  * [LLaMA](https://huggingface.co/models?sort=trending&search=llama+gguf)\n\n\nYou can either manually download the GGUF file or directly use any `llama.cpp`-compatible models from [Hugging Face](https://huggingface.co/) or other model hosting sites, such as [ModelScope](https://modelscope.cn/), by using this CLI argument: `-hf <user>/<model>[:quant]`.\nBy default, the CLI would download from Hugging Face, you can switch to other options with the environment variable `MODEL_ENDPOINT`. For example, you may opt to downloading model checkpoints from ModelScope or other model sharing communities by setting the environment variable, e.g. `MODEL_ENDPOINT=https://www.modelscope.cn/`.\nAfter downloading a model, use the CLI tools to run it locally - see below.\n`llama.cpp` requires the model to be stored in the [GGUF](https://github.com/ggml-org/ggml/blob/master/docs/gguf.md) file format. Models in other data formats can be converted to GGUF using the `convert_*.py` Python scripts in this repo.\nThe Hugging Face platform provides a variety of online tools for converting, quantizing and hosting models with `llama.cpp`:\n  * Use the [GGUF-my-repo space](https://huggingface.co/spaces/ggml-org/gguf-my-repo) to convert to GGUF format and quantize model weights to smaller sizes\n  * Use the [GGUF-my-LoRA space](https://huggingface.co/spaces/ggml-org/gguf-my-lora) to convert LoRA adapters to GGUF format (more info: [#10123](https://github.com/ggml-org/llama.cpp/discussions/10123))\n  * Use the [GGUF-editor space](https://huggingface.co/spaces/CISCai/gguf-editor) to edit GGUF meta data in the browser (more info: [#9268](https://github.com/ggml-org/llama.cpp/discussions/9268))\n  * Use the [Inference Endpoints](https://ui.endpoints.huggingface.co/) to directly host `llama.cpp` in the cloud (more info: [#9669](https://github.com/ggml-org/llama.cpp/discussions/9669))\n\n\nTo learn more about model quantization, [read this documentation](https://github.com/ggml-org/llama.cpp/blob/master/tools/quantize/README.md)\n## [`llama-cli`](https://github.com/ggml-org/llama.cpp/blob/master/tools/main)\n[](https://github.com/ggml-org/llama.cpp#llama-cli)\n#### A CLI tool for accessing and experimenting with most of `llama.cpp`'s functionality.\n[](https://github.com/ggml-org/llama.cpp#a-cli-tool-for-accessing-and-experimenting-with-most-of-llamacpps-functionality)\n  * Run in conversation mode\nModels with a built-in chat template will automatically activate conversation mode. If this doesn't occur, you can manually enable it by adding `-cnv` and specifying a suitable chat template with `--chat-template NAME`\n```\nllama-cli -m model.gguf\n# > hi, who are you?\n# Hi there! I'm your helpful assistant! I'm an AI-powered chatbot designed to assist and provide information to users like you. I'm here to help answer your questions, provide guidance, and offer support on a wide range of topics. I'm a friendly and knowledgeable AI, and I'm always happy to help with anything you need. What's on your mind, and how can I assist you today?\n#\n# > what is 1+1?\n# Easy peasy! The answer to 1+1 is... 2!\n```\n\n  * Run in conversation mode with custom chat template\n```\n# use the \"chatml\" template (use -h to see the list of supported templates)\nllama-cli -m model.gguf -cnv --chat-template chatml\n# use a custom template\nllama-cli -m model.gguf -cnv --in-prefix 'User: ' --reverse-prompt 'User:'\n```\n\n  * Run simple text completion\nTo disable conversation mode explicitly, use `-no-cnv`\n```\nllama-cli -m model.gguf -p \"I believe the meaning of life is\" -n 128 -no-cnv\n# I believe the meaning of life is to find your own truth and to live in accordance with it. For me, this means being true to myself and following my passions, even if they don't align with societal expectations. I think that's what I love about yoga â it's not just a physical practice, but a spiritual one too. It's about connecting with yourself, listening to your inner voice, and honoring your own unique journey.\n```\n\n  * Constrain the output with a custom grammar\n```\nllama-cli -m model.gguf -n 256 --grammar-file grammars/json.gbnf -p 'Request: schedule a call at 8pm; Command:'\n# {\"appointmentTime\": \"8pm\", \"appointmentDetails\": \"schedule a a call\"}\n```\n\nThe [grammars/](https://github.com/ggml-org/llama.cpp/blob/master/grammars) folder contains a handful of sample grammars. To write your own, check out the [GBNF Guide](https://github.com/ggml-org/llama.cpp/blob/master/grammars/README.md).\nFor authoring more complex JSON grammars, check out <https://grammar.intrinsiclabs.ai/>\n\n\n## [`llama-server`](https://github.com/ggml-org/llama.cpp/blob/master/tools/server)\n[](https://github.com/ggml-org/llama.cpp#llama-server)\n#### A lightweight, [OpenAI API](https://github.com/openai/openai-openapi) compatible, HTTP server for serving LLMs.\n[](https://github.com/ggml-org/llama.cpp#a-lightweight-openai-api-compatible-http-server-for-serving-llms)\n  * Start a local HTTP server with default configuration on port 8080\n```\nllama-server -m model.gguf --port 8080\n# Basic web UI can be accessed via browser: http://localhost:8080\n# Chat completion endpoint: http://localhost:8080/v1/chat/completions\n```\n\n  * Support multiple-users and parallel decoding\n```\n# up to 4 concurrent requests, each with 4096 max context\nllama-server -m model.gguf -c 16384 -np 4\n```\n\n  * Enable speculative decoding\n```\n# the draft.gguf model should be a small variant of the target model.gguf\nllama-server -m model.gguf -md draft.gguf\n```\n\n  * Serve an embedding model\n```\n# use the /embedding endpoint\nllama-server -m model.gguf --embedding --pooling cls -ub 8192\n```\n\n  * Serve a reranking model\n```\n# use the /reranking endpoint\nllama-server -m model.gguf --reranking\n```\n\n  * Constrain all outputs with a grammar\n```\n# custom grammar\nllama-server -m model.gguf --grammar-file grammar.gbnf\n# JSON\nllama-server -m model.gguf --grammar-file grammars/json.gbnf\n```\n\n\n\n## [`llama-perplexity`](https://github.com/ggml-org/llama.cpp/blob/master/tools/perplexity)\n[](https://github.com/ggml-org/llama.cpp#llama-perplexity)\n#### A tool for measuring the perplexity [1](https://github.com/ggml-org/llama.cpp#user-content-fn-1-4fe0083f563412805e035f8393dd9038)[2](https://github.com/ggml-org/llama.cpp#user-content-fn-2-4fe0083f563412805e035f8393dd9038) (and other quality metrics) of a model over a given text.\n[](https://github.com/ggml-org/llama.cpp#a-tool-for-measuring-the-perplexity-12-and-other-quality-metrics-of-a-model-over-a-given-text)\n  * Measure the perplexity over a text file\n```\nllama-perplexity -m model.gguf -f file.txt\n# [1]15.2701,[2]5.4007,[3]5.3073,[4]6.2965,[5]5.8940,[6]5.6096,[7]5.7942,[8]4.9297, ...\n# Final estimate: PPL = 5.4007 +/- 0.67339\n```\n\n  * Measure KL divergence\n```\n# TODO\n```\n\n\n\n## [`llama-bench`](https://github.com/ggml-org/llama.cpp/blob/master/tools/llama-bench)\n[](https://github.com/ggml-org/llama.cpp#llama-bench)\n#### Benchmark the performance of the inference for various parameters.\n[](https://github.com/ggml-org/llama.cpp#benchmark-the-performance-of-the-inference-for-various-parameters)\n  * Run default benchmark\n```\nllama-bench -m model.gguf\n# Output:\n# | model        |    size |   params | backend  | threads |     test |         t/s |\n# | ------------------- | ---------: | ---------: | ---------- | ------: | ------------: | -------------------: |\n# | qwen2 1.5B Q4_0   | 885.97 MiB |   1.54 B | Metal,BLAS |   16 |     pp512 |   5765.41 Â± 20.55 |\n# | qwen2 1.5B Q4_0   | 885.97 MiB |   1.54 B | Metal,BLAS |   16 |     tg128 |    197.71 Â± 0.81 |\n#\n# build: 3e0ba0e60 (4229)\n```\n\n\n\n## [`llama-run`](https://github.com/ggml-org/llama.cpp/blob/master/tools/run)\n[](https://github.com/ggml-org/llama.cpp#llama-run)\n#### A comprehensive example for running `llama.cpp` models. Useful for inferencing. Used with RamaLama [3](https://github.com/ggml-org/llama.cpp#user-content-fn-3-4fe0083f563412805e035f8393dd9038).\n[](https://github.com/ggml-org/llama.cpp#a-comprehensive-example-for-running-llamacpp-models-useful-for-inferencing-used-with-ramalama-3)\n  * Run a model with a specific prompt (by default it's pulled from Ollama registry)\n```\nllama-run granite-code\n```\n\n\n\n## [`llama-simple`](https://github.com/ggml-org/llama.cpp/blob/master/examples/simple)\n[](https://github.com/ggml-org/llama.cpp#llama-simple)\n#### A minimal example for implementing apps with `llama.cpp`. Useful for developers.\n[](https://github.com/ggml-org/llama.cpp#a-minimal-example-for-implementing-apps-with-llamacpp-useful-for-developers)\n  * Basic text completion\n```\nllama-simple -m model.gguf\n# Hello my name is Kaitlyn and I am a 16 year old girl. I am a junior in high school and I am currently taking a class called \"The Art of\n```\n\n\n\n## Contributing\n[](https://github.com/ggml-org/llama.cpp#contributing)\n  * Contributors can open PRs\n  * Collaborators can push to branches in the `llama.cpp` repo and merge PRs into the `master` branch\n  * Collaborators will be invited based on contributions\n  * Any help with managing issues, PRs and projects is very appreciated!\n  * See [good first issues](https://github.com/ggml-org/llama.cpp/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22) for tasks suitable for first contributions\n  * Read the [CONTRIBUTING.md](https://github.com/ggml-org/llama.cpp/blob/master/CONTRIBUTING.md) for more information\n  * Make sure to read this: [Inference at the edge](https://github.com/ggml-org/llama.cpp/discussions/205)\n  * A bit of backstory for those who are interested: [Changelog podcast](https://changelog.com/podcast/532)\n\n\n## Other documentation\n[](https://github.com/ggml-org/llama.cpp#other-documentation)\n  * [main (cli)](https://github.com/ggml-org/llama.cpp/blob/master/tools/main/README.md)\n  * [server](https://github.com/ggml-org/llama.cpp/blob/master/tools/server/README.md)\n  * [GBNF grammars](https://github.com/ggml-org/llama.cpp/blob/master/grammars/README.md)\n\n\n#### Development documentation\n[](https://github.com/ggml-org/llama.cpp#development-documentation)\n  * [How to build](https://github.com/ggml-org/llama.cpp/blob/master/docs/build.md)\n  * [Running on Docker](https://github.com/ggml-org/llama.cpp/blob/master/docs/docker.md)\n  * [Build on Android](https://github.com/ggml-org/llama.cpp/blob/master/docs/android.md)\n  * [Performance troubleshooting](https://github.com/ggml-org/llama.cpp/blob/master/docs/development/token_generation_performance_tips.md)\n  * [GGML tips & tricks](https://github.com/ggml-org/llama.cpp/wiki/GGML-Tips-&-Tricks)\n\n\n#### Seminal papers and background on the models\n[](https://github.com/ggml-org/llama.cpp#seminal-papers-and-background-on-the-models)\nIf your issue is with model generation quality, then please at least scan the following links and papers to understand the limitations of LLaMA models. This is especially important when choosing an appropriate model size and appreciating both the significant and subtle differences between LLaMA models and ChatGPT:\n  * LLaMA: \n    * [Introducing LLaMA: A foundational, 65-billion-parameter large language model](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/)\n    * [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971)\n  * GPT-3 \n    * [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165)\n  * GPT-3.5 / InstructGPT / ChatGPT: \n    * [Aligning language models to follow instructions](https://openai.com/research/instruction-following)\n    * [Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155)\n\n\n## XCFramework\n[](https://github.com/ggml-org/llama.cpp#xcframework)\nThe XCFramework is a precompiled version of the library for iOS, visionOS, tvOS, and macOS. It can be used in Swift projects without the need to compile the library from source. For example:\n```\n// swift-tools-version: 5.10\n// The swift-tools-version declares the minimum version of Swift required to build this package.\nimport PackageDescription\nlet package = Package(\n  name: \"MyLlamaPackage\",\n  targets: [\n    .executableTarget(\n      name: \"MyLlamaPackage\",\n      dependencies: [\n        \"LlamaFramework\"\n      ]),\n    .binaryTarget(\n      name: \"LlamaFramework\",\n      url: \"https://github.com/ggml-org/llama.cpp/releases/download/b5046/llama-b5046-xcframework.zip\",\n      checksum: \"c19be78b5f00d8d29a25da41042cb7afa094cbf6280a225abe614b03b20029ab\"\n    )\n  ]\n)\n```\n\nThe above example is using an intermediate build `b5046` of the library. This can be modified to use a different version by changing the URL and checksum.\n## Completions\n[](https://github.com/ggml-org/llama.cpp#completions)\nCommand-line completion is available for some environments.\n#### Bash Completion\n[](https://github.com/ggml-org/llama.cpp#bash-completion)\n```\n$ build/bin/llama-cli --completion-bash > ~/.llama-completion.bash\n$ source ~/.llama-completion.bash\n```\n\nOptionally this can be added to your `.bashrc` or `.bash_profile` to load it automatically. For example:\n```\n$ echo \"source ~/.llama-completion.bash\" >> ~/.bashrc\n```\n\n## Dependencies\n[](https://github.com/ggml-org/llama.cpp#dependencies)\n  * [yhirose/cpp-httplib](https://github.com/yhirose/cpp-httplib) - Single-header HTTP server, used by `llama-server` - MIT license\n  * [stb-image](https://github.com/nothings/stb) - Single-header image format decoder, used by multimodal subsystem - Public domain\n  * [nlohmann/json](https://github.com/nlohmann/json) - Single-header JSON library, used by various tools/examples - MIT License\n  * [minja](https://github.com/google/minja) - Minimal Jinja parser in C++, used by various tools/examples - MIT License\n  * [linenoise.cpp](https://github.com/ggml-org/llama.cpp/blob/master/tools/run/linenoise.cpp/linenoise.cpp) - C++ library that provides readline-like line editing capabilities, used by `llama-run` - BSD 2-Clause License\n  * [curl](https://curl.se/) - Client-side URL transfer library, used by various tools/examples - [CURL License](https://curl.se/docs/copyright.html)\n  * [miniaudio.h](https://github.com/mackron/miniaudio) - Single-header audio format decoder, used by multimodal subsystem - Public domain\n\n\n## Footnotes\n  1. [tools/perplexity/README.md](https://github.com/ggml-org/tools/perplexity/README.md) [â©](https://github.com/ggml-org/llama.cpp#user-content-fnref-1-4fe0083f563412805e035f8393dd9038)\n  2. <https://huggingface.co/docs/transformers/perplexity> [â©](https://github.com/ggml-org/llama.cpp#user-content-fnref-2-4fe0083f563412805e035f8393dd9038)\n  3. [RamaLama](https://github.com/containers/ramalama) [â©](https://github.com/ggml-org/llama.cpp#user-content-fnref-3-4fe0083f563412805e035f8393dd9038)\n\n\n## About\nLLM inference in C/C++ \n### Topics\n[ llama ](https://github.com/topics/llama \"Topic: llama\") [ ggml ](https://github.com/topics/ggml \"Topic: ggml\")\n### Resources\n[ Readme ](https://github.com/ggml-org/llama.cpp#readme-ov-file)\n### License\n[ MIT license ](https://github.com/ggml-org/llama.cpp#MIT-1-ov-file)\n### Security policy\n[ Security policy ](https://github.com/ggml-org/llama.cpp#security-ov-file)\n###  Uh oh! \nThere was an error while loading. [Please reload this page](https://github.com/ggml-org/llama.cpp).\n[ Activity](https://github.com/ggml-org/llama.cpp/activity)\n[ Custom properties](https://github.com/ggml-org/llama.cpp/custom-properties)\n### Stars\n[ **81k** stars](https://github.com/ggml-org/llama.cpp/stargazers)\n### Watchers\n[ **587** watching](https://github.com/ggml-org/llama.cpp/watchers)\n### Forks\n[ **12k** forks](https://github.com/ggml-org/llama.cpp/forks)\n[ Report repository ](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fggml-org%2Fllama.cpp&report=ggml-org+%28user%29)\n##  [Releases 3,535](https://github.com/ggml-org/llama.cpp/releases)\n[ b5527 Latest  May 28, 2025 ](https://github.com/ggml-org/llama.cpp/releases/tag/b5527)\n[+ 3,534 releases](https://github.com/ggml-org/llama.cpp/releases)\n##  [Packages 1](https://github.com/orgs/ggml-org/packages?repo_name=llama.cpp)\n  * [ llama.cpp ](https://github.com/orgs/ggml-org/packages/container/package/llama.cpp)\n\n\n###  Uh oh! \nThere was an error while loading. [Please reload this page](https://github.com/ggml-org/llama.cpp).\n##  [Contributors 1,156](https://github.com/ggml-org/llama.cpp/graphs/contributors)\n  * [ ![@ggerganov](https://avatars.githubusercontent.com/u/1991296?s=64&v=4) ](https://github.com/ggerganov)\n  * [ ![@slaren](https://avatars.githubusercontent.com/u/2141330?s=64&v=4) ](https://github.com/slaren)\n  * [ ![@ngxson](https://avatars.githubusercontent.com/u/7702203?s=64&v=4) ](https://github.com/ngxson)\n  * [ ![@JohannesGaessler](https://avatars.githubusercontent.com/u/18492268?s=64&v=4) ](https://github.com/JohannesGaessler)\n  * [ ![@cebtenzzre](https://avatars.githubusercontent.com/u/14168726?s=64&v=4) ](https://github.com/cebtenzzre)\n  * [ ![@danbev](https://avatars.githubusercontent.com/u/432351?s=64&v=4) ](https://github.com/danbev)\n  * [ ![@ikawrakow](https://avatars.githubusercontent.com/u/48489457?s=64&v=4) ](https://github.com/ikawrakow)\n  * [ ![@Kawrakow](https://avatars.githubusercontent.com/u/31961568?s=64&v=4) ](https://github.com/Kawrakow)\n  * [ ![@jeffbolznv](https://avatars.githubusercontent.com/u/8260565?s=64&v=4) ](https://github.com/jeffbolznv)\n  * [ ![@ochafik](https://avatars.githubusercontent.com/u/273860?s=64&v=4) ](https://github.com/ochafik)\n  * [ ![@compilade](https://avatars.githubusercontent.com/u/113953597?s=64&v=4) ](https://github.com/compilade)\n  * [ ![@phymbert](https://avatars.githubusercontent.com/u/5741141?s=64&v=4) ](https://github.com/phymbert)\n  * [ ![@CISC](https://avatars.githubusercontent.com/u/1629204?s=64&v=4) ](https://github.com/CISC)\n  * [ ![@0cc4m](https://avatars.githubusercontent.com/u/11707594?s=64&v=4) ](https://github.com/0cc4m)\n\n\n[+ 1,142 contributors](https://github.com/ggml-org/llama.cpp/graphs/contributors)\n## Languages\n  * [ C++ 62.7% ](https://github.com/ggml-org/llama.cpp/search?l=c%2B%2B)\n  * [ C 11.7% ](https://github.com/ggml-org/llama.cpp/search?l=c)\n  * [ Python 8.0% ](https://github.com/ggml-org/llama.cpp/search?l=python)\n  * [ Cuda 6.1% ](https://github.com/ggml-org/llama.cpp/search?l=cuda)\n  * [ Objective-C 2.2% ](https://github.com/ggml-org/llama.cpp/search?l=objective-c)\n  * [ Metal 2.0% ](https://github.com/ggml-org/llama.cpp/search?l=metal)\n  * Other 7.3%\n\n\n## Footer\n[ ](https://github.com) Â© 2025 GitHub, Inc. \n### Footer navigation\n  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n  * [Security](https://github.com/security)\n  * [Status](https://www.githubstatus.com/)\n  * [Docs](https://docs.github.com/)\n  * [Contact](https://support.github.com?tags=dotcom-footer)\n  * Manage cookies \n  * Do not share my personal information \n\n\nYou canât perform that action at this time. \n"
  },
  {
    "link": "https://github.com/NirDiamant/GenAI_Agents",
    "raw_content": "[Skip to content](https://github.com/NirDiamant/GenAI_Agents#start-of-content)\n## Navigation Menu\nToggle navigation\n[ ](https://github.com/)\n[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FNirDiamant%2FGenAI_Agents)\nAppearance settings\n  * Product \n    * [ GitHub Copilot  Write better code with AI  ](https://github.com/features/copilot)\n    * [ GitHub Models  New  Manage and compare prompts  ](https://github.com/features/models)\n    * [ GitHub Advanced Security  Find and fix vulnerabilities  ](https://github.com/security/advanced-security)\n    * [ Actions  Automate any workflow  ](https://github.com/features/actions)\n    * [ Codespaces  Instant dev environments  ](https://github.com/features/codespaces)\n    * [ Issues  Plan and track work  ](https://github.com/features/issues)\n    * [ Code Review  Manage code changes  ](https://github.com/features/code-review)\n    * [ Discussions  Collaborate outside of code  ](https://github.com/features/discussions)\n    * [ Code Search  Find more, search less  ](https://github.com/features/code-search)\nExplore\n    * [ Why GitHub ](https://github.com/why-github)\n    * [ All features ](https://github.com/features)\n    * [ Documentation ](https://docs.github.com)\n    * [ GitHub Skills ](https://skills.github.com)\n    * [ Blog ](https://github.blog)\n  * Solutions \nBy company size\n    * [ Enterprises ](https://github.com/enterprise)\n    * [ Small and medium teams ](https://github.com/team)\n    * [ Startups ](https://github.com/enterprise/startups)\n    * [ Nonprofits ](https://github.com/solutions/industry/nonprofits)\nBy use case\n    * [ DevSecOps ](https://github.com/solutions/use-case/devsecops)\n    * [ DevOps ](https://github.com/solutions/use-case/devops)\n    * [ CI/CD ](https://github.com/solutions/use-case/ci-cd)\n    * [ View all use cases ](https://github.com/solutions/use-case)\nBy industry\n    * [ Healthcare ](https://github.com/solutions/industry/healthcare)\n    * [ Financial services ](https://github.com/solutions/industry/financial-services)\n    * [ Manufacturing ](https://github.com/solutions/industry/manufacturing)\n    * [ Government ](https://github.com/solutions/industry/government)\n    * [ View all industries ](https://github.com/solutions/industry)\n[ View all solutions ](https://github.com/solutions)\n  * Resources \nTopics\n    * [ AI ](https://github.com/resources/articles/ai)\n    * [ DevOps ](https://github.com/resources/articles/devops)\n    * [ Security ](https://github.com/resources/articles/security)\n    * [ Software Development ](https://github.com/resources/articles/software-development)\n    * [ View all ](https://github.com/resources/articles)\nExplore\n    * [ Learning Pathways ](https://resources.github.com/learn/pathways)\n    * [ Events & Webinars ](https://resources.github.com)\n    * [ Ebooks & Whitepapers ](https://github.com/resources/whitepapers)\n    * [ Customer Stories ](https://github.com/customer-stories)\n    * [ Partners ](https://partner.github.com)\n    * [ Executive Insights ](https://github.com/solutions/executive-insights)\n  * Open Source \n    * [ GitHub Sponsors  Fund open source developers  ](https://github.com/sponsors)\n    * [ The ReadME Project  GitHub community articles  ](https://github.com/readme)\nRepositories\n    * [ Topics ](https://github.com/topics)\n    * [ Trending ](https://github.com/trending)\n    * [ Collections ](https://github.com/collections)\n  * Enterprise \n    * [ Enterprise platform  AI-powered developer platform  ](https://github.com/enterprise)\nAvailable add-ons\n    * [ GitHub Advanced Security  Enterprise-grade security features  ](https://github.com/security/advanced-security)\n    * [ Copilot for business  Enterprise-grade AI features  ](https://github.com/features/copilot/copilot-business)\n    * [ Premium Support  Enterprise-grade 24/7 support  ](https://github.com/premium-support)\n  * [Pricing](https://github.com/pricing)\n\n\nSearch or jump to...\n# Search code, repositories, users, issues, pull requests...\nSearch \nClear\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n#  Provide feedback \nWe read every piece of feedback, and take your input very seriously.\nInclude my email address so I can be contacted\nCancel  Submit feedback \n#  Saved searches \n## Use saved searches to filter your results more quickly\nName\nQuery\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax). \nCancel  Create saved search \n[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FNirDiamant%2FGenAI_Agents)\n[ Sign up ](https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=NirDiamant%2FGenAI_Agents)\nAppearance settings\nResetting focus\nYou signed in with another tab or window. [Reload](https://github.com/NirDiamant/GenAI_Agents) to refresh your session. You signed out in another tab or window. [Reload](https://github.com/NirDiamant/GenAI_Agents) to refresh your session. You switched accounts on another tab or window. [Reload](https://github.com/NirDiamant/GenAI_Agents) to refresh your session. Dismiss alert\n{{ message }}\n[ NirDiamant ](https://github.com/NirDiamant) / **[GenAI_Agents](https://github.com/NirDiamant/GenAI_Agents) ** Public\n  * [ Sponsor  ](https://github.com/sponsors/NirDiamant)\n  * [ Notifications ](https://github.com/login?return_to=%2FNirDiamant%2FGenAI_Agents) You must be signed in to change notification settings\n  * [ Fork 1.6k ](https://github.com/login?return_to=%2FNirDiamant%2FGenAI_Agents)\n  * [ Star  12.5k ](https://github.com/login?return_to=%2FNirDiamant%2FGenAI_Agents)\n\n\nThis repository provides tutorials and implementations for various Generative AI Agent techniques, from basic to advanced. It serves as a comprehensive guide for building intelligent, interactive AI systems. \n### License\n[ View license ](https://github.com/NirDiamant/GenAI_Agents/blob/main/LICENSE)\n[ 12.5k stars ](https://github.com/NirDiamant/GenAI_Agents/stargazers) [ 1.6k forks ](https://github.com/NirDiamant/GenAI_Agents/forks) [ Branches ](https://github.com/NirDiamant/GenAI_Agents/branches) [ Tags ](https://github.com/NirDiamant/GenAI_Agents/tags) [ Activity ](https://github.com/NirDiamant/GenAI_Agents/activity)\n[ Star  ](https://github.com/login?return_to=%2FNirDiamant%2FGenAI_Agents)\n[ Notifications ](https://github.com/login?return_to=%2FNirDiamant%2FGenAI_Agents) You must be signed in to change notification settings\n  * [ Code ](https://github.com/NirDiamant/GenAI_Agents)\n  * [ Issues 1 ](https://github.com/NirDiamant/GenAI_Agents/issues)\n  * [ Pull requests 14 ](https://github.com/NirDiamant/GenAI_Agents/pulls)\n  * [ Actions ](https://github.com/NirDiamant/GenAI_Agents/actions)\n  * [ Projects 0 ](https://github.com/NirDiamant/GenAI_Agents/projects)\n  * [ Security ](https://github.com/NirDiamant/GenAI_Agents/security)\n[ ](https://github.com/NirDiamant/GenAI_Agents/security)\n[ ](https://github.com/NirDiamant/GenAI_Agents/security)\n[ ](https://github.com/NirDiamant/GenAI_Agents/security)\n### [ Uh oh!  ](https://github.com/NirDiamant/GenAI_Agents/security)\n[There was an error while loading. ](https://github.com/NirDiamant/GenAI_Agents/security)[Please reload this page](https://github.com/NirDiamant/GenAI_Agents).\n  * [ Insights ](https://github.com/NirDiamant/GenAI_Agents/pulse)\n\n\nAdditional navigation options\n  * [ Code  ](https://github.com/NirDiamant/GenAI_Agents)\n  * [ Issues  ](https://github.com/NirDiamant/GenAI_Agents/issues)\n  * [ Pull requests  ](https://github.com/NirDiamant/GenAI_Agents/pulls)\n  * [ Actions  ](https://github.com/NirDiamant/GenAI_Agents/actions)\n  * [ Projects  ](https://github.com/NirDiamant/GenAI_Agents/projects)\n  * [ Security  ](https://github.com/NirDiamant/GenAI_Agents/security)\n  * [ Insights  ](https://github.com/NirDiamant/GenAI_Agents/pulse)\n\n\n# NirDiamant/GenAI_Agents\nmain\n[**1** Branch](https://github.com/NirDiamant/GenAI_Agents/branches)[**0** Tags](https://github.com/NirDiamant/GenAI_Agents/tags)\n[](https://github.com/NirDiamant/GenAI_Agents/branches)[](https://github.com/NirDiamant/GenAI_Agents/tags)\nGo to file\nCode\n## Folders and files\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n## Latest commit\n[![NirDiamant](https://avatars.githubusercontent.com/u/28316913?v=4&size=40)](https://github.com/NirDiamant)[NirDiamant](https://github.com/NirDiamant/GenAI_Agents/commits?author=NirDiamant)[minor update](https://github.com/NirDiamant/GenAI_Agents/commit/236ddc539de35f03e46b6d1adcd98d889be6ee5b)May 15, 2025[236ddc5](https://github.com/NirDiamant/GenAI_Agents/commit/236ddc539de35f03e46b6d1adcd98d889be6ee5b) Â· May 15, 2025\n## History\n[304 Commits](https://github.com/NirDiamant/GenAI_Agents/commits/main/)[](https://github.com/NirDiamant/GenAI_Agents/commits/main/)  \n[.github](https://github.com/NirDiamant/GenAI_Agents/tree/main/.github \".github\")| [.github](https://github.com/NirDiamant/GenAI_Agents/tree/main/.github \".github\")| [copying files from private repo](https://github.com/NirDiamant/GenAI_Agents/commit/55708ca909677067c433c4fc90da3d095cff26fb \"copying files from private repo\")| Sep 10, 2024  \n[all_agents_tutorials](https://github.com/NirDiamant/GenAI_Agents/tree/main/all_agents_tutorials \"all_agents_tutorials\")| [all_agents_tutorials](https://github.com/NirDiamant/GenAI_Agents/tree/main/all_agents_tutorials \"all_agents_tutorials\")| [minor update](https://github.com/NirDiamant/GenAI_Agents/commit/236ddc539de35f03e46b6d1adcd98d889be6ee5b \"minor update\")| May 15, 2025  \n[audio](https://github.com/NirDiamant/GenAI_Agents/tree/main/audio \"audio\")| [audio](https://github.com/NirDiamant/GenAI_Agents/tree/main/audio \"audio\")| [updated tts](https://github.com/NirDiamant/GenAI_Agents/commit/99453af644e288dd67f4adf665c391f411cfff89 \"updated tts\")| Sep 10, 2024  \n[data](https://github.com/NirDiamant/GenAI_Agents/tree/main/data \"data\")| [data](https://github.com/NirDiamant/GenAI_Agents/tree/main/data \"data\")| [minor fix](https://github.com/NirDiamant/GenAI_Agents/commit/009a35a9706d11149d9d645fcbdb6bee73381b87 \"minor fix\")| Mar 27, 2025  \n[images](https://github.com/NirDiamant/GenAI_Agents/tree/main/images \"images\")| [images](https://github.com/NirDiamant/GenAI_Agents/tree/main/images \"images\")| [minor update](https://github.com/NirDiamant/GenAI_Agents/commit/236ddc539de35f03e46b6d1adcd98d889be6ee5b \"minor update\")| May 15, 2025  \n[.gitignore](https://github.com/NirDiamant/GenAI_Agents/blob/main/.gitignore \".gitignore\")| [.gitignore](https://github.com/NirDiamant/GenAI_Agents/blob/main/.gitignore \".gitignore\")| [copying files from private repo](https://github.com/NirDiamant/GenAI_Agents/commit/55708ca909677067c433c4fc90da3d095cff26fb \"copying files from private repo\")| Sep 10, 2024  \n[CONTRIBUTING.md](https://github.com/NirDiamant/GenAI_Agents/blob/main/CONTRIBUTING.md \"CONTRIBUTING.md\")| [CONTRIBUTING.md](https://github.com/NirDiamant/GenAI_Agents/blob/main/CONTRIBUTING.md \"CONTRIBUTING.md\")| [minor update](https://github.com/NirDiamant/GenAI_Agents/commit/6f3e8a334bbc6765a60d15c123d8b5f5b4258ffd \"minor update\")| Apr 15, 2025  \n[LICENSE](https://github.com/NirDiamant/GenAI_Agents/blob/main/LICENSE \"LICENSE\")| [LICENSE](https://github.com/NirDiamant/GenAI_Agents/blob/main/LICENSE \"LICENSE\")| [updated license](https://github.com/NirDiamant/GenAI_Agents/commit/8af7d36635242966f9145c77d9bed4222dba8a78 \"updated license\")| Oct 4, 2024  \n[README.md](https://github.com/NirDiamant/GenAI_Agents/blob/main/README.md \"README.md\")| [README.md](https://github.com/NirDiamant/GenAI_Agents/blob/main/README.md \"README.md\")| [Update README.md](https://github.com/NirDiamant/GenAI_Agents/commit/0aeb447b0e46f7473bc7990b1c2da35a20cf990b \"Update README.md\")| Apr 17, 2025  \n[requirements.txt](https://github.com/NirDiamant/GenAI_Agents/blob/main/requirements.txt \"requirements.txt\")| [requirements.txt](https://github.com/NirDiamant/GenAI_Agents/blob/main/requirements.txt \"requirements.txt\")| [chore: upgrade duckduckgo to latest and platform to pywin32](https://github.com/NirDiamant/GenAI_Agents/commit/4aa23a4f152d043c54f8fd8f669bd97cfcc46da1 \"chore: upgrade duckduckgo to latest and platform to pywin32\")| Sep 28, 2024  \nView all files  \n## Repository files navigation\n  * [README](https://github.com/NirDiamant/GenAI_Agents)\n  * [License](https://github.com/NirDiamant/GenAI_Agents)\n\n\n[![PRs Welcome](https://camo.githubusercontent.com/88482ebfc5e3e4f2d667148ab6a3eb55948789f1dba71dfa0eb2e05afe02958c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5052732d77656c636f6d652d627269676874677265656e2e7376673f7374796c653d666c61742d737175617265)](http://makeapullrequest.com) [![LinkedIn](https://camo.githubusercontent.com/7f4fa09b1856697217ac8392123d9ab7b47e4d8f8b96d82fb5ba375f7b5f0406/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c696e6b6564496e2d436f6e6e6563742d626c7565)](https://www.linkedin.com/in/nir-diamant-759323134/) [![Twitter](https://camo.githubusercontent.com/77144d97330c42418af5c6a0db3e37f7776815dc76ce06c4dc436b5c7ee5c00c/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f4e69724469616d616e7441493f6c6162656c3d466f6c6c6f77253230404e69724469616d616e744149267374796c653d736f6369616c)](https://twitter.com/NirDiamantAI) [![Discord](https://camo.githubusercontent.com/9e829a68987b31f1ac8844d03ba67f279dbced2cc7f46d5ec42a35f7b5d5ec93/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446973636f72642d4a6f696e2532306f7572253230636f6d6d756e6974792d3732383964613f7374796c653d666c61742d737175617265266c6f676f3d646973636f7264266c6f676f436f6c6f723d7768697465)](https://discord.gg/cA6Aa4uyDX)\n> ð **Support This Project:** Your sponsorship fuels innovation in GenAI agent development. **[Become a sponsor](https://github.com/sponsors/NirDiamant)** to help maintain and expand this valuable resource!\n# GenAI Agents: Comprehensive Repository for Development and Implementation ð\n[](https://github.com/NirDiamant/GenAI_Agents#genai-agents-comprehensive-repository-for-development-and-implementation-)\nWelcome to one of the most extensive and dynamic collections of Generative AI (GenAI) agent tutorials and implementations available today. This repository serves as a comprehensive resource for learning, building, and sharing GenAI agents, ranging from simple conversational bots to complex, multi-agent systems.\n## ð« Stay Updated!\n[](https://github.com/NirDiamant/GenAI_Agents#-stay-updated)\nð**Cutting-edgeUpdates** | ð¡**ExpertInsights** | ð¯**Top 0.1%Content**  \n---|---|---  \n[![Subscribe to DiamantAI Newsletter](https://github.com/NirDiamant/GenAI_Agents/raw/main/images/subscribe-button.svg)](https://diamantai.substack.com/?r=336pe4&utm_campaign=pub-share-checklist)\n_Join over 20,000 of AI enthusiasts getting unique cutting-edge insights and free tutorials!_ _**Plus, subscribers get exclusive early access and special 33% discounts to my book and the upcoming RAG Techniques course!**_\n[![DiamantAI's newsletter](https://github.com/NirDiamant/GenAI_Agents/raw/main/images/substack_image.png)](https://diamantai.substack.com/?r=336pe4&utm_campaign=pub-share-checklist)\n## Introduction\n[](https://github.com/NirDiamant/GenAI_Agents#introduction)\nGenerative AI agents are at the forefront of artificial intelligence, revolutionizing the way we interact with and leverage AI technologies. This repository is designed to guide you through the development journey, from basic agent implementations to advanced, cutting-edge systems.\n### ð Learn to Build Your First AI Agent\n[](https://github.com/NirDiamant/GenAI_Agents#-learn-to-build-your-first-ai-agent) **[Your First AI Agent: Simpler Than You Think](https://diamantai.substack.com/p/your-first-ai-agent-simpler-than)** This detailed blog post complements the repository by providing a complete A-Z walkthrough with in-depth explanations of core concepts, step-by-step implementation, and the theory behind AI agents. It's designed to be incredibly simple to follow while covering everything you need to know to build your first working agent from scratch. _ð¡ Plus: Subscribe to the newsletter for exclusive early access to tutorials and special discounts on upcoming courses and books!_  \n---  \nOur goal is to provide a valuable resource for everyone - from beginners taking their first steps in AI to seasoned practitioners pushing the boundaries of what's possible. By offering a range of examples from foundational to complex, we aim to facilitate learning, experimentation, and innovation in the rapidly evolving field of GenAI agents.\nFurthermore, this repository serves as a platform for showcasing innovative agent creations. Whether you've developed a novel agent architecture or found an innovative application for existing techniques, we encourage you to share your work with the community.\n## Related Projects\n[](https://github.com/NirDiamant/GenAI_Agents#related-projects)\nð Dive into my **[comprehensive guide on RAG techniques](https://github.com/NirDiamant/RAG_Techniques)** to learn about integrating external knowledge into AI systems, enhancing their capabilities with up-to-date and relevant information retrieval.\nðï¸ Explore my **[Prompt Engineering Techniques guide](https://github.com/NirDiamant/Prompt_Engineering)** for an extensive collection of prompting strategies, from fundamental concepts to advanced methods, improving your ability to communicate effectively with AI language models.\n## A Community-Driven Knowledge Hub\n[](https://github.com/NirDiamant/GenAI_Agents#a-community-driven-knowledge-hub)\n**This repository grows stronger with your contributions!** Join our vibrant Discord community â the central hub for shaping and advancing this project together ð¤\n**[GenAI Agents Discord Community](https://discord.gg/cA6Aa4uyDX)**\nWhether you're a novice eager to learn or an expert ready to share your knowledge, your insights can shape the future of GenAI agents. Join us to propose ideas, get feedback, and collaborate on innovative implementations. For contribution guidelines, please refer to our **[CONTRIBUTING.md](https://github.com/NirDiamant/GenAI_Agents/blob/main/CONTRIBUTING.md)** file. Let's advance GenAI agent technology together!\nð For discussions on GenAI, agents, or to explore knowledge-sharing opportunities, feel free to **[connect on LinkedIn](https://www.linkedin.com/in/nir-diamant-759323134/)**.\n## Key Features\n[](https://github.com/NirDiamant/GenAI_Agents#key-features)\n  * ð Learn to build GenAI agents from beginner to advanced levels\n  * ð§  Explore a wide range of agent architectures and applications\n  * ð Step-by-step tutorials and comprehensive documentation\n  * ð ï¸ Practical, ready-to-use agent implementations\n  * ð Regular updates with the latest advancements in GenAI\n  * ð¤ Share your own agent creations with the community\n\n\n## GenAI Agent Implementations\n[](https://github.com/NirDiamant/GenAI_Agents#genai-agent-implementations)\nBelow is a comprehensive overview of our GenAI agent implementations, organized by category and functionality. Each implementation is designed to showcase different aspects of AI agent development, from basic conversational agents to complex multi-agent systems.\n# | Category | Agent Name | Framework | Key Features  \n---|---|---|---|---  \n1 | ð± **Beginner** | [Simple Conversational Agent](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/simple_conversational_agent.ipynb) | LangChain/PydanticAI | Context-aware conversations, history management  \n2 | ð± **Beginner** | [Simple Question Answering](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/simple_question_answering_agent.ipynb) | LangChain | Query understanding, concise answers  \n3 | ð± **Beginner** | [Simple Data Analysis](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/simple_data_analysis_agent_notebook.ipynb) | LangChain/PydanticAI | Dataset interpretation, natural language queries  \n4 | ð§ **Framework** | [Introduction to LangGraph](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/langgraph-tutorial.ipynb) | LangGraph | Modular AI workflows, state management  \n5 | ð§ **Framework** | [Model Context Protocol (MCP)](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/mcp-tutorial.ipynb) | MCP | AI-external resource integration  \n6 | ð **Educational** | [ATLAS: Academic Task System](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/Academic_Task_Learning_Agent_LangGraph.ipynb) | LangGraph | Multi-agent academic planning, note-taking  \n7 | ð **Educational** | [Scientific Paper Agent](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/scientific_paper_agent_langgraph.ipynb) | LangGraph | Literature review automation  \n8 | ð **Educational** | [Chiron - Feynman Learning](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/chiron_learning_agent_langgraph.ipynb) | LangGraph | Adaptive learning, checkpoint system  \n9 | ð¼ **Business** | [Customer Support Agent](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/customer_support_agent_langgraph.ipynb) | LangGraph | Query categorization, sentiment analysis  \n10 | ð¼ **Business** | [Essay Grading Agent](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/essay_grading_system_langgraph.ipynb) | LangGraph | Automated grading, multiple criteria  \n11 | ð¼ **Business** | [Travel Planning Agent](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/simple_travel_planner_langgraph.ipynb) | LangGraph | Personalized itineraries  \n12 | ð¼ **Business** | [GenAI Career Assistant](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/agent_hackathon_genAI_career_assistant.ipynb) | LangGraph | Career guidance, learning paths  \n13 | ð¼ **Business** | [Project Manager Assistant](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/project_manager_assistant_agent.ipynb) | LangGraph | Task generation, risk assessment  \n14 | ð¼ **Business** | [Contract Analysis Assistant](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/ClauseAI.ipynb) | LangGraph | Clause analysis, compliance checking  \n15 | ð¼ **Business** | [E2E Testing Agent](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/e2e_testing_agent.ipynb) | LangGraph | Test automation, browser control  \n16 | ð¨ **Creative** | [GIF Animation Generator](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/gif_animation_generator_langgraph.ipynb) | LangGraph | Text-to-animation pipeline  \n17 | ð¨ **Creative** | [TTS Poem Generator](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/tts_poem_generator_agent_langgraph.ipynb) | LangGraph | Text classification, speech synthesis  \n18 | ð¨ **Creative** | [Music Compositor](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/music_compositor_agent_langgraph.ipynb) | LangGraph | AI music composition  \n19 | ð¨ **Creative** | [Content Intelligence](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/ContentIntelligence.ipynb) | LangGraph | Multi-platform content generation  \n20 | ð¨ **Creative** | [Business Meme Generator](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/business_meme_generator.ipynb) | LangGraph | Brand-aligned meme creation  \n21 | ð¨ **Creative** | [Murder Mystery Game](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/murder_mystery_agent_langgraph.ipynb) | LangGraph | Procedural story generation  \n22 | ð **Analysis** | [Memory-Enhanced Conversational](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/memory_enhanced_conversational_agent.ipynb) | LangChain | Short/long-term memory integration  \n23 | ð **Analysis** | [Multi-Agent Collaboration](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/multi_agent_collaboration_system.ipynb) | LangChain | Historical research, data analysis  \n24 | ð **Analysis** | [Self-Improving Agent](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/self_improving_agent.ipynb) | LangChain | Learning from interactions  \n25 | ð **Analysis** | [Task-Oriented Agent](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/task_oriented_agent.ipynb) | LangChain | Text summarization, translation  \n26 | ð **Analysis** | [Internet Search Agent](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/search_the_internet_and_summarize.ipynb) | LangChain | Web research, summarization  \n27 | ð **Analysis** | [Research Team - Autogen](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/research_team_autogen.ipynb) | AutoGen | Multi-agent research collaboration  \n28 | ð **Analysis** | [Sales Call Analyzer](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/sales_call_analyzer_agent.ipynb) | LangGraph | Audio transcription, NLP analysis  \n29 | ð **Analysis** | [Weather Emergency System](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/Weather_Disaster_Management_AI_AGENT.ipynb) | LangGraph | Real-time data processing  \n30 | ð **Analysis** | [Self-Healing Codebase](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/self_healing_code.ipynb) | LangGraph | Error detection, automated fixes  \n31 | ð **Analysis** | [DataScribe](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/database_discovery_fleet.ipynb) | LangGraph | Database exploration, query planning  \n32 | ð **Analysis** | [Memory-Enhanced Email](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/memory-agent-tutorial.ipynb) | LangGraph | Email triage, response generation  \n33 | ð° **News** | [News TL;DR](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/news_tldr_langgraph.ipynb) | LangGraph | News summarization, API integration  \n34 | ð° **News** | [AInsight](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/ainsight_langgraph.ipynb) | LangGraph | AI/ML news aggregation  \n35 | ð° **News** | [Journalism Assistant](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/journalism_focused_ai_assistant_langgraph.ipynb) | LangGraph | Fact-checking, bias detection  \n36 | ð° **News** | [Blog Writer](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/blog_writer_swarm.ipynb) | OpenAI Swarm | Collaborative content creation  \n37 | ð° **News** | [Podcast Generator](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/generate_podcast_agent_langgraph.ipynb) | LangGraph | Content search, audio generation  \n38 | ðï¸ **Shopping** | [ShopGenie](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/ShopGenie.ipynb) | LangGraph | Product comparison, recommendations  \n39 | ðï¸ **Shopping** | [Car Buyer Agent](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/car_buyer_agent_langgraph.ipynb) | LangGraph | Web scraping, decision support  \n40 | ð¯ **Task Management** | [Taskifier](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/taskifier.ipynb) | LangGraph | Work style analysis, task breakdown  \n41 | ð¯ **Task Management** | [Grocery Management](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/grocery_management_agents_system.ipynb) | CrewAI | Inventory tracking, recipe suggestions  \n42 | ð **QA** | [LangGraph Inspector](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/graph_inspector_system_langgraph.ipynb) | LangGraph | System testing, vulnerability detection  \n43 | ð **QA** | [EU Green Deal Bot](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/EU_Green_Compliance_FAQ_Bot.ipynb) | LangGraph | Regulatory compliance, FAQ system  \n44 | ð **QA** | [Systematic Review](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/systematic_review_of_scientific_articles.ipynb) | LangGraph | Academic paper processing, draft generation  \n45 | ð **Advanced** | [Controllable RAG Agent](https://github.com/NirDiamant/Controllable-RAG-Agent) | Custom | Complex question answering, deterministic graph  \nExplore our extensive list of GenAI agent implementations, sorted by categories:\n### ð± Beginner-Friendly Agents\n[](https://github.com/NirDiamant/GenAI_Agents#-beginner-friendly-agents)\n  1. **Simple Conversational Agent**\n     * **[LangChain](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/simple_conversational_agent.ipynb)**\n     * **[PydanticAI](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/simple_conversational_agent-pydanticai.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview-)\nA context-aware conversational AI maintains information across interactions, enabling more natural dialogues.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸)\nIntegrates a language model, prompt template, and history manager to generate contextual responses and track conversation sessions.\n  2. **[Simple Question Answering Agent](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/simple_question_answering_agent.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--1)\nAnswering (QA) agent using LangChain and OpenAI's language model understands user queries and provides relevant, concise answers.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-1)\nCombines OpenAI's GPT model, a prompt template, and an LLMChain to process user questions and generate AI-driven responses in a streamlined manner.\n  3. **Simple Data Analysis Agent**\n     * **[LangChain](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/simple_data_analysis_agent_notebook.ipynb)**\n     * **[PydanticAI](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/simple_data_analysis_agent_notebook-pydanticai.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--2)\nAn AI-powered data analysis agent interprets and answers questions about datasets using natural language, combining language models with data manipulation tools for intuitive data exploration.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-2)\nIntegrates a language model, data manipulation framework, and agent framework to process natural language queries and perform data analysis on a synthetic dataset, enabling accessible insights for non-technical users.\n\n\n### ð§ Framework Tutorial\n[](https://github.com/NirDiamant/GenAI_Agents#-framework-tutorial)\n  1. **[Introduction to LangGraph: Building Modular AI Workflows](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/langgraph-tutorial.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--3)\nThis tutorial introduces LangGraph, a powerful framework for creating modular, graph-based AI workflows. Learn how to leverage LangGraph to build more complex and flexible AI agents that can handle multi-step processes efficiently.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-3)\nStep-by-step guide on using LangGraph to create a StateGraph workflow. The tutorial covers key concepts such as state management, node creation, and graph compilation. It demonstrates these principles by constructing a simple text analysis pipeline, serving as a foundation for more advanced agent architectures.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/GenAI_Agents#additional-resources-)\n     * **[Blog Post](https://open.substack.com/pub/diamantai/p/your-first-ai-agent-simpler-than?r=336pe4&utm_campaign=post&utm_medium=web&showWelcomeOnShare=false)**\n  2. **[Model Context Protocol (MCP): Seamless Integration of AI and External Resources](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/mcp-tutorial.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--4)\nThis tutorial introduces the Model Context Protocol (MCP), an open standard for connecting AI models with external data sources and tools. Learn how MCP serves as a universal bridge between GenAI agents and the wider digital ecosystem, enabling more capable and context-aware AI applications.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-4)\nProvides a hands-on guide to implementing MCP servers and clients, demonstrating how to connect language models with external tools and data sources. The tutorial covers server setup, tool definition, and integration with AI clients, with practical examples of building useful agent capabilities through the protocol.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/GenAI_Agents#additional-resources--1)\n     * **[Blog Post](https://open.substack.com/pub/diamantai/p/model-context-protocol-mcp-explained?r=336pe4&utm_campaign=post&utm_medium=web&showWelcomeOnShare=false)**\n     * **[Official MCP Documentation](https://modelcontextprotocol.io/introduction)**\n     * **[MCP GitHub Repository](https://github.com/modelcontextprotocol)**\n\n\n### ð Educational and Research Agents\n[](https://github.com/NirDiamant/GenAI_Agents#-educational-and-research-agents)\n  1. **[ATLAS: Academic Task and Learning Agent System](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/Academic_Task_Learning_Agent_LangGraph.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--5)\nATLAS demonstrates how to build an intelligent multi-agent system that transforms academic support through AI-powered assistance. The system leverages LangGraph's workflow framework to coordinate multiple specialized agents that provide personalized academic planning, note-taking, and advisory support.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-5)\nImplements a state-managed multi-agent architecture using four specialized agents (Coordinator, Planner, Notewriter, and Advisor) working in concert through LangGraph's workflow framework. The system features sophisticated workflows for profile analysis and academic support, with continuous adaptation based on student performance and feedback.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/GenAI_Agents#additional-resources--2)\n     * **[YouTube Explanation](https://www.youtube.com/watch?v=yxowMLL2dDI)**\n     * **[Blog Post](https://open.substack.com/pub/diamantai/p/atlas-when-artificial-intelligence?r=336pe4&utm_campaign=post&utm_medium=web&showWelcomeOnShare=false)**\n  2. **[Scientific Paper Agent - Literature Review](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/scientific_paper_agent_langgraph.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--6)\nAn intelligent research assistant that helps users navigate, understand, and analyze scientific literature through an orchestrated workflow. The system combines academic APIs with sophisticated paper processing techniques to automate literature review tasks, enabling researchers to efficiently extract insights from academic papers while maintaining research rigor and quality control.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-6)\nLeverages LangGraph to create a five-node workflow system including decision making, planning, tool execution, and quality validation nodes. The system integrates the CORE API for paper access, PDFplumber for document processing, and advanced language models for analysis. Key features include a retry mechanism for robust paper downloads, structured data handling through Pydantic models, and quality-focused improvement cycles with human-in-the-loop validation options.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/GenAI_Agents#additional-resources--3)\n     * **[YouTube Explanation](https://youtu.be/Bc4YtpHY6Ws)**\n     * **[Blog Post](https://open.substack.com/pub/diamantai/p/nexus-ai-the-revolutionary-research?r=336pe4&utm_campaign=post&utm_medium=web&showWelcomeOnShare=false)**\n  3. **[Chiron - A Feynman-Enhanced Learning Agent](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/chiron_learning_agent_langgraph.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--7)\nAn adaptive learning agent that guides users through educational content using a structured checkpoint system and Feynman-style teaching. The system processes learning materials (either user-provided or web-retrieved), verifies understanding through interactive checkpoints, and provides simplified explanations when needed, creating a personalized learning experience that mimics one-on-one tutoring.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-7)\nUses LangGraph to orchestrate a learning workflow that includes checkpoint definition, context building, understanding verification, and Feynman teaching nodes. The system integrates web search for dynamic content retrieval, employs semantic chunking for context processing, and manages embeddings for relevant information retrieval. Key features include a 70% understanding threshold for progression, interactive human-in-the-loop validation, and structured output through Pydantic models for consistent data handling.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/GenAI_Agents#additional-resources--4)\n     * **[YouTube Explanation](https://www.youtube.com/watch?v=qsdiTGkB8mk)**\n\n\n### ð¼ Business and Professional Agents\n[](https://github.com/NirDiamant/GenAI_Agents#-business-and-professional-agents)\n  1. **[Customer Support Agent (LangGraph)](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/customer_support_agent_langgraph.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--8)\nAn intelligent customer support agent using LangGraph categorizes queries, analyzes sentiment, and provides appropriate responses or escalates issues.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-8)\nUtilizes LangGraph to create a workflow combining state management, query categorization, sentiment analysis, and response generation.\n  2. **[Essay Grading Agent (LangGraph)](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/essay_grading_system_langgraph.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--9)\nAn automated essay grading system using LangGraph and an LLM model evaluates essays based on relevance, grammar, structure, and depth of analysis.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-9)\nUtilizes a state graph to define the grading workflow, incorporating separate grading functions for each criterion.\n  3. **[Travel Planning Agent (LangGraph)](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/simple_travel_planner_langgraph.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--10)\nA Travel Planner using LangGraph demonstrates how to build a stateful, multi-step conversational AI application that collects user input and generates personalized travel itineraries.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-10)\nUtilizes StateGraph to define the application flow, incorporates custom PlannerState for process management.\n  4. **[GenAI Career Assistant Agent](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/agent_hackathon_genAI_career_assistant.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--11)\nThe GenAI Career Assistant demonstrates how to create a multi-agent system that provides personalized guidance for careers in Generative AI. Using LangGraph and Gemini LLM, the system delivers customized learning paths, resume assistance, interview preparation, and job search support.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-11)\nLeverages a multi-agent architecture using LangGraph to coordinate specialized agents (Learning, Resume, Interview, Job Search) through TypedDict-based state management. The system employs sophisticated query categorization and routing while integrating with external tools like DuckDuckGo for job searches and dynamic content generation.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/GenAI_Agents#additional-resources--5)\n     * **[YouTube Explanation](https://www.youtube.com/watch?v=IcKh0ltXO_8)**\n  5. **[Project Manager Assistant Agent](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/project_manager_assistant_agent.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--12)\nAn AI agent designed to assist in project management tasks by automating the process of creating actionable tasks from project descriptions, identifying dependencies, scheduling work, and assigning tasks to team members based on expertise. The system includes risk assessment and self-reflection capabilities to optimize project plans through multiple iterations, aiming to minimize overall project risk.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-12)\nLeverages LangGraph to orchestrate a workflow of specialized nodes including task generation, dependency mapping, scheduling, allocation, and risk assessment. Each node uses GPT-4o-mini for structured outputs following Pydantic models. The system implements a feedback loop for self-improvement, where risk scores trigger reflection cycles that generate insights to optimize the project plan. Visualization tools display Gantt charts of the generated schedules across iterations.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/GenAI_Agents#additional-resources--6)\n     * **[YouTube Explanation](https://www.youtube.com/watch?v=R7YWjzg3LpI)**\n  6. **[Contract Analysis Assistant (ClauseAI)](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/ClauseAI.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--13)\nClauseAI demonstrates how to build an AI-powered contract analysis system using a multi-agent approach. The system employs specialized AI agents for different aspects of contract review, from clause analysis to compliance checking, and leverages LangGraph for workflow orchestration and Pinecone for efficient clause retrieval and comparison.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-13)\nImplements a sophisticated state-based workflow using LangGraph to coordinate multiple AI agents through contract analysis stages. The system features Pydantic models for data validation, vector storage with Pinecone for clause comparison, and LLM-based analysis for generating comprehensive contract reports. The implementation includes parallel processing capabilities and customizable report generation based on user requirements.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/GenAI_Agents#additional-resources--7)\n     * **[YouTube Explanation](https://www.youtube.com/watch?v=rP8uv_tXuSI)**\n  7. **[E2E Testing Agent](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/e2e_testing_agent.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--14)\nThe E2E Testing Agent demonstrates how to build an AI-powered system that converts natural language test instructions into executable end-to-end web tests. Using LangGraph for workflow orchestration and Playwright for browser automation, the system enables users to specify test cases in plain English while handling the complexity of test generation and execution.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-14)\nImplements a structured workflow using LangGraph to coordinate test generation, validation, and execution. The system features TypedDict state management, integration with Playwright for browser automation, and LLM-based code generation for converting natural language instructions into executable test scripts. The implementation includes DOM state analysis, error handling, and comprehensive test reporting.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/GenAI_Agents#additional-resources--8)\n     * **[YouTube Explanation](https://www.youtube.com/watch?v=jPXtpzcCtyA)**\n\n\n### ð¨ Creative and Content Generation Agents\n[](https://github.com/NirDiamant/GenAI_Agents#-creative-and-content-generation-agents)\n  1. **[GIF Animation Generator Agent (LangGraph)](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/gif_animation_generator_langgraph.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--15)\nA GIF animation generator that integrates LangGraph for workflow management, GPT-4 for text generation, and DALL-E for image creation, producing custom animations from user prompts.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-15)\nUtilizes LangGraph to orchestrate a workflow that generates character descriptions, plots, and image prompts using GPT-4, creates images with DALL-E 3, and assembles them into GIFs using PIL. Employs asynchronous programming for efficient parallel processing.\n  2. **[TTS Poem Generator Agent (LangGraph)](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/tts_poem_generator_agent_langgraph.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--16)\nAn advanced text-to-speech (TTS) agent using LangGraph and OpenAI's APIs classifies input text, processes it based on content type, and generates corresponding speech output.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-16)\nUtilizes LangGraph to orchestrate a workflow that classifies input text using GPT models, applies content-specific processing, and converts the processed text to speech using OpenAI's TTS API. The system adapts its output based on the identified content type (general, poem, news, or joke).\n  3. **[Music Compositor Agent (LangGraph)](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/music_compositor_agent_langgraph.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--17)\nAn AI Music Compositor using LangGraph and OpenAI's language models generates custom musical compositions based on user input. The system processes the input through specialized components, each contributing to the final musical piece, which is then converted to a playable MIDI file.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-17)\nLangGraph orchestrates a workflow that transforms user input into a musical composition, using ChatOpenAI (GPT-4) to generate melody, harmony, and rhythm, which are then style-adapted. The final AI-generated composition is converted to a MIDI file using music21 and can be played back using pygame.\n  4. **[Content Intelligence: Multi-Platform Content Generation Agent](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/ContentIntelligence.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--18)\nContent Intelligence demonstrates how to build an advanced content generation system that transforms input text into platform-optimized content across multiple social media channels. The system employs LangGraph for workflow orchestration to analyze content, conduct research, and generate tailored content while maintaining brand consistency across different platforms.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-18)\nImplements a sophisticated workflow using LangGraph to coordinate multiple specialized nodes (Summary, Research, Platform-Specific) through the content generation process. The system features TypedDict and Pydantic models for state management, integration with Tavily Search for research enhancement, and platform-specific content generation using GPT-4. The implementation includes parallel processing for multiple platforms and customizable content templates.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/GenAI_Agents#additional-resources--9)\n     * **[YouTube Explanation](https://www.youtube.com/watch?v=DPMtPbKmWnU)**\n  5. **[Business Meme Generator Using LangGraph and Memegen.link](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/business_meme_generator.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--19)\nThe Business Meme Generator demonstrates how to create an AI-powered system that generates contextually relevant memes based on company website analysis. Using LangGraph for workflow orchestration, the system combines Groq's Llama model for text analysis and the Memegen.link API to automatically produce brand-aligned memes for digital marketing.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-19)\nImplements a state-managed workflow using LangGraph to coordinate website content analysis, meme concept generation, and image creation. The system features Pydantic models for data validation, asynchronous processing with aiohttp, and integration with external APIs (Groq, Memegen.link) to create a complete meme generation pipeline with customizable templates.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/GenAI_Agents#additional-resources--10)\n     * **[YouTube Explanation](https://youtu.be/lsdDaGmkSCw?si=oF3CGfhbRqz1_Vm8)**\n  6. **[Murder Mystery Game with LLM Agents](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/murder_mystery_agent_langgraph.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--20)\nA text-based detective game that utilizes autonomous LLM agents as interactive characters in a procedurally generated murder mystery. Drawing inspiration from the UNBOUNDED paper, the system creates unique scenarios each time, with players taking on the role of Sherlock Holmes to solve the case through character interviews and deductive reasoning.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-20)\nLeverages two LangGraph workflows - a main game loop for story/character generation and game progression, and a conversation sub-graph for character interactions. The system uses a combination of LLM-powered narrative generation, character AI, and structured game mechanics to create an immersive investigative experience with replayable storylines.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/GenAI_Agents#additional-resources--11)\n     * **[YouTube Explanation](https://www.youtube.com/watch?v=_3cJYlk2EmA)**\n\n\n### ð Analysis and Information Processing Agents\n[](https://github.com/NirDiamant/GenAI_Agents#-analysis-and-information-processing-agents)\n  1. **[Memory-Enhanced Conversational Agent](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/memory_enhanced_conversational_agent.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--21)\nA memory-enhanced conversational AI agent incorporates short-term and long-term memory systems to maintain context within conversations and across multiple sessions, improving interaction quality and personalization.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-21)\nIntegrates a language model with separate short-term and long-term memory stores, utilizes a prompt template incorporating both memory types, and employs a memory manager for storage and retrieval. The system includes an interaction loop that updates and utilizes memories for each response.\n  2. **[Multi-Agent Collaboration System](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/multi_agent_collaboration_system.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--22)\nA multi-agent collaboration system combining historical research with data analysis, leveraging large language models to simulate specialized agents working together to answer complex historical questions.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-22)\nUtilizes a base Agent class to create specialized HistoryResearchAgent and DataAnalysisAgent, orchestrated by a HistoryDataCollaborationSystem. The system follows a five-step process: historical context provision, data needs identification, historical data provision, data analysis, and final synthesis.\n  3. **[Self-Improving Agent](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/self_improving_agent.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--23)\nA Self-Improving Agent using LangChain engages in conversations, learns from interactions, and continuously improves its performance over time through reflection and adaptation.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-23)\nIntegrates a language model with chat history management, response generation, and a reflection mechanism. The system employs a learning system that incorporates insights from reflection to enhance future performance, creating a continuous improvement loop.\n  4. **[Task-Oriented Agent](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/task_oriented_agent.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--24)\nA language model application using LangChain that summarizes text and translates the summary to Spanish, combining custom functions, structured tools, and an agent for efficient text processing.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-24)\nUtilizes custom functions for summarization and translation, wrapped as structured tools. Employs a prompt template to guide the agent, which orchestrates the use of tools. An agent executor manages the process, taking input text and producing both an English summary and its Spanish translation.\n  5. **[Internet Search and Summarize Agent](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/search_the_internet_and_summarize.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--25)\nAn intelligent web research assistant that combines web search capabilities with AI-powered summarization, automating the process of gathering information from the internet and distilling it into concise, relevant summaries.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-25)\nIntegrates a web search module using DuckDuckGo's API, a result parser, and a text summarization engine leveraging OpenAI's language models. The system performs site-specific or general searches, extracts relevant content, generates concise summaries, and compiles attributed results for efficient information retrieval and synthesis.\n  6. **[Multi agent research team - Autogen](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/research_team_autogen.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--26)\nThis technique explores a multi-agent system for collaborative research using the AutoGen library. It employs agents to solve tasks collaboratively, focusing on efficient execution and quality assurance. The system enhances research by distributing tasks among specialized agents.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-26)\nAgents are configured with specific roles using the GPT-4 model, including admin, developer, planner, executor, and quality assurance. Interaction management ensures orderly communication with defined transitions. Task execution involves collaborative planning, coding, execution, and quality checking, demonstrating a scalable framework for various domains.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/GenAI_Agents#additional-resources--12)\n     * **[comprehensive solution with UI](https://github.com/yanivvak/dream-team)**\n     * **[Blogpost](https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/build-your-dream-team-with-autogen/ba-p/4157961)**\n  7. **[Sales Call Analyzer](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/sales_call_analyzer_agent.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--27)\nAn intelligent system that automates the analysis of sales call recordings by combining audio transcription with advanced natural language processing. The analyzer transcribes audio using OpenAI's Whisper, processes the text using NLP techniques, and generates comprehensive reports including sentiment analysis, key phrases, pain points, and actionable recommendations to improve sales performance.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-27)\nUtilizes multiple components in a structured workflow: OpenAI Whisper for audio transcription, CrewAI for task automation and agent management, and LangChain for orchestrating the analysis pipeline. The system processes audio through a series of steps from transcription to detailed analysis, leveraging custom agents and tasks to generate structured JSON reports containing insights about customer sentiment, sales opportunities, and recommended improvements.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/GenAI_Agents#additional-resources--13)\n     * **[YouTube Explanation](https://www.youtube.com/watch?v=SKAt_PvznDw)**\n  8. **[Weather Emergency& Response System](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/Weather_Disaster_Management_AI_AGENT.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--28)\nA comprehensive system demonstrating two agent graph implementations for weather emergency response: a real-time graph processing live weather data, and a hybrid graph combining real and simulated data for testing high-severity scenarios. The system handles complete workflow from data gathering through emergency plan generation, with automated notifications and human verification steps.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-28)\nUtilizes LangGraph for orchestrating complex workflows with state management, integrating OpenWeatherMap API for real-time data, and Gemini for analysis and response generation. The system incorporates email notifications, social media monitoring simulation, and severity-based routing with configurable human verification for low/medium severity events.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/GenAI_Agents#additional-resources--14)\n     * **[YouTube Explanation](https://www.youtube.com/watch?v=AgiOAJl_apw)**\n  9. **[Self-Healing Codebase System](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/self_healing_code.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--29)\nAn intelligent system that automatically detects, diagnoses, and fixes runtime code errors using LangGraph workflow orchestration and ChromaDB vector storage. The system maintains a memory of encountered bugs and their fixes through vector embeddings, enabling pattern recognition for similar errors across the codebase.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-29)\nUtilizes a state-based graph workflow that processes function definitions and runtime arguments through specialized nodes for error detection, code analysis, and fix generation. Incorporates ChromaDB for vector-based storage of bug patterns and fixes, with automated search and retrieval capabilities for similar error patterns, while maintaining code execution safety through structured validation steps.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/GenAI_Agents#additional-resources--15)\n     * **[YouTube Explanation](https://www.youtube.com/watch?v=ga7ShvIXOvE)**\n  10. **[DataScribe: AI-Powered Schema Explorer](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/database_discovery_fleet.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--30)\nAn intelligent agent system that enables intuitive exploration and querying of relational databases through natural language interactions. The system utilizes a fleet of specialized agents, coordinated by a stateful Supervisor, to handle schema discovery, query planning, and data analysis tasks while maintaining contextual understanding through vector-based relationship graphs.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-30)\nLeverages LangGraph for orchestrating a multi-agent workflow including discovery, inference, and planning agents, with NetworkX for relationship graph visualization and management. The system incorporates dynamic state management through TypedDict classes, maintains database context between sessions using a db_graph attribute, and includes safety measures to prevent unauthorized database modifications.\n  11. **[Memory-Enhanced Email Agent (LangGraph& LangMem)](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/memory-agent-tutorial.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--31)\nAn intelligent email assistant that combines three types of memory (semantic, episodic, and procedural) to create a system that improves over time. The agent can triage incoming emails, draft contextually appropriate responses using stored knowledge, and enhance its performance based on user feedback.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-31)\nLeverages LangGraph for workflow orchestration and LangMem for sophisticated memory management across multiple memory types. The system implements a triage workflow with memory-enhanced decision making, specialized tools for email composition and calendar management, and a self-improvement mechanism that updates its own prompts based on feedback and past performance.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/GenAI_Agents#additional-resources--16)\n     * **[Blog Post](https://open.substack.com/pub/diamantai/p/building-an-ai-agent-with-memory?r=336pe4&utm_campaign=post&utm_medium=web&showWelcomeOnShare=false)\n\n\n### ð° News and Information Agents\n[](https://github.com/NirDiamant/GenAI_Agents#-news-and-information-agents)\n  1. **[News TL;DR using LangGraph](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/news_tldr_langgraph.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--32)\nA news summarization system that generates concise TL;DR summaries of current events based on user queries. The system leverages large language models for decision making and summarization while integrating with news APIs to access up-to-date content, allowing users to quickly catch up on topics of interest through generated bullet-point summaries.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-32)\nUtilizes LangGraph to orchestrate a workflow combining multiple components: GPT-4o-mini for generating search terms and article summaries, NewsAPI for retrieving article metadata, BeautifulSoup for web scraping article content, and Asyncio for concurrent processing. The system follows a structured pipeline from query processing through article selection and summarization, managing the flow between components to produce relevant TL;DRs of current news articles.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/GenAI_Agents#additional-resources--17)\n     * **[YouTube Explanation](https://www.youtube.com/watch?v=0fRxW6miybI)**\n     * **[Blog Post](https://open.substack.com/pub/diamantai/p/stop-reading-start-understanding?r=336pe4&utm_campaign=post&utm_medium=web&showWelcomeOnShare=false)**\n  2. **[AInsight: AI/ML Weekly News Reporter](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/ainsight_langgraph.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--33)\nAInsight demonstrates how to build an intelligent news aggregation and summarization system using a multi-agent architecture. The system employs three specialized agents (NewsSearcher, Summarizer, Publisher) to automatically collect, process and summarize AI/ML news for general audiences through LangGraph-based workflow orchestration.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-33)\nImplements a state-managed multi-agent system using LangGraph to coordinate the news collection (Tavily API), technical content summarization (GPT-4), and report generation processes. The system features modular architecture with TypedDict-based state management, external API integration, and markdown report generation with customizable templates.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/GenAI_Agents#additional-resources--18)\n     * **[YouTube Explanation](https://www.youtube.com/watch?v=kH5S1is2D_0)**\n  3. **[Journalism-Focused AI Assistant](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/journalism_focused_ai_assistant_langgraph.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--34)\nA specialized AI assistant that helps journalists tackle modern journalistic challenges like misinformation, bias, and information overload. The system integrates fact-checking, tone analysis, summarization, and grammar review tools to enhance the accuracy and efficiency of journalistic work while maintaining ethical reporting standards.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-34)\nLeverages LangGraph to orchestrate a workflow of specialized components including language models for analysis and generation, web search integration via DuckDuckGo's API, document parsing tools like PyMuPDFLoader and WebBaseLoader, text splitting with RecursiveCharacterTextSplitter, and structured JSON outputs. Each component works together through a unified workflow to analyze content, verify facts, detect bias, extract quotes, and generate comprehensive reports.\n  4. **[Blog Writer (Open AI Swarm)](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/blog_writer_swarm.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--35)\nA multi-agent system for collaborative blog post creation using OpenAI's Swarm package. It leverages specialized agents to perform research, planning, writing, and editing tasks efficiently.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-35)\nUtilizes OpenAI's Swarm Package to manage agent interactions. Includes an admin, researcher, planner, writer, and editor, each with specific roles. The system follows a structured workflow: topic setting, outlining, research, drafting, and editing. This approach enhances content creation through task distribution, specialization, and collaborative problem-solving.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/GenAI_Agents#additional-resources--19)\n     * **[Swarm Repo](https://github.com/openai/swarm)**\n  5. **[Podcast Internet Search and Generate Agent ðï¸](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/generate_podcast_agent_langgraph.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--36)\nA two step agent that first searches the internet for a given topic and then generates a podcast on the topic found. The search step uses a search agent and search function to find the most relevant information. The second step uses a podcast generation agent and generation function to create a podcast on the topic found.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-36)\nUtilizes LangGraph to orchestrate a two-step workflow. The first step involves a search agent and function to gather information from the internet. The second step uses a podcast generation agent and function to create a podcast based on the gathered information.\n\n\n### ðï¸ Shopping and Product Analysis Agents\n[](https://github.com/NirDiamant/GenAI_Agents#ï¸-shopping-and-product-analysis-agents)\n  1. **[ShopGenie - Redefining Online Shopping Customer Experience](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/ShopGenie.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--37)\nAn AI-powered shopping assistant that helps customers make informed purchasing decisions even without domain expertise. The system analyzes product information from multiple sources, compares specifications and reviews, identifies the best option based on user needs, and delivers recommendations through email with supporting video reviews, creating a comprehensive shopping experience.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-37)\nUses LangGraph to orchestrate a workflow combining Tavily for web search, Llama-3.1-70B for structured data analysis and product comparison, and YouTube API for review video retrieval. The system processes search results through multiple nodes including schema mapping, product comparison, review identification, and email generation. Key features include structured Pydantic models for consistent data handling, retry mechanisms for robust API interactions, and email delivery through SMTP for sharing recommendations.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/GenAI_Agents#additional-resources--20)\n     * **[YouTube Explanation](https://www.youtube.com/watch?v=Js0sK0u53dQ)**\n  2. **[Car Buyer AI Agent](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/car_buyer_agent_langgraph.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--38)\nThe Smart Product Buyer AI Agent demonstrates how to build an intelligent system that assists users in making informed purchasing decisions. Using LangGraph and LLM-based intelligence, the system processes user requirements, scrapes product listings from websites like AutoTrader, and provides detailed analysis and recommendations for car purchases.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-38)\nImplements a state-based workflow using LangGraph to coordinate user interaction, web scraping, and decision support. The system features TypedDict state management, async web scraping with Playwright, and integrates with external APIs for comprehensive product analysis. The implementation includes a Gradio interface for real-time chat interaction and modular scraper architecture for easy extension to additional product categories.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/GenAI_Agents#additional-resources--21)\n     * **[YouTube Explanation](https://www.youtube.com/watch?v=I61I1fp0qys)**\n\n\n### ð¯ Task Management and Productivity Agents\n[](https://github.com/NirDiamant/GenAI_Agents#-task-management-and-productivity-agents)\n  1. **[Taskifier - Intelligent Task Allocation& Management](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/taskifier.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--39)\nAn intelligent task management system that analyzes user work styles and creates personalized task breakdown strategies, born from the observation that procrastination often stems from task ambiguity among students and early-career professionals. The system evaluates historical work patterns, gathers relevant task information through web search, and generates customized step-by-step approaches to optimize productivity and reduce workflow paralysis.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-39)\nLeverages LangGraph for orchestrating a multi-step workflow including work style analysis, information gathering via Tavily API, and customized plan generation. The system maintains state through the process, integrating historical work pattern data with fresh task research to output detailed, personalized task execution plans aligned with the user's natural working style.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/GenAI_Agents#additional-resources--22)\n     * **[YouTube Explanation](https://www.youtube.com/watch?v=1W_p_RVi9KE&t=25s)**\n  2. **[Grocery Management Agents System](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/grocery_management_agents_system.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--40)\nA multi-agent system built with CrewAI that automates grocery management tasks including receipt interpretation, expiration date tracking, inventory management, and recipe recommendations. The system uses specialized agents to extract data from receipts, estimate product shelf life, track consumption, and suggest recipes to minimize food waste.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-40)\nImplements four specialized agents using CrewAI - a Receipt Interpreter that extracts item details from receipts, an Expiration Date Estimator that determines shelf life using online sources, a Grocery Tracker that maintains inventory based on consumption, and a Recipe Recommender that suggests meals using available ingredients. Each agent has specific tools and tasks orchestrated through a crew workflow.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/GenAI_Agents#additional-resources--23)\n     * **[YouTube Explanation](https://www.youtube.com/watch?v=FlMu5pKSaHI)**\n\n\n### ð Quality Assurance and Testing Agents\n[](https://github.com/NirDiamant/GenAI_Agents#-quality-assurance-and-testing-agents)\n  1. **[LangGraph-Based Systems Inspector](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/graph_inspector_system_langgraph.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--41)\nA comprehensive testing and validation tool for LangGraph-based applications that automatically analyzes system architecture, generates test cases, and identifies potential vulnerabilities through multi-agent inspection. The inspector employs specialized AI testers to evaluate different aspects of the system, from basic functionality to security concerns and edge cases.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-41)\nIntegrates LangGraph for workflow orchestration, multiple LLM-powered testing agents, and a structured evaluation pipeline that includes static analysis, test case generation, and results verification. The system uses Pydantic for data validation, NetworkX for graph representation, and implements a modular architecture that allows for parallel test execution and comprehensive result analysis.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/GenAI_Agents#additional-resources--24)\n     * **[YouTube Explanation](https://www.youtube.com/watch?v=fQd6lXc-Y9A)**\n     * **[Blog Post](https://open.substack.com/pub/diamantai/p/langgraph-systems-inspector-an-ai?r=336pe4&utm_campaign=post&utm_medium=web&showWelcomeOnShare=false)**\n  2. **[EU Green Deal FAQ Bot](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/EU_Green_Compliance_FAQ_Bot.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--42)\nThe EU Green Deal FAQ Bot demonstrates how to build a RAG-based AI agent that helps businesses understand EU green deal policies. The system processes complex regulatory documents into manageable chunks and provides instant, accurate answers to common questions about environmental compliance, emissions reporting, and waste management requirements.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-42)\nImplements a sophisticated RAG pipeline using FAISS vectorstore for document storage, semantic chunking for preprocessing, and multiple specialized agents (Retriever, Summarizer, Evaluator) for query processing. The system features query rephrasing for improved accuracy, cross-reference with gold Q&A datasets for answer validation, and comprehensive evaluation metrics to ensure response quality and relevance.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/GenAI_Agents#additional-resources--25)\n     * **[YouTube Explanation](https://www.youtube.com/watch?v=Av0kBQjwU-Y)**\n  3. **[Systematic Review Automation System + Paper Draft Creation](https://github.com/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/systematic_review_of_scientific_articles.ipynb)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--43)\nA comprehensive system for automating academic systematic reviews using a directed graph architecture and LangChain components. The system generates complete, publication-ready systematic review papers, automatically processing everything from literature search through final draft generation with multiple revision cycles.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-43)\nUtilizes a state-based graph workflow that handles paper search and selection (up to 3 papers), PDF processing, and generates a complete academic paper with all standard sections (abstract, introduction, methods, results, conclusions, references). The system incorporates multiple revision cycles with automated critique and improvement phases, all orchestrated through LangGraph state management.\n#### Additional Resources ð\n[](https://github.com/NirDiamant/GenAI_Agents#additional-resources--26)\n     * **[YouTube Explanation](https://www.youtube.com/watch?v=qi35mGGkCtg)**\n\n\n### ð Special Advanced Technique ð\n[](https://github.com/NirDiamant/GenAI_Agents#-special-advanced-technique-)\n  1. **[Sophisticated Controllable Agent for Complex RAG Tasks ð¤](https://github.com/NirDiamant/Controllable-RAG-Agent)**\n#### Overview ð\n[](https://github.com/NirDiamant/GenAI_Agents#overview--44)\nAn advanced RAG solution designed to tackle complex questions that simple semantic similarity-based retrieval cannot solve. This approach uses a sophisticated deterministic graph as the \"brain\" ð§  of a highly controllable autonomous agent, capable of answering non-trivial questions from your own data.\n#### Implementation ð ï¸\n[](https://github.com/NirDiamant/GenAI_Agents#implementation-ï¸-44)\nâ¢ Implement a multi-step process involving question anonymization, high-level planning, task breakdown, adaptive information retrieval and question answering, continuous re-planning, and rigorous answer verification to ensure grounded and accurate responses.\n\n\n## Getting Started\n[](https://github.com/NirDiamant/GenAI_Agents#getting-started)\nTo begin exploring and building GenAI agents:\n  1. Clone this repository: \n```\ngit clone https://github.com/NirDiamant/GenAI_Agents.git\n\n```\n\n  2. Navigate to the technique you're interested in: \n```\ncd all_agents_tutorials/technique-name\n\n```\n\n  3. Follow the detailed implementation guide in each technique's notebook.\n\n\n## Contributing\n[](https://github.com/NirDiamant/GenAI_Agents#contributing)\nWe welcome contributions from the community! If you have a new technique or improvement to suggest:\n  1. Fork the repository\n  2. Create your feature branch: `git checkout -b feature/AmazingFeature`\n  3. Commit your changes: `git commit -m 'Add some AmazingFeature'`\n  4. Push to the branch: `git push origin feature/AmazingFeature`\n  5. Open a pull request\n\n\n## Contributors\n[](https://github.com/NirDiamant/GenAI_Agents#contributors)\n[![Contributors](https://camo.githubusercontent.com/a0bdadd04daeec604823a67754956f7f592bdb64f5453294ba4b103afac76e64/68747470733a2f2f636f6e747269622e726f636b732f696d6167653f7265706f3d4e69724469616d616e742f47656e41495f4167656e7473)](https://github.com/NirDiamant/GenAI_Agents/graphs/contributors)\n## License\n[](https://github.com/NirDiamant/GenAI_Agents#license)\nThis project is licensed under a custom non-commercial license - see the [LICENSE](https://github.com/NirDiamant/GenAI_Agents/blob/main/LICENSE) file for details.\nâ­ï¸ If you find this repository helpful, please consider giving it a star!\nKeywords: GenAI, Generative AI, Agents, NLP, AI, Machine Learning, Natural Language Processing, LLM, Conversational AI, Task-Oriented AI\n## About\nThis repository provides tutorials and implementations for various Generative AI Agent techniques, from basic to advanced. It serves as a comprehensive guide for building intelligent, interactive AI systems. \n### Topics\n[ ai ](https://github.com/topics/ai \"Topic: ai\") [ tutorials ](https://github.com/topics/tutorials \"Topic: tutorials\") [ openai ](https://github.com/topics/openai \"Topic: openai\") [ agents ](https://github.com/topics/agents \"Topic: agents\") [ llm ](https://github.com/topics/llm \"Topic: llm\") [ llms ](https://github.com/topics/llms \"Topic: llms\") [ langchain ](https://github.com/topics/langchain \"Topic: langchain\") [ genai ](https://github.com/topics/genai \"Topic: genai\") [ langgraph ](https://github.com/topics/langgraph \"Topic: langgraph\")\n### Resources\n[ Readme ](https://github.com/NirDiamant/GenAI_Agents#readme-ov-file)\n### License\n[ View license ](https://github.com/NirDiamant/GenAI_Agents#License-1-ov-file)\n###  Uh oh! \nThere was an error while loading. [Please reload this page](https://github.com/NirDiamant/GenAI_Agents).\n[ Activity](https://github.com/NirDiamant/GenAI_Agents/activity)\n### Stars\n[ **12.5k** stars](https://github.com/NirDiamant/GenAI_Agents/stargazers)\n### Watchers\n[ **176** watching](https://github.com/NirDiamant/GenAI_Agents/watchers)\n### Forks\n[ **1.6k** forks](https://github.com/NirDiamant/GenAI_Agents/forks)\n[ Report repository ](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2FNirDiamant%2FGenAI_Agents&report=NirDiamant+%28user%29)\n##  [Releases](https://github.com/NirDiamant/GenAI_Agents/releases)\nNo releases published\n## Sponsor this project\n[ ![@NirDiamant](https://avatars.githubusercontent.com/u/28316913?s=64&v=4) ](https://github.com/NirDiamant) [ **NirDiamant** ](https://github.com/NirDiamant)\n[ Sponsor  ](https://github.com/sponsors/NirDiamant)\n[Learn more about GitHub Sponsors](https://github.com/sponsors)\n##  [Packages 0](https://github.com/users/NirDiamant/packages?repo_name=GenAI_Agents)\nNo packages published \n###  Uh oh! \nThere was an error while loading. [Please reload this page](https://github.com/NirDiamant/GenAI_Agents).\n##  [Contributors 38](https://github.com/NirDiamant/GenAI_Agents/graphs/contributors)\n  * [ ![@NirDiamant](https://avatars.githubusercontent.com/u/28316913?s=64&v=4) ](https://github.com/NirDiamant)\n  * [ ![@Avtr99](https://avatars.githubusercontent.com/u/178707668?s=64&v=4) ](https://github.com/Avtr99)\n  * [ ![@louisgthier](https://avatars.githubusercontent.com/u/64224825?s=64&v=4) ](https://github.com/louisgthier)\n  * [ ![@FRAMEEE17](https://avatars.githubusercontent.com/u/94170028?s=64&v=4) ](https://github.com/FRAMEEE17)\n  * [ ![@ofir-ov](https://avatars.githubusercontent.com/u/2121694?s=64&v=4) ](https://github.com/ofir-ov)\n  * [ ![@mr-fool](https://avatars.githubusercontent.com/u/6241984?s=64&v=4) ](https://github.com/mr-fool)\n  * [ ![@arcsi1989](https://avatars.githubusercontent.com/u/7024078?s=64&v=4) ](https://github.com/arcsi1989)\n  * [ ![@bmwise14](https://avatars.githubusercontent.com/u/10377564?s=64&v=4) ](https://github.com/bmwise14)\n  * [ ![@AurorePDSA](https://avatars.githubusercontent.com/u/122347817?s=64&v=4) ](https://github.com/AurorePDSA)\n  * [ ![@danigil](https://avatars.githubusercontent.com/u/7474985?s=64&v=4) ](https://github.com/danigil)\n  * [ ![@0xdesdenova](https://avatars.githubusercontent.com/u/8091957?s=64&v=4) ](https://github.com/0xdesdenova)\n  * [ ![@Zovi343](https://avatars.githubusercontent.com/u/39067421?s=64&v=4) ](https://github.com/Zovi343)\n  * [ ![@ClementFrvl](https://avatars.githubusercontent.com/u/89713000?s=64&v=4) ](https://github.com/ClementFrvl)\n  * [ ![@yanivvak](https://avatars.githubusercontent.com/u/42068219?s=64&v=4) ](https://github.com/yanivvak)\n\n\n[+ 24 contributors](https://github.com/NirDiamant/GenAI_Agents/graphs/contributors)\n## Languages\n  * [ Jupyter Notebook 100.0% ](https://github.com/NirDiamant/GenAI_Agents/search?l=jupyter-notebook)\n\n\n## Footer\n[ ](https://github.com) Â© 2025 GitHub, Inc. \n### Footer navigation\n  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n  * [Security](https://github.com/security)\n  * [Status](https://www.githubstatus.com/)\n  * [Docs](https://docs.github.com/)\n  * [Contact](https://support.github.com?tags=dotcom-footer)\n  * Manage cookies \n  * Do not share my personal information \n\n\nYou canât perform that action at this time. \n"
  },
  {
    "link": "https://github.com/NVIDIA/TensorRT-LLM",
    "raw_content": "[Skip to content](https://github.com/NVIDIA/TensorRT-LLM#start-of-content)\n## Navigation Menu\nToggle navigation\n[ ](https://github.com/)\n[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FNVIDIA%2FTensorRT-LLM)\nAppearance settings\n  * Product \n    * [ GitHub Copilot  Write better code with AI  ](https://github.com/features/copilot)\n    * [ GitHub Models  New  Manage and compare prompts  ](https://github.com/features/models)\n    * [ GitHub Advanced Security  Find and fix vulnerabilities  ](https://github.com/security/advanced-security)\n    * [ Actions  Automate any workflow  ](https://github.com/features/actions)\n    * [ Codespaces  Instant dev environments  ](https://github.com/features/codespaces)\n    * [ Issues  Plan and track work  ](https://github.com/features/issues)\n    * [ Code Review  Manage code changes  ](https://github.com/features/code-review)\n    * [ Discussions  Collaborate outside of code  ](https://github.com/features/discussions)\n    * [ Code Search  Find more, search less  ](https://github.com/features/code-search)\nExplore\n    * [ Why GitHub ](https://github.com/why-github)\n    * [ All features ](https://github.com/features)\n    * [ Documentation ](https://docs.github.com)\n    * [ GitHub Skills ](https://skills.github.com)\n    * [ Blog ](https://github.blog)\n  * Solutions \nBy company size\n    * [ Enterprises ](https://github.com/enterprise)\n    * [ Small and medium teams ](https://github.com/team)\n    * [ Startups ](https://github.com/enterprise/startups)\n    * [ Nonprofits ](https://github.com/solutions/industry/nonprofits)\nBy use case\n    * [ DevSecOps ](https://github.com/solutions/use-case/devsecops)\n    * [ DevOps ](https://github.com/solutions/use-case/devops)\n    * [ CI/CD ](https://github.com/solutions/use-case/ci-cd)\n    * [ View all use cases ](https://github.com/solutions/use-case)\nBy industry\n    * [ Healthcare ](https://github.com/solutions/industry/healthcare)\n    * [ Financial services ](https://github.com/solutions/industry/financial-services)\n    * [ Manufacturing ](https://github.com/solutions/industry/manufacturing)\n    * [ Government ](https://github.com/solutions/industry/government)\n    * [ View all industries ](https://github.com/solutions/industry)\n[ View all solutions ](https://github.com/solutions)\n  * Resources \nTopics\n    * [ AI ](https://github.com/resources/articles/ai)\n    * [ DevOps ](https://github.com/resources/articles/devops)\n    * [ Security ](https://github.com/resources/articles/security)\n    * [ Software Development ](https://github.com/resources/articles/software-development)\n    * [ View all ](https://github.com/resources/articles)\nExplore\n    * [ Learning Pathways ](https://resources.github.com/learn/pathways)\n    * [ Events & Webinars ](https://resources.github.com)\n    * [ Ebooks & Whitepapers ](https://github.com/resources/whitepapers)\n    * [ Customer Stories ](https://github.com/customer-stories)\n    * [ Partners ](https://partner.github.com)\n    * [ Executive Insights ](https://github.com/solutions/executive-insights)\n  * Open Source \n    * [ GitHub Sponsors  Fund open source developers  ](https://github.com/sponsors)\n    * [ The ReadME Project  GitHub community articles  ](https://github.com/readme)\nRepositories\n    * [ Topics ](https://github.com/topics)\n    * [ Trending ](https://github.com/trending)\n    * [ Collections ](https://github.com/collections)\n  * Enterprise \n    * [ Enterprise platform  AI-powered developer platform  ](https://github.com/enterprise)\nAvailable add-ons\n    * [ GitHub Advanced Security  Enterprise-grade security features  ](https://github.com/security/advanced-security)\n    * [ Copilot for business  Enterprise-grade AI features  ](https://github.com/features/copilot/copilot-business)\n    * [ Premium Support  Enterprise-grade 24/7 support  ](https://github.com/premium-support)\n  * [Pricing](https://github.com/pricing)\n\n\nSearch or jump to...\n# Search code, repositories, users, issues, pull requests...\nSearch \nClear\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n#  Provide feedback \nWe read every piece of feedback, and take your input very seriously.\nInclude my email address so I can be contacted\nCancel  Submit feedback \n#  Saved searches \n## Use saved searches to filter your results more quickly\nName\nQuery\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax). \nCancel  Create saved search \n[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FNVIDIA%2FTensorRT-LLM)\n[ Sign up ](https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=NVIDIA%2FTensorRT-LLM)\nAppearance settings\nResetting focus\nYou signed in with another tab or window. [Reload](https://github.com/NVIDIA/TensorRT-LLM) to refresh your session. You signed out in another tab or window. [Reload](https://github.com/NVIDIA/TensorRT-LLM) to refresh your session. You switched accounts on another tab or window. [Reload](https://github.com/NVIDIA/TensorRT-LLM) to refresh your session. Dismiss alert\n{{ message }}\n[ NVIDIA ](https://github.com/NVIDIA) / **[TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM) ** Public\n  * [ Notifications ](https://github.com/login?return_to=%2FNVIDIA%2FTensorRT-LLM) You must be signed in to change notification settings\n  * [ Fork 1.5k ](https://github.com/login?return_to=%2FNVIDIA%2FTensorRT-LLM)\n  * [ Star  10.6k ](https://github.com/login?return_to=%2FNVIDIA%2FTensorRT-LLM)\n\n\nTensorRT-LLM provides users with an easy-to-use Python API to define Large Language Models (LLMs) and support state-of-the-art optimizations to perform inference efficiently on NVIDIA GPUs. TensorRT-LLM also contains components to create Python and C++ runtimes that orchestrate the inference execution in performant way. \n[nvidia.github.io/TensorRT-LLM](https://nvidia.github.io/TensorRT-LLM \"https://nvidia.github.io/TensorRT-LLM\")\n### License\n[ Apache-2.0 license ](https://github.com/NVIDIA/TensorRT-LLM/blob/main/LICENSE)\n[ 10.6k stars ](https://github.com/NVIDIA/TensorRT-LLM/stargazers) [ 1.5k forks ](https://github.com/NVIDIA/TensorRT-LLM/forks) [ Branches ](https://github.com/NVIDIA/TensorRT-LLM/branches) [ Tags ](https://github.com/NVIDIA/TensorRT-LLM/tags) [ Activity ](https://github.com/NVIDIA/TensorRT-LLM/activity)\n[ Star  ](https://github.com/login?return_to=%2FNVIDIA%2FTensorRT-LLM)\n[ Notifications ](https://github.com/login?return_to=%2FNVIDIA%2FTensorRT-LLM) You must be signed in to change notification settings\n  * [ Code ](https://github.com/NVIDIA/TensorRT-LLM)\n  * [ Issues 618 ](https://github.com/NVIDIA/TensorRT-LLM/issues)\n  * [ Pull requests 240 ](https://github.com/NVIDIA/TensorRT-LLM/pulls)\n  * [ Discussions ](https://github.com/NVIDIA/TensorRT-LLM/discussions)\n  * [ Actions ](https://github.com/NVIDIA/TensorRT-LLM/actions)\n  * [ Projects 1 ](https://github.com/NVIDIA/TensorRT-LLM/projects)\n  * [ Security ](https://github.com/NVIDIA/TensorRT-LLM/security)\n[ ](https://github.com/NVIDIA/TensorRT-LLM/security)\n[ ](https://github.com/NVIDIA/TensorRT-LLM/security)\n[ ](https://github.com/NVIDIA/TensorRT-LLM/security)\n### [ Uh oh!  ](https://github.com/NVIDIA/TensorRT-LLM/security)\n[There was an error while loading. ](https://github.com/NVIDIA/TensorRT-LLM/security)[Please reload this page](https://github.com/NVIDIA/TensorRT-LLM).\n  * [ Insights ](https://github.com/NVIDIA/TensorRT-LLM/pulse)\n\n\nAdditional navigation options\n  * [ Code  ](https://github.com/NVIDIA/TensorRT-LLM)\n  * [ Issues  ](https://github.com/NVIDIA/TensorRT-LLM/issues)\n  * [ Pull requests  ](https://github.com/NVIDIA/TensorRT-LLM/pulls)\n  * [ Discussions  ](https://github.com/NVIDIA/TensorRT-LLM/discussions)\n  * [ Actions  ](https://github.com/NVIDIA/TensorRT-LLM/actions)\n  * [ Projects  ](https://github.com/NVIDIA/TensorRT-LLM/projects)\n  * [ Security  ](https://github.com/NVIDIA/TensorRT-LLM/security)\n  * [ Insights  ](https://github.com/NVIDIA/TensorRT-LLM/pulse)\n\n\n# NVIDIA/TensorRT-LLM\nmain\n[**12** Branches](https://github.com/NVIDIA/TensorRT-LLM/branches)[**26** Tags](https://github.com/NVIDIA/TensorRT-LLM/tags)\n[](https://github.com/NVIDIA/TensorRT-LLM/branches)[](https://github.com/NVIDIA/TensorRT-LLM/tags)\nGo to file\nCode\n## Folders and files\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n## Latest commit\n[![Superjomn](https://avatars.githubusercontent.com/u/328693?v=4&size=40)](https://github.com/Superjomn)[Superjomn](https://github.com/NVIDIA/TensorRT-LLM/commits?author=Superjomn)[chore: rename ExecutorBindingsWorker/Proxy (](https://github.com/NVIDIA/TensorRT-LLM/commit/ac171424958b7d1036f09d96e5ba2ba339eb602d)[#4716](https://github.com/NVIDIA/TensorRT-LLM/pull/4716)[)](https://github.com/NVIDIA/TensorRT-LLM/commit/ac171424958b7d1036f09d96e5ba2ba339eb602d)May 29, 2025[ac17142](https://github.com/NVIDIA/TensorRT-LLM/commit/ac171424958b7d1036f09d96e5ba2ba339eb602d) Â· May 29, 2025\n## History\n[1,102 Commits](https://github.com/NVIDIA/TensorRT-LLM/commits/main/)[](https://github.com/NVIDIA/TensorRT-LLM/commits/main/)  \n[.devcontainer](https://github.com/NVIDIA/TensorRT-LLM/tree/main/.devcontainer \".devcontainer\")| [.devcontainer](https://github.com/NVIDIA/TensorRT-LLM/tree/main/.devcontainer \".devcontainer\")| |   \n[.github](https://github.com/NVIDIA/TensorRT-LLM/tree/main/.github \".github\")| [.github](https://github.com/NVIDIA/TensorRT-LLM/tree/main/.github \".github\")| |   \n[3rdparty](https://github.com/NVIDIA/TensorRT-LLM/tree/main/3rdparty \"3rdparty\")| [3rdparty](https://github.com/NVIDIA/TensorRT-LLM/tree/main/3rdparty \"3rdparty\")| |   \n[benchmarks](https://github.com/NVIDIA/TensorRT-LLM/tree/main/benchmarks \"benchmarks\")| [benchmarks](https://github.com/NVIDIA/TensorRT-LLM/tree/main/benchmarks \"benchmarks\")| |   \n[cpp](https://github.com/NVIDIA/TensorRT-LLM/tree/main/cpp \"cpp\")| [cpp](https://github.com/NVIDIA/TensorRT-LLM/tree/main/cpp \"cpp\")| |   \n[docker](https://github.com/NVIDIA/TensorRT-LLM/tree/main/docker \"docker\")| [docker](https://github.com/NVIDIA/TensorRT-LLM/tree/main/docker \"docker\")| |   \n[docs](https://github.com/NVIDIA/TensorRT-LLM/tree/main/docs \"docs\")| [docs](https://github.com/NVIDIA/TensorRT-LLM/tree/main/docs \"docs\")| |   \n[examples](https://github.com/NVIDIA/TensorRT-LLM/tree/main/examples \"examples\")| [examples](https://github.com/NVIDIA/TensorRT-LLM/tree/main/examples \"examples\")| |   \n[jenkins](https://github.com/NVIDIA/TensorRT-LLM/tree/main/jenkins \"jenkins\")| [jenkins](https://github.com/NVIDIA/TensorRT-LLM/tree/main/jenkins \"jenkins\")| |   \n[scripts](https://github.com/NVIDIA/TensorRT-LLM/tree/main/scripts \"scripts\")| [scripts](https://github.com/NVIDIA/TensorRT-LLM/tree/main/scripts \"scripts\")| |   \n[tensorrt_llm](https://github.com/NVIDIA/TensorRT-LLM/tree/main/tensorrt_llm \"tensorrt_llm\")| [tensorrt_llm](https://github.com/NVIDIA/TensorRT-LLM/tree/main/tensorrt_llm \"tensorrt_llm\")| |   \n[tests](https://github.com/NVIDIA/TensorRT-LLM/tree/main/tests \"tests\")| [tests](https://github.com/NVIDIA/TensorRT-LLM/tree/main/tests \"tests\")| |   \n[triton_backend](https://github.com/NVIDIA/TensorRT-LLM/tree/main/triton_backend \"triton_backend\")| [triton_backend](https://github.com/NVIDIA/TensorRT-LLM/tree/main/triton_backend \"triton_backend\")| |   \n[.clang-format](https://github.com/NVIDIA/TensorRT-LLM/blob/main/.clang-format \".clang-format\")| [.clang-format](https://github.com/NVIDIA/TensorRT-LLM/blob/main/.clang-format \".clang-format\")| |   \n[.clang-tidy](https://github.com/NVIDIA/TensorRT-LLM/blob/main/.clang-tidy \".clang-tidy\")| [.clang-tidy](https://github.com/NVIDIA/TensorRT-LLM/blob/main/.clang-tidy \".clang-tidy\")| |   \n[.clangd](https://github.com/NVIDIA/TensorRT-LLM/blob/main/.clangd \".clangd\")| [.clangd](https://github.com/NVIDIA/TensorRT-LLM/blob/main/.clangd \".clangd\")| |   \n[.cursorignore](https://github.com/NVIDIA/TensorRT-LLM/blob/main/.cursorignore \".cursorignore\")| [.cursorignore](https://github.com/NVIDIA/TensorRT-LLM/blob/main/.cursorignore \".cursorignore\")| |   \n[.dockerignore](https://github.com/NVIDIA/TensorRT-LLM/blob/main/.dockerignore \".dockerignore\")| [.dockerignore](https://github.com/NVIDIA/TensorRT-LLM/blob/main/.dockerignore \".dockerignore\")| |   \n[.gitattributes](https://github.com/NVIDIA/TensorRT-LLM/blob/main/.gitattributes \".gitattributes\")| [.gitattributes](https://github.com/NVIDIA/TensorRT-LLM/blob/main/.gitattributes \".gitattributes\")| |   \n[.gitignore](https://github.com/NVIDIA/TensorRT-LLM/blob/main/.gitignore \".gitignore\")| [.gitignore](https://github.com/NVIDIA/TensorRT-LLM/blob/main/.gitignore \".gitignore\")| |   \n[.gitmodules](https://github.com/NVIDIA/TensorRT-LLM/blob/main/.gitmodules \".gitmodules\")| [.gitmodules](https://github.com/NVIDIA/TensorRT-LLM/blob/main/.gitmodules \".gitmodules\")| |   \n[.pre-commit-config.yaml](https://github.com/NVIDIA/TensorRT-LLM/blob/main/.pre-commit-config.yaml \".pre-commit-config.yaml\")| [.pre-commit-config.yaml](https://github.com/NVIDIA/TensorRT-LLM/blob/main/.pre-commit-config.yaml \".pre-commit-config.yaml\")| |   \n[CODE_OF_CONDUCT.md](https://github.com/NVIDIA/TensorRT-LLM/blob/main/CODE_OF_CONDUCT.md \"CODE_OF_CONDUCT.md\")| [CODE_OF_CONDUCT.md](https://github.com/NVIDIA/TensorRT-LLM/blob/main/CODE_OF_CONDUCT.md \"CODE_OF_CONDUCT.md\")| |   \n[CODING_GUIDELINES.md](https://github.com/NVIDIA/TensorRT-LLM/blob/main/CODING_GUIDELINES.md \"CODING_GUIDELINES.md\")| [CODING_GUIDELINES.md](https://github.com/NVIDIA/TensorRT-LLM/blob/main/CODING_GUIDELINES.md \"CODING_GUIDELINES.md\")| |   \n[CONTRIBUTING.md](https://github.com/NVIDIA/TensorRT-LLM/blob/main/CONTRIBUTING.md \"CONTRIBUTING.md\")| [CONTRIBUTING.md](https://github.com/NVIDIA/TensorRT-LLM/blob/main/CONTRIBUTING.md \"CONTRIBUTING.md\")| |   \n[LICENSE](https://github.com/NVIDIA/TensorRT-LLM/blob/main/LICENSE \"LICENSE\")| [LICENSE](https://github.com/NVIDIA/TensorRT-LLM/blob/main/LICENSE \"LICENSE\")| |   \n[README.md](https://github.com/NVIDIA/TensorRT-LLM/blob/main/README.md \"README.md\")| [README.md](https://github.com/NVIDIA/TensorRT-LLM/blob/main/README.md \"README.md\")| |   \n[constraints.txt](https://github.com/NVIDIA/TensorRT-LLM/blob/main/constraints.txt \"constraints.txt\")| [constraints.txt](https://github.com/NVIDIA/TensorRT-LLM/blob/main/constraints.txt \"constraints.txt\")| |   \n[pyproject.toml](https://github.com/NVIDIA/TensorRT-LLM/blob/main/pyproject.toml \"pyproject.toml\")| [pyproject.toml](https://github.com/NVIDIA/TensorRT-LLM/blob/main/pyproject.toml \"pyproject.toml\")| |   \n[requirements-dev.txt](https://github.com/NVIDIA/TensorRT-LLM/blob/main/requirements-dev.txt \"requirements-dev.txt\")| [requirements-dev.txt](https://github.com/NVIDIA/TensorRT-LLM/blob/main/requirements-dev.txt \"requirements-dev.txt\")| |   \n[requirements.txt](https://github.com/NVIDIA/TensorRT-LLM/blob/main/requirements.txt \"requirements.txt\")| [requirements.txt](https://github.com/NVIDIA/TensorRT-LLM/blob/main/requirements.txt \"requirements.txt\")| |   \n[setup.py](https://github.com/NVIDIA/TensorRT-LLM/blob/main/setup.py \"setup.py\")| [setup.py](https://github.com/NVIDIA/TensorRT-LLM/blob/main/setup.py \"setup.py\")| |   \nView all files  \n## Repository files navigation\n  * [README](https://github.com/NVIDIA/TensorRT-LLM)\n  * [Code of conduct](https://github.com/NVIDIA/TensorRT-LLM)\n  * [Apache-2.0 license](https://github.com/NVIDIA/TensorRT-LLM)\n\n\n# TensorRT-LLM\n[](https://github.com/NVIDIA/TensorRT-LLM#tensorrt-llm)\n####  A TensorRT Toolbox for Optimized Large Language Model Inference\n[](https://github.com/NVIDIA/TensorRT-LLM#-a-tensorrt-toolbox-for-optimized-large-language-model-inference)\n[![Documentation](https://camo.githubusercontent.com/c191e0610a0b83ed5bef19569b59b7f27f7da4b11c720841af9028c9f239bf97/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6c61746573742d627269676874677265656e2e7376673f7374796c653d666c6174)](https://nvidia.github.io/TensorRT-LLM/) [![python](https://camo.githubusercontent.com/c9460927ab208c58be7bb60094b09a7a29f7ab9e09e59c555992fceef38d236e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e31322d677265656e)](https://www.python.org/downloads/release/python-3123/) [![python](https://camo.githubusercontent.com/390d871e5bf777de2ed63aa5243962314ec1871c19ffc6d89cf29022cd4bf374/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e31302d677265656e)](https://www.python.org/downloads/release/python-31012/) [![cuda](https://camo.githubusercontent.com/fc3a6b27d5b1d7f86ea7bf892a5e698614f07cc07b8c8ab463259cd75ab91799/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f637564612d31322e392e302d677265656e)](https://developer.nvidia.com/cuda-downloads) [![trt](https://camo.githubusercontent.com/27834bcf7a278130897017d4864313b90ed975ebdcd9abe9cac15f8b79f57d0c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5452542d31302e31302e302d677265656e)](https://developer.nvidia.com/tensorrt) [![version](https://camo.githubusercontent.com/70117671c69e7b7e07935fdbfb04d6062cdd9634398af920de13dcceb5c1102e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f72656c656173652d302e32312e307263302d677265656e)](https://github.com/NVIDIA/TensorRT-LLM/blob/main/tensorrt_llm/version.py) [![license](https://camo.githubusercontent.com/babc55b476ce60b545de3012f13503eea326b5d8d8b9957b2d850c2e3f0cf507/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d417061636865253230322d626c7565)](https://github.com/NVIDIA/TensorRT-LLM/blob/main/LICENSE)\n[Architecture](https://github.com/NVIDIA/TensorRT-LLM/blob/main/docs/source/torch/arch_overview.md) | [Performance](https://github.com/NVIDIA/TensorRT-LLM/blob/main/docs/source/performance/perf-overview.md) | [Examples](https://nvidia.github.io/TensorRT-LLM/quick-start-guide.html) | [Documentation](https://github.com/NVIDIA/TensorRT-LLM/blob/main/docs/source) | [Roadmap](https://github.com/NVIDIA/TensorRT-LLM/issues?q=is%3Aissue%20state%3Aopen%20label%3Aroadmap)\n## Tech Blogs\n[](https://github.com/NVIDIA/TensorRT-LLM#tech-blogs)\n  * [05/23] DeepSeek R1 MTP Implementation and Optimization â¨ [â¡ï¸ link](https://github.com/NVIDIA/TensorRT-LLM/blob/main/docs/source/blogs/tech_blog/blog2_DeepSeek_R1_MTP_Implementation_and_Optimization.md)\n  * [05/16] Pushing Latency Boundaries: Optimizing DeepSeek-R1 Performance on NVIDIA B200 GPUs â¨ [â¡ï¸ link](https://github.com/NVIDIA/TensorRT-LLM/blob/main/docs/source/blogs/tech_blog/blog1_Pushing_Latency_Boundaries_Optimizing_DeepSeek-R1_Performance_on_NVIDIA_B200_GPUs.md)\n\n\n## Latest News\n[](https://github.com/NVIDIA/TensorRT-LLM#latest-news)\n  * [05/22] Blackwell Breaks the 1,000 TPS/User Barrier With Metaâs Llama 4 Maverick â¨ [â¡ï¸ link](https://developer.nvidia.com/blog/blackwell-breaks-the-1000-tps-user-barrier-with-metas-llama-4-maverick/)\n  * [04/10] TensorRT-LLM DeepSeek R1 performance benchmarking best practices now published. â¨ [â¡ï¸ link](https://github.com/NVIDIA/TensorRT-LLM/blob/main/docs/source/blogs/Best_perf_practice_on_DeepSeek-R1_in_TensorRT-LLM.md)\n  * [04/05] TensorRT-LLM can run Llama 4 at over 40,000 tokens per second on B200 GPUs!\n\n\n[![L4_perf](https://github.com/NVIDIA/TensorRT-LLM/raw/main/docs/source/media/l4_launch_perf.png)](https://github.com/NVIDIA/TensorRT-LLM/blob/main/docs/source/media/l4_launch_perf.png)\n  * [03/22] TensorRT-LLM is now fully open-source, with developments moved to GitHub!\n  * [03/18] ðð NVIDIA Blackwell Delivers World-Record DeepSeek-R1 Inference Performance with TensorRT-LLM [â¡ï¸ Link](https://developer.nvidia.com/blog/nvidia-blackwell-delivers-world-record-deepseek-r1-inference-performance/)\n  * [02/28] ð NAVER Place Optimizes SLM-Based Vertical Services with TensorRT-LLM [â¡ï¸ Link](https://developer.nvidia.com/blog/spotlight-naver-place-optimizes-slm-based-vertical-services-with-nvidia-tensorrt-llm/)\n  * [02/25] ð DeepSeek-R1 performance now optimized for Blackwell [â¡ï¸ Link](https://huggingface.co/nvidia/DeepSeek-R1-FP4)\n  * [02/20] Explore the complete guide to achieve great accuracy, high throughput, and low latency at the lowest cost for your business [here](https://www.nvidia.com/en-us/solutions/ai/inference/balancing-cost-latency-and-performance-ebook/?ncid=so-twit-348956&linkId=100000341423615).\n  * [02/18] Unlock #LLM inference with auto-scaling on @AWS EKS â¨ [â¡ï¸ link](https://aws.amazon.com/blogs/hpc/scaling-your-llm-inference-workloads-multi-node-deployment-with-tensorrt-llm-and-triton-on-amazon-eks/)\n  * [02/12] ð¦¸â¡ Automating GPU Kernel Generation with DeepSeek-R1 and Inference Time Scaling [â¡ï¸ link](https://developer.nvidia.com/blog/automating-gpu-kernel-generation-with-deepseek-r1-and-inference-time-scaling/?ncid=so-twit-997075&linkId=100000338909937)\n  * [02/12] ð How Scaling Laws Drive Smarter, More Powerful AI [â¡ï¸ link](https://blogs.nvidia.com/blog/ai-scaling-laws/?ncid=so-link-889273&linkId=100000338837832)\n  * [01/25] Nvidia moves AI focus to inference cost, efficiency [â¡ï¸ link](https://www.fierceelectronics.com/ai/nvidia-moves-ai-focus-inference-cost-efficiency?linkId=100000332985606)\n  * [01/24] ðï¸ Optimize AI Inference Performance with NVIDIA Full-Stack Solutions [â¡ï¸ link](https://developer.nvidia.com/blog/optimize-ai-inference-performance-with-nvidia-full-stack-solutions/?ncid=so-twit-400810&linkId=100000332621049)\n  * [01/23] ð Fast, Low-Cost Inference Offers Key to Profitable AI [â¡ï¸ link](https://blogs.nvidia.com/blog/ai-inference-platform/?ncid=so-twit-693236-vt04&linkId=100000332307804)\n  * [01/16] Introducing New KV Cache Reuse Optimizations in TensorRT-LLM [â¡ï¸ link](https://developer.nvidia.com/blog/introducing-new-kv-cache-reuse-optimizations-in-nvidia-tensorrt-llm/?ncid=so-twit-363876&linkId=100000330323229)\n  * [01/14] ð£ Bing's Transition to LLM/SLM Models: Optimizing Search with TensorRT-LLM [â¡ï¸ link](https://blogs.bing.com/search-quality-insights/December-2024/Bing-s-Transition-to-LLM-SLM-Models-Optimizing-Search-with-TensorRT-LLM)\n  * [01/04] â¡Boost Llama 3.3 70B Inference Throughput 3x with TensorRT-LLM Speculative Decoding [â¡ï¸ link](https://developer.nvidia.com/blog/boost-llama-3-3-70b-inference-throughput-3x-with-nvidia-tensorrt-llm-speculative-decoding/)\n\nPrevious News\n  * [2024/12/10] â¡ Llama 3.3 70B from AI at Meta is accelerated by TensorRT-LLM. ð State-of-the-art model on par with Llama 3.1 405B for reasoning, math, instruction following and tool use. Explore the preview [â¡ï¸ link](https://build.nvidia.com/meta/llama-3_3-70b-instruct)\n  * [2024/12/03] ð Boost your AI inference throughput by up to 3.6x. We now support speculative decoding and tripling token throughput with our NVIDIA TensorRT-LLM. Perfect for your generative AI apps. â¡Learn how in this technical deep dive [â¡ï¸ link](https://nvda.ws/3ZCZTzD)\n  * [2024/12/02] Working on deploying ONNX models for performance-critical applications? Try our NVIDIA Nsight Deep Learning Designer â¡ A user-friendly GUI and tight integration with NVIDIA TensorRT that offers: â Intuitive visualization of ONNX model graphs â Quick tweaking of model architecture and parameters â Detailed performance profiling with either ORT or TensorRT â Easy building of TensorRT engines [â¡ï¸ link](https://developer.nvidia.com/nsight-dl-designer?ncid=so-link-485689&linkId=100000315016072)\n  * [2024/11/26] ð£ Introducing TensorRT-LLM for Jetson AGX Orin, making it even easier to deploy on Jetson AGX Orin with initial support in JetPack 6.1 via the v0.12.0-jetson branch of the TensorRT-LLM repo. â Pre-compiled TensorRT-LLM wheels & containers for easy integration â Comprehensive guides & docs to get you started [â¡ï¸ link](https://forums.developer.nvidia.com/t/tensorrt-llm-for-jetson/313227?linkId=100000312718869)\n  * [2024/11/21] NVIDIA TensorRT-LLM Multiblock Attention Boosts Throughput by More Than 3x for Long Sequence Lengths on NVIDIA HGX H200 [â¡ï¸ link](https://developer.nvidia.com/blog/nvidia-tensorrt-llm-multiblock-attention-boosts-throughput-by-more-than-3x-for-long-sequence-lengths-on-nvidia-hgx-h200/)\n  * [2024/11/19] Llama 3.2 Full-Stack Optimizations Unlock High Performance on NVIDIA GPUs [â¡ï¸ link](https://developer.nvidia.com/blog/llama-3-2-full-stack-optimizations-unlock-high-performance-on-nvidia-gpus/?ncid=so-link-721194)\n  * [2024/11/09] ððð 3x Faster AllReduce with NVSwitch and TensorRT-LLM MultiShot [â¡ï¸ link](https://developer.nvidia.com/blog/3x-faster-allreduce-with-nvswitch-and-tensorrt-llm-multishot/)\n  * [2024/11/09] â¨ NVIDIA advances the AI ecosystem with the AI model of LG AI Research ð [â¡ï¸ link](https://blogs.nvidia.co.kr/blog/nvidia-lg-ai-research/)\n  * [2024/11/02] ððð NVIDIA and LlamaIndex Developer Contest ð Enter for a chance to win prizes including an NVIDIAÂ® GeForce RTXâ¢ 4080 SUPER GPU, DLI credits, and moreð [â¡ï¸ link](https://developer.nvidia.com/llamaindex-developer-contest)\n  * [2024/10/28] ðï¸ðï¸ðï¸ NVIDIA GH200 Superchip Accelerates Inference by 2x in Multiturn Interactions with Llama Models [â¡ï¸ link](https://developer.nvidia.com/blog/nvidia-gh200-superchip-accelerates-inference-by-2x-in-multiturn-interactions-with-llama-models/)\n  * [2024/10/22] New ð Step-by-step instructions on how to â Optimize LLMs with NVIDIA TensorRT-LLM, â Deploy the optimized models with Triton Inference Server, â Autoscale LLMs deployment in a Kubernetes environment. ð Technical Deep Dive: [â¡ï¸ link](https://nvda.ws/3YgI8UT)\n  * [2024/10/07] ðððOptimizing Microsoft Bing Visual Search with NVIDIA Accelerated Libraries [â¡ï¸ link](https://developer.nvidia.com/blog/optimizing-microsoft-bing-visual-search-with-nvidia-accelerated-libraries/)\n  * [2024/09/29] ð AI at Meta PyTorch + TensorRT v2.4 ð â¡TensorRT 10.1 â¡PyTorch 2.4 â¡CUDA 12.4 â¡Python 3.12 [â¡ï¸ link](https://github.com/pytorch/TensorRT/releases/tag/v2.4.0)\n  * [2024/09/17] â¨ NVIDIA TensorRT-LLM Meetup [â¡ï¸ link](https://drive.google.com/file/d/1RR8GqC-QbuaKuHj82rZcXb3MS20SWo6F/view?usp=share_link)\n  * [2024/09/17] â¨ Accelerating LLM Inference at Databricks with TensorRT-LLM [â¡ï¸ link](https://drive.google.com/file/d/1NeSmrLaWRJAY1rxD9lJmzpB9rzr38j8j/view?usp=sharing)\n  * [2024/09/17] â¨ TensorRT-LLM @ Baseten [â¡ï¸ link](https://drive.google.com/file/d/1Y7L2jqW-aRmt31mCdqhwvGMmCSOzBUjG/view?usp=share_link)\n  * [2024/09/04] ðï¸ðï¸ðï¸ Best Practices for Tuning TensorRT-LLM for Optimal Serving with BentoML [â¡ï¸ link](https://www.bentoml.com/blog/tuning-tensor-rt-llm-for-optimal-serving-with-bentoml)\n  * [2024/08/20] ðï¸SDXL with #TensorRT Model Optimizer â±ï¸â¡ ð cache diffusion ð quantization aware training ð QLoRA ð #Python 3.12 [â¡ï¸ link](https://developer.nvidia.com/blog/nvidia-tensorrt-model-optimizer-v0-15-boosts-inference-performance-and-expands-model-support/)\n  * [2024/08/13] ð DIY Code Completion with #Mamba â¡ #TensorRT #LLM for speed ð¤ NIM for ease âï¸ deploy anywhere [â¡ï¸ link](https://developer.nvidia.com/blog/revolutionizing-code-completion-with-codestral-mamba-the-next-gen-coding-llm/)\n  * [2024/08/06] ð« Multilingual Challenge Accepted ð« ð¤ #TensorRT #LLM boosts low-resource languages like Hebrew, Indonesian and Vietnamese â¡[â¡ï¸ link](https://developer.nvidia.com/blog/accelerating-hebrew-llm-performance-with-nvidia-tensorrt-llm/?linkId=100000278659647)\n  * [2024/07/30] Introducingð @SliceXAI ELM Turbo ð¤ train ELM once â¡ #TensorRT #LLM optimize âï¸ deploy anywhere [â¡ï¸ link](https://developer.nvidia.com/blog/supercharging-llama-3-1-across-nvidia-platforms)\n  * [2024/07/23] ð @AIatMeta Llama 3.1 405B trained on 16K NVIDIA H100s - inference is #TensorRT #LLM optimized â¡ ð¦ 400 tok/s - per node ð¦ 37 tok/s - per user ð¦ 1 node inference [â¡ï¸ link](https://developer.nvidia.com/blog/supercharging-llama-3-1-across-nvidia-platforms)\n  * [2024/07/09] Checklist to maximize multi-language performance of @meta #Llama3 with #TensorRT #LLM inference: â MultiLingual â NIM â LoRA tuned adaptors[â¡ï¸ Tech blog](https://developer.nvidia.com/blog/deploy-multilingual-llms-with-nvidia-nim/)\n  * [2024/07/02] Let the @MistralAI MoE tokens fly ð ð #Mixtral 8x7B with NVIDIA #TensorRT #LLM on #H100. [â¡ï¸ Tech blog](https://developer.nvidia.com/blog/achieving-high-mixtral-8x7b-performance-with-nvidia-h100-tensor-core-gpus-and-tensorrt-llm?ncid=so-twit-928467)\n  * [2024/06/24] Enhanced with NVIDIA #TensorRT #LLM, @upstage.aiâs solar-10.7B-instruct is ready to power your developer projects through our API catalog ðï¸. â¨[â¡ï¸ link](https://build.nvidia.com/upstage/solar-10_7b-instruct?snippet_tab=Try)\n  * [2024/06/18] CYMI: ð¤© Stable Diffusion 3 dropped last week ð ðï¸ Speed up your SD3 with #TensorRT INT8 Quantization[â¡ï¸ link](https://build.nvidia.com/upstage/solar-10_7b-instruct?snippet_tab=Try)\n  * [2024/06/18] ð§°Deploying ComfyUI with TensorRT? Hereâs your setup guide [â¡ï¸ link](https://github.com/comfyanonymous/ComfyUI_TensorRT)\n  * [2024/06/11] â¨#TensorRT Weight-Stripped Engines â¨ Technical Deep Dive for serious coders â+99% compression â1 set of weights â ** GPUs â0 performance loss â** modelsâ¦LLM, CNN, etc.[â¡ï¸ link](https://developer.nvidia.com/blog/maximum-performance-and-minimum-footprint-for-ai-apps-with-nvidia-tensorrt-weight-stripped-engines/)\n  * [2024/06/04] â¨ #TensorRT and GeForce #RTX unlock ComfyUI SD superhero powers ð¦¸â¡ ð¥ Demo: [â¡ï¸ link](https://youtu.be/64QEVfbPHyg) ð DIY notebook: [â¡ï¸ link](https://console.brev.dev/launchable/deploy?userID=2x2sil999&orgID=ktj33l4xj&name=ComfyUI_TensorRT&instance=L4%40g2-standard-4%3Anvidia-l4%3A1&diskStorage=500&cloudID=GCP&baseImage=docker.io%2Fpytorch%2Fpytorch%3A2.2.0-cuda12.1-cudnn8-runtime&ports=ComfUI%3A8188&file=https%3A%2F%2Fgithub.com%2Fbrevdev%2Fnotebooks%2Fblob%2Fmain%2Ftensorrt-comfyui.ipynb&launchableID=env-2hQX3n7ae5mq3NjNZ32DfAG0tJf)\n  * [2024/05/28] â¨#TensorRT weight stripping for ResNet-50 â¨ â+99% compression â1 set of weights â ** GPUs\\ â0 performance loss â** modelsâ¦LLM, CNN, etc ð ð DIY [â¡ï¸ link](https://console.brev.dev/launchable/deploy?userID=2x2sil999&orgID=ktj33l4xj&launchableID=env-2h6bym7h5GFNho3vpWQQeUYMwTM&instance=L4%40g6.xlarge&diskStorage=500&cloudID=devplane-brev-1&baseImage=nvcr.io%2Fnvidia%2Ftensorrt%3A24.05-py3&file=https%3A%2F%2Fgithub.com%2FNVIDIA%2FTensorRT%2Fblob%2Frelease%2F10.0%2Fsamples%2Fpython%2Fsample_weight_stripping%2Fnotebooks%2Fweight_stripping.ipynb&name=tensorrt_weight_stripping_resnet50)\n  * [2024/05/21] â¨@modal_labs has the codes for serverless @AIatMeta Llama 3 on #TensorRT #LLM â¨ð ð Marvelous Modal Manual: Serverless TensorRT-LLM (LLaMA 3 8B) | Modal Docs [â¡ï¸ link](https://modal.com/docs/examples/trtllm_llama)\n  * [2024/05/08] NVIDIA TensorRT Model Optimizer -- the newest member of the #TensorRT ecosystem is a library of post-training and training-in-the-loop model optimization techniques âquantization âsparsity âQAT [â¡ï¸ blog](https://developer.nvidia.com/blog/accelerate-generative-ai-inference-performance-with-nvidia-tensorrt-model-optimizer-now-publicly-available/)\n  * [2024/05/07] ð¦ð¦ð¦ 24,000 tokens per second ð«Meta Llama 3 takes off with #TensorRT #LLM ð[â¡ï¸ link](https://blogs.nvidia.com/blog/meta-llama3-inference-acceleration/)\n  * [2024/02/06] [ð Speed up inference with SOTA quantization techniques in TRT-LLM](https://github.com/NVIDIA/TensorRT-LLM/blob/main/docs/source/blogs/quantization-in-TRT-LLM.md)\n  * [2024/01/30] [ New XQA-kernel provides 2.4x more Llama-70B throughput within the same latency budget](https://github.com/NVIDIA/TensorRT-LLM/blob/main/docs/source/blogs/XQA-kernel.md)\n  * [2023/12/04] [Falcon-180B on a single H200 GPU with INT4 AWQ, and 6.7x faster Llama-70B over A100](https://github.com/NVIDIA/TensorRT-LLM/blob/main/docs/source/blogs/Falcon180B-H200.md)\n  * [2023/11/27] [SageMaker LMI now supports TensorRT-LLM - improves throughput by 60%, compared to previous version](https://aws.amazon.com/blogs/machine-learning/boost-inference-performance-for-llms-with-new-amazon-sagemaker-containers/)\n  * [2023/11/13] [H200 achieves nearly 12,000 tok/sec on Llama2-13B](https://github.com/NVIDIA/TensorRT-LLM/blob/main/docs/source/blogs/H200launch.md)\n  * [2023/10/22] [ð RAG on Windows using TensorRT-LLM and LlamaIndex ð¦](https://github.com/NVIDIA/trt-llm-rag-windows#readme)\n  * [2023/10/19] Getting Started Guide - [Optimizing Inference on Large Language Models with NVIDIA TensorRT-LLM, Now Publicly Available ](https://developer.nvidia.com/blog/optimizing-inference-on-llms-with-tensorrt-llm-now-publicly-available/)\n  * [2023/10/17] [Large Language Models up to 4x Faster on RTX With TensorRT-LLM for Windows ](https://blogs.nvidia.com/blog/2023/10/17/tensorrt-llm-windows-stable-diffusion-rtx/)\n\n\n## TensorRT-LLM Overview\n[](https://github.com/NVIDIA/TensorRT-LLM#tensorrt-llm-overview)\nTensorRT-LLM is an open-sourced library for optimizing Large Language Model (LLM) inference. It provides state-of-the-art optimizations, including custom attention kernels, inflight batching, paged KV caching, quantization (FP8, [FP4](https://www.nvidia.com/en-us/data-center/technologies/blackwell-architecture/), INT4 [AWQ](https://arxiv.org/abs/2306.00978), INT8 [SmoothQuant](https://arxiv.org/abs/2211.10438), ...), speculative decoding, and much more, to perform inference efficiently on NVIDIA GPUs.\nRecently [re-architected with a **PyTorch backend**](https://nvidia.github.io/TensorRT-LLM/torch.html), TensorRT-LLM now combines peak performance with a more flexible and developer-friendly workflow. The original [TensorRT](https://developer.nvidia.com/tensorrt)-based backend remains supported and continues to provide an ahead-of-time compilation path for building highly optimized \"[Engines](https://docs.nvidia.com/deeplearning/tensorrt/quick-start-guide/index.html#ecosystem)\" for deployment. The PyTorch backend complements this by enabling faster development iteration and rapid experimentation.\nTensorRT-LLM provides a flexible [**LLM API**](https://nvidia.github.io/TensorRT-LLM/quick-start-guide.html#llm-api) to simplify model setup and inference across both PyTorch and TensorRT backends. It supports a wide range of inference use cases from a single GPU to multiple nodes with multiple GPUs using [Tensor Parallelism](https://docs.nvidia.com/nemo-framework/user-guide/latest/nemotoolkit/features/parallelisms.html#tensor-parallelism) and/or [Pipeline Parallelism](https://docs.nvidia.com/nemo-framework/user-guide/latest/nemotoolkit/features/parallelisms.html#pipeline-parallelism). It also includes a [backend](https://github.com/triton-inference-server/tensorrtllm_backend) for integration with the [NVIDIA Triton Inference Server](https://developer.nvidia.com/nvidia-triton-inference-server).\nSeveral popular models are pre-defined and can be easily customized or extended using [native PyTorch code](https://github.com/NVIDIA/TensorRT-LLM/blob/main/tensorrt_llm/_torch/models/modeling_deepseekv3.py) (for the PyTorch backend) or a [PyTorch-style Python API](https://github.com/NVIDIA/TensorRT-LLM/blob/main/tensorrt_llm/models/llama/model.py) (for the TensorRT backend).\n## Getting Started\n[](https://github.com/NVIDIA/TensorRT-LLM#getting-started)\nTo get started with TensorRT-LLM, visit our documentation:\n  * [Quick Start Guide](https://nvidia.github.io/TensorRT-LLM/quick-start-guide.html)\n    * [Running DeepSeek](https://github.com/NVIDIA/TensorRT-LLM/blob/main/examples/models/core/deepseek_v3)\n  * [Installation Guide for Linux](https://nvidia.github.io/TensorRT-LLM/installation/linux.html)\n  * [Installation Guide for Grace Hopper](https://nvidia.github.io/TensorRT-LLM/installation/grace-hopper.html)\n  * [Supported Hardware, Models, and other Software](https://nvidia.github.io/TensorRT-LLM/reference/support-matrix.html)\n  * [Benchmarking Performance](https://nvidia.github.io/TensorRT-LLM/performance/performance-tuning-guide/benchmarking-default-performance.html#benchmarking-with-trtllm-bench)\n  * [Release Notes](https://nvidia.github.io/TensorRT-LLM/release-notes.html)\n\n\n## Useful Links\n[](https://github.com/NVIDIA/TensorRT-LLM#useful-links)\n  * [Quantized models on Hugging Face](https://huggingface.co/collections/nvidia/model-optimizer-66aa84f7966b3150262481a4): A growing collection of quantized (e.g., FP8, FP4) and optimized LLMs, including [DeepSeek FP4](https://huggingface.co/nvidia/DeepSeek-R1-FP4), ready for fast inference with TensorRT-LLM.\n  * [NVIDIA Dynamo](https://github.com/ai-dynamo/dynamo): A datacenter scale distributed inference serving framework that works seamlessly with TensorRT-LLM.\n  * [AutoDeploy](https://github.com/NVIDIA/TensorRT-LLM/blob/main/examples/auto_deploy/README.md): An experimental backend for TensorRT-LLM to simplify and accelerate the deployment of PyTorch models.\n\n\n## About\nTensorRT-LLM provides users with an easy-to-use Python API to define Large Language Models (LLMs) and support state-of-the-art optimizations to perform inference efficiently on NVIDIA GPUs. TensorRT-LLM also contains components to create Python and C++ runtimes that orchestrate the inference execution in performant way. \n[nvidia.github.io/TensorRT-LLM](https://nvidia.github.io/TensorRT-LLM \"https://nvidia.github.io/TensorRT-LLM\")\n### Resources\n[ Readme ](https://github.com/NVIDIA/TensorRT-LLM#readme-ov-file)\n### License\n[ Apache-2.0 license ](https://github.com/NVIDIA/TensorRT-LLM#Apache-2.0-1-ov-file)\n### Code of conduct\n[ Code of conduct ](https://github.com/NVIDIA/TensorRT-LLM#coc-ov-file)\n###  Uh oh! \nThere was an error while loading. [Please reload this page](https://github.com/NVIDIA/TensorRT-LLM).\n[ Activity](https://github.com/NVIDIA/TensorRT-LLM/activity)\n[ Custom properties](https://github.com/NVIDIA/TensorRT-LLM/custom-properties)\n### Stars\n[ **10.6k** stars](https://github.com/NVIDIA/TensorRT-LLM/stargazers)\n### Watchers\n[ **123** watching](https://github.com/NVIDIA/TensorRT-LLM/watchers)\n### Forks\n[ **1.5k** forks](https://github.com/NVIDIA/TensorRT-LLM/forks)\n[ Report repository ](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2FNVIDIA%2FTensorRT-LLM&report=NVIDIA+%28user%29)\n##  [Releases 22](https://github.com/NVIDIA/TensorRT-LLM/releases)\n[ v0.19.0 Latest  May 9, 2025 ](https://github.com/NVIDIA/TensorRT-LLM/releases/tag/v0.19.0)\n[+ 21 releases](https://github.com/NVIDIA/TensorRT-LLM/releases)\n##  [Packages 0](https://github.com/orgs/NVIDIA/packages?repo_name=TensorRT-LLM)\nNo packages published \n###  Uh oh! \nThere was an error while loading. [Please reload this page](https://github.com/NVIDIA/TensorRT-LLM).\n##  [Contributors 238](https://github.com/NVIDIA/TensorRT-LLM/graphs/contributors)\n  * [ ![@kaiyux](https://avatars.githubusercontent.com/u/26294424?s=64&v=4) ](https://github.com/kaiyux)\n  * [ ![@QiJune](https://avatars.githubusercontent.com/u/22017000?s=64&v=4) ](https://github.com/QiJune)\n  * [ ![@Shixiaowei02](https://avatars.githubusercontent.com/u/39303645?s=64&v=4) ](https://github.com/Shixiaowei02)\n  * [ ![@Funatiq](https://avatars.githubusercontent.com/u/19427718?s=64&v=4) ](https://github.com/Funatiq)\n  * [ ![@yuxianq](https://avatars.githubusercontent.com/u/142763828?s=64&v=4) ](https://github.com/yuxianq)\n  * [ ![@syuoni](https://avatars.githubusercontent.com/u/21126786?s=64&v=4) ](https://github.com/syuoni)\n  * [ ![@xinhe-nv](https://avatars.githubusercontent.com/u/200704525?s=64&v=4) ](https://github.com/xinhe-nv)\n  * [ ![@byshiue](https://avatars.githubusercontent.com/u/11360707?s=64&v=4) ](https://github.com/byshiue)\n  * [ ![@Superjomn](https://avatars.githubusercontent.com/u/328693?s=64&v=4) ](https://github.com/Superjomn)\n  * [ ![@chzblych](https://avatars.githubusercontent.com/u/20898724?s=64&v=4) ](https://github.com/chzblych)\n  * [ ![@ZhanruiSunCh](https://avatars.githubusercontent.com/u/184402041?s=64&v=4) ](https://github.com/ZhanruiSunCh)\n  * [ ![@yiqingy0](https://avatars.githubusercontent.com/u/200167850?s=64&v=4) ](https://github.com/yiqingy0)\n  * [ ![@nv-guomingz](https://avatars.githubusercontent.com/u/137257613?s=64&v=4) ](https://github.com/nv-guomingz)\n  * [ ![@hlu1](https://avatars.githubusercontent.com/u/14827759?s=64&v=4) ](https://github.com/hlu1)\n\n\n[+ 224 contributors](https://github.com/NVIDIA/TensorRT-LLM/graphs/contributors)\n## Languages\n  * [ C++ 55.6% ](https://github.com/NVIDIA/TensorRT-LLM/search?l=c%2B%2B)\n  * [ Python 33.4% ](https://github.com/NVIDIA/TensorRT-LLM/search?l=python)\n  * [ Cuda 9.4% ](https://github.com/NVIDIA/TensorRT-LLM/search?l=cuda)\n  * [ Shell 0.5% ](https://github.com/NVIDIA/TensorRT-LLM/search?l=shell)\n  * [ CMake 0.5% ](https://github.com/NVIDIA/TensorRT-LLM/search?l=cmake)\n  * [ Groovy 0.4% ](https://github.com/NVIDIA/TensorRT-LLM/search?l=groovy)\n  * Other 0.2%\n\n\n## Footer\n[ ](https://github.com) Â© 2025 GitHub, Inc. \n### Footer navigation\n  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n  * [Security](https://github.com/security)\n  * [Status](https://www.githubstatus.com/)\n  * [Docs](https://docs.github.com/)\n  * [Contact](https://support.github.com?tags=dotcom-footer)\n  * Manage cookies \n  * Do not share my personal information \n\n\nYou canât perform that action at this time. \n"
  },
  {
    "link": "https://arxiv.org/html/2405.20900v1",
    "raw_content": "## Table of Contents\n  1. [ Abstract  ](https://arxiv.org/html/2405.20900v1#abstract \"Abstract\")\n  2. [1 Introduction](https://arxiv.org/html/2405.20900v1#S1 \"In Large Language Models: A New Approach for Privacy Policy Analysis at Scale\")\n  3. [2 Related Work](https://arxiv.org/html/2405.20900v1#S2 \"In Large Language Models: A New Approach for Privacy Policy Analysis at Scale\")\n  4. [3 Experimental Design](https://arxiv.org/html/2405.20900v1#S3 \"In Large Language Models: A New Approach for Privacy Policy Analysis at Scale\")\n    1. [3.1 Ground Truth](https://arxiv.org/html/2405.20900v1#S3.SS1 \"In 3 Experimental Design â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\")\n    2. [3.2 Prompt Design](https://arxiv.org/html/2405.20900v1#S3.SS2 \"In 3 Experimental Design â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\")\n    3. [3.3 Parameter Tuning](https://arxiv.org/html/2405.20900v1#S3.SS3 \"In 3 Experimental Design â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\")\n    4. [3.4 Fine-tuning](https://arxiv.org/html/2405.20900v1#S3.SS4 \"In 3 Experimental Design â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\")\n    5. [3.5 Validation](https://arxiv.org/html/2405.20900v1#S3.SS5 \"In 3 Experimental Design â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\")\n  5. [4 Demonstration](https://arxiv.org/html/2405.20900v1#S4 \"In Large Language Models: A New Approach for Privacy Policy Analysis at Scale\")\n    1. [4.1 Comparison with Llama 2](https://arxiv.org/html/2405.20900v1#S4.SS1 \"In 4 Demonstration â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\")\n    2. [4.2 Comparison with state-of-the-art techniques](https://arxiv.org/html/2405.20900v1#S4.SS2 \"In 4 Demonstration â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\")\n      1. [4.2.1 Statistical approaches](https://arxiv.org/html/2405.20900v1#S4.SS2.SSS1 \"In 4.2 Comparison with state-of-the-art techniques â£ 4 Demonstration â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\")\n      2. [4.2.2 Symbolic approaches](https://arxiv.org/html/2405.20900v1#S4.SS2.SSS2 \"In 4.2 Comparison with state-of-the-art techniques â£ 4 Demonstration â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\")\n    3. [4.3 Generalization Capabilities](https://arxiv.org/html/2405.20900v1#S4.SS3 \"In 4 Demonstration â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\")\n  6. [5 Discussion](https://arxiv.org/html/2405.20900v1#S5 \"In Large Language Models: A New Approach for Privacy Policy Analysis at Scale\")\n  7. [6 Conclusion](https://arxiv.org/html/2405.20900v1#S6 \"In Large Language Models: A New Approach for Privacy Policy Analysis at Scale\")\n  8. [7 Aknowledgments](https://arxiv.org/html/2405.20900v1#S7 \"In Large Language Models: A New Approach for Privacy Policy Analysis at Scale\")\n  9. [ References  ](https://arxiv.org/html/2405.20900v1#bib \"References\")\n\n\n# Large Language Models: A New Approach for Privacy Policy Analysis at Scale \nReport issue for preceding element\nDavid Rodriguez ETSI TelecomunicaciÃ³n Universidad PolitÃ©cnica de Madrid Spain david.rtorrado@upm.es &Ian Yang School of Computer Science Carnegie Mellon University Forbes Ave, Pittsburgh, Pennsylvania United States iyang30@gatech.edu &Jose M. Del Alamo ETSI TelecomunicaciÃ³n Universidad PolitÃ©cnica de Madrid Spain jm.delalamo@upm.es &Norman Sadeh School of Computer Science Carnegie Mellon University Forbes Ave, Pittsburgh, Pennsylvania United States sadeh@cs.cmu.edu\nReport issue for preceding element\n###### Abstract\nReport issue for preceding element\nThe number and dynamic nature of web and mobile applications presents significant challenges for assessing their compliance with data protection laws. In this context, symbolic and statistical Natural Language Processing (NLP) techniques have been employed for the automated analysis of these systemsâ privacy policies. However, these techniques typically require labor-intensive and potentially error-prone manually annotated datasets for training and validation. This research proposes the application of Large Language Models (LLMs) as an alternative for effectively and efficiently extracting privacy practices from privacy policies at scale. Particularly, we leverage well-known LLMs such as ChatGPT and Llama 2, and offer guidance on the optimal design of prompts, parameters, and models, incorporating advanced strategies such as few-shot learning. We further illustrate its capability to detect detailed and varied privacy practices accurately. Using several renowned datasets in the domain as a benchmark, our evaluation validates its exceptional performance, achieving an F1 score exceeding 93%. Besides, it does so with reduced costs, faster processing times, and fewer technical knowledge requirements. Consequently, we advocate for LLM-based solutions as a sound alternative to traditional NLP techniques for the automated analysis of privacy policies at scale.\nReport issue for preceding element\n_K_ eywords Large Language Models ââ\\cdotâ Natural Language Processing ââ\\cdotâ Privacy policies ââ\\cdotâ Data protection ââ\\cdotâ Privacy ââ\\cdotâ Feature extraction\nReport issue for preceding element\n##  1 Introduction\nReport issue for preceding element\nThe digital era has led to an unprecedented expansion of web and mobile applications and a myriad of online services. This growth is a testament to technological advancement and the increasing reliance of businesses and organizations on digital platforms for various operations. A central aspect of this digital proliferation is the extensive use of technologies for personal data collection, primarily driven by the objective of enhancing targeted marketing strategies. The ability to collect, analyze, and utilize user data has become a cornerstone of modern commerce, offering businesses invaluable insights into consumer behavior and preferences.\nReport issue for preceding element\nHowever, the increasing collection and utilization of personal data have raised significant privacy concerns. Usersâ privacy is at risk as their data becomes valuable in the digital marketplace. This concern has led to the emergence of regulatory bodies and the formulation of data protection legislation aimed at safeguarding user privacy. These legislations, such as the General Data Protection Regulation (GDPR) in the European Union and the California Consumer Privacy Act (CCPA) in the United States, impose stringent requirements on how organizations should handle personal data.\nReport issue for preceding element\nEnsuring compliance with these legislations, however, poses a formidable challenge. The overgrowth of online services, compounded by globalization, makes it impractical, if not impossible, for regulators to manually assess each serviceâs adherence to privacy laws. This situation is further exacerbated by the dynamic nature of online services, where data processing practices and the privacy policies disclosing them are subject to frequent changes [[1](https://arxiv.org/html/2405.20900v1#bib.bib1)]. In response to these challenges, automated-driven methods have been proposed for analyzing privacy policies at scale [[2](https://arxiv.org/html/2405.20900v1#bib.bib2)]. This approach holds the potential for research endeavors aimed at understanding and highlighting privacy concerns, and it also offers a practical tool for regulators to conduct mass evaluations of applications and services, thereby promoting a higher level of compliance with privacy regulations.\nReport issue for preceding element\nThe automated analysis of privacy policies has leveraged Natural Language Processing (NLP) techniques [[2](https://arxiv.org/html/2405.20900v1#bib.bib2)]. Symbolic and statistical state-of-the-art NLP techniques are proposed to address this task, although each has drawbacks. Symbolic approaches rely on pre-defined rules, leading to lower performance when compared to statistical approaches due to the lack of adaptability to differences present in legal texts. Thus, state-of-the-art research has predominantly relied on statistical approaches such as machine learning (ML) techniques, and particularly supervised learning models, to train and evaluate models identifying privacy practice disclosures such as personal data collection or sharing [[3](https://arxiv.org/html/2405.20900v1#bib.bib3)]. These models require the use of manually annotated datasets [[4](https://arxiv.org/html/2405.20900v1#bib.bib4), [5](https://arxiv.org/html/2405.20900v1#bib.bib5), [6](https://arxiv.org/html/2405.20900v1#bib.bib6)], which are often expensive, time-consuming to create, and prone to errors [[7](https://arxiv.org/html/2405.20900v1#bib.bib7)]. Furthermore, building and training those models require advanced technical expertise, contributing to a higher barrier to entry. As a result, their practical application is mainly suitable for large-scale projects where the benefits can outweigh these significant costs. On the other hand, modern Generative Artificial Intelligence (GenAI), particularly Large Language Models (LLMs), represents a significant advancement in the NLP domain, being able to understand and generate human-like text, making it particularly well-suited for parsing and analyzing the complex language present in privacy policies without needing annotated datasets. In this context, this paper proposes the application of LLMs for the effective and efficient extraction of privacy practices from privacy policies. In particular, we focus on ChatGPT, which relies on Generative Pre-trained Transformer (GPT) models.\nReport issue for preceding element\nOur study identifies the optimal configuration of ChatGPT prompts, parameters, and models, integrating advanced techniques such as few-shot learning. Additionally, we conduct a comparative analysis of our proposed ChatGPT configuration with Llama 2 and other state-of-the-art techniques. Our findings reveal that our proposal competes with and even outperforms these traditional methods. Moreover, we discuss its advantages regarding lower upfront costs, reduced processing times, and greater ease of use.\nReport issue for preceding element\nThus, we propose LLM-based solutions and our specific ChatGPT configuration as a viable replacement for traditional NLP techniques in the task of automated privacy policy processing. Our research contributes to the ongoing discourse on the application of GenAI in legal and regulatory contexts [[8](https://arxiv.org/html/2405.20900v1#bib.bib8), [9](https://arxiv.org/html/2405.20900v1#bib.bib9), [10](https://arxiv.org/html/2405.20900v1#bib.bib10)], suggesting a paradigm shift towards more efficient, cost-effective, and accessible tools for privacy policy analysis.\nReport issue for preceding element\n##  2 Related Work\nReport issue for preceding element\nPrivacy policies are documents written in plain text that outline how organizations handle personal data. However, the complexity and length of these documents often make them challenging to understand and process [[11](https://arxiv.org/html/2405.20900v1#bib.bib11)]. This has spurred interest in automated methods for analyzing privacy policies [[2](https://arxiv.org/html/2405.20900v1#bib.bib2)], which fall into two major categories, namely, symbolic and statistical NLP.\nReport issue for preceding element\nSymbolic NLP approaches [[12](https://arxiv.org/html/2405.20900v1#bib.bib12), [13](https://arxiv.org/html/2405.20900v1#bib.bib13), [14](https://arxiv.org/html/2405.20900v1#bib.bib14)] are relevant but come with inherent limitations when processing new texts: these techniques model language through grammar rules and lexicons, thus requiring extensive manual effort to create and code these rules. This process is both time-consuming and hard to scale, especially when dealing with intricate aspects of privacy policies. Symbolic NLP is effective in morphological and lexical analysis, such as identifying privacy practices through keyword analysis. It also handles more complex tasks like syntactic and semantic analysis, using tools like the Stanford dependency parser [[15](https://arxiv.org/html/2405.20900v1#bib.bib15)]. PolicyLint [[16](https://arxiv.org/html/2405.20900v1#bib.bib16)] is a state-of-the-art tool based on this symbolic NLP approach that employs ontologies to detect contradictions in privacy policy statements about personal data collection and sharing. Its ability to identify negative sentences âa challenging task for statistical NLP techniquesâ highlights its potential for specific privacy policy analysis tasks. However, it faces challenges with unanticipated variations, including typos or infrequent cases, thus limiting its applicability to new cases.\nReport issue for preceding element\nStatistical NLP approaches, on the other hand, leverage machine learning techniques for language processing: supervised, unsupervised, and Artificial Neural Networks (ANN)-based techniques. Supervised methods are the predominant technique usually employed for automated privacy policy analysis, with geometric algorithms like Support Vector Machine (SVM) [[17](https://arxiv.org/html/2405.20900v1#bib.bib17), [18](https://arxiv.org/html/2405.20900v1#bib.bib18), [19](https://arxiv.org/html/2405.20900v1#bib.bib19), [20](https://arxiv.org/html/2405.20900v1#bib.bib20)] and Logistic Regression (LR) [[21](https://arxiv.org/html/2405.20900v1#bib.bib21), [22](https://arxiv.org/html/2405.20900v1#bib.bib22)] being the most prevalent. Unsupervised techniques, although less common, utilize models like Hidden Markov Models (HMM) [[23](https://arxiv.org/html/2405.20900v1#bib.bib23), [18](https://arxiv.org/html/2405.20900v1#bib.bib18)] and Latent Dirichlet Allocation (LDA) [[24](https://arxiv.org/html/2405.20900v1#bib.bib24)] for clustering practices during policy analysis. ANN-based techniques are also in use for this task, including Convolutional Neural Networks (CNNs) [[6](https://arxiv.org/html/2405.20900v1#bib.bib6), [25](https://arxiv.org/html/2405.20900v1#bib.bib25)], Recurrent Neural Networks (RNN) [[26](https://arxiv.org/html/2405.20900v1#bib.bib26)], and Googleâs BERT [[4](https://arxiv.org/html/2405.20900v1#bib.bib4), [27](https://arxiv.org/html/2405.20900v1#bib.bib27)], sometimes showing superior performance than supervised learning methods [[4](https://arxiv.org/html/2405.20900v1#bib.bib4), [27](https://arxiv.org/html/2405.20900v1#bib.bib27)].\nReport issue for preceding element\nThe development of new privacy policy analysis methods leveraging statistical NLP approaches frequently requires labeled corpora for training and validation. In the domain of privacy policy analysis, several datasets manually annotated by legal experts have been employed to build supervised learning methods. MAPP corpus [[28](https://arxiv.org/html/2405.20900v1#bib.bib28)] is a public multilingual dataset that contains 64 Google Play Store app privacy policies, chunked into segments (i.e., paragraphs) manually annotated as disclosing the collection or sharing of various types of personal data. The OPP-115 dataset [[18](https://arxiv.org/html/2405.20900v1#bib.bib18)] is the most widely used dataset in the domain. It follows the same structure and contains annotations of almost identical practices and data types to MAPP but with a larger number (n=115) of annotated policies. APP-350 [[29](https://arxiv.org/html/2405.20900v1#bib.bib29)] is the largest dataset of this type, which has 350 privacy policies with annotations of collection/sharing of even more specific data types than the previous ones. Likewise, the IT100 [[30](https://arxiv.org/html/2405.20900v1#bib.bib30)] is a dataset of 100 privacy policies containing annotations of statements disclosing international transfers of personal data.\nReport issue for preceding element\nExpanding upon symbolic and statistical NLP methods, LLMs can generate coherent text based on a given input, such as GPTs [[31](https://arxiv.org/html/2405.20900v1#bib.bib31)] and Llama 2 [[32](https://arxiv.org/html/2405.20900v1#bib.bib32)]. Building on those LLMs, ChatGPT and Llama 2-Chat are chatbots trained to provide meaningful answers to pieces of text inputs (i.e., prompts) and with adjustable performance through parameters like âtemperatureâ that influence the resultsâ variability [[33](https://arxiv.org/html/2405.20900v1#bib.bib33)], and response times. The ability to provide relevant answers is achieved through a combination of unsupervised and supervised learning techniques underpinned by neural networks trained on extensive datasets. Additionally, the relevance and format of the responses are typically enhanced through prompt augmentation [[34](https://arxiv.org/html/2405.20900v1#bib.bib34)], which involves modifying the given input prompt to improve the output performance or to steer the output in a specific direction. Notably, LLMsâ proficiency in processing lengthy input texts is boosted by the attention mechanisms inherent in transformer architectures [[35](https://arxiv.org/html/2405.20900v1#bib.bib35)]. A recent study conducted by Qin et al. [[36](https://arxiv.org/html/2405.20900v1#bib.bib36)] has analyzed to what extent LLMs like ChatGPT can perform various tasks âreasoning, language inference, Q&A, dialogue, summarization, entity recognition, and sentiment analysisâ using 20 well-established NLP datasets to benchmark their performance, showing high reasoning capabilities.\nReport issue for preceding element\nIntegrating LLMs into the automated analysis of privacy policies and legal texts [[37](https://arxiv.org/html/2405.20900v1#bib.bib37)] represents a significant evolution in assessing compliance with data protection regulations. Tang et al. [[10](https://arxiv.org/html/2405.20900v1#bib.bib10)] have explored their application in this context, highlighting its potential to surpass traditional methods in extracting and classifying general, coarse-grained privacy practices within legal texts. Our research extends this exploration by thoroughly analyzing LLMsâ ability to identify more detailed data practices in privacy policies. We provide insights into the optimal model configuration for this task and further demonstrate LLMsâ generalization capabilities, particularly ChatGPTâs, to identify varied privacy practices. Our findings reveal that ChatGPT, leveraging few-shot learning, outperforms traditional symbolic and statistical NLP methods in key areas, including classification performance, time efficiency, and cost-effectiveness.\nReport issue for preceding element\n##  3 Experimental Design\nReport issue for preceding element\nGPT models have an intrinsically complex behavior dependent on the prompt design, configuration parameters, and model selection. We rely on the Design Science Research (DSR) methodology [[38](https://arxiv.org/html/2405.20900v1#bib.bib38)] to propose a ChatGPT framework for privacy policy analysis and evaluate its effectiveness. DSR guides the design of new artifacts through an iterative and systematic process. Specifically, we followed an iterative split testing process [[39](https://arxiv.org/html/2405.20900v1#bib.bib39)] to assess the performance of the prompt, parameter, or model selection changes within each iteration. Finally, we check our proposed configuration performance against two unseen sets of policies, conduct a set of comparative analyses with state-of-the-art solutions, and demonstrate its generalization capabilities. Through this systematic process, we propose a well-performing and generalizable configuration of ChatGPT as a novel and effective approach for the automated analysis of privacy policies.\nReport issue for preceding element\n###  3.1 Ground Truth\nReport issue for preceding element\nDetermining the optimal ChatGPT configuration that offers the best performance requires using a ground truth dataset to validate and quantify results. We relied on the MAPP dataset [[28](https://arxiv.org/html/2405.20900v1#bib.bib28)] for this task, retaining an experimental set on which to apply changes and measure their impacts and a control set to validate the final configurationâs overall performance. Unlike traditional NLP techniques, using a ground truth dataset is only required while designing the configuration framework. Afterward, we can generalize it to identify other privacy practices without generating new annotated datasets or validating new methods, as demonstrated in Section [4](https://arxiv.org/html/2405.20900v1#S4 \"4 Demonstration â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\").\nReport issue for preceding element\nThe MAPP dataset is unbalanced. Thus, we stratified sampling to generate the experimental (33 policies) and control (31 policies) subsets. With a standard deviation between both datasets of 2.44 for all data categories, with categories annotated in almost all policies (e.g., IP address and device IDs, in 95%) and others in only one of them (e.g., Political, religious, or philosophical belief). This is contextualized against the backdrop of the mean annotation counts per policy, which are 8.13 and 8.18 for the experimental and control sets, respectively. The observed standard deviation, in relation to the means, suggests a moderate degree of variance in annotation frequency per policy across the datasets. This degree of variability is within acceptable limits for the intended analytical scope, affirming a balanced and representative data stratification for the empirical analysis.\nReport issue for preceding element\n###  3.2 Prompt Design\nReport issue for preceding element\nWe departed from the prompt design depicted in Figure [1(a)](https://arxiv.org/html/2405.20900v1#S3.F1.sf1 \"In Figure 1 â£ 3.2 Prompt Design â£ 3 Experimental Design â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\"). This baseline prompt is structured in _Data_ , _Task_ and _Output_ format instruction segments. _Data_ is the privacy policy for identifying practices. _Task_ is the actual practice in which identification in the policy is requested. _Output_ format instruction provides the guidelines to obtain responses that can be processed automatically.\nReport issue for preceding element\nWe applied this baseline prompt to the specific task of identifying types of personal data purportedly collected or shared as per the privacy policy. This required providing the privacy policy in the Data segment, asking about each data type in the Task segment, and steering the formatting of responses, including â _Data: Answer_ â in the Output format instruction segment. In our experiment, this baseline prompt achieved the following metrics: 0.79 accuracy, 0.92 recall, 0.78 precision and 0.84 F1 score.\nReport issue for preceding element\nCrafting the optimum prompt design requires a split testing process to reveal the effects of various changes in the prompt. The only ChatGPT parameter adjusted during this phase is the temperature value, set to zero to provide more deterministic responses [[40](https://arxiv.org/html/2405.20900v1#bib.bib40)], and using the GPT-4 Turbo model to take advantage of its speed and input prompt size capabilities up to 128k tokens. While numerous tests were conducted, this section will focus solely on those that involved a significant change in performance metrics. A detailed summary of these metrics, derived from each test, is encapsulated in Table [1](https://arxiv.org/html/2405.20900v1#S3.T1 \"Table 1 â£ 3.2 Prompt Design â£ 3 Experimental Design â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\"). In this testing sequence, each technique that demonstrated a performance improvement was systematically integrated into the subsequent tests. Thus, each new test was benchmarked against the last updated configuration.\nReport issue for preceding element\nSpecifying Data boundaries. Incorporating the phrase âThe following text is a privacy policyâ improved the metrics, specifically a +1.47% increase in accuracy (from 0.793 to 0.804), +0.4% in recall, +1.36% in precision, and +0.92% in F1 score. This improvement is attributed to enhancing the modelâs ability to discern the limits of the privacy policy text. A minor adjustment involving the indication that the privacy policy text is enclosed in double quotes led to an additional +0.8% rise in recall, precision, and F1 score, and a +1.16% increase in accuracy.\nReport issue for preceding element\nData placement. We evaluated the impact of the placement of the privacy policy within the prompt âeither at the beginning or the endâ on the performance metrics. Positioning the privacy policy at the end, contrary to the beginning, slightly diminished the overall metrics, including a decrease in accuracy by -1.15%, recall by -1.98%, precision by -0.07%, and F1 score by -0.97%.\nReport issue for preceding element\nAugmenting Task description. The initial prompt version primarily focused on enumerating the types of data to be identified. However, given the inherent complexity of data categorization âa challenge even for human annotators as substantiated in related literature [[41](https://arxiv.org/html/2405.20900v1#bib.bib41)]â the prompt was augmented to include the internal definitions used for manual annotations in the MAPP dataset. While this expansion resulted in a lengthier prompt, it significantly enhanced all metrics except for recall, with an increase of +4.58% in accuracy, a decrease of -0.79% in recall, +5.96% in precision, and +2.72% in F1 score.\nReport issue for preceding element\nMessage splitting. We have tested splitting the prompt into two different messages, passed to ChatGPT one after the other. Specifically, we separated the privacy policy (Data segment) from the remainder prompt. The results show a better overall understanding and comprehension of the privacy policy, reflected in a +1.56% increase in precision, +0.56% increase in accuracy and +0.22% increase in F1 score, at the cost of a -1.2% decrease in recall.\nReport issue for preceding element\nData pruning. This technique eliminates the paragraphs of the policy that do not have information regarding collecting or sharing personal data. We crafted a specific prompt for this task. The results show the overall policy metrics have remained practically the same.\nReport issue for preceding element\nSegmentation. We also assessed the role of input processing in the results with three different configurations: 1) Data segmentation, i.e., analyzing each individual paragraph at a time; 2) Task segmentation, i.e., asking only for one specific practice (e.g., a given data type collection) at a time, and 3) Data and Task segmentation, i.e., asking for one specific practice in one specific paragraph. Data segmentation did not show significant improvement. However, Task segmentation had a surprising effect on the result: accuracy decreased by -5.48%, recall decreased by -18.4%, precision increased by +8.06%, and overall leading to a decrease in the F1 score of -6.46%. This suggests that asking for each practice individually may lead to a loss of a broader contextual understanding of the model, negatively impacting its overall performance. Finally, Data and Task segmentation showed the worst results, dropping recall by -59.6% and decreasing F1 score by -40.97%, reinforcing the importance of context for ChatGPT when analyzing privacy policies.\nReport issue for preceding element\nItâs worth noting that while Data segmentation showed a similar performance to keep the whole policy, it increases the cost of the queries since they are computed according to the prompt and response size and not specifically by the number of requests. Furthermore, it also increases the processing time for each policy, as more requests (as many as policy paragraphs) must be processed. Thus, we have discarded this option in favor of processing the whole policy.\nReport issue for preceding element\nFew-shot prompting. Few-shot prompting [[42](https://arxiv.org/html/2405.20900v1#bib.bib42)] refers to providing a set of examples (shots) with the prompt to guide the model. We have tested this technique, including in the prompt one, two, and three examples ârandomly chosenâ of paragraph annotations. The best result was obtained with two-shot examples, showing a significant improvement in the metrics (+3.31% accuracy, +0.0% recall, +4.29% precision, +2.18% F1 score).\nReport issue for preceding element\nFinal prompt design. Figure [1(b)](https://arxiv.org/html/2405.20900v1#S3.F1.sf2 \"In Figure 1 â£ 3.2 Prompt Design â£ 3 Experimental Design â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\") presents the prompt configuration that our tests have consistently found to be most effective in identifying privacy practices. In this optimized prompt structure, the Data segment is introduced in an initial message, followed by the Task segment in a subsequent message. This Task segment incorporates definitions of the targeted practice âin this instance, data typesâ along with the same Output format instruction used in the Baseline prompt and a Few-shot learning component. The Few-shot learning part includes two illustrative examples (Two-shot) of processing paragraphs from privacy policies and the corresponding expected outputs.\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/5634937/Prompt_design-Baseline_Prompt_Big.png) (a) Baseline prompt design. Report issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/5634937/Prompt_design-Enhanced_Prompt_Big.png) (b) Final prompt design. Report issue for preceding element\nFigure 1: Baseline and final ChatGPT prompt designs for the identification of privacy practices in privacy policies. Report issue for preceding element Table 1: Metrics obtained with each technique tested on ChatGPT and Llama 2. The tests have been executed sequentially and are incremental: when a technique exhibits superior performance (highlighted in bold within the table), it is incorporated into the subsequent test. The sole exception to this is the Data Segmentation test, which demonstrated a minimal improvement in the F1 score at the expense of significantly increased processing time and a decrease in precision; hence, this technique has not been ultimately integrated. GPT-4 Turbo and Llama 2 70B-Chat models are used unless otherwise stated, as they showed the best performance. | Prompt technique | Accuracy | Precision | Recall | F1 Score  \n---|---|---|---|---|---  \nChatGPT |  |  |  |  |   \nBaseline prompt | 0.793 | 0.785 | 0.922 | 0.848  \nSpecify Data boundaries | 0.804 | 0.796 | 0.926 | 0.856  \nSpecify Data boundaries (double quotes) | 0.814 | 0.803 | 0.933 | 0.863  \nData placement (Bottom) | 0.804 | 0.802 | 0.915 | 0.855  \nAugmenting Task description | 0.851 | 0.850 | 0.926 | 0.887  \nMessage splitting | 0.855 | 0.864 | 0.915 | 0.888  \nData pruning | 0.848 | 0.847 | 0.926 | 0.885  \nData segmentation | 0.850 | 0.837 | 0.948 | 0.889  \nTask segmentation | 0.804 | 0.919 | 0.756 | 0.829  \nData & Task segmentation | 0.571 | 0.871 | 0.374 | 0.523  \nOne-shot prompting | 0.862 | 0.889 | 0.893 | 0.891  \nTwo-shot prompting | 0.874 | 0.886 | 0.919 | 0.902  \nThree-shot prompting | 0.858 | 0.872 | 0.907 | 0.889  \nLlama 2 |  |  |  |  |   \nBaseline prompt | 0.846 | 0.880 | 0.873 | 0.877  \nData segmentation | 0.625 | 0.625 | 1.000 | 0.770  \nTask segmentation | 0.613 | 0.870 | 0.490 | 0.627  \nData & Task segmentation | 0.846 | 0.847 | 0.921 | 0.882  \nTwo-shot prompting | 0.623 | 0.623 | 1.000 | 0.768  \nReport issue for preceding element\n###  3.3 Parameter Tuning\nReport issue for preceding element\nChatGPT offers a number of parameters that can be configured to modify its responses [[40](https://arxiv.org/html/2405.20900v1#bib.bib40)], namely temperature, top p, and system inputs. For testing these parameters, we used the final prompt design presented in Figure [1(b)](https://arxiv.org/html/2405.20900v1#S3.F1.sf2 \"In Figure 1 â£ 3.2 Prompt Design â£ 3 Experimental Design â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\").\nReport issue for preceding element\nTemperature. Temperature is a hyperparameter that allows controlling the randomness and creativity of the text generated by a GenAI. If the temperature is low, the model will probably produce the most âcorrectâ text, but with little variation. Conversely, a higher temperature value shows greater variation (i.e., creativity). Lower temperature values are preferable for the development of a deterministic framework. We automated queries to ChatGPT to measure this feature, using the same prompt for all 33 privacy policies in the experimental dataset and performing the requests on 3 different days and at 5 different times of the day (from 9 am to 9 pm). This amounts to 495 different requests and responses, and we observed 52 discrepancies (i.e., different responses compared to the typical answer), which means 89.5% consistency in ChatGPT responses. This âalthough far from absolute determinismâ highly increases the 59.6% percentage of determinism achieved with the default temperature value of 1.0.\nReport issue for preceding element\nThe GPT-4 Turbo model introduced a new feature called seed, specifically for obtaining consistent responses over time with the same prompt. Even though determinism is its declared purpose, we observed that using a seed value and default temperature provided only 84.65% of similar responses. Nonetheless, the combination of 0 temperature and seed shows 90.51%, being the most reliable combination of these two parameters.\nReport issue for preceding element\nIn our evaluation of the ChatGPTâs performance across different temperature settings, we found that higher temperature values inversely impact the consistency of the metrics, with deterministic responses being optimal. This tendency is notable as the quality of the outputs deteriorates with increasing temperature. Concurrently, a manual inspection of the responses revealed a propensity for incomplete data type coverage. Specifically, responses frequently reported only the initial data type queried. This issue not only aggravates the decline in the F1 score but also results in a significant proportion of the data typesânearly halfâremaining unaddressed in the responses. Such findings underscore the importance of temperature configuration in ensuring both the accuracy and completeness of the information extracted by ChatGPT.\nReport issue for preceding element\nTop p. Top p, or â _nucleus sampling_ â, consists of selecting the next token from the ânucleusâ or subset of the vocabulary that constitutes the cumulative probability mass of the top p most probable tokens. For example, setting tâ¢oâ¢pâ¢_â¢p=0.1ð¡ðð_ð0.1top\\\\_p=0.1italic_t italic_o italic_p _ italic_p = 0.1 means only tokens comprising the top 10% probability mass are considered [[40](https://arxiv.org/html/2405.20900v1#bib.bib40)]. We have observed little performance variability when testing different values of tâ¢oâ¢pâ¢_â¢p=ð¡ðð_ðabsenttop\\\\_p=italic_t italic_o italic_p _ italic_p = [0,1]01[0,1][ 0 , 1 ] while keeping the default temperature value (T=1ð1T=1italic_T = 1). Furthermore, in its official documentation, OpenAI recommends modifying the temperature value or the top p parameter, but not both simultaneously. Thus, we chose the default value of top p for our implementation and set the temperature to zero. These settings allow us to obtain more reproducible results.\nReport issue for preceding element\nSystem inputs. Using the OpenAI API, messages can be assigned to different roles (i.e., user, assistant, or system), where the system instruction can give high-level instructions for the conversation. We tested two system instructions: 1) â _You are a helpful assistant with extensive knowledge in data protection and privacy engineering_.â and 2) â _You are a helpful assistant with extensive knowledge in data protection and law_ â, which specifically indicate areas of knowledge that are important for our task analyzing privacy policies. Neither of the two system instructions improved the results obtained but rather worsened them.\nReport issue for preceding element\n###  3.4 Fine-tuning\nReport issue for preceding element\nOpenAI facilitates model customization through fine-tuning, which involves re-training a model on a specific dataset to enhance its performance. This approach is beneficial for augmenting response consistency and can enable the use of shorter prompts while still achieving the desired format. During our experimentation phase, fine-tuning was available only for the _gpt-3.5-turbo-0613_ model. Thus, we tested the effect of model fine-tuning using this ChatGPT version.\nReport issue for preceding element\nThe _gpt-3.5-turbo-0613_ model sets a maximum prompt size of 4,096 tokens. Thus, we segmented the policies into smaller subsets (chunks), each conforming to the condition that the combined length of the policy text (TðTitalic_T) and prompt (PðPitalic_P) did not exceed 4,096 tokens (T+P<4,096ðð4096T+P<4,096italic_T + italic_P < 4 , 096). This process led to the creation of a training set comprising 73 chunks, aligned with the manual annotations from the MAPP corpus and subjected to a default training configuration of three epochs as determined by OpenAI based on dataset size.\nReport issue for preceding element\nThis fine-tuned model demonstrated superior performance when compared to the baseline (not fine-tuned) model: accuracy increased from 0.677 to 0.867, precision increased from 0.519 to 0.803, and the F1 score increased from 0.670 to 0.803. Still, it could not beat the GPT-4 Turbo model (which does not require chunking the policies thanks to the 128K tokens limit), probably due to its ability to retain context (see Table [2](https://arxiv.org/html/2405.20900v1#S3.T2 \"Table 2 â£ 3.4 Fine-tuning â£ 3 Experimental Design â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\")).\nReport issue for preceding element\nTable 2: Comparison between the baseline and the fine-tuned GPT-3.5 model analyzing privacy policies by chunks and GPT-4 Turbo model analyzing privacy policies as a whole. | Chunked privacy policy processing |  Whole privacy policy processing  \n---|---|---  \nMetrics |  gpt-3.5-turbo- 0613 (fine-tuned) |  gpt-3.5 -turbo-0613 |  GPT-4 Turbo  \nAccuracy | 0.867 | 0.677 | 0.916  \nPrecision | 0.803 | 0.519 | 0.898  \nRecall | 0.803 | 0.944 | 0.963  \nF1 score | 0.803 | 0.670 | 0.935  \nReport issue for preceding element\n###  3.5 Validation\nReport issue for preceding element\nWe first applied our proposed configuration framework to the MAPP ground-truth control set, comprising 31 privacy policies, utilizing the prompt, parameters, and model based on our findings in prior sections. The prompt employed is the one described in Section [3.2](https://arxiv.org/html/2405.20900v1#S3.SS2 \"3.2 Prompt Design â£ 3 Experimental Design â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\"). The selection of parameter values was based on determinism consideration: tâ¢eâ¢mâ¢pâ¢eâ¢râ¢aâ¢tâ¢uâ¢râ¢e=0ð¡ððððððð¡ð¢ðð0temperature=0italic_t italic_e italic_m italic_p italic_e italic_r italic_a italic_t italic_u italic_r italic_e = 0, a fixed seed, and tâ¢oâ¢pâ¢_â¢p=1ð¡ðð_ð1top\\\\_p=1italic_t italic_o italic_p _ italic_p = 1 (the default setting). Finally, the GPT-4 Turbo model is employed for its performance, speed, and significantly higher input token limit balance. This configuration yields an accuracy of 0.916, a recall of 0.976, a precision of 0.898, and an F1 score of 0.935 on the control set of the MAPP corpus.\nReport issue for preceding element\nWe further validated our prompt design and model configuration against a larger ground truth, i.e., OPP-115 dataset [[18](https://arxiv.org/html/2405.20900v1#bib.bib18)], renowned for its fine-grained manual annotations of privacy practices. This validation yielded consistent results: 0.904 accuracy, 0.912 recall, 0.949 precision, and 0.930 F1 score, indicating that our proposal exhibits robust performance even when applied to a larger and more varied set of privacy policies.\nReport issue for preceding element\n##  4 Demonstration\nReport issue for preceding element\nThis section aims to demonstrate why LLMs, specifically ChatGPT, can be considered a competent technique for privacy policy analysis at scale. First, we compare ChatGPT to its closest GenAI rival, Llama 2, in terms of extracting the same privacy practices across identical test sets. We then compare ChatGPT with state-of-the-art statistical and symbolic NLP approaches to evaluate its performance and verify whether it can rival or even replace them. Finally, we analyze our proposalâs generalization capabilities for identifying other privacy practices, namely the declaration of international transfers in privacy policies.\nReport issue for preceding element\n###  4.1 Comparison with Llama 2\nReport issue for preceding element\nLlama 2 [[32](https://arxiv.org/html/2405.20900v1#bib.bib32)] is a family of open-source LLMs released by Meta that competes with ChatGPT in the GenAI space. Specifically, Meta has released versions with 7, 13, and 70 billion parameters, each with a fine-tuned âChatâ version optimized for dialogue. For a more direct comparison with the ChatGPT models, we focus on the chat variant of each of the Llama 2 models.\nReport issue for preceding element\nWe downloaded the 7B directly from Meta via their GitHub repository and ran it using four NVIDIA GeForce RTX 2080 Ti GPUs. Due to GPU constraints, we used the Python library from Together.AI to run the 70B model [[43](https://arxiv.org/html/2405.20900v1#bib.bib43)]. We initially tried to run the 13B model in our local environment, but as we achieved poor performance, we also used the Together.AI installation.\nReport issue for preceding element\nPrompt. We departed from the final prompt design shown in Figure [1(b)](https://arxiv.org/html/2405.20900v1#S3.F1.sf2 \"In Figure 1 â£ 3.2 Prompt Design â£ 3 Experimental Design â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\") and followed another split testing process to identify the best-performing Llama 2 prompt design. All the Llama 2-Chat models have a 4,096 token limit, which forced us to segment the privacy policies (i.e., the Data part) to ensure that our prompts are under the maximum token limit. Additionally, we removed the few-shot learning part from the prompt, as this yielded worse performance in our experiments with Llama 2. We observed that this technique resulted in outputs that did not conform to the requested format and additionally caused overfitting to the provided examples. Finally, we tried segmenting the Task in the prompt by asking for each data practice at a time, improving the results. Table [1](https://arxiv.org/html/2405.20900v1#S3.T1 \"Table 1 â£ 3.2 Prompt Design â£ 3 Experimental Design â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\") summarizes the different tests and the resulting performance.\nReport issue for preceding element\nParameters. Just as for the ChatGPT models, we parameter-tuned across the temperature and the top p values. Similar to observations with ChatGPT, our experiments suggest setting a temperature value of 0 and a default top p of 1.0 as the best-performing configuration.\nReport issue for preceding element\nWe carried out our experiments with the three Llama 2 versions. As the Llama 2 70B-Chat model consistently showed better results, we used this version to assess its performance against the MAPP control set (31 annotated policies) (Table [3](https://arxiv.org/html/2405.20900v1#S4.T3 \"Table 3 â£ 4.1 Comparison with Llama 2 â£ 4 Demonstration â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\")). Llama 2 demonstrates comparable but slightly lower performance in identifying privacy practices in this dataset compared to our ChatGPT-4 proposal.\nReport issue for preceding element\nWe further evaluated the performance of the Llama 2-70B configuration against the OPP-115 dataset. The results (Table [3](https://arxiv.org/html/2405.20900v1#S4.T3 \"Table 3 â£ 4.1 Comparison with Llama 2 â£ 4 Demonstration â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\")) show that Llama 2 obtains worse performance against this new dataset, suggesting that, unlike ChatGPT, this Llama 2 configuration does not generalize well to different datasets.\nReport issue for preceding element\nTable 3: Metrics comparison between the best-performing Llama 2 70B-Chat (Llama 2) and ChatGPT-4 Turbo configurations. |  | Accuracy | Precision | Recall | F1 score  \n---|---|---|---|---|---  \nMAPP | Llama 2 | 0.846 | 0.847 | 0.921 | 0.882  \nGPT-4 Turbo | 0.916 | 0.898 | 0.976 | 0.935  \nOPP-115 | Llama 2 | 0.749 | 0.700 | 0.814 | 0.753  \nGPT-4 Turbo | 0.904 | 0.949 | 0.912 | 0.930  \nReport issue for preceding element\n###  4.2 Comparison with state-of-the-art techniques\nReport issue for preceding element\nWe propose LLMs and, specifically, ChatGPT as a new technique for automating privacy policy information processing and extraction. To confirm it as such, we compare its performance in extracting fine-grained practices from policies with state-of-the-art statistical and symbolic approaches.\nReport issue for preceding element\n####  4.2.1 Statistical approaches\nReport issue for preceding element\nIn this study, we conducted a comparative analysis of our configuration framework proficiency in identifying fine-grained privacy practices against statistical classifiers based on Support Vector Classifiers (SVC) âa subtype of SVMâ, which were trained and validated using the APP-350 corpus [[29](https://arxiv.org/html/2405.20900v1#bib.bib29)]. To ensure a rigorous comparison, the same policy dataset was employed to evaluate the performance of both methods.\nReport issue for preceding element\nThe primary objective was to assess ChatGPTâs ability to accurately identify particular types of personal data collection as stated in privacy policies. For this purpose, we selected 10 distinct data types, with an emphasis on higher specificity (for instance, choosing âContact email addressâ over the broader âContact informationâ), spanning various categories such as contact data, identifiers, and social login data.\nReport issue for preceding element\nTable [4](https://arxiv.org/html/2405.20900v1#S4.T4 \"Table 4 â£ 4.2.1 Statistical approaches â£ 4.2 Comparison with state-of-the-art techniques â£ 4 Demonstration â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\") delineates the comparative performance of ChatGPT against the pre-trained SVC classifiers for identifying each specified data type. The results indicate a comparable level of performance across most data types. However, a notable exception was observed with the SIM identifier, where ChatGPTâs performance was significantly lower despite achieving 100% precision. A detailed manual review of the annotations for this data type in the original policies revealed a common annotation issue: Human annotators wrongly coded this data type. Specifically, the annotators coded âdevice serial numberâ under the âSIM serial numberâ category. However, the former is issued by the device manufacturer, while the latter is provided by the mobile carrier. This discrepancy likely contributed to the lower F1 score for ChatGPT in identifying the SIM identifier.\nReport issue for preceding element\nTable 4: ChatGPT vs. traditional machine learning classifiersâ performance for identifying first-party data collection per data type. | ChatGPT | SVC classifiers  \n---|---|---  \nData type | Precision | Recall | F1 score | Precision | Recall | F1 score  \nContact Email Address | 95% | 95% | 95% | 97% | 94% | 96%  \nContact Phone Number | 100% | 85% | 92% | 94% | 94% | 94%  \nIdentifier Cookie | 92% | 97% | 95% | 95% | 100% | 98%  \nIdentifier IMEI | 83% | 88% | 86% | 94% | 94% | 94%  \nIdentifier Device ID | 74% | 89% | 81% | 96% | 87% | 91%  \nIdentifier MAC | 94% | 84% | 89% | 88% | 79% | 83%  \nIdentifier Mobile Carrier | 79% | 90% | 84% | 100% | 57% | 73%  \nIdentifier SIM Serial | 100% | 13% | 22% | 73% | 100% | 84%  \nLocation WiFi | 70% | 58% | 64% | 48% | 92% | 63%  \nSocial login | 77% | 65% | 71% | 83% | 81% | 82%  \nReport issue for preceding element\nExcluding the analysis of the SIM serial identifier, which was identified as an anomaly, the comparative evaluation yielded an average F1 score of 84.1% for ChatGPT, as opposed to 86% achieved by the SVC-based classifiers for the selected data types. This outcome illustrates that while traditional SVC-based classifiers are recognized for their reliability and accuracy, ChatGPT presents a comparable level of performance. ChatGPT offers the added advantage of significantly simpler usability, making it a viable alternative for similar tasks in data practice identification.\nReport issue for preceding element\n####  4.2.2 Symbolic approaches\nReport issue for preceding element\nPolicyLint [[16](https://arxiv.org/html/2405.20900v1#bib.bib16)], a tool designed to analyze privacy policies, employs a symbolic approach based on ontologies to detect contradictions in statements regarding personal data collection and sharing. This tool identifies negative sentences, which are often challenging for conventional machine learning techniques. The public repository of PolicyLintâs code [[44](https://arxiv.org/html/2405.20900v1#bib.bib44)], as referenced, was utilized to process the privacy policies in our control set, facilitating a comparative analysis with our proposal.\nReport issue for preceding element\nPolicyLint operates by identifying sentence structures characterized by [actor] [action] [data_object] [entity]. Here, âactorâ signifies a first or third party involved in data handling, âactionâ denotes the nature of data interaction (positive or negative, such as collection or non-collection), âdata_objectâ pertains to the type of data in question, and âentityâ refers to the recipient of the data (for instance, advertisers).\nReport issue for preceding element\nGiven that the data_objects in PolicyLint do not align format-wise with those in our MAPP corpus, a manual matching process was undertaken by two authors to correlate PolicyLintâs classifications with the data types in our corpus. This matching was independently conducted, followed by an agreement phase for resolving discrepancies. The matching criteria were aligned with the definitions provided in the MAPP corpus. Subsequently, the comparative performance metrics of both methods were analyzed and presented in Figure [2](https://arxiv.org/html/2405.20900v1#S4.F2 \"Figure 2 â£ 4.2.2 Symbolic approaches â£ 4.2 Comparison with state-of-the-art techniques â£ 4 Demonstration â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\").\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/5634937/PolicyLint_comparison.png) Figure 2: Metrics comparison between the ChatGPT-based method and PolicyLint. Report issue for preceding element\nOur analysis revealed that PolicyLint exhibits high precision, surpassing the metrics its authors reported. This discrepancy might stem from our methodology, where we assess whether a data type is identified at least once in a policy, instead of PolicyLintâs validation across all relevant statements. However, PolicyLintâs approach overlooks negative cases, leading to a lower recall. Overall, our evaluation indicates that our ChatGPT configuration framework significantly outperforms PolicyLintâs F1 score, highlighting its efficacy in extracting and analyzing data practices from privacy policies.\nReport issue for preceding element\n###  4.3 Generalization Capabilities\nReport issue for preceding element\nThe proficiency of ChatGPT in extracting data collection and sharing practices from privacy policies has been notably demonstrated in our study. In this section, we extend the evaluation to assess ChatGPTâs generalization capabilities in identifying a broader range of practices within privacy policies. This extension is grounded in our prior research [[45](https://arxiv.org/html/2405.20900v1#bib.bib45)], which focused on analyzing privacy policies to find disclosures related to international data transfers. This previous study produced a dataset (IT100) comprising 100 privacy policies where privacy practices related to international data transfers were manually annotated by legal experts [[30](https://arxiv.org/html/2405.20900v1#bib.bib30)]. A Support Vector Machines (SVM)-based classifier was trained to identify these specific practices.\nReport issue for preceding element\nIn Figure [3](https://arxiv.org/html/2405.20900v1#S4.F3 \"Figure 3 â£ 4.3 Generalization Capabilities â£ 4 Demonstration â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\"), we present the comparative analysis of the performance metrics between our configuration proposal of ChatGPT and the SVM-based classifier, utilizing the IT100 dataset for evaluation. ChatGPT was configured as per the parameters delineated in Section [3](https://arxiv.org/html/2405.20900v1#S3 \"3 Experimental Design â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\"), which included an instantiation of our enhanced prompt in Section [3.2](https://arxiv.org/html/2405.20900v1#S3.SS2 \"3.2 Prompt Design â£ 3 Experimental Design â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\"), and settings like temperature=0, top_p=1, and an absence of system_input. The results displayed by ChatGPT were significantly superior in most metrics, reinforcing its efficacy in extracting information about diverse practices from privacy policies.\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/5634937/int_transfers_comparison.png) Figure 3: Metrics comparison between the ChatGPT and SVM machine learning classifier performance identifying international data transfer practices. Report issue for preceding element\n##  5 Discussion\nReport issue for preceding element\nChatGPT demonstrates a more balanced and adaptable performance in privacy policy analysis compared to traditional symbolic and statistical methods, overcoming the limitations of manual annotations and varying data across different corpora. Symbolic methods are characterized by their rigidity, which is reflected in their performance metrics. High precision in symbolic methods indicates their well-defined patterns and rules are closely aligned with specific instances in the data. However, this precision comes at the cost of completeness, as evidenced by their lower recall. In contrast, ChatGPT demonstrates a more balanced performance, achieving a notably higher F1 score than PolicyLint. This suggests that ChatGPT âand our proposed configurationâ, while less rigid in its approach, captures the breadth of privacy practices within policies more effectively.\nReport issue for preceding element\nWhen comparing ChatGPT with statistical methods such as SVM, we find that these traditional classifiers perform similarly in identifying certain data types. However, ChatGPT excels particularly in recognizing practices like international data transfers, which are complex and multifaceted. This superior performance is notable, given that statistical methods often depend on extensive manual annotations, which can introduce errors. As seen in the Identifier SIM Serial case in Table [4](https://arxiv.org/html/2405.20900v1#S4.T4 \"Table 4 â£ 4.2.1 Statistical approaches â£ 4.2 Comparison with state-of-the-art techniques â£ 4 Demonstration â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\"), such annotation errors can significantly impact classifier performance. Wagner et al. [[46](https://arxiv.org/html/2405.20900v1#bib.bib46)] supports this observation, indicating that the average agreement among human annotators for attribute values is considerably lower than for top-level categories. This discrepancy highlights the challenges in achieving consensus among annotators and the advantage of ChatGPTâs approach, which is not constrained by the limitations of manual annotations.\nReport issue for preceding element\nFurthermore, our analysis of different corpora, specifically the MAPP and OPP-115 datasets, sheds light on the variance in annotations across datasets. The performance disparities observed for _Social media data_ and _Personal identifier data_ between these two corpora suggest that the annotations for these data types likely vary, underscoring the issues associated with training classifiers on manually annotated data [[47](https://arxiv.org/html/2405.20900v1#bib.bib47)]. This reinforces the need for approaches like ChatGPT that rely less on such annotations, offering a more adaptable and potentially more accurate solution for privacy policy analysis.\nReport issue for preceding element\nEconomic considerations play a significant role in the choice of the technique to process privacy policies. Manual annotators in the United States are reported to earn approximately $8.5 per hour, while rates in lower-income countries range between $3 to $4 per hour [[48](https://arxiv.org/html/2405.20900v1#bib.bib48)]. However, the annotation of privacy policies demands legal expertise for accurately identifying data protection practices, entailing a higher pay rate, assumed here at a minimum of $10 per hour. For the MAPP corpus, three experts annotated each policy, averaging 1 hour and 52 minutes each [[28](https://arxiv.org/html/2405.20900v1#bib.bib28)]. Multiple annotations of the same content by different experts ensure reliable and high-quality data where inter-annotation agreement can be measured. Previous research [[45](https://arxiv.org/html/2405.20900v1#bib.bib45)] demonstrated that training classifiers with 100 policies can be sufficient, which raises costs by up to $5,601.\nReport issue for preceding element\nSetting aside the technical expertise required for classifier development, the cost-effectiveness of traditional classifiers becomes behooveful with GPT-4 Turbo at approximately 81,500 privacy policies and with GPT-3.5 Turbo at around 825,000 policies. This cost difference suggests that depending on specific application needs and constraints, GPT-3.5 Turbo, with an F1 score of 87.2% measured on the MAPP corpus control set, might be a pragmatic choice compared to GPT-4 Turbo, which achieved an F1 score of 93.5%111This difference is not only due to the model performance but also because the few-shot prompting technique that can be applied to the GPT-4 Turbo model thanks to its increased token limit. in our evaluation. Furthermore, Llama 2 models, specifically 7B and 70B, may be considered in terms of cost discussion. Both models were publicly released for free use, but our hardware limitations imposed by the latter forced us to use Together.AI API for that version. The current API cost for the Llama 2-70B model is 10% lower than the GPT-3.5 Turbo model while showing an even higher performance â88.2% F1 scoreâ making it even more convenient in terms of cost by performance. Llama 2-7B has significantly lower computational requirements, leading to no other cost but computation and achieving an 80.1% F1 score. Thus, GPT-4 Turbo offers the best performance of the LLMs compared, but at the highest cost. Whereas if the computing capabilities are sufficient to run it locally, Llama 2-70B offers good performance at a low cost.\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/5634937/chatgpt_api_costs.png) Figure 4: Cost Comparison of analyzing privacy policies with ChatGPT API. Report issue for preceding element\nIn assessing the processing capabilities of ChatGPT models, our analysis indicates a marked efficiency advantage over traditional machine learning and symbolic AI techniques. Acknowledging the operational constraints imposed by OpenAI on these models, specifically regarding token throughput per minute is critical. GPT-4 Turbo is limited to 300,000 tokens per minute, while GPT-3.5 Turbo can process up to 1,000,000 tokens within the same timeframe.\nReport issue for preceding element\nWith an average of 6,652 tokens required in average to fully process a privacy policy, GPT-4 Turbo can analyze up to 45 policies per minute, in contrast to the 150 policies per minute capability of GPT-3.5 Turbo. Figure [5](https://arxiv.org/html/2405.20900v1#S5.F5 \"Figure 5 â£ 5 Discussion â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\") depicts this variance in processing capacity, with GPT-4 Turbo necessitating slightly more time for large-scale privacy policy analyses when compared to GPT-3.5 Turbo. Furthermore, the SVM-based classifier takes approximately double the time of the slower GPT model to process an equivalent number of policies. In stark contrast, PolicyLint, while being at the forefront of privacy policy analysis symbolic-based tools, demands up to six times the processing time of GPT-3.5 Turbo for comparable tasks. The two versions of Llama 2 show remarkably different processing times. The Llama 2-7B, locally analyzing each policy at once (truncating policies when length limit required), shows a similar processing time compared to GPT-4 Turbo, while Llama 2-70B through Together.AI API (analyzing policies by chunks), shows the slowest performance of all techniques.\nReport issue for preceding element\nThese findings underscore the superior speed of LLM models and highlight the need to balance performance with processing time, especially when scaling to analyze vast numbers of privacy policies. Thus, organizations may find the trade-off between the slightly lower speed of GPT-4 Turbo and its enhanced accuracy acceptable, particularly in scenarios where quality of analysis is paramount. Conversely, for applications where time efficiency is a priority, GPT-3.5 Turbo presents a compelling option, offering rapid analysis with a modest compromise in performance metrics.\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/5634937/chatgpt_api_time.png) Figure 5: Time comparison between ChatGPT models and SVM to process privacy policies. Report issue for preceding element\nFor the GPT models, parallel processing can be employed to concurrently analyze up to 150 and 45 policies per minute for GPT-3.5 and GPT-4, respectively, adhering to the stipulated token rate limits. To scale up concurrent processing capabilities with ChatGPT, users may opt for multiple paid accounts, which entails additional costs due to the subscription requirements for accessing the API via ChatGPT Plus. Another avenue is to request OpenAI for elevated rate limits, a request that hinges on the companyâs approval. Anticipation of expanded rate limits by OpenAI in the future could potentially democratize access to more extensive parallel processing for all users, thereby broadening âeven moreâ the scope of large-scale privacy policy analysis.\nReport issue for preceding element\nThe rapid progression of generative AI technology is evident in the quick succession of ChatGPT models introduced. Within the span of mere months, we have witnessed the release of successive ChatGPT iterations, namely GPT-3.5 Turbo, GPT-4, and GPT-4 Turbo. Alongside the expected speed and cost efficiency enhancements, a notable shift has been observed in model determinism. For instance, the determinism observed in ChatGPT-3.5 (99.19%) significantly exceeds that of GPT-4 Turbo, suggesting a potential trade-off between response variability and model robustness.\nReport issue for preceding element\nThis rapid succession has introduced variations in the modelsâ performance, particularly regarding prompt responsiveness and temperature settings. Current outputs from most recent models align more closely with expectations even at increased temperature settings, evidencing an enhanced capacity of ChatGPT to interpret prompts with fewer instructions and diminishing the necessity for techniques such as prompt augmentation.\nReport issue for preceding element\nThe execution speeds of the Turbo models are noteworthy, achieving significant throughput without compromising performance for the task at hand. Moreover, the cost efficiencies introduced with these models âthreefold less for GPT-4 Turbo and tenfold less for GPT-3.5 Turboâ consolidate ChatGPTâs position as a vying competitor to state-of-the-art tools for large-scale studies.\nReport issue for preceding element\nWe have observed that the token limit per minute has substantially increasedâup to 30 times for GPT-4 and nearly 10 times for GPT-3.5 Turbo. This escalation, coupled with the modelsâ improved response times, results in more expedient processing of privacy policies, as evidenced in Figure [5](https://arxiv.org/html/2405.20900v1#S5.F5 \"Figure 5 â£ 5 Discussion â£ Large Language Models: A New Approach for Privacy Policy Analysis at Scale\"). Regarding F1 score performance, the new GPT-4 Turbo model remains consistent with its predecessors, albeit with notable variations: a 1.36% increase in the F1 score for the MAPP corpus and a similar decrease for the OPP-115. The intricacies of these models make it challenging to pinpoint the exact causes of these variations, but it is remarkable that the optimization inherent in the Turbo models has not detrimentally impacted performance for this specific task.\nReport issue for preceding element\n##  6 Conclusion\nReport issue for preceding element\nThroughout this article, we have substantiated the applicability of LLMs in analyzing and extracting privacy practices from privacy policies. Specifically, ChatGPT has proven to be as effective as traditional NLP techniques, offering significant advantages in terms of cost, runtime, and ease of development. This work has also presented a tailored configuration of prompts, parameters, and the ChatGPT model, which shows outstanding performance in identifying various privacy practices within privacy policies. We have demonstrated that fine-tuning, while valuable, may not be the most optimal approach against the backdrop of few-shot and zero-shot learning paradigms. Intriguingly, few-shot learning has exhibited superior performance metrics even over zero-shot learning.\nReport issue for preceding element\nOur study demonstrates a notable advance in automated privacy policy analysis through the generalization capabilities of our proposal. This approach potentially eliminates the reliance on annotated datasets, enabling the analysis to encompass a wider array of privacy practices previously limited by the necessity for in-depth legal knowledge. Future work will focus on integrating this method into automated systems for assessing data protection compliance, contributing towards raising awareness among developers, regulators, and users of the potential privacy risks in the data protection ecosystem.\nReport issue for preceding element\n##  7 Aknowledgments\nReport issue for preceding element\nThis work has been partially supported by the TED2021-130455A-I00 project funded by MCIN/AEI/10.13039/501100011033 and by the European Union âNextGenerationEUâ/PRTR. Jose M. del Alamo has received a grant from the Spanish âMinisterio de Universidadesâ through the âMovilidadâ sub-programme of the âPrograma Estatal para Desarrollar, Atraer y Retener Talentoâ, within the âPlan Estatal de InvestigaciÃ³n CientÃ­fica, TÃ©cnica y de InnovaciÃ³n 2021-2023â. This research has also been partially supported by the National Science Foundation under its Security and Trustworthy Computing Program (grant CNS-1914486).\nReport issue for preceding element\n## References\nReport issue for preceding element\n  * [1] Mukund Srinath, Lee Matheson, Pranav Narayanan Venkit, Gabriela Zanfir-Fortuna, Florian Schaub, C. Lee Giles, and Shomir Wilson.  Privacy now or never: Large-scale extraction and analysis of dates in privacy policy text.  In Proceedings of the ACM Symposium on Document Engineering 2023. ACM, 2023. \n  * [2] J.M. Del Alamo, D.S. Guaman, B. GarcÃ­a, et al.  A systematic mapping study on automated analysis of privacy policies.  Computing, 104:2053â2076, 2022. \n  * [3] Sebastian Zimmeck, Ziqi Wang, Li Zou, Ravi Iyengar, Bin Liu, Florian Schaub, Shomir Wilson, Norman Sadeh, Steven M. Bellovin, and Joel Reidenberg.  Automated analysis of privacy requirements for mobile apps.  In 24th Annual Network and Distributed System Security Symposium, NDSS 2017, 2017. \n  * [4] Shomir Wilson, Florian Schaub, Frederick Liu, Kanthashree Mysore Sathyendra, Daniel Smullen, Sebastian Zimmeck, Rohan Ramanath, Peter Story, Fei Liu, Norman Sadeh, et al.  Analyzing privacy policies at scale: From crowdsourcing to automated annotations.  ACM Transactions on the Web (TWEB), 13(1):1â29, 2018. \n  * [5] Duc Bui, Kang G Shin, Jong-Min Choi, and Junbum Shin.  Automated extraction and presentation of data practices in privacy policies.  Proc. Priv. Enhancing Technol., 2021(2):88â110, 2021. \n  * [6] Hamza Harkous, Kassem Fawaz, RÃ©mi Lebret, Florian Schaub, Kang G Shin, and Karl Aberer.  Polisis: Automated analysis and presentation of privacy policies using deep learning.  In 27th USENIX Security Symposium (USENIX Security 18), pages 531â548, 2018. \n  * [7] Jan-Christoph Klie, Bonnie Webber, and Iryna Gurevych.  Annotation error detection: Analyzing the past and present for a more coherent future.  Computational Linguistics, 49(1):157â198, 2023. \n  * [8] Jonathan H. Choi, Kristin E. Hickman, Amy Monahan, and Daniel Schwarcz.  Chatgpt goes to law school.  Journal of Legal Education, 71:387, 2022. \n  * [9] Jinzhe Tan, Hannes Westermann, and Karim Benyekhlef.  Chatgpt as an artificial lawyer?  Artificial Intelligence for Access to Justice (AI4AJ 2023), 2023. \n  * [10] Chenhao Tang, Zhengliang Liu, Chong Ma, Zihao Wu, Yiwei Li, Wei Liu, Dajiang Zhu, Quanzheng Li, Xiang Li, Tianming Liu, and Lei Fan.  Policygpt: Automated analysis of privacy policies with large language models, 2023.  Preprint at <https://arxiv.org/abs/2309.10238>. \n  * [11] Joel R. Reidenberg, Travis Breaux, Lorrie Faith Cranor, Brian French, Amanda Grannis, James T. Graves, Fei Liu, Aleecia McDonald, Thomas B. Norton, Rohan Ramanath, N. Cameron Russell, Norman Sadeh, and Florian Schaub.  Disagreeable privacy policies: Mismatches between meaning and usersâ understanding.  Berkeley Technology Law Journal, 30:39â88, 2015. \n  * [12] Mathieu dâAquin, Sabrina Kirrane, Serena Villata, Alessandro Oltramari, Dhivya Piraviperumal, Florian Schaub, Shomir Wilson, Sushain Cherivirala, Thomas B. Norton, N. Cameron Russell, Peter Story, Joel Reidenberg, and Norman Sadeh.  Privonto: A semantic framework for the analysis of privacy policies.  Semantic Web, 9(2):185â203, 2018. \n  * [13] Morgan C. Evans, Jaspreet Bhatia, Sudarshan Wadkar, and Travis D. Breaux.  An evaluation of constituency-based hyponymy extraction from privacy policies.  In 2017 IEEE 25th International Requirements Engineering Conference, pages 312â321, 2017. \n  * [14] Mitra Bokaei Hosseini, Sudarshan Wadkar, Travis D. Breaux, and Jianwei Niu.  Lexical similarity of information type hypernyms, meronyms and synonyms in privacy policies.  In 2016 AAAI Fall Symposium Series, 2016. \n  * [15] Danqi Chen and Christopher D Manning.  A fast and accurate dependency parser using neural networks.  In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 740â750, 2014. \n  * [16] Benjamin Andow, Samin Yaseer Mahmud, Wenyu Wang, Justin Whitaker, William Enck, Bradley Reaves, Kapil Singh, and Tao Xie.  Policylint: Investigating internal privacy policy contradictions on google play.  In 28th USENIX Security Symposium (USENIX Security 19), pages 585â602. USENIX Association, aug 2019. \n  * [17] Niharika Guntamukkala, Rozita Dara, and Gary Grewal.  A machine-learning based approach for measuring the completeness of online privacy policies.  In 2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA), pages 289â294. IEEE, 2015. \n  * [18] Shomir Wilson, Florian Schaub, Aswarth Abhilash Dara, et al.  The creation and analysis of a website privacy policy corpus.  In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1330â1340, Berlin, Germany, aug 2016. Association for Computational Linguistics. \n  * [19] Alberto Rodrigues da Silva, JoÃ£o Caramujo, Shaghayegh Monfared, Pavel Calado, and Travis Breaux.  Improving the specification and analysis of privacy policies.  ICEIS 2016, page 336, 2016. \n  * [20] Peter Story, Sebastian Zimmeck, Abhilasha Ravichander, et al.  Natural language processing for mobile app privacy compliance.  In AAAI Spring Symposium on Privacy-Enhancing Artificial Intelligence and Language Technologies, volume 2, page 4, 2019. \n  * [21] Kanthashree Mysore Sathyendra, Florian Schaub, Shomir Wilson, and Norman Sadeh.  Automatic extraction of opt-out choices from privacy policies.  In 2016 AAAI Fall Symposium Series, 2016. \n  * [22] Kanthashree Mysore Sathyendra, Shomir Wilson, Florian Schaub, Sebastian Zimmeck, and Norman Sadeh.  Identifying the provision of choices in privacy policy text.  In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2774â2779, 2017. \n  * [23] Fei Liu, Rohan Ramanath, Norman Sadeh, and Noah A Smith.  A step towards usable privacy policy: Automatic alignment of privacy statements.  In Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers, pages 884â894, 2014. \n  * [24] Aaron K Massey, Jacob Eisenstein, Annie I AntÃ³n, and Peter P Swire.  Automated text mining for requirements analysis of policy documents.  In 2013 21st IEEE International Requirements Engineering Conference (RE), pages 4â13. IEEE, 2013. \n  * [25] Moniba Keymanesh, Micha Elsner, and Srinivasan Sarthasarathy.  Toward domain-guided controllable summarization of privacy policies.  In NLLP@ KDD, pages 18â24, 2020. \n  * [26] Fei Liu, Nicole Lee Fella, and Kexin Liao.  Modeling language vagueness in privacy policies using deep neural networks.  In 2016 AAAI Fall Symposium Series, 2016. \n  * [27] Abhilasha Ravichander, Alan W Black, Shomir Wilson, Thomas Norton, and Norman Sadeh.  Question answering for privacy policies: Combining computational and legal perspectives.  In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 4949â4959, Hong Kong, China, November 2019. Association for Computational Linguistics. \n  * [28] Siddhant Arora et al.  A tale of two regulatory regimes: Creation and analysis of a bilingual privacy policy corpus.  In Proceedings of the Thirteenth Language Resources and Evaluation Conference, pages 5460â5472, 2022. \n  * [29] Sebastian Zimmeck, Peter Story, Daniel Smullen, Abhilasha Ravichander, Ziqi Wang, Joel R Reidenberg, N Cameron Russell, and Norman Sadeh.  Maps: Scaling privacy compliance analysis to a million apps.  Proc. Priv. Enhancing Tech., 2019:66, 2019. \n  * [30] PrivApp.  It100-corpus, 2024.  Accessed: January 10, 2024. \n  * [31] Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al.  Improving language understanding by generative pre-training.  2018. \n  * [32] Hugo Touvron et al.  Llama 2: Open foundation and fine-tuned chat models, 2023.  Preprint at <https://arxiv.org/abs/2307.09288>. \n  * [33] Hamideh Ghanadian, Isar Nejadgholi, and Hussein Al Osman.  ChatGPT for suicide risk assessment on social media: Quantitative evaluation of model performance, potentials and limitations.  In Jeremy Barnes, OrphÃ©e De Clercq, and Roman Klinger, editors, Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, & Social Media Analysis, pages 172â183, Toronto, Canada, July 2023. Association for Computational Linguistics. \n  * [34] Kashun Shum, Shizhe Diao, and Tong Zhang.  Automatic prompt augmentation and selection with chain-of-thought from labeled data.  In Houda Bouamor, Juan Pino, and Kalika Bali, editors, Findings of the Association for Computational Linguistics: EMNLP 2023, pages 12113â12139, Singapore, December 2023. Association for Computational Linguistics. \n  * [35] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Åukasz Kaiser, and Illia Polosukhin.  Attention is all you need.  Advances in neural information processing systems, 30, 2017. \n  * [36] Chengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao Chen, Michihiro Yasunaga, and Diyi Yang.  Is chatgpt a general-purpose natural language processing task solver?, 2023.  Preprint at <https://arxiv.org/abs/2302.06476>. \n  * [37] Jaromir Savelka and Kevin D Ashley.  The unreasonable effectiveness of large language models in zero-shot semantic annotation of legal texts.  Frontiers in Artificial Intelligence, 6, 2023. \n  * [38] Jan vom Brocke, Alan Hevner, and Alexander Maedche.  Introduction to Design Science Research, pages 1â13.  Springer International Publishing, 2020. \n  * [39] Ron Kohavi and Roger Longbotham.  Online controlled experiments and a/b tests.  Encyclopedia of machine learning and data mining, pages 1â11, 2015. \n  * [40] OpenAI.  Chat api reference, 2024.  Accessed: January 10, 2024. \n  * [41] Teodor Fredriksson, David Issa Mattos, Jan Bosch, and Helena HolmstrÃ¶m Olsson.  Data labeling: An empirical investigation into industrial challenges and mitigation strategies.  In Maurizio Morisio, Marco Torchiano, and Andreas Jedlitschka, editors, Product-Focused Software Process Improvement, pages 202â216, Cham, 2020. Springer International Publishing. \n  * [42] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al.  Language models are few-shot learners.  Advances in neural information processing systems, 33:1877â1901, 2020. \n  * [43] Together AI.  Inference python documentation, 2024.  Accessed: January 10, 2024. \n  * [44] Ben Andow.  Privacypolicyanalysis, 2024.  Accessed: January 10, 2024. \n  * [45] Danny S. GuamÃ¡n, David Rodriguez, Jose M. del Alamo, and Jose Such.  Automated gdpr compliance assessment for cross-border personal data transfers in android applications.  Computers & Security, 130:103262, 2023. \n  * [46] Isabel Wagner.  Privacy policies across the ages: Content of privacy policies 1996â2021.  26(3), may 2023. \n  * [47] Yan Yan, RÃ³mer Rosales, Glenn Fung, et al.  Learning from multiple annotators with varying expertise.  Machine Learning, 95:291â327, 2014. \n  * [48] Allen Institute for AI.  Crowdsourcing, pricing, ethics, and best practices.  <https://blog.allenai.org/crowdsourcing-pricing-ethics-and-best-practices-8487fd5c9872>, 2024.  Accessed: January 10, 2024. \n\n\nGenerated on Fri May 31 15:07:38 2024 by [LaTeXML![Mascot Sammy](https://arxiv.org/html/2405.20900v1)](http://dlmf.nist.gov/LaTeXML/)\nReport Issue\n##### Report Github Issue\nTitle:Content selection saved. Describe the issue below:Description:\nSubmit without GithubSubmit in Github\nReport Issue for Selection\n"
  },
  {
    "link": "https://arxiv.org/html/2402.12617v1",
    "raw_content": "[ ![logo](https://services.dev.arxiv.org/html/static/arxiv-logomark-small-white.svg) Back to arXiv ](https://arxiv.org/)\n[ ](https://arxiv.org/abs/2402.12617v1) [ ](javascript:toggleColorScheme\\(\\) \"Toggle dark/light mode\")\n[ ![logo](https://services.dev.arxiv.org/html/static/arxiv-logo-one-color-white.svg) Back to arXiv ](https://arxiv.org/)\nThis is **experimental HTML** to improve accessibility. We invite you to report rendering errors. Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off. Learn more [about this project](https://info.arxiv.org/about/accessible_HTML.html) and [help improve conversions](https://info.arxiv.org/help/submit_latex_best_practices.html). \n[Why HTML?](https://info.arxiv.org/about/accessible_HTML.html) [Report Issue](https://arxiv.org/html/2402.12617v1#myForm) [Back to Abstract](https://arxiv.org/abs/2402.12617v1) [Download PDF](https://arxiv.org/pdf/2402.12617v1) [ ](javascript:toggleColorScheme\\(\\) \"Toggle dark/light mode\")\n## Table of Contents\n  1. [1 A Distinct Problem from Traditional Security](https://arxiv.org/html/2402.12617v1#S1 \"1 A Distinct Problem from Traditional Security â£ Generative AI Security: Challenges and Countermeasures\")\n    1. [1.1 Target: GenAI models are susceptible to attack](https://arxiv.org/html/2402.12617v1#S1.SS1 \"1.1 Target: GenAI models are susceptible to attack â£ 1 A Distinct Problem from Traditional Security â£ Generative AI Security: Challenges and Countermeasures\")\n    2. [1.2 Fool: Misplaced reliance on GenAI might lead to vulnerabilities](https://arxiv.org/html/2402.12617v1#S1.SS2 \"1.2 Fool: Misplaced reliance on GenAI might lead to vulnerabilities â£ 1 A Distinct Problem from Traditional Security â£ Generative AI Security: Challenges and Countermeasures\")\n      1. [Data Leakage Risks.](https://arxiv.org/html/2402.12617v1#S1.SS2.SSS0.Px1 \"Data Leakage Risks. â£ 1.2 Fool: Misplaced reliance on GenAI might lead to vulnerabilities â£ 1 A Distinct Problem from Traditional Security â£ Generative AI Security: Challenges and Countermeasures\")\n      2. [Generation of Insecure Code.](https://arxiv.org/html/2402.12617v1#S1.SS2.SSS0.Px2 \"Generation of Insecure Code. â£ 1.2 Fool: Misplaced reliance on GenAI might lead to vulnerabilities â£ 1 A Distinct Problem from Traditional Security â£ Generative AI Security: Challenges and Countermeasures\")\n    3. [1.3 Tool: GenAI models could be used by threat actors](https://arxiv.org/html/2402.12617v1#S1.SS3 \"1.3 Tool: GenAI models could be used by threat actors â£ 1 A Distinct Problem from Traditional Security â£ Generative AI Security: Challenges and Countermeasures\")\n  2. [2 Existing Approaches Fall Short](https://arxiv.org/html/2402.12617v1#S2 \"2 Existing Approaches Fall Short â£ Generative AI Security: Challenges and Countermeasures\")\n    1. [2.1 GenAI vs. ML](https://arxiv.org/html/2402.12617v1#S2.SS1 \"2.1 GenAI vs. ML â£ 2 Existing Approaches Fall Short â£ Generative AI Security: Challenges and Countermeasures\")\n      1. [Emergent threat vectors.](https://arxiv.org/html/2402.12617v1#S2.SS1.SSS0.Px1 \"Emergent threat vectors. â£ 2.1 GenAI vs. ML â£ 2 Existing Approaches Fall Short â£ Generative AI Security: Challenges and Countermeasures\")\n      2. [Expanded attack surfaces.](https://arxiv.org/html/2402.12617v1#S2.SS1.SSS0.Px2 \"Expanded attack surfaces. â£ 2.1 GenAI vs. ML â£ 2 Existing Approaches Fall Short â£ Generative AI Security: Challenges and Countermeasures\")\n      3. [Deep integrations.](https://arxiv.org/html/2402.12617v1#S2.SS1.SSS0.Px3 \"Deep integrations. â£ 2.1 GenAI vs. ML â£ 2 Existing Approaches Fall Short â£ Generative AI Security: Challenges and Countermeasures\")\n      4. [Economic value.](https://arxiv.org/html/2402.12617v1#S2.SS1.SSS0.Px4 \"Economic value. â£ 2.1 GenAI vs. ML â£ 2 Existing Approaches Fall Short â£ Generative AI Security: Challenges and Countermeasures\")\n    2. [2.2 GenAI vs. security](https://arxiv.org/html/2402.12617v1#S2.SS2 \"2.2 GenAI vs. security â£ 2 Existing Approaches Fall Short â£ Generative AI Security: Challenges and Countermeasures\")\n      1. [Access control.](https://arxiv.org/html/2402.12617v1#S2.SS2.SSS0.Px1 \"Access control. â£ 2.2 GenAI vs. security â£ 2 Existing Approaches Fall Short â£ Generative AI Security: Challenges and Countermeasures\")\n      2. [Rule-based blocking.](https://arxiv.org/html/2402.12617v1#S2.SS2.SSS0.Px2 \"Rule-based blocking. â£ 2.2 GenAI vs. security â£ 2 Existing Approaches Fall Short â£ Generative AI Security: Challenges and Countermeasures\")\n      3. [Sandboxing.](https://arxiv.org/html/2402.12617v1#S2.SS2.SSS0.Px3 \"Sandboxing. â£ 2.2 GenAI vs. security â£ 2 Existing Approaches Fall Short â£ Generative AI Security: Challenges and Countermeasures\")\n      4. [Antivirus and blacklisting.](https://arxiv.org/html/2402.12617v1#S2.SS2.SSS0.Px4 \"Antivirus and blacklisting. â£ 2.2 GenAI vs. security â£ 2 Existing Approaches Fall Short â£ Generative AI Security: Challenges and Countermeasures\")\n      5. [Parameterized queries.](https://arxiv.org/html/2402.12617v1#S2.SS2.SSS0.Px5 \"Parameterized queries. â£ 2.2 GenAI vs. security â£ 2 Existing Approaches Fall Short â£ Generative AI Security: Challenges and Countermeasures\")\n      6. [Software patching.](https://arxiv.org/html/2402.12617v1#S2.SS2.SSS0.Px6 \"Software patching. â£ 2.2 GenAI vs. security â£ 2 Existing Approaches Fall Short â£ Generative AI Security: Challenges and Countermeasures\")\n      7. [Encryption.](https://arxiv.org/html/2402.12617v1#S2.SS2.SSS0.Px7 \"Encryption. â£ 2.2 GenAI vs. security â£ 2 Existing Approaches Fall Short â£ Generative AI Security: Challenges and Countermeasures\")\n      8. [Rely on vendors.](https://arxiv.org/html/2402.12617v1#S2.SS2.SSS0.Px8 \"Rely on vendors. â£ 2.2 GenAI vs. security â£ 2 Existing Approaches Fall Short â£ Generative AI Security: Challenges and Countermeasures\")\n  3. [3 Potential Research Directions](https://arxiv.org/html/2402.12617v1#S3 \"3 Potential Research Directions â£ Generative AI Security: Challenges and Countermeasures\")\n    1. [3.1 AI Firewall](https://arxiv.org/html/2402.12617v1#S3.SS1 \"3.1 AI Firewall â£ 3 Potential Research Directions â£ Generative AI Security: Challenges and Countermeasures\")\n    2. [3.2 Integrated Firewall](https://arxiv.org/html/2402.12617v1#S3.SS2 \"3.2 Integrated Firewall â£ 3 Potential Research Directions â£ Generative AI Security: Challenges and Countermeasures\")\n    3. [3.3 Guardrails](https://arxiv.org/html/2402.12617v1#S3.SS3 \"3.3 Guardrails â£ 3 Potential Research Directions â£ Generative AI Security: Challenges and Countermeasures\")\n    4. [3.4 Watermarking and Content Detection](https://arxiv.org/html/2402.12617v1#S3.SS4 \"3.4 Watermarking and Content Detection â£ 3 Potential Research Directions â£ Generative AI Security: Challenges and Countermeasures\")\n    5. [3.5 Regulations Enforcement](https://arxiv.org/html/2402.12617v1#S3.SS5 \"3.5 Regulations Enforcement â£ 3 Potential Research Directions â£ Generative AI Security: Challenges and Countermeasures\")\n    6. [3.6 Evolving Threat Management](https://arxiv.org/html/2402.12617v1#S3.SS6 \"3.6 Evolving Threat Management â£ 3 Potential Research Directions â£ Generative AI Security: Challenges and Countermeasures\")\n\n\nReport issue for preceding element\nHTML conversions [sometimes display errors](https://info.dev.arxiv.org/about/accessibility_html_error_messages.html) due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.\nReport issue for preceding element\n  * failed: environ\n\n\nAuthors: achieve the best HTML results from your LaTeX submissions by following these [best practices](https://info.arxiv.org/help/submit_latex_best_practices.html).\nReport issue for preceding element\nLicense: arXiv.org perpetual non-exclusive license\narXiv:2402.12617v1 [cs.CR] 20 Feb 2024\n\\NewEnviron\nresizealign  \\BODY\\BODY\\displaystyle\\BODY (1)\nReport issue for preceding element\n# Generative AI Security: Challenges and Countermeasures\nReport issue for preceding element\nBanghua Zhu  University of California, Berkeley  Norman Mu  University of California, Berkeley  Jiantao Jiao  University of California, Berkeley  David Wagner  University of California, Berkeley \nReport issue for preceding element\n###### Abstract\nReport issue for preceding element\nGenerative AIâs expanding footprint across numerous industries has led to both excitement and increased scrutiny. This paper delves into the unique security challenges posed by Generative AI, and outlines potential research directions for managing these risks.\nReport issue for preceding element\n##  1 A Distinct Problem from Traditional Security\nReport issue for preceding element\nGenerative AI (GenAI) systems enable users to quickly generate high-quality content. Recent advances in Large Language Models (LLMs) (Radford et al., [2019](https://arxiv.org/html/2402.12617v1#bib.bib53), Chowdhery et al., [2022](https://arxiv.org/html/2402.12617v1#bib.bib14), Brown et al., [2020](https://arxiv.org/html/2402.12617v1#bib.bib10), Touvron et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib68), Bubeck et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib11), Schulman et al., [2022](https://arxiv.org/html/2402.12617v1#bib.bib60), OpenAI, [2023](https://arxiv.org/html/2402.12617v1#bib.bib47), Anthropic, [2023](https://arxiv.org/html/2402.12617v1#bib.bib3)), Vision Language Models (VLMs) (Radford et al., [2021](https://arxiv.org/html/2402.12617v1#bib.bib54), Liu et al., [2023a](https://arxiv.org/html/2402.12617v1#bib.bib33), Driess et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib17), Team, [2023](https://arxiv.org/html/2402.12617v1#bib.bib66)) and diffusion models (Ramesh et al., [2021](https://arxiv.org/html/2402.12617v1#bib.bib55), Song et al., [2020](https://arxiv.org/html/2402.12617v1#bib.bib63), Yang et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib78)) have revolutionized the capability of GenAI. GenAI models are designed to understand and generate content with a degree of autonomy that surpasses traditional machine learning systems, providing novel capabilities to generate text and code, interact with humans and Internet services, generate realistic images, and understand visual scenes. This capability enables a broader range of applications, and in this way introduces new security challenges unique to these novel GenAI-integrated applications. In this paper we discuss the challenges and opportunities for the field, starting in this section with the security risks, including how GenAI models might become a target of attack, a âfoolâ that unintentionally harms security, or a tool for bad actors to attack others.\nReport issue for preceding element\n###  1.1 Target: GenAI models are susceptible to attack\nReport issue for preceding element\nWhile GenAI models have groundbreaking capabilities, they are also susceptible to adversarial attack and manipulation. _Jailbreaking_ and _prompt injection_ are two prominent threats to GenAI models and applications built using them.\nReport issue for preceding element\n_Jailbreaking_ is an emergent technique where adversaries use specially crafted prompts to manipulate AI models into generating harmful or misleading outputs (Chao et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib13), Wei et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib73), Liu et al., [2023d](https://arxiv.org/html/2402.12617v1#bib.bib36)). This exploitation can lead to the AI system bypassing its own safety protocols or ethical guidelines. It is similar to how root access is obtained in smartphones, but in the context of AI, it involves circumventing the modelâs restrictions to generate prohibited or unintended content.\nReport issue for preceding element\n_Prompt injection attacks_ insert malicious data or instructions into the modelâs input stream, tricking the model into following the attackerâs instructions rather than the application developerâs instructions (Branch et al., [2022](https://arxiv.org/html/2402.12617v1#bib.bib9), Toyer et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib69), Liu et al., [2023c](https://arxiv.org/html/2402.12617v1#bib.bib35), Greshake et al., [2023a](https://arxiv.org/html/2402.12617v1#bib.bib23)). This is analogous to SQL injection attacks in database systems, where an attacker can craft malicious data that, when incorporated by the application into a SQL query, is interpreted by the database as a new query. In the context of GenAI, prompt injection can leverage the modelâs generative capabilities to produce outputs that deviate significantly from the intended functionality of the application. This becomes particularly concerning when GenAI-integrated applications interact with external tools, plugins, or software APIs, thereby amplifying the attack surface.\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/5418896/aiinjection-blog.png) Figure 1: An example of a prompt injection attack on Bing Chat222See the link [here](https://embracethered.com/blog/posts/2023/ai-injections-direct-and-indirect-prompt-injection-basics/) for the full content.. An injection prompt is hidden in the website content, leading to undesired behavior of the chat model. In this example, the attack causes the model to start outputting emojis, but it could also have more serious consequences, such as outputting disinformation or abusive content. Report issue for preceding element\nBoth jailbreaking and prompt injection attacks pose significant risks. Brand or reputational damage could occur if the AI model is tricked into generating offensive or embarrassing content. More alarmingly, when integrated into broader applications including search, tool-use, or even powering real-world robots, these vulnerabilities can lead to substantial security breaches. An illustrative example is shown in Figure [2](https://arxiv.org/html/2402.12617v1#footnote2 \"footnote 2 â£ Figure 1 â£ 1.1 Target: GenAI models are susceptible to attack â£ 1 A Distinct Problem from Traditional Security â£ Generative AI Security: Challenges and Countermeasures\"), where Bing Chat, powered by GenAI models, becomes vulnerable to prompt injection attacks, leading to potential security compromises.\nReport issue for preceding element\nBesides continual fine-tuning on known jailbreaking prompts, no good solutions to these risks are known yet. New research is needed to find strong defenses against these threats. We encourage those interested in jailbreaking to focus on evaluating use cases where jailbreaks result in tangible harm (to parties other than the person using the jailbreak), such as facilitating social engineering attacks, spreading disinformation, or creating malware. We advocate pragmatic threat models that acknowledge the impossibility of perfect security; sometimes, it suffices to increase the difficulty for attackers, adopting an âarms raceâ mentality rather than striving for an unattainable Fort Knox-like impregnability. Furthermore, we call for exploring a wider array of solutions for safety, including filtering training sets and detecting usage of jailbreaks to cause specific harms. Emphasis should also be placed on developing defenses, even if they are not perfect, prioritizing them over the creation of more sophisticated attacks.\nReport issue for preceding element\nUntil more effective defenses are discovered, we recommend continuous monitoring for anomalous behavior and not allowing GenAI models to take or cause high-sensitivity actions (e.g., spending money, disclosing sensitive information). Software companies might consider educating developers about these vulnerabilities to foster a security-aware culture in this burgeoning field.\nReport issue for preceding element\n###  1.2 Fool: Misplaced reliance on GenAI might lead to vulnerabilities\nReport issue for preceding element\nIn the previous section, we discuss how GenAI can be susceptible to attack from strong adversaries. However, vulnerabilities within GenAI systems may not solely stem from deliberate adversarial actions. In practical scenarios, it is equally plausible that non-adversarial or weakly adversarial behavior could inadvertently lead to vulnerabilities, especially when GenAI is misapplied in contexts for which it was not designed or adequately secured. The integration of AI in various domains, especially in generating or processing sensitive data, might inadvertently lead to new vulnerabilities, if GenAI models generate insecure code or leak sensitive data.\nReport issue for preceding element\n#### Data Leakage Risks.\nReport issue for preceding element\nGenAI models are not good at keeping secrets. GenAI models that are trained on proprietary or sensitive data might inadvertently reveal this sensitive information, either directly or indirectly (Gupta et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib25), Wu et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib76), ThankGod Chinonso, [2023](https://arxiv.org/html/2402.12617v1#bib.bib67), Sebastian, [2023](https://arxiv.org/html/2402.12617v1#bib.bib61)). This can include the leakage of personally identifiable information (PII), confidential business information, or access tokens. Additionally, one could input a dataset containing sensitive information into the prompt, with the expectation that the model will generate only aggregated statistics and summaries. However, existing LLMs may occasionally reveal private information, even in infrequent instances. Such occurrences are particularly concerning in domains where privacy is paramount, such as healthcare and finance. The complexity and unpredictability of these models make it difficult to proactively determine under what conditions a model trained on sensitive data might reveal that data. The exponentially large space of potential user prompts renders it nearly impossible to anticipate and prevent all forms of data leakage. For instance, subtle patterns in the training data might be unintentionally revealed when the model is prompted in specific, unanticipated ways.\nReport issue for preceding element\nMalicious attacks can also extract the training data of GenAI models. This type of security breach represents a significant threat as it can compromise the confidentiality of the data used to train these advanced systems (Nasr et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib46)).\nReport issue for preceding element\nTo mitigate data leakage risks, we suggest a crude heuristic: if a GenAI model is trained on private or secret data, then assume the model can be induced to reveal that data in its outputs. Thus, it is best to avoid training or fine-tuning on sensitive data, perhaps by masking out or redacting sensitive data before training. It is also an interesting research direction to develop monitoring systems to detect inadvertent data exposures.\nReport issue for preceding element\n#### Generation of Insecure Code.\nReport issue for preceding element\nWhile GenAI tools like Microsoft CoPilot and ChatGPT have become increasingly popular for code generation and revision, their reliability is still under scrutiny. Recent studies show that code generated by these AI models can contain security vulnerabilities (Fu et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib19)). These vulnerabilities range from simple syntactic errors to complex logical flaws that could be exploited. Developers, enticed by the ease of use of these tools, might inadvertently introduce these flaws into their codebases. However, there is also emerging research suggesting the potential for GenAI to aid in developing more secure code (Asare et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib4)). This research highlights the potential risks of utilizing GenAI in code development but also the opportunities to improve software security.\nReport issue for preceding element\nTo mitigate code generation risks, further research is needed on how to ensure generated code is secure, perhaps by improving the ability of models to recognize whether the code they generate has security problems, or by new prompting strategies to teach these models secure coding practices. Until then, educating developers on the potential pitfalls of GenAI-generated code and fostering a security-aware culture in software development seems prudent.\nReport issue for preceding element\n###  1.3 Tool: GenAI models could be used by threat actors\nReport issue for preceding element\nGenAI tools could also be abused by bad actors for malicious purposes. Bad actors might use GenAI to create malicious code or harmful content, posing a significant threat to digital security systems (Glukhov et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib22), Bommasani et al., [2021](https://arxiv.org/html/2402.12617v1#bib.bib8)). The capabilities of GenAI might be repurposed to enhance or automate traditional cyber-attacks. This includes, but is not limited to:\nReport issue for preceding element\n  * â¢\nCrafting sophisticated phishing emails, including automating the process of creating individually targeted spear phishing messages (Renaud et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib58), Alawida et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib2)).\nReport issue for preceding element\n  * â¢\nGenerating fake images or video clips for misinformation campaigns or for scams (Zhang et al., [2019](https://arxiv.org/html/2402.12617v1#bib.bib79)), where a video call that appears to be from a known contact might be persuasive.\nReport issue for preceding element\n  * â¢\nProducing malicious code capable of attacking online systems (Monje et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib40), Pa Pa et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib49)).\nReport issue for preceding element\n  * â¢\nGenerating prompts that exploit GenAI systems to âjailbreakâ or bypass their own security protocols (Ganguli et al., [2022](https://arxiv.org/html/2402.12617v1#bib.bib20), Chao et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib13)).\nReport issue for preceding element\n\n\nThe evolving nature of GenAI systems necessitates a proactive approach in cybersecurity and governance. It is imperative to develop robust frameworks to mitigate these risks, ensuring that the advancement in AI technology is aligned with ethical standards and security protocols to prevent misuse.\nReport issue for preceding element\nIn conclusion, while GenAI offers substantial benefits in automating and enhancing various tasks, its potential to introduce new vulnerabilities necessitates a cautious and well-informed approach to its deployment and usage in sensitive domains.\nReport issue for preceding element\n##  2 Existing Approaches Fall Short\nReport issue for preceding element\nMany of the challenges and research directions we propose studying are familiar to the fields of both machine learning and computer security. However, a number of key practical differences between GenAI systems and existing AI and computer systems require new approaches in order to make progress towards concrete security outcomes.\nReport issue for preceding element\n###  2.1 GenAI vs. ML\nReport issue for preceding element\nWe distinguish between modern GenAI systems such as LLMs, and previous AI systems such as machine translation and object detectors. Previous systems were typically built for a single task and domain, whereas GenAI systems offer broad, general capabilities across many domains (e.g., LLMs are fluent in conversation, prose, technical reports, code) and sometimes even multiple modalities like audio and video. A recent report from DeepMind draws a distinction between âgeneralâ and ânarrowâ AI, and considers LLMs the first forms of âgeneralâ AI Morris et al. ([2023](https://arxiv.org/html/2402.12617v1#bib.bib41)). GenAI systems also exhibit a variety of security-relevant differences, including:\nReport issue for preceding element\n  * â¢\nEmergent threat vectors: unexpected GenAI capabilities can create unforeseen threat vectors.\nReport issue for preceding element\n  * â¢\nExpanded attack surfaces: reliance on huge user-generated datasets for training and inference exposes a much larger attack surface.\nReport issue for preceding element\n  * â¢\nDeep integrations: unmediated connections with other computer systems paint a bigger target for attackers.\nReport issue for preceding element\n  * â¢\nEconomic value: valuable GenAI-powered applications pose a more lucrative target for attackers.\nReport issue for preceding element\n\n\n#### Emergent threat vectors.\nReport issue for preceding element\nMany useful and significant capabilities in GenAI systems develop during the course of training without any intentional human design (Wei et al., [2022a](https://arxiv.org/html/2402.12617v1#bib.bib74)). For instance, the abilities of LLMs to learn new tasks âin-contextâ from a handful of demonstrations (Brown et al., [2020](https://arxiv.org/html/2402.12617v1#bib.bib10)), or perform âchain-of-thoughtâ reasoning (Wei et al., [2022b](https://arxiv.org/html/2402.12617v1#bib.bib75)) were only discovered after training at a large enough scale. Threat actors may be able to leverage undocumented âzero-dayâ capabilities within GenAI systems to execute attacks. Unexpected capabilities in LLMs may also enable the use of known existing capabilities in attacks, analogous to how the PDF specification, in allowing users to embed code, enables its use as a malware delivery mechanism. The difficulty of enumerating all the capabilities of a GenAI system makes it much harder to anticipate potential threat vectors.\nReport issue for preceding element\n#### Expanded attack surfaces.\nReport issue for preceding element\nGenAI systems are trained on massive amounts of user-generated content, collected through various means such as large-scale webscraping, crowdsourcing, or licensing digital archives. In the context of LLM training, user-generated data comes in the form of pretraining documents, supervised task demonstrations, feedback data, all of which are susceptible to adversarial manipulation such as data poisoning attacks to insert hidden backdoor functionality into models (Carlini et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib12), Rando and TramÃ¨r, [2023](https://arxiv.org/html/2402.12617v1#bib.bib56)). At inference time, systems such as chat assistants, retrieval-augmented generation (RAG), and âweb agentsâ all rely on additional untrusted data such as user messages, reference documents, and website responses. This poses an opportunity for the use of adversarial inputs to hijack system objectives, such as through (indirect) prompt injection attacks (Perez and Ribeiro, [2022](https://arxiv.org/html/2402.12617v1#bib.bib50), Greshake et al., [2023b](https://arxiv.org/html/2402.12617v1#bib.bib24)). Maintaining up-to-date world knowledge also requires continually training on new data, which turns all of these risks into a persistent threat. Validating all of these input sources is a daunting undertaking, warranting the study and development of new techniques to handle the sheer scale of data at hand. \nReport issue for preceding element\n#### Deep integrations.\nReport issue for preceding element\nA now common design pattern for GenAI systems is to connect previously un-interoperable software systems, such as mobile apps333See link [here](https://www.theverge.com/2024/1/9/24030667/rabbit-r1-ai-action-model-price-release-date) for an example of mobile app, Rabbit R1., or to leverage external tools (Schick et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib59)). The latter use case is generalized by OpenAIâs custom GPTs444See link [here](https://www.wired.com/story/openai-custom-chatbots-gpts-prompt-injection-attacks/) for data leakage issues from GPTs. which enables ChatGPT to call arbitrary user-defined APIs and take real-world actions. Researchers have also started to explore the use of GenAI models in robotic systems, paving the way to household robots driven by natural language input (Driess et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib17)). GenAI systems are already being deeply integrated into many facets of consumer technology, such as email and digital banking, as well as enterprise technology, such as customer support555See the link [here](https://www.inc.com/ben-sherry/chevrolet-used-chatgpt-for-customer-service-and-learned-that-ai-isnt-always-on-your-side.html) for an example of customer support. and code review666See the link [here](https://blog.research.google/2023/05/resolving-code-review-comments-with-ml.html) for an example of code review.. In all these instances, the model is given unmediated access to its connected systems, making it a prime target for attackers seeking to access these systems.\nReport issue for preceding element\n#### Economic value.\nReport issue for preceding element\nApplication areas such as healthcare, customer service, and software engineering have drawn lots of investment attention, as successfully automating or extending human workers has the potential to generate tremendous amounts of economic value. The high price of inference also push the usage of GenAI toward more valuable tasks that can bear the additional cost. Many first deployments of initial and particularly insecure GenAI systems will therefore be concentrated in economically valuable domains, as compared with prior ML systems. This means that the costs of a successful attack are much higher, and that GenAI systems are likely to draw much more attention from malicious actors.\nReport issue for preceding element\nSecuring GenAI systems poses greater challenges and carries higher stakes than prior ML systems. Model providers, application developers, and end users will all need to consider security more seriously and systematically.\nReport issue for preceding element\n###  2.2 GenAI vs. security\nReport issue for preceding element\nIn traditional computer systems, a variety of different techniques have been developed to defend against common patterns of attacks and system vulnerabilities. Techniques such as access control, firewalls, sandboxing, and malware detection have found success and enjoy broad usage in practice. Generally, security techniques rely on the assumption that systems are modular and highly predictable: individual components can be easily replaced, and their effect on overall system behavior can be precisely characterized. In the setting of GenAI systems, attacks will appear much more like social engineering attacks against human organizations, rather than highly targeted technical exploits. So while some high-level principles may transfer over, many existing tools from computer security are not suitable for direct application to GenAI. Effective defenses will need to leverage machine learning as a core tool, while robustly handling the brittleness of the underlying GenAI and ML systems.\nReport issue for preceding element\n#### Access control.\nReport issue for preceding element\nAccess control restricts users and programs so they can only access resources (e.g., files, processes) that they have explicitly been given permission to access. We envision that LLM-integrated applications might control access to confidential or critical data by using access control to limit which data entries can be accessed by Retrieval Augmented Generation (RAG) systems, or to limit which tools/APIs the LLM can invoke, depending on the user who invoked the application. However, the open-ended nature of user requests to LLM assistants makes it difficult to decide in advance all the data and tools that will be required to complete a task, so we expect it will typically be difficult or impossible to limit what data the LLM can access or what actions it can take.\nReport issue for preceding element\n#### Rule-based blocking.\nReport issue for preceding element\nTraditionally, rule-based filtering methods have been used as a first line of defense against undesirable outputs. A natural idea is to do the same with GenAI, scanning the AIâs inputs and outputs, and prevent the display of any content that meets certain predefined criteria. However, the complexity of GenAI prompts and opportunities for obfuscation mean that relying exclusively on rules to filter harmful content is likely to result in numerous false positives and negatives. Malicious actors can also find ways around these rule-based systems, rendering them inadequate for ensuring AI safety. Consequently, relying solely on basic rule-based filtering methods to safeguard a sophisticated intelligence system like GPT-4 is impractical and insufficient. Figure 2 shows a few examples of non-trivial jailbreaking prompts that are challenging to detect with simple rules. Consequently, we expect filtering defenses will need to have some intelligence to be effective.\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/5418896/ex3.png) Report issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/5418896/ex1.png) Report issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/5418896/ex2.png) Report issue for preceding element\nFigure 2: Rule-based defenses can be easily defeated. Report issue for preceding element\n#### Sandboxing.\nReport issue for preceding element\nSandboxing is the practice of executing programs in isolation, which prevents malicious software from harming other system functions. Software with complex integrations such as Adobe Flash are difficult to sandbox without limiting functionality. Similarly, GenAI systems like ChatGPT are often connected to a variety of powerful plugins such as web browsing or other live APIs and not amenable to airtight isolation. \nReport issue for preceding element\n#### Antivirus and blacklisting.\nReport issue for preceding element\nAntivirus software constantly scans files and programs for malware, relying on known identifying characteristics, in order to promptly isolate or remove the suspected data. Unfortunately, we do not expect such approaches to be very effective at protecting GenAI, because there are simply too many ways for an attacker to phrase an attack and too many ways to obfuscate attacks. For example, many jailbreak attacks remain effective even if they are translated to a different language or typographically degraded. \nReport issue for preceding element\n#### Parameterized queries.\nReport issue for preceding element\nParameterized queries can effectively defend against SQL injection attacks by restricting user control of a command to just the data fields. Using parameterized queries requires developers to precisely delineate between code and data, which is not always feasible with inputs to LLMs where âcodeâ must be inferred from âdataâ in the case of few-shot prompting/in-context learning. Parameterized queries also limit program functionality to only the set of queries for which templates have been pre-defined, which would negate the flexibility of LLM applications.\nReport issue for preceding element\n#### Software patching.\nReport issue for preceding element\nFor many applications, security engineers may reasonably rely on users to regularly install software updates through which patches to newly discovered vulnerabilities may be applied. The monolithic nature of LLMs makes it hard to develop localized fixes once vulnerabilities are discovered, since different knowledge and capabilities may be entangled within the weights of the model, and editing a specific behavior without affecting any other behaviors can be difficult. Proprietary LLMs served via API do not have to worry about users running outdated versions, but with open models it may be just as difficult to get users to update models as it has been with traditional software.\nReport issue for preceding element\n#### Encryption.\nReport issue for preceding element\nEncryption is used to protect sensitive information and ensure data privacy. However, the challenge of data obfuscation for GenAI is the difficulty in pinpointing and defining which data is âsensitiveâ (Narayanan and Shmatikov, [2010](https://arxiv.org/html/2402.12617v1#bib.bib44)). Furthermore, the interdependencies in data sets mean that even if certain pieces of information are obfuscated, other, seemingly benign data points might provide enough context for an AI to infer the missing data (Narayanan et al., [2016](https://arxiv.org/html/2402.12617v1#bib.bib45), Narayanan, [2008](https://arxiv.org/html/2402.12617v1#bib.bib43)).\nReport issue for preceding element\n#### Rely on vendors.\nReport issue for preceding element\nWhile proprietary companies like OpenAI and Anthropic lead in pioneering AI safety, expecting it to be a panacea for every GenAI security issue is optimistic. Current models use reinforcement learning with human feedback (RLHF) to align model outputs with universal human values (Schulman et al., [2022](https://arxiv.org/html/2402.12617v1#bib.bib60), Ouyang et al., [2022](https://arxiv.org/html/2402.12617v1#bib.bib48)). However, universal values may not be sufficient: each application of GenAI is likely to have its own application-specific security requirements. It is not realistic to expect vendors to be able to anticipate and address application-specific issues; developers building GenAI-enabled applications will need to take responsibility for the security of their applications. \nReport issue for preceding element\n##  3 Potential Research Directions \nReport issue for preceding element\nNew approaches to security are needed, to address the new issues associated with GenAI. We discuss several potential research directions to combat the security challenges posed by GenAI, and call on the research community to develop novel solutions.\nReport issue for preceding element\n###  3.1 AI Firewall\nReport issue for preceding element\nWe suggest researchers study how to build an âAI firewallâ, which protects a black-box GenAI model by monitoring and possibly transforming its inputs and outputs. An AI firewall might monitor inputs to detect possible jailbreak attacks; it is an interesting research question how to use continuous learning to detect new jailbreak prompts. Additionally, the system could be stateful, analyzing a sequence of inputs from a particular user to determine if they might indicate malicious intent. An AI firewall might also monitor outputs to check if they violate security policies (e.g., contain toxic/offensive/inappropriate content), perhaps using a suitable content moderation model (Phute et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib51), Markov et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib39)).\nReport issue for preceding element\nThe work of Wei et al. ([2023](https://arxiv.org/html/2402.12617v1#bib.bib73)) advocates for employing a detection and moderation model that matches the sophistication and capabilities of the model it aims to protect. A less capable model for moderation can be susceptible to obfuscation techniques, especially if they rely on a enumeration-based blacklist policy for filtering which may fail to recognize complex or subtly crafted inputs designed to bypass its restrictions. On the other hand, thereâs a growing interest in the possibility of using smaller models for moderation purposes. This remains an open research question: Can moderation be effectively and safely conducted with smaller models? This question is also closely related to the problem of superalignment, where we hope to align a model that is much more intelligent using a model that is less capable.\nReport issue for preceding element\nAn intriguing example of a strong moderation model in practice is the relationship between DALL-E 3 and ChatGPT (Betker et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib7)). In this setup, the user sends instructions to ChatGPT, which crafts prompts for DALL-E 3 to generate images. ChatGPT acts as an AI firewall, providing a moderation model that enforces policy on the types of images DALL-E 3 can generate. Notably, ChatGPTâs superior language understanding capabilities compared to DALL-E 3 play a crucial role in preventing attacks that might exploit DALL-E 3âs vulnerability to unsafe prompts. Another example of AI moderation in action is the content filtering in Azure AI services777See the link [here](https://azure.microsoft.com/en-us/products/ai-services/ai-content-safety) for descriptions of content filtering in Azure., and possibly input filtering as well, which is widely applied in applications like Bing Chat. This approach demonstrates how AI systems are increasingly being equipped with mechanisms to monitor and control the content they generate or interact with, ensuring adherence to set guidelines and preventing misuse.\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/5418896/blackbox.png) Figure 3: An AI Firewall, built by apply a moderation model to LLM inputs and outputs. Report issue for preceding element\nFinally, an AI firewall might impose limits or access control on the modelâs ability to invoke tools or take actions. It is an open problem how to design a suitable access control system, perhaps based on second model that analyzes the query to determine what limits are appropriate and obtain consent from the user when needed (Felt et al., [2012](https://arxiv.org/html/2402.12617v1#bib.bib18), Iqbal et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib27)).\nReport issue for preceding element\n###  3.2 Integrated Firewall\nReport issue for preceding element\nGaining access to a GenAI modelâs weights opens up enhanced opportunities for defense, allowing for more effective detection of attacks. We discuss two potential research directions:\nReport issue for preceding element\nInternal State Monitoring: One approach involves the surveillance of the modelâs internal states. Certain neurons or neuron clusters within the language model might be correlated with the generation of hallucinatory or unethical outputs (Azaria and Mitchell, [2023](https://arxiv.org/html/2402.12617v1#bib.bib5), Rateike et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib57)). By monitoring these specific neurons, it might be possible to detect and mitigate undesirable model behaviors early in the response generation process.\nReport issue for preceding element\nSafety Fine-Tuning: Open-source GenAI models could be fine-tuned against known malicious prompts and behaviors with either supervised fine-tuning (SFT) or reinforcement learning from human feedback (RLHF) (Radford et al., [2019](https://arxiv.org/html/2402.12617v1#bib.bib53), Stiennon et al., [2020](https://arxiv.org/html/2402.12617v1#bib.bib64), Ziegler et al., [2019](https://arxiv.org/html/2402.12617v1#bib.bib84), Ouyang et al., [2022](https://arxiv.org/html/2402.12617v1#bib.bib48), Schulman et al., [2022](https://arxiv.org/html/2402.12617v1#bib.bib60), Ivison et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib28), Wang et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib72), Lv et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib38), Zhu et al., [2023c](https://arxiv.org/html/2402.12617v1#bib.bib83), [b](https://arxiv.org/html/2402.12617v1#bib.bib82), [a](https://arxiv.org/html/2402.12617v1#bib.bib81), Bai et al., [2022](https://arxiv.org/html/2402.12617v1#bib.bib6), Christiano et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib16)). This method is akin to equipping a person with self-defense skills, enhancing the modelâs inherent ability to recognize and counteract harmful inputs. Training the model on a dataset of known threats would enable it to learn and adapt its responses to minimize risks.\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/5418896/whitebox.png) Figure 4: An integrated firewall can use visibility into the model to detect more attacks. Report issue for preceding element\nCombining an AI firewall and integrated firewall might be stronger than either alone, since direct integration with the AI modelâs intelligence promises superior efficiency and efficacy in countering threats, aligning with the safety-capability criterion discussed in Wei et al. ([2023](https://arxiv.org/html/2402.12617v1#bib.bib73)). \nReport issue for preceding element\n###  3.3 Guardrails\nReport issue for preceding element\nWe also identify another important research challenge: is it possible to enforce âguardrailsâ, i.e., application-specific restrictions or policies, on the output of a LLM? We envision a scenario where we have black-box access to an off-the-shelf LLM (e.g., GPT4 or Claude), and an application-specific guardrail (e.g., âOnly talk about our companyâs products. Do not discuss other companyâs products, religion, or politics.â). The challenge then is to steer the output of the LLM at test time, to produce outputs that obey the guardrail.\nReport issue for preceding element\nOne simple yet effective method is rejection sampling, or best-of-K sampling (Liu et al., [2023b](https://arxiv.org/html/2402.12617v1#bib.bib34), Stiennon et al., [2020](https://arxiv.org/html/2402.12617v1#bib.bib64), Gao et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib21)): run the LLM 10 times on the same prompt, to generate 10 outputs, use a second model to score how well each follows the guardrail, and then keep the output with the highest score. Rejection sampling is effective, but it is computationally expensive, increasing the test-time costs by an order of magnitude. Can we achieve similar effectiveness at enforcing guardrails, at significantly lower cost? Some promising attempts along this direction include controlled decoding (Yang and Klein, [2021](https://arxiv.org/html/2402.12617v1#bib.bib77), Mudgal et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib42), Qin et al., [2022](https://arxiv.org/html/2402.12617v1#bib.bib52)), which adds bias in the logits of LLM during decoding process.\nReport issue for preceding element\n###  3.4 Watermarking and Content Detection\nReport issue for preceding element\nDifferentiating between human-generated and machine-generated content is critical in contexts such as plagiarism, data contamination, and misinformation propagation. Recent research has concentrated on two approaches: training a classifier to distinguish between human-generated and machine-generated content, or embedding hidden signals in LLMs with _watermarks_ (Venugopal et al., [2011](https://arxiv.org/html/2402.12617v1#bib.bib71), Aaronson, [2022](https://arxiv.org/html/2402.12617v1#bib.bib1), Kirchenbauer et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib30), Kuditipudi et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib31), Christ et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib15), Zhao et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib80), Huang et al., [2023](https://arxiv.org/html/2402.12617v1#bib.bib26)). These watermarks facilitate the identification of their machine origin.\nReport issue for preceding element\nWe envision that the classification-based methods may not be worth future research efforts, as new GenAI models are likely to be harder to recognize. Also, classification-based approaches are highly sensitive to the distribution of model outputs, which can vary significantly, presenting a moving target in content detection. Furthermore, the classification-based approach can have biases for non-English content or rarely-seen samples during the training. Therefore, watermarking might be a more promising direction than classification-based methods.\nReport issue for preceding element\nWe envision several potential future research directions.\nReport issue for preceding element\n  * â¢\nWatermarking Open Source Models: It is unclear how to watermark open-source models, since it is easy for an attacker to remove any watermark-specific code or modify the weights and decoding method. Without a practical way to watermark open-source models, it is very easy to use open-source models for rephrasing watermarked content generated by closed-source models.\nReport issue for preceding element\n  * â¢\nWatermarking Human-Generated Content:  Image authentication methods (Lu and Liao, [2000](https://arxiv.org/html/2402.12617v1#bib.bib37), Kutter et al., [1997](https://arxiv.org/html/2402.12617v1#bib.bib32), Sinha and Singh, [2003](https://arxiv.org/html/2402.12617v1#bib.bib62)), such as signing photos taken by digital cameras, hint at the possibility of developing special watermarks for human-authored content. This approach could offer an alternative or complementary method to distinguish between human- and machine-generated content, adding another layer to content authentication processes. Such a dual approach, focusing on both machine and human content verification, could significantly enhance the robustness of content verification systems.\nReport issue for preceding element\n  * â¢\nCross-Model Coordination: Ensuring that watermarking mechanisms are effective across different models and generations of AI technologies is crucial. This requires a unified watermarking method that is acceptable for all model providers.\nReport issue for preceding element\n\n\n###  3.5 Regulations Enforcement\nReport issue for preceding element\nPolicies and regulations can potentially play a role in mitigating risks associated with misuse of GenAI. Researchers can have influence by making realistic predictions on the development and effect of GenAI, and proposing a range of policy options for policymakers. We suggest several considerations for policymakers:\nReport issue for preceding element\n  * â¢\nRegulation of Proprietary and Open Source Models: Drawing insights from the âcrypto warsâ (Taskinsoy, [2019](https://arxiv.org/html/2402.12617v1#bib.bib65), Jarvis, [2020](https://arxiv.org/html/2402.12617v1#bib.bib29)), we know that overly stringent national regulations can be counterproductive, potentially stifling innovation and slowing adoption of beneficial technology rather than mitigating the adverse impacts of emerging technologies. This observation is particularly pertinent in the context of proprietary and open-source models in the field of Generative AI (GenAI). Proprietary models may be easier to regulate, as there are only a few companies that would need to be controlled, but depend largely on the responsible and ethical practices of those companies. Open models permit unregulated use and uncontrolled modifications, but foster rapid innovation and support research on improving AI safety. Policy should take into account the challenges and benefits presented by each type of model, aiming to strike a balance between fostering innovation and ensuring security.\nReport issue for preceding element\n  * â¢\nGovernment Licensing of LLM Companies: One approach might be government licensing of companies developing large language models (LLMs). This could establish a structured framework for accountability, oversight, and ethical compliance, thereby enhancing the trustworthiness of GenAI systems.\nReport issue for preceding element\n  * â¢\nDynamic Policy Evolution: Given the rapid advancement of GenAI technology, policies and regulation will require regular updates, to adapt to new technological realities and challenges.\nReport issue for preceding element\n\n\n###  3.6 Evolving Threat Management \nReport issue for preceding element\nGenAI threats, like all technology threats, arenât stagnant. We face a cat and mouse game where for every defensive move, attackers design a counter-move. Thus, security systems need to be ever-evolving, learning from past breaches and anticipating future strategies. Just as with adversarial examples for computer vision (Tramer et al., [2020](https://arxiv.org/html/2402.12617v1#bib.bib70)), there is no universal protection for prompt injection, jailbreaks, or other attacks, so for now, one pragmatic defense might be to monitor and detect threats. Developers will need tools to monitor, detect, and respond to attacks on GenAI, and a threat intelligence strategy to track new emerging threats.\nReport issue for preceding element\nSociety has had thousands of years to come up with ways to protect against scammers; GenAIs have only been around for several years, so weâre still figuring out how to defend them. Predicting the exact nature of future AI threats is challenging. Researchers are actively investigating new countermeasures to defend against threats on GenAI. Therefore, we recommend developers design systems in a way that preserves flexibility for the future, so that new defenses can be slotted in as they are discovered.\nReport issue for preceding element\n## Acknowledgements\nReport issue for preceding element\nThis research was supported by the National Science Foundation under grants 2229876 (the ACTION center) and 2154873, a NSF Graduate Fellowship, OpenAI, C3.ai DTI, Open Philanthropy, Google, the Department of Homeland Security, and IBM.\nReport issue for preceding element\n## Broader Impacts\nReport issue for preceding element\nOur work explores the threats society and technologists might face. We believe it is in the public interest to understand future risks, so that the research community can begin developing novel methods to mitigate those risks. We also sketch a roadmap of directions for future research that we believe holds promise for addressing a number of these risks.\nReport issue for preceding element\n## References\nReport issue for preceding element\n  * Aaronson (2022)â S. Aaronson.  My AI safety lecture for UT Effective Altruism.  _Shtetl-Optimized: The blog of Scott Aaronson. Retrieved on September_ , 11:2023, 2022.  URL <https://scottaaronson.blog/?p=6823>. \n  * Alawida et al. (2023)â M. Alawida, B. A. Shawar, O. I. Abiodun, A. Mehmood, A. E. Omolara, et al.  Unveiling the Dark Side of ChatGPT: Exploring Cyberattacks and Enhancing User Awareness.  _Information_ , 15, 2023. \n  * Anthropic (2023)â Anthropic.  Model Card and Evaluations for Claude Models, 2023.  URL <https://www-files.anthropic.com/production/images/Model-Card-Claude-2.pdf>.  Accessed: Sep. 27, 2023. \n  * Asare et al. (2023)â O. Asare, M. Nagappan, and N. Asokan.  Is Githubâs Copilot as bad as humans at introducing vulnerabilities in code?  _Empirical Software Engineering_ , 28(6):1â24, 2023. \n  * Azaria and Mitchell (2023)â A. Azaria and T. Mitchell.  The Internal State of an LLM Knows When Itâs Lying, 2023.  arXiv:2304.13734. \n  * Bai et al. (2022)â Y. Bai, A. Jones, K. Ndousse, A. Askell, A. Chen, N. DasSarma, D. Drain, S. Fort, D. Ganguli, T. Henighan, et al.  Training a helpful and harmless assistant with reinforcement learning from human feedback.  _arXiv preprint arXiv:2204.05862_ , 2022. \n  * Betker et al. (2023)â J. Betker, G. Goh, L. Jing, T. Brooks, J. Wang, L. Li, L. Ouyang, J. Zhuang, J. Lee, Y. Guo, et al.  Improving image generation with better captions.  _Computer Science. https://cdn. openai. com/papers/dall-e-3. pdf_ , 2023. \n  * Bommasani et al. (2021)â R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. Arora, S. von Arx, M. S. Bernstein, J. Bohg, A. Bosselut, E. Brunskill, et al.  On the opportunities and risks of foundation models.  _arXiv preprint arXiv:2108.07258_ , 2021. \n  * Branch et al. (2022)â H. J. Branch, J. R. Cefalu, J. McHugh, L. Hujer, A. Bahl, D. d. C. Iglesias, R. Heichman, and R. Darwishi.  Evaluating the susceptibility of pre-trained language models via handcrafted adversarial examples.  _arXiv preprint arXiv:2209.02128_ , 2022. \n  * Brown et al. (2020)â T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al.  Language models are few-shot learners.  _Advances in neural information processing systems_ , 33:1877â1901, 2020. \n  * Bubeck et al. (2023)â S. Bubeck, V. Chandrasekaran, R. Eldan, J. Gehrke, E. Horvitz, E. Kamar, P. Lee, Y. T. Lee, Y. Li, S. Lundberg, et al.  Sparks of artificial general intelligence: Early experiments with gpt-4.  _arXiv preprint arXiv:2303.12712_ , 2023. \n  * Carlini et al. (2023)â N. Carlini, M. Jagielski, C. A. Choquette-Choo, D. Paleka, W. Pearce, H. Anderson, A. Terzis, K. Thomas, and F. TramÃ¨r.  Poisoning web-scale training datasets is practical.  _arXiv preprint arXiv:2302.10149_ , 2023. \n  * Chao et al. (2023)â P. Chao, A. Robey, E. Dobriban, H. Hassani, G. J. Pappas, and E. Wong.  Jailbreaking black box large language models in twenty queries.  _arXiv preprint arXiv:2310.08419_ , 2023. \n  * Chowdhery et al. (2022)â A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W. Chung, C. Sutton, S. Gehrmann, et al.  Palm: Scaling language modeling with pathways.  _arXiv preprint arXiv:2204.02311_ , 2022. \n  * Christ et al. (2023)â M. Christ, S. Gunn, and O. Zamir.  Undetectable watermarks for language models.  _arXiv preprint arXiv:2306.09194_ , 2023. \n  * Christiano et al. (2023)â P. Christiano, J. Leike, T. B. Brown, M. Martic, S. Legg, and D. Amodei.  Deep reinforcement learning from human preferences, 2023.  arXiv:1706.03741. \n  * Driess et al. (2023)â D. Driess, F. Xia, M. S. Sajjadi, C. Lynch, A. Chowdhery, B. Ichter, A. Wahid, J. Tompson, Q. Vuong, T. Yu, et al.  Palm-e: An embodied multimodal language model.  _arXiv preprint arXiv:2303.03378_ , 2023. \n  * Felt et al. (2012)â A. P. Felt, S. Egelman, M. Finifter, D. Akhawe, and D. Wagner.  How to ask for permission.  In _HotSec 2012_ , 2012. \n  * Fu et al. (2023)â Y. Fu, P. Liang, A. Tahir, Z. Li, M. Shahin, and J. Yu.  Security weaknesses of copilot generated code in github.  _arXiv preprint arXiv:2310.02059_ , 2023. \n  * Ganguli et al. (2022)â D. Ganguli, L. Lovitt, J. Kernion, A. Askell, Y. Bai, S. Kadavath, B. Mann, E. Perez, N. Schiefer, K. Ndousse, et al.  Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned.  _arXiv preprint arXiv:2209.07858_ , 2022. \n  * Gao et al. (2023)â L. Gao, J. Schulman, and J. Hilton.  Scaling laws for reward model overoptimization.  In _International Conference on Machine Learning_ , pages 10835â10866. PMLR, 2023. \n  * Glukhov et al. (2023)â D. Glukhov, I. Shumailov, Y. Gal, N. Papernot, and V. Papyan.  LLM Censorship: A Machine Learning Challenge or a Computer Security Problem?  _arXiv preprint arXiv:2307.10719_ , 2023. \n  * Greshake et al. (2023a)â K. Greshake, S. Abdelnabi, S. Mishra, C. Endres, T. Holz, and M. Fritz.  More than youâve asked for: A comprehensive analysis of novel prompt injection threats to application-integrated large language models.  _arXiv e-prints_ , pages arXivâ2302, 2023a. \n  * Greshake et al. (2023b)â K. Greshake, S. Abdelnabi, S. Mishra, C. Endres, T. Holz, and M. Fritz.  Not what youâve signed up for: Compromising real-world llm-integrated applications with indirect prompt injection.  In _Proceedings of the 16th ACM Workshop on Artificial Intelligence and Security_ , pages 79â90, 2023b. \n  * Gupta et al. (2023)â M. Gupta, C. Akiri, K. Aryal, E. Parker, and L. Praharaj.  From ChatGPT to ThreatGPT: Impact of Generative AI in Cybersecurity and Privacy.  _IEEE Access_ , 2023. \n  * Huang et al. (2023)â B. Huang, B. Zhu, H. Zhu, J. D. Lee, J. Jiao, and M. I. Jordan.  Towards optimal statistical watermarking.  _arXiv preprint arXiv:2312.07930_ , 2023. \n  * Iqbal et al. (2023)â U. Iqbal, T. Kohno, and F. Roesner.  LLM Platform Security: Applying a Systematic Evaluation Framework to OpenAIâs ChatGPT Plugins, 2023.  arXiv:2309.10254. \n  * Ivison et al. (2023)â H. Ivison, Y. Wang, V. Pyatkin, N. Lambert, M. Peters, P. Dasigi, J. Jang, D. Wadden, N. A. Smith, I. Beltagy, and H. Hajishirzi.  Camels in a changing climate: Enhancing lm adaptation with tulu 2, 2023. \n  * Jarvis (2020)â C. Jarvis.  _Crypto wars: the fight for privacy in the digital age: A political history of digital encryption_.  CRC Press, 2020. \n  * Kirchenbauer et al. (2023)â J. Kirchenbauer, J. Geiping, Y. Wen, J. Katz, I. Miers, and T. Goldstein.  A watermark for large language models.  _arXiv preprint arXiv:2301.10226_ , 2023. \n  * Kuditipudi et al. (2023)â R. Kuditipudi, J. Thickstun, T. Hashimoto, and P. Liang.  Robust distortion-free watermarks for language models.  _arXiv preprint arXiv:2307.15593_ , 2023. \n  * Kutter et al. (1997)â M. Kutter, F. D. Jordan, and F. Bossen.  Digital signature of color images using amplitude modulation.  In _Storage and Retrieval for Image and Video Databases V_ , volume 3022, pages 518â526. SPIE, 1997. \n  * Liu et al. (2023a)â H. Liu, C. Li, Q. Wu, and Y. J. Lee.  Visual instruction tuning.  _arXiv preprint arXiv:2304.08485_ , 2023a. \n  * Liu et al. (2023b)â T. Liu, Y. Zhao, R. Joshi, M. Khalman, M. Saleh, P. J. Liu, and J. Liu.  Statistical rejection sampling improves preference optimization.  _arXiv preprint arXiv:2309.06657_ , 2023b. \n  * Liu et al. (2023c)â Y. Liu, G. Deng, Y. Li, K. Wang, T. Zhang, Y. Liu, H. Wang, Y. Zheng, and Y. Liu.  Prompt Injection attack against LLM-integrated Applications.  _arXiv preprint arXiv:2306.05499_ , 2023c. \n  * Liu et al. (2023d)â Y. Liu, G. Deng, Z. Xu, Y. Li, Y. Zheng, Y. Zhang, L. Zhao, T. Zhang, and Y. Liu.  Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study, 2023d.  arXiv:2305.13860. \n  * Lu and Liao (2000)â C.-S. Lu and H.-Y. M. Liao.  Structural digital signature for image authentication: an incidental distortion resistant scheme.  In _Proceedings of the 2000 ACM workshops on Multimedia_ , pages 115â118, 2000. \n  * Lv et al. (2023)â K. Lv, W. Zhang, and H. Shen.  Supervised fine-tuning and direct preference optimization on intel gaudi2 â by intel(r) neural compressor â intel analytics software â nov, 2023 â medium.  <https://medium.com/intel-analytics-software/the-practice-of-supervised-finetuning-and-direct-preference-optimization-on-habana-gaudi2-a1197d8a3cd3>, 2023.  (Accessed on 01/12/2024). \n  * Markov et al. (2023)â T. Markov, C. Zhang, S. Agarwal, F. E. Nekoul, T. Lee, S. Adler, A. Jiang, and L. Weng.  A holistic approach to undesired content detection in the real world.  In _Proceedings of the AAAI Conference on Artificial Intelligence_ , pages 15009â15018, 2023. \n  * Monje et al. (2023)â A. Monje, A. Monje, R. A. Hallman, and G. Cybenko.  Being a bad influence on the kids: Malware generation in less than five minutes using ChatGPT, 2023. \n  * Morris et al. (2023)â M. R. Morris, J. Sohl-dickstein, N. Fiedel, T. Warkentin, A. Dafoe, A. Faust, C. Farabet, and S. Legg.  âLevels of AGIâ: Operationalizing Progress on the Path to AGI, 2023.  arXiv:2311.02462. \n  * Mudgal et al. (2023)â S. Mudgal, J. Lee, H. Ganapathy, Y. Li, T. Wang, Y. Huang, Z. Chen, H.-T. Cheng, M. Collins, T. Strohman, et al.  Controlled decoding from language models.  _arXiv preprint arXiv:2310.17022_ , 2023. \n  * Narayanan (2008)â A. Narayanan.  Lendingclub.com: A de-anonymization walkthrough, 2008.  https://33bits.wordpress.com/2008/11/12/57/. \n  * Narayanan and Shmatikov (2010)â A. Narayanan and V. Shmatikov.  Myths and fallacies ofâ personally identifiable informationâ.  _Communications of the ACM_ , 53(6):24â26, 2010. \n  * Narayanan et al. (2016)â A. Narayanan, J. Huey, and E. W. Felten.  A precautionary approach to big data privacy.  _Data protection on the move: Current developments in ICT and privacy/data protection_ , pages 357â385, 2016. \n  * Nasr et al. (2023)â M. Nasr, N. Carlini, J. Hayase, M. Jagielski, A. F. Cooper, D. Ippolito, C. A. Choquette-Choo, E. Wallace, F. TramÃ¨r, and K. Lee.  Scalable extraction of training data from (production) language models.  _arXiv preprint arXiv:2311.17035_ , 2023. \n  * OpenAI (2023)â OpenAI.  Gpt-4 technical report, 2023. \n  * Ouyang et al. (2022)â L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, et al.  Training language models to follow instructions with human feedback.  _Advances in Neural Information Processing Systems_ , 35:27730â27744, 2022. \n  * Pa Pa et al. (2023)â Y. M. Pa Pa, S. Tanizaki, T. Kou, M. Van Eeten, K. Yoshioka, and T. Matsumoto.  An Attackerâs Dream? Exploring the Capabilities of ChatGPT for Developing Malware.  In _Proceedings of the 16th Cyber Security Experimentation and Test Workshop_ , pages 10â18, 2023. \n  * Perez and Ribeiro (2022)â F. Perez and I. Ribeiro.  Ignore previous prompt: Attack techniques for language models.  _arXiv preprint arXiv:2211.09527_ , 2022. \n  * Phute et al. (2023)â M. Phute, A. Helbling, M. Hull, S. Peng, S. Szyller, C. Cornelius, and D. H. Chau.  LLM Self Defense: By Self Examination, LLMs Know They Are Being Tricked, 2023.  arXiv:2308.07308. \n  * Qin et al. (2022)â L. Qin, S. Welleck, D. Khashabi, and Y. Choi.  Cold decoding: Energy-based constrained text generation with langevin dynamics.  _Advances in Neural Information Processing Systems_ , 35:9538â9551, 2022. \n  * Radford et al. (2019)â A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al.  Language models are unsupervised multitask learners.  _OpenAI blog_ , 1(8):9, 2019. \n  * Radford et al. (2021)â A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark, et al.  Learning transferable visual models from natural language supervision.  In _International conference on machine learning_ , pages 8748â8763. PMLR, 2021. \n  * Ramesh et al. (2021)â A. Ramesh, M. Pavlov, G. Goh, S. Gray, C. Voss, A. Radford, M. Chen, and I. Sutskever.  Zero-shot text-to-image generation.  In _International Conference on Machine Learning_ , pages 8821â8831. PMLR, 2021. \n  * Rando and TramÃ¨r (2023)â J. Rando and F. TramÃ¨r.  Universal jailbreak backdoors from poisoned human feedback.  _arXiv preprint arXiv:2311.14455_ , 2023. \n  * Rateike et al. (2023)â M. Rateike, C. Cintas, J. Wamburu, T. Akumu, and S. Speakman.  Weakly Supervised Detection of Hallucinations in LLM Activations.  _arXiv preprint arXiv:2312.02798_ , 2023. \n  * Renaud et al. (2023)â K. Renaud, M. Warkentin, and G. Westerman.  _From ChatGPT to HackGPT: Meeting the Cybersecurity Threat of Generative AI_.  MIT Sloan Management Review, 2023. \n  * Schick et al. (2023)â T. Schick, J. Dwivedi-Yu, R. DessÃ¬, R. Raileanu, M. Lomeli, L. Zettlemoyer, N. Cancedda, and T. Scialom.  Toolformer: Language models can teach themselves to use tools.  _arXiv preprint arXiv:2302.04761_ , 2023. \n  * Schulman et al. (2022)â J. Schulman, B. Zoph, C. Kim, J. Hilton, J. Menick, J. Weng, J. F. C. Uribe, L. Fedus, L. Metz, M. Pokorny, et al.  ChatGPT: Optimizing language models for dialogue.  _OpenAI blog_ , 2022. \n  * Sebastian (2023)â G. Sebastian.  Privacy and Data Protection in ChatGPT and Other AI Chatbots: Strategies for Securing User Information, 2023.  SSRN 4454761. \n  * Sinha and Singh (2003)â A. Sinha and K. Singh.  A technique for image encryption using digital signature.  _Optics communications_ , 218(4-6):229â234, 2003. \n  * Song et al. (2020)â Y. Song, J. Sohl-Dickstein, D. P. Kingma, A. Kumar, S. Ermon, and B. Poole.  Score-based generative modeling through stochastic differential equations.  _arXiv preprint arXiv:2011.13456_ , 2020. \n  * Stiennon et al. (2020)â N. Stiennon, L. Ouyang, J. Wu, D. Ziegler, R. Lowe, C. Voss, A. Radford, D. Amodei, and P. F. Christiano.  Learning to summarize with human feedback.  _Advances in Neural Information Processing Systems_ , 33:3008â3021, 2020. \n  * Taskinsoy (2019)â J. Taskinsoy.  Facebookâs libra: Why does us government fear price stable cryptocurrency?  _Available at SSRN 3482441_ , 2019. \n  * Team (2023)â O. Team.  GPT-4V(ision) System Card, 2023. \n  * ThankGod Chinonso (2023)â E. ThankGod Chinonso.  The impact of ChatGPT on privacy and data protection laws, 2023.  SSRN 4574016. \n  * Touvron et al. (2023)â H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. RoziÃ¨re, N. Goyal, E. Hambro, F. Azhar, et al.  Llama: Open and efficient foundation language models.  _arXiv preprint arXiv:2302.13971_ , 2023. \n  * Toyer et al. (2023)â S. Toyer, O. Watkins, E. A. Mendes, J. Svegliato, L. Bailey, T. Wang, I. Ong, K. Elmaaroufi, P. Abbeel, T. Darrell, et al.  Tensor trust: Interpretable prompt injection attacks from an online game.  _arXiv preprint arXiv:2311.01011_ , 2023. \n  * Tramer et al. (2020)â F. Tramer, N. Carlini, W. Brendel, and A. Madry.  On adaptive attacks to adversarial example defenses.  _Advances in neural information processing systems_ , 33:1633â1645, 2020. \n  * Venugopal et al. (2011)â A. Venugopal, J. Uszkoreit, D. Talbot, F. J. Och, and J. Ganitkevitch.  Watermarking the outputs of structured prediction with an application in statistical machine translation.  In _Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing_ , pages 1363â1372, 2011. \n  * Wang et al. (2023)â G. Wang, S. Cheng, X. Zhan, X. Li, S. Song, and Y. Liu.  Openchat: Advancing open-source language models with mixed-quality data.  _arXiv preprint arXiv:2309.11235_ , 2023. \n  * Wei et al. (2023)â A. Wei, N. Haghtalab, and J. Steinhardt.  Jailbroken: How does llm safety training fail?  _arXiv preprint arXiv:2307.02483_ , 2023. \n  * Wei et al. (2022a)â J. Wei, Y. Tay, R. Bommasani, C. Raffel, B. Zoph, S. Borgeaud, D. Yogatama, M. Bosma, D. Zhou, D. Metzler, et al.  Emergent abilities of large language models.  _arXiv preprint arXiv:2206.07682_ , 2022a. \n  * Wei et al. (2022b)â J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D. Zhou, et al.  Chain-of-thought prompting elicits reasoning in large language models.  _Advances in Neural Information Processing Systems_ , 35:24824â24837, 2022b. \n  * Wu et al. (2023)â X. Wu, R. Duan, and J. Ni.  Unveiling security, privacy, and ethical concerns of ChatGPT.  _Journal of Information and Intelligence_ , 2023. \n  * Yang and Klein (2021)â K. Yang and D. Klein.  Fudge: Controlled text generation with future discriminators.  _arXiv preprint arXiv:2104.05218_ , 2021. \n  * Yang et al. (2023)â L. Yang, Z. Zhang, Y. Song, S. Hong, R. Xu, Y. Zhao, W. Zhang, B. Cui, and M.-H. Yang.  Diffusion models: A comprehensive survey of methods and applications.  _ACM Computing Surveys_ , 56(4):1â39, 2023. \n  * Zhang et al. (2019)â X. Zhang, S. Karaman, and S.-F. Chang.  Detecting and simulating artifacts in gan fake images.  In _2019 IEEE international workshop on information forensics and security (WIFS)_ , pages 1â6. IEEE, 2019. \n  * Zhao et al. (2023)â X. Zhao, P. Ananth, L. Li, and Y.-X. Wang.  Provable robust watermarking for ai-generated text.  _arXiv preprint arXiv:2306.17439_ , 2023. \n  * Zhu et al. (2023a)â B. Zhu, E. Frick, T. Wu, H. Zhu, and J. Jiao.  Starling-7b: Improving llm helpfulness & harmlessness with rlaif, 2023a. \n  * Zhu et al. (2023b)â B. Zhu, J. Jiao, and M. I. Jordan.  Principled reinforcement learning with human feedback from pairwise or kðkitalic_k-wise comparisons.  _arXiv preprint arXiv:2301.11270_ , 2023b. \n  * Zhu et al. (2023c)â B. Zhu, H. Sharma, F. V. Frujeri, S. Dong, C. Zhu, M. I. Jordan, and J. Jiao.  Fine-tuning language models with advantage-induced policy alignment.  _arXiv preprint arXiv:2306.02231_ , 2023c. \n  * Ziegler et al. (2019)â D. M. Ziegler, N. Stiennon, J. Wu, T. B. Brown, A. Radford, D. Amodei, P. Christiano, and G. Irving.  Fine-tuning language models from human preferences.  _arXiv preprint arXiv:1909.08593_ , 2019. \n\n\nGenerated by [ L A T E xml ![\\[LOGO\\]](https://arxiv.org/html/2402.12617v1) ](https://math.nist.gov/~BMiller/LaTeXML/)\n## Instructions for reporting errors\nWe are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:\n  * Click the \"Report Issue\" button.\n  * Open a report feedback form via keyboard, use \"**Ctrl + ?** \".\n  * Make a text selection and click the \"Report Issue for Selection\" button near your cursor.\n  * You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.\n\n\nOur team has already identified [the following issues](https://github.com/arXiv/html_feedback/issues). We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.\nHave a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a [list of packages that need conversion](https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML), and welcome [developer contributions](https://github.com/brucemiller/LaTeXML/issues).\nReport Issue\n##### Report Github Issue\nTitle:Content selection saved. Describe the issue below:Description:\nSubmit without GithubSubmit in Github\nReport Issue for Selection\n"
  },
  {
    "link": "https://arxiv.org/html/2402.11512v2",
    "raw_content": "[ ![logo](https://services.dev.arxiv.org/html/static/arxiv-logomark-small-white.svg) Back to arXiv ](https://arxiv.org/)\n[ ](https://arxiv.org/abs/2402.11512v2) [ ](javascript:toggleColorScheme\\(\\) \"Toggle dark/light mode\")\n[ ![logo](https://services.dev.arxiv.org/html/static/arxiv-logo-one-color-white.svg) Back to arXiv ](https://arxiv.org/)\nThis is **experimental HTML** to improve accessibility. We invite you to report rendering errors. Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off. Learn more [about this project](https://info.arxiv.org/about/accessible_HTML.html) and [help improve conversions](https://info.arxiv.org/help/submit_latex_best_practices.html). \n[Why HTML?](https://info.arxiv.org/about/accessible_HTML.html) [Report Issue](https://arxiv.org/html/2402.11512v2#myForm) [Back to Abstract](https://arxiv.org/abs/2402.11512v2) [Download PDF](https://arxiv.org/pdf/2402.11512v2) [ ](javascript:toggleColorScheme\\(\\) \"Toggle dark/light mode\")\n## Table of Contents\n  1. [1 Introduction](https://arxiv.org/html/2402.11512v2#S1 \"1 Introduction â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n  2. [2 Data](https://arxiv.org/html/2402.11512v2#S2 \"2 Data â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n    1. [2.1 L2-Reddit Corpus](https://arxiv.org/html/2402.11512v2#S2.SS1 \"2.1 L2-Reddit Corpus â£ 2 Data â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n    2. [2.2 StereoSet](https://arxiv.org/html/2402.11512v2#S2.SS2 \"2.2 StereoSet â£ 2 Data â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n    3. [2.3 CrowS-Pairs](https://arxiv.org/html/2402.11512v2#S2.SS3 \"2.3 CrowS-Pairs â£ 2 Data â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n  3. [3 Methodology](https://arxiv.org/html/2402.11512v2#S3 \"3 Methodology â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n    1. [3.1 Bias Identification and Data Structure](https://arxiv.org/html/2402.11512v2#S3.SS1 \"3.1 Bias Identification and Data Structure â£ 3 Methodology â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n    2. [3.2 Soft Debiasing: The Baseline Approach](https://arxiv.org/html/2402.11512v2#S3.SS2 \"3.2 Soft Debiasing: The Baseline Approach â£ 3 Methodology â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n    3. [3.3 DeepSoftDebias: Our Proposed Approach](https://arxiv.org/html/2402.11512v2#S3.SS3 \"3.3 DeepSoftDebias: Our Proposed Approach â£ 3 Methodology â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n  4. [4 Effects of LLM Size and Dependency of Network Size](https://arxiv.org/html/2402.11512v2#S4 \"4 Effects of LLM Size and Dependency of Network Size â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n  5. [5 Results](https://arxiv.org/html/2402.11512v2#S5 \"5 Results â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n    1. [5.1 Mean Average Cosine Similarity (MAC)](https://arxiv.org/html/2402.11512v2#S5.SS1 \"5.1 Mean Average Cosine Similarity \\(MAC\\) â£ 5 Results â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n    2. [5.2 Stereotype Score](https://arxiv.org/html/2402.11512v2#S5.SS2 \"5.2 Stereotype Score â£ 5 Results â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n    3. [5.3 Crows-Pairs Dataset](https://arxiv.org/html/2402.11512v2#S5.SS3 \"5.3 Crows-Pairs Dataset â£ 5 Results â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n  6. [6 DownStream Results](https://arxiv.org/html/2402.11512v2#S6 \"6 DownStream Results â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n    1. [6.1 Sentiment Classification](https://arxiv.org/html/2402.11512v2#S6.SS1 \"6.1 Sentiment Classification â£ 6 DownStream Results â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n    2. [6.2 Named Entity Recognition (NER)](https://arxiv.org/html/2402.11512v2#S6.SS2 \"6.2 Named Entity Recognition \\(NER\\) â£ 6 DownStream Results â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n  7. [7 Ablation Experiments](https://arxiv.org/html/2402.11512v2#S7 \"7 Ablation Experiments â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n  8. [8 Discussion](https://arxiv.org/html/2402.11512v2#S8 \"8 Discussion â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n    1. [8.1 RQ1](https://arxiv.org/html/2402.11512v2#S8.SS1 \"8.1 RQ1 â£ 8 Discussion â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n    2. [8.2 RQ2](https://arxiv.org/html/2402.11512v2#S8.SS2 \"8.2 RQ2 â£ 8 Discussion â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n    3. [8.3 RQ3](https://arxiv.org/html/2402.11512v2#S8.SS3 \"8.3 RQ3 â£ 8 Discussion â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n    4. [8.4 RQ4](https://arxiv.org/html/2402.11512v2#S8.SS4 \"8.4 RQ4 â£ 8 Discussion â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n  9. [9 Conclusion](https://arxiv.org/html/2402.11512v2#S9 \"9 Conclusion â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n  10. [10 Limitations](https://arxiv.org/html/2402.11512v2#S10 \"10 Limitations â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n  11. [11 Ethics Statement](https://arxiv.org/html/2402.11512v2#S11 \"11 Ethics Statement â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n  12. [A MAC Scores of DeepSoftDebias](https://arxiv.org/html/2402.11512v2#A1 \"Appendix A MAC Scores of DeepSoftDebias â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n  13. [B Stereoset Scores of DeepSoftDebias](https://arxiv.org/html/2402.11512v2#A2 \"Appendix B Stereoset Scores of DeepSoftDebias â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n  14. [C Downstream Testing Results](https://arxiv.org/html/2402.11512v2#A3 \"Appendix C Downstream Testing Results â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")\n\n\nReport issue for preceding element\nHTML conversions [sometimes display errors](https://info.dev.arxiv.org/about/accessibility_html_error_messages.html) due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.\nReport issue for preceding element\n  * failed: inconsolata\n\n\nAuthors: achieve the best HTML results from your LaTeX submissions by following these [best practices](https://info.arxiv.org/help/submit_latex_best_practices.html).\nReport issue for preceding element\nLicense: CC BY 4.0\narXiv:2402.11512v2 [cs.CL] 20 Feb 2024\n# From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\nReport issue for preceding element\nAishik Rakshit Indian Institute of Technology, Guwahati &Smriti Singh The University of Texas at Austin &Shuvam Keshari The University of Texas at Austin \\ANDArijit Ghosh Chowdhury University of Illinois Urbana-Champaign &Vinija Jain Stanford University &Aman Chadha Stanford University, Amazon GenAI  Work does not relate to position at Amazon.\nReport issue for preceding element\n###### Abstract\nReport issue for preceding element\nEmbeddings play a pivotal role in the efficacy of Large Language Models. They are the bedrock on which these models grasp contextual relationships and foster a more nuanced understanding of language and consequently perform remarkably on a plethora of complex tasks that require a fundamental understanding of human language. Given that these embeddings themselves often reflect or exhibit bias, it stands to reason that these models may also inadvertently learn this bias. In this work, we build on the seminal previous work and propose DeepSoftDebias, an algorithm that uses a neural network to perform âsoft debiasingâ. We exhaustively evaluate this algorithm across a variety of SOTA datasets, accuracy metrics, and challenging NLP tasks. We find that DeepSoftDebias outperforms the current state-of-the-art methods at reducing bias across gender, race, and religion.\nReport issue for preceding element\n##  1 Introduction\nReport issue for preceding element\nWord embeddings are a foundational element in the architecture of large language models (LLMs). They act as the basis for these models to understand and subsequently, generate human-like language. However, it has been shown that these models rely on word embeddings, which themselves may reflect or exhibit bias Papakyriakopoulos et al. ([2020](https://arxiv.org/html/2402.11512v2#bib.bib24)); Dev et al. ([2020](https://arxiv.org/html/2402.11512v2#bib.bib7)). Given the exponential increase in the use of large language models on a plethora of downstream tasks, these representations can amplify bias and result in discriminatory actions, especially when it comes to the fields of education, healthcare, and justice. Existing work in this field has looked most commonly into gender bias Kotek et al. ([2023](https://arxiv.org/html/2402.11512v2#bib.bib14)); Bordia and Bowman ([2019](https://arxiv.org/html/2402.11512v2#bib.bib4)); de Vassimon Manela et al. ([2021](https://arxiv.org/html/2402.11512v2#bib.bib6)), racial bias Mozafari et al. ([2020](https://arxiv.org/html/2402.11512v2#bib.bib19)); Omiye et al. ([2023](https://arxiv.org/html/2402.11512v2#bib.bib23)); [Tang et al. ](https://arxiv.org/html/2402.11512v2#bib.bib29), and religious bias Baligudam ([2022](https://arxiv.org/html/2402.11512v2#bib.bib2)); Kirk et al. ([2021](https://arxiv.org/html/2402.11512v2#bib.bib13)). In this work, we build on the seminal work of Gonen and Goldberg ([2019](https://arxiv.org/html/2402.11512v2#bib.bib9)), which brought attention to the inherent biases present in traditional GloVe embeddings Pennington et al. ([2014](https://arxiv.org/html/2402.11512v2#bib.bib25)). This study prompted the NLP community to reevaluate the fundamental choices underlying our word representation models. Specifically, we present DeepSoftBias: an algorithm that furthers the application of their methodology, by diverging from the conventional GloVe embeddings and delving into the word embeddings produced by the best-performing models on the Massive Text Embedding Benchmark (MTEB) Muennighoff et al. ([2022](https://arxiv.org/html/2402.11512v2#bib.bib20)) leaderboard. By employing these advanced embeddings on the same set of words as used in GloVe embeddings, we seek to investigate whether these state-of-the-art (SoTA) models inherently exhibit reduced bias. Our primary objective is twofold: first, to de-bias the embeddings from these selected models, and second, to rigorously assess the effectiveness of the bias removal process. Our proposed approach, DeepSoftDebias, is an innovative methodology to de-bias LLM word embeddings which involves integrating a neural network into the soft debiasing approach developed by Bolukbasi et al. ([2016](https://arxiv.org/html/2402.11512v2#bib.bib3)). This novel amalgamation is driven by the aspiration to enhance the debiasing process and contribute to the ongoing discourse on creating fair and ethically sound language models. To this end, our work answers the following research questions:\nReport issue for preceding element\n  1. RQ1: Compared to traditional methods, does our proposed methodology attain better performance metrics when it comes to debiasing SOTA model embeddings?\nReport issue for preceding element\n  2. RQ2: How do parameters of the model (size, complexity) interact with various SOTA debiasing techniques? What effect do they have on each other?\nReport issue for preceding element\n  3. RQ3: To what extent do various SOTA debiasing techniques influence the performance of models on different downstream tasks?\nReport issue for preceding element\n  4. RQ4: How does the type of bias (gender, race, religion) affect the effectiveness of the debiasing process?\nReport issue for preceding element\n\n\nTo answer the above questions, we make the following contributions through this research:\nReport issue for preceding element\nOur Contributions\nReport issue for preceding element [leftmargin=1mm] â  We provide, to the best of our knowledge, the first comprehensive study of how various debiasing methods work on SoTA LLM word embeddings â  We present a novel methodology, DeepSoftDebias, for debiasing LLM word embeddings, which beats SoTA debiasing methods across multiple bias formats including gender, race, and religion. â  We perform an exhaustive quantitative analysis, establishing SoTA baselines and leveraging multiple evaluation metrics to provide a comparison against accessible SoTA baselines Report issue for preceding element\nWe illustrate our pipeline in Fig. [1](https://arxiv.org/html/2402.11512v2#S1.F1 \"Figure 1 â£ 1 Introduction â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\"). We find that DeepSoftDebias not only outperforms the state-of-the-art methods at reducing bias across gender, race, and religion but also does so while preserving the full information of the original embedding (which is an additional improvement on previous methods). Further, we find that model performance on challenging downstream tasks like NER and sentiment analysis remains largely unaffected when we test using our debiased embeddings.\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/x1.png) Figure 1: A step-by-step visualization of the pipeline for DeepSoftDebias. Our pipeline has 3 major components, Initial Word Vector Generation, Debiasing, and Quantitative Analysis. The Debiasing stage leverages the DeepSoftDebias network. Report issue for preceding element\n##  2 Data\nReport issue for preceding element\nThis study leverages several datasets to examine and address biases in word embeddings and language models, focusing on the representation and perpetuation of stereotypes within these systems.\nReport issue for preceding element\n###  2.1 L2-Reddit Corpus\nReport issue for preceding element\nWe utilize the L2-Reddit111<https://github.com/ellarabi/reddit-l2> Rabinovich et al. ([2018](https://arxiv.org/html/2402.11512v2#bib.bib26)) corpus, a collection of Reddit posts and comments by both native and non-native English speakers, featuring approximately 56 million sentences from the United States. This dataset serves as the foundation for training the word embeddings, aiming to capture the nuanced and inherently biased linguistic patterns present in social media discourse. The corpus provides a rich linguistic resource for analyzing and understanding the initial biased word embeddings. In our study, we employ the Reddit L2 corpus as the source for our initial Word2Vec Mikolov et al. ([2013](https://arxiv.org/html/2402.11512v2#bib.bib18)) word embeddings. Subsequently, we leverage the vocabulary derived from these word vectors to obtain the word embeddings from the Language Model Models (LLMs).\nReport issue for preceding element\n###  2.2 StereoSet\nReport issue for preceding element\nStereoSet Nadeem et al. ([2020](https://arxiv.org/html/2402.11512v2#bib.bib21)) stands out as a critical dataset for measuring stereotype bias in language models, containing around 17,000 sentences across demographic dimensions like gender, race, religion, and profession. It introduces the Context Association Tests (CAT) for evaluating model preferences and biases, providing a structured approach to assess and quantify biases in popular models like BERT Devlin et al. ([2019](https://arxiv.org/html/2402.11512v2#bib.bib8)), GPT-2 Radford et al. ([2019](https://arxiv.org/html/2402.11512v2#bib.bib27)), RoBERTa Liu et al. ([2019](https://arxiv.org/html/2402.11512v2#bib.bib15)), and XLNet Yang et al. ([2020](https://arxiv.org/html/2402.11512v2#bib.bib34)). The datasetâs creation involved a rigorous crowdsourcing process, ensuring a wide coverage of stereotypes and anti-stereotypes to challenge and evaluate the fairness of NLP systems. In our words we use the stereoset dataset to benchmark our debiasing method against all the other debiasing methods. To accomplish this, we compute the average sentence vector for all sentences and their respective contexts. We then compare these vectors against each other to derive the stereotype score.\nReport issue for preceding element\n###  2.3 CrowS-Pairs\nReport issue for preceding element\nCrowS-Pairs Nangia et al. ([2020](https://arxiv.org/html/2402.11512v2#bib.bib22)), designed to assess social biases in masked language models (MLMs), comprises 1,508 examples covering nine bias types, including race, religion, and age. It contrasts sentences related to historically disadvantaged and advantaged groups in the U.S., with annotations from crowd workers highlighting the degree of stereotyping. Despite its noise and reliability issues, CrowS-Pairs remains a valuable resource for evaluating the bias in major language models, providing a nuanced metric that quantifies preference for stereotypical versus non-stereotypical expressions. In our study, we obtain debiased word embeddings for sentences by computing the average sentence vector for both less and more stereotypical or anti-stereotypical directions. We then compare these embeddings against each other to calculate the Crows Metric score.\nReport issue for preceding element\n##  3 Methodology\nReport issue for preceding element\nIn this research, we delve into the domain of debiasing word embeddings, presenting both an established and a newly proposed methodology for mitigating biases in word vector representations. These biases span across gender, racial, and religious lines and are encoded inadvertently within language models.\nReport issue for preceding element\n###  3.1 Bias Identification and Data Structure\nReport issue for preceding element\nTo quantitatively assess bias in word embeddings, we measure the projection of word vectors onto a gender-specific axis, defined by the vectorial difference between the terms âheâ and âshe.â The magnitude of this projection serves as an indicator of bias. We use a structured vocabulary with its associated vector representations from the Word2Vec model to facilitate the identification of biases. For a comprehensive evaluation, we utilize additional data files that include definitive sets of gender-associated word pairs, analogy templates that list occupational roles often linked with specific genders, and a set of neutral terms used as evaluation targets. These resources are crucial for the systematic identification and rectification of biases in word embeddings.\nReport issue for preceding element\n###  3.2 Soft Debiasing: The Baseline Approach\nReport issue for preceding element\nThe initial method as seen in the paper Manzini et al. ([2019](https://arxiv.org/html/2402.11512v2#bib.bib17)) leverages a method called soft debiasing. We recap its algorithm in Algorithm [1](https://arxiv.org/html/2402.11512v2#algorithm1 \"1 â£ 3.2 Soft Debiasing: The Baseline Approach â£ 3 Methodology â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\"). Soft debiasing involves learning a projection of the embedding matrix that preserves the inner product between biased and debiased embeddings while minimizing the projection onto the bias subspace of embeddings mentioned in [3.1](https://arxiv.org/html/2402.11512v2#S3.SS1 \"3.1 Bias Identification and Data Structure â£ 3 Methodology â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\") that should be neutral. Given embeddings WðWitalic_W and NðNitalic_N which are embeddings for the whole vocabulary and the subset of bias-neutral words respectively, and the bias subspace B obtained in Section [2.1](https://arxiv.org/html/2402.11512v2#S2.SS1 \"2.1 L2-Reddit Corpus â£ 2 Data â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\"), soft debiasing seeks a linear transformation A that minimizes the following objective defined in Eq. ([1](https://arxiv.org/html/2402.11512v2#S3.E1 \"1 â£ 3.2 Soft Debiasing: The Baseline Approach â£ 3 Methodology â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")) as follows: \nReport issue for preceding element |  â(Aâ¢W)Tâ¢(Aâ¢W)âWTâ¢WâF2+Î»â¢â(Aâ¢N)Tâ¢(Aâ¢B)âF2superscriptsubscriptnormsuperscriptð´ððð´ðsuperscriptðððð¹2ðsuperscriptsubscriptnormsuperscriptð´ððð´ðµð¹2\\left\\|(AW)^{T}(AW)-W^{T}W\\right\\|_{F}^{2}+\\lambda\\left\\|(AN)^{T}(AB)\\right\\|_% {F}^{2}â¥ ( italic_A italic_W ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ( italic_A italic_W ) - italic_W start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_W â¥ start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_Î» â¥ ( italic_A italic_N ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ( italic_A italic_B ) â¥ start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPTReport issue for preceding element |  | (1)  \n---|---|---|---  \nMinimizing the first term preserves the inner product after the linear transformation A, and minimizing the second term minimizes the projection onto the bias subspace B of embeddings. R is a tunable parameter that balances the two objectives.\nReport issue for preceding element\nInput: Biased word embeddings (embbiasedsubscriptembbiased\\text{emb}_{\\text{biased}}emb start_POSTSUBSCRIPT biased end_POSTSUBSCRIPT), Bias Subspace (BiasSpace), Neutral word embeddings (embneutralsubscriptembneutral\\text{emb}_{\\text{neutral}}emb start_POSTSUBSCRIPT neutral end_POSTSUBSCRIPT) \nOutput: Debiased word embeddings \nPerform Singular Value Decomposition (SVD) on embbiasedsubscriptembbiased\\text{emb}_{\\text{biased}}emb start_POSTSUBSCRIPT biased end_POSTSUBSCRIPT to obtain singular values (sð sitalic_s) and left singular vectors (uð¢uitalic_u); \nPrecompute tâ¢1=sâuTð¡1âð superscriptð¢ðt1=s\\cdot u^{T}italic_t 1 = italic_s â italic_u start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT and tâ¢2=uâsð¡2âð¢ð t2=u\\cdot sitalic_t 2 = italic_u â italic_s; \nCompute norm1 as âtâ¢1â(TTâTâI)âtâ¢2âFsubscriptnormâð¡1âsuperscriptðððð¼ð¡2ð¹\\|t1\\cdot(T^{T}\\cdot T-I)\\cdot t2\\|_{F}â¥ italic_t 1 â ( italic_T start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT â italic_T - italic_I ) â italic_t 2 â¥ start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT; \nCompute norm2 as âembneutralTâTTâBiasSpaceâFsubscriptnormâsuperscriptsubscriptembneutralðsuperscriptððBiasSpaceð¹\\|\\text{emb}_{\\text{neutral}}^{T}\\cdot T^{T}\\cdot\\text{BiasSpace}\\|_{F}â¥ emb start_POSTSUBSCRIPT neutral end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT â italic_T start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT â BiasSpace â¥ start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT; \nTotal loss is a weighted combination of norm1 and norm2; \nOptimize transformation matrix using SGD; \nOutput debiased word embeddings after recomputing using TðTitalic_T and normalizing; \nAlgorithm 1 Transformation Matrix Approach Report issue for preceding element\n###  3.3 DeepSoftDebias: Our Proposed Approach\nReport issue for preceding element\nIn the original approach introduced by Bolukbasi et al. ([2016](https://arxiv.org/html/2402.11512v2#bib.bib3)), a transformation matrix is utilized and optimized by an optimizer to enable a direct mapping between input and output embeddings. To enhance performance, we propose DeepSoftDebias. In this approach, we replace the transformation matrix with a neural network, leveraging its capability to represent a sequence of transformation matrices. This adaptation enables the algorithm to handle more complex functions mapping between input and output embeddings. We use the same loss functions as mentioned in the section [3.2](https://arxiv.org/html/2402.11512v2#S3.SS2 \"3.2 Soft Debiasing: The Baseline Approach â£ 3 Methodology â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\"). Furthermore, we transition from stochastic gradient descent (SGD Robbins and Monro ([1951](https://arxiv.org/html/2402.11512v2#bib.bib28))) to the Adam Kingma and Ba ([2017](https://arxiv.org/html/2402.11512v2#bib.bib12)) optimizer, resulting in enhanced efficiency, speed, and optimization quality. We describe our full algorithm in Algorithm [2](https://arxiv.org/html/2402.11512v2#algorithm2 \"2 â£ 3.3 DeepSoftDebias: Our Proposed Approach â£ 3 Methodology â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\"). While these modifications were implemented, the fundamental aspects of the method remain unaltered, ensuring minimal alterations in embeddings and preserving orthogonality with the bias space. Unlike the baseline, which relies on singular value decomposition (SVD) and incurred information loss, DeepSoftDebias preserves the full information of the original matrix. Moreover, unlike the baseline, DeepSoftDebias can handle large embedding dimensions of more than 4.5k. We demonstrate the effectiveness of DeepSoftDebias on various datasets and tasks, and show that it outperforms the state-of-the-art methods in terms of accuracy and efficiency. Fig. [2](https://arxiv.org/html/2402.11512v2#S3.F2 \"Figure 2 â£ 3.3 DeepSoftDebias: Our Proposed Approach â£ 3 Methodology â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\") presents a visualization of our approach to downstream testing.\nReport issue for preceding element\nInput: Biased word embeddings (embbiasedsubscriptembbiased\\text{emb}_{\\text{biased}}emb start_POSTSUBSCRIPT biased end_POSTSUBSCRIPT), Bias Subspace (BiasSpace), Neutral word embeddings (embneutralsubscriptembneutral\\text{emb}_{\\text{neutral}}emb start_POSTSUBSCRIPT neutral end_POSTSUBSCRIPT) \nOutput: Debiased word embeddings \nInitialize neural network Nâ¢NððNNitalic_N italic_N with input dimension as embedding dimension and output dimension as embedding dimension; \nPass embbiasedsubscriptembbiased\\text{emb}_{\\text{biased}}emb start_POSTSUBSCRIPT biased end_POSTSUBSCRIPT through Nâ¢NððNNitalic_N italic_N to obtain transformed embeddings; \nCompute TTsuperscriptððT^{T}italic_T start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT as the matrix multiplication of the transpose of outputs of Nâ¢NððNNitalic_N italic_N and the outputs; \nCompute norm1 as â(TTâTâI)âFsubscriptnormâsuperscriptðððð¼ð¹\\|(T^{T}\\cdot T-I)\\|_{F}â¥ ( italic_T start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT â italic_T - italic_I ) â¥ start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT; \nCompute norm2 as âembneutralTâTTâBiasSpaceâFsubscriptnormâsuperscriptsubscriptembneutralðsuperscriptððBiasSpaceð¹\\|\\text{emb}_{\\text{neutral}}^{T}\\cdot T^{T}\\cdot\\text{BiasSpace}\\|_{F}â¥ emb start_POSTSUBSCRIPT neutral end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT â italic_T start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT â BiasSpace â¥ start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT; \nTotal loss is a weighted combination of norm1 and norm2; \nOptimize Nâ¢NððNNitalic_N italic_N using an Adam optimizer; \nOutput normalized embeddings obtained after passing embbiasedsubscriptembbiased\\text{emb}_{\\text{biased}}emb start_POSTSUBSCRIPT biased end_POSTSUBSCRIPT through Nâ¢NððNNitalic_N italic_N; \nAlgorithm 2 Neural Network Approach Report issue for preceding element ![Refer to caption](https://arxiv.org/html/x2.png) Figure 2: A step-by-step visualization of our downstream testing process to effectively evaluate DeepSoftDebias Report issue for preceding element\n##  4 Effects of LLM Size and Dependency of Network Size\nReport issue for preceding element\nThe debiasing performance of word embeddings depends on the size of the embeddings and the depth of the debiasing neural network, rather than the number of parameters of the language model. We observe in [11](https://arxiv.org/html/2402.11512v2#A3.F11 \"Figure 11 â£ Appendix C Downstream Testing Results â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\") Smaller models, such as bge-small Xiao et al. ([2023](https://arxiv.org/html/2402.11512v2#bib.bib33)) and DeBERTa-v3-base He et al. ([2023](https://arxiv.org/html/2402.11512v2#bib.bib10)) or DeBERTa-v3-large, can be debiased effectively by a single-layer neural network. Larger models, such as Llama-2 Touvron et al. ([2023](https://arxiv.org/html/2402.11512v2#bib.bib31)), Alpaca Taori et al. ([2023](https://arxiv.org/html/2402.11512v2#bib.bib30)) and Yi-6b 01.ai ([2024](https://arxiv.org/html/2402.11512v2#bib.bib1)) need a more complex debiasing neural network. For embedding dimensions around 2000, a two-layer neural network is sufficient, while for larger embedding dimensions, a three-layer neural network is required to achieve good debiasing results. Additionally, the debiasing neural network and the optimization algorithm need to be hyperparameter-tuned, such as adjusting the learning rate, to get optimal results. The hyperparameters may vary depending on the model size, the embedding dimension, and the debiasing task. Therefore, a systematic search for the best hyperparameters is necessary to ensure the effectiveness of the debiasing process.\nReport issue for preceding element\n##  5 Results\nReport issue for preceding element\nThe results obtained are described in the following subsections.\nReport issue for preceding element\n###  5.1 Mean Average Cosine Similarity (MAC)\nReport issue for preceding element\nMAC Manzini et al. ([2019](https://arxiv.org/html/2402.11512v2#bib.bib17)) is a metric used to quantify semantic associations between word classes and attributes. MAC takes word embeddings, targets (representing classes), and attributes as inputs. By computing the mean cosine distance between target words and attribute sets, MAC offers a concise measure of semantic proximity. This metric provides valuable insights into the contextual semantics encoded within word embeddings. Table [1](https://arxiv.org/html/2402.11512v2#S5.T1 \"Table 1 â£ 5.1 Mean Average Cosine Similarity \\(MAC\\) â£ 5 Results â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\") shows that the word embeddings debiased in the direction of race and gender have comparable increases in their average MAC of 0.64, whereas word embeddings debiased in the direction of religion have an increase in MAC of around 0.61. We see that our debiasing procedure categorically moves MAC scores closer to 1.0. This indicates an increase in cosine distance. Further, the associated P-values indicate these changes are statistically significant. This demonstrates that our approach for multiclass debiasing decreases bias in the word embeddings. We provide visual representations of the efficiency of DeepSoftDebias at removing gender bias, racial bias, and religion bias in Appendix [A](https://arxiv.org/html/2402.11512v2#A1 \"Appendix A MAC Scores of DeepSoftDebias â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\").\nReport issue for preceding element\nModel | Variant | Topic | BMAC | NSMAC | SS | CMS | CSS | CAS  \n---|---|---|---|---|---|---|---|---  \nYi | Yi-6B | Gender | 0.148 | 0.964 | 55.372 | 49.620 | 58.970 | 37.250  \nAlpaca | Alpaca-7B | 0.612 | 0.816 | 53.306 | 48.850 | 57.690 | 37.250  \nBAAI | bge-base-en-v1.5 | 0.471 | 0.997 | 50.000 | 48.090 | 42.310 | 58.820  \nBAAI | bge-large-en-v1.5 | 0.404 | 0.983 | 49.174 | 50.380 | 50.640 | 51.960  \nZephyr | Zephyr-7B-beta | 0.393 | 0.981 | 52.893 | 46.950 | 59.620 | 29.410  \nMistral | e5-mistral-7b-instruct | 0.343 | 0.971 | 52.893 | 48.090 | 55.770 | 38.240  \nLlama 2 | Llama-2-7b-hf | 0.182 | 0.964 | 48.347 | 44.660 | 57.690 | 26.470  \nSalesforce | SFR-Embedding-Mistral | 0.343 | 0.971 | 50.000 | 45.420 | 50.000 | 40.200  \nFalcon | falcon-7b | 0.011 | 0.964 | 51.240 | 48.850 | 60.900 | 32.350  \nYi | Yi-6B | Race | 0.111 | 0.964 | 46.209 | 64.150 | 66.170 | 53.660  \nAlpaca | Alpaca-7B | 0.655 | 0.938 | 52.357 | 41.280 | 41.540 | 46.340  \nBAAI | bge-base-en-v1.5 | 0.496 | 0.992 | 49.590 | 44.770 | 46.250 | 36.590  \nBAAI | bge-large-en-v1.5 | 0.404 | 0.990 | 50.922 | 40.890 | 40.690 | 51.220  \nZephyr | Zephyr-7B-beta | 0.419 | 0.992 | 49.283 | 42.250 | 41.330 | 60.980  \nMistral | e5-mistral-7b-instruct | 0.380 | 0.999 | 50.922 | 52.520 | 52.680 | 60.980  \nLlama 2 | Llama-2-7b-hf | 0.175 | 0.990 | 50.410 | 45.930 | 46.680 | 46.340  \nSalesforce | SFR-Embedding-Mistral | 0.381 | 0.994 | 51.639 | 49.030 | 50.750 | 39.020  \nFalcon | falcon-7b | 0.010 | 0.985 | 50.922 | 46.710 | 46.900 | 53.660  \nYi | Yi-6B | Religion | 0.147 | 0.984 | 52.564 | 47.620 | 48.480 | 33.330  \nAlpaca | Alpaca-7B | 0.676 | 0.823 | 51.282 | 80.000 | 82.830 | 33.330  \nBAAI | bge-base-en-v1.5 | 0.497 | 0.990 | 46.154 | 59.050 | 61.620 | 16.670  \nBAAI | bge-large-en-v1.5 | 0.406 | 0.985 | 51.282 | 60.000 | 61.620 | 33.330  \nZephyr | Zephyr-7B-beta | 0.465 | 0.996 | 51.282 | 48.570 | 50.510 | 16.670  \nMistral | e5-mistral-7b-instruct | 0.436 | 0.985 | 52.564 | 52.380 | 51.520 | 66.670  \nLlama 2 | Llama-2-7b-hf | 0.202 | 1.003 | 44.872 | 64.760 | 66.670 | 33.330  \nSalesforce | SFR-Embedding-Mistral | 0.437 | 0.988 | 51.282 | 40.950 | 39.390 | 66.670  \nFalcon | falcon-7b | 0.009 | 0.998 | 48.718 | 50.480 | 51.520 | 33.330  \nTable 1: Quantitative analysis for DeepSoftDebias using BiasedMAC (BMAC), New SoftMAC (NSMAC), StereotypeScore (SS), Crows Metric Score (CMS), Crows Stereotype Score (CSS), Crows Antistereotype Score (CAS). The best performance is highlighted in bold. Report issue for preceding element\n###  5.2 Stereotype Score\nReport issue for preceding element\nOur research focuses on evaluating and mitigating stereotypical bias in natural language inference tasks using the Stereoset dataset. This dataset comprises pairs of sentences differing only in the substitution of words related to social groups like gender, race, or religion. The objective is to predict their relationship as same, entailment, or contradiction. We introduce a method aimed at reducing bias in word embeddings, with Sâ¢SððSSitalic_S italic_S values closer to 50 indicating decreased bias. Table [2](https://arxiv.org/html/2402.11512v2#S5.T2 \"Table 2 â£ 5.2 Stereotype Score â£ 5 Results â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\") presents DeepSoftDebiasâs results alongside existing approaches on the Stereoset dataset. Notably, DeepSoftDebias achieves the lowest Sâ¢SððSSitalic_S italic_S across all social groups, demonstrating its effectiveness in bias reduction. Particularly impressive is DeepSoftDebiasâs performance in the gender and race categories, where it significantly outperforms existing methods. For instance, with the SFR-Embedding-Mistral Jiang et al. ([2023](https://arxiv.org/html/2402.11512v2#bib.bib11)) model, DeepSoftDebias achieves an Sâ¢SððSSitalic_S italic_S of 50 for gender and 50.409 for race using the Llama-2-7b model. Additionally, DeepSoftDebias attains a score of 51.282 (or 48.717) for the Zephyr-7b-beta Tunstall et al. ([2023](https://arxiv.org/html/2402.11512v2#bib.bib32)) (or Alpaca-7b Taori et al. ([2023](https://arxiv.org/html/2402.11512v2#bib.bib30))) group. We present an illustration of these scores in Fig. [6](https://arxiv.org/html/2402.11512v2#A2.F6 \"Figure 6 â£ Appendix B Stereoset Scores of DeepSoftDebias â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\").\nReport issue for preceding element\nStereotype Score (SS)  \n---  \nStereoset | Gender | Race | Religion  \nFineDeb | 53.27 | 50.82 | 50.39  \nCDA | 59.61 | 56.73 | 58.37  \nINLP | 57.25 | 57.29 | 60.31  \nSelf-Debias | 59.34 | 54.30 | 57.26  \nSentence Debias | 59.37 | 57.78 | 58.73  \nDeepSoftDebias | 50.00 | 50.41 | 51.28  \nTable 2: StereoSet evaluation. Closer to 50 is better for SS. The best performance is highlighted in bold while the next best is underlined). Report issue for preceding element\n###  5.3 Crows-Pairs Dataset\nReport issue for preceding element\nOur study evaluates social bias in natural language generation tasks using the CrowS Pairs dataset, comprising pairs of sentences differing in their degree of bias. By ranking these sentences according to bias level, we quantify the effectiveness of various methods in reducing bias in word embeddings. But as our work is based on word embeddings instead of getting the log-likelihood of the next token from the language model, we compute the average sentence vector for the common parts shared between two sentences. Next, we compare the similarity of this average sentence vector with the uncommon part (i.e., the modified tokens) using word embeddings. By doing so, we capture the semantic differences between stereotypical and non-stereotypical components within the sentence pairs. The rest of the metric remains the same.\nReport issue for preceding element\nTable [3](https://arxiv.org/html/2402.11512v2#S5.T3 \"Table 3 â£ 5.3 Crows-Pairs Dataset â£ 5 Results â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\") presents DeepSoftDebiasâs results alongside existing approaches on the CrowS Pairs dataset. Notably, DeepSoftDebias achieves scores closest to 50 across all social groups, indicating a significant reduction in social bias. The metric used here is defined in Eq. ([2](https://arxiv.org/html/2402.11512v2#S5.E2 \"2 â£ 5.3 Crows-Pairs Dataset â£ 5 Results â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\")) as follows:\nReport issue for preceding element |  Metric score: â¢(stereo_score+antistereo_score)Ã100NMetric score: stereo_scoreantistereo_score100ð\\text{Metric score: }\\frac{{(\\text{{stereo\\\\_score}}+\\text{{antistereo\\\\_score}}% )\\times 100}}{N}Metric score: divide start_ARG ( stereo_score + antistereo_score ) Ã 100 end_ARG start_ARG italic_N end_ARGReport issue for preceding element |  | (2)  \n---|---|---|---  \nwhere stereoscore is the number of stereotypical samples that agree with their label direction and antistereoscore is the number of anti-stereotypical samples that agree with their label direction. Particularly noteworthy is _DeepSoftDebias_ âs superior performance in the gender and religion categories. For instance, with the Yi-6B model, DeepSoftDebias achieves a score of 49.62 for gender and 50.48 for religion with the falcon-7b model. Similarly, using the SFR-Embedding-Mistral model, DeepSoftDebias achieves a score of 49.03 for race biasing the SFR-Embedding-Mistral model. These results underscore the effectiveness of DeepSoftDebias in mitigating social bias in word embeddings. We depict the variation of these scores in Fig. [8](https://arxiv.org/html/2402.11512v2#A2.F8 \"Figure 8 â£ Appendix B Stereoset Scores of DeepSoftDebias â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\").\nReport issue for preceding element\nCrows Pairs Metric Score (CMS)  \n---  \nCrows Pairs Dataset | Gender | Race | Religion  \nFineDeb | 54.58 | 65.24 | 44.76  \nCDA | 56.11 | 56.70 | 60.00  \nINLP | 51.15 | 67.96 | 60.95  \nSelf-Debias | 52.29 | 56.70 | 56.19  \nSentence Debias | 52.29 | 62.72 | 63.81  \nDeepSoftDebias | 50.38 | 49.07 | 50.48  \nTable 3: Crows Pairs evaluation. Metric score for every demographic. Closer to 50 is better for the metric (best; next best). Report issue for preceding element\n##  6 DownStream Results\nReport issue for preceding element\nModel | Variant |  Bias Direction |  Biased Text Class. Acc. |  Debiased Text Class. Acc. |  Biased NER Macro F1 Avg. |  Debiased NER Macro F1 Avg.  \n---|---|---|---|---|---|---  \nMistral | e5-mistral-7b-instruct | Gender | 0.809 | 0.810 | 0.385 | 0.433  \nZephyr | Zephyr-7B-beta | 0.806 | 0.810 | 0.368 | 0.429  \nSalesforce | SFR-Embedding-Mistral | 0.807 | 0.821 | 0.373 | 0.428  \nYi | Yi-6B | 0.748 | 0.782 | 0.378 | 0.423  \nAlpaca | Alpaca-7B | 0.745 | 0.729 | 0.349 | 0.391  \nBAAI | bge-large-en-v1.5 | 0.831 | 0.822 | 0.456 | 0.421  \nBAAI | bge-base-en-v1.5 | 0.831 | 0.822 | 0.453 | 0.392  \nMistral | e5-mistral-7b-instruct | Race | 0.811 | 0.817 | 0.362 | 0.435  \nZephyr | Zephyr-7B-beta | 0.806 | 0.814 | 0.393 | 0.443  \nSalesforce | SFR-Embedding-Mistral | 0.810 | 0.818 | 0.382 | 0.413  \nYi | Yi-6B | 0.748 | 0.782 | 0.378 | 0.423  \nAlpaca | Alpaca-7B | 0.751 | 0.729 | 0.358 | 0.373  \nBAAI | bge-large-en-v1.5 | 0.832 | 0.821 | 0.473 | 0.424  \nBAAI | bge-base-en-v1.5 | 0.830 | 0.813 | 0.457 | 0.433  \nMistral | e5-mistral-7b-instruct | Religion | 0.808 | 0.815 | 0.385 | 0.437  \nZephyr | Zephyr-7B-beta | 0.805 | 0.812 | 0.389 | 0.444  \nSalesforce | SFR-Embedding-Mistral | 0.808 | 0.817 | 0.389 | 0.440  \nYi | Yi-6B | 0.750 | 0.769 | 0.384 | 0.439  \nAlpaca | Alpaca-7B | 0.751 | 0.726 | 0.364 | 0.389  \nBAAI | bge-large-en-v1.5 | 0.830 | 0.816 | 0.457 | 0.419  \nBAAI | bge-base-en-v1.5 | 0.830 | 0.817 | 0.459 | 0.421  \nTable 4: Downstream testing results with embeddings debiased using DeepSoftDebias. The first two columns represent results for downstream performance on sentiment analysis. The second two columns represent results for downstream performance on NER. The best performance is highlighted in bold. Report issue for preceding element\nDebiasing Direction | Biased | Baseline |  Baseline + Adam |  DeepSoftBias + SGD |  DeepSoftBias + Adam  \n---|---|---|---|---|---  \nGender | 0.390 | 0.623 | 0.799 | 0.893 | 0.982  \nRace | 0.404 | 0.656 | 0.824 | 0.984 | 0.987  \nReligion | 0.406 | 0.623 | 0.812 | 0.966 | 0.983  \nTable 5: Ablations to characterize various design decisions in the development of DeepSoftDebias. We start with the transformation matrix, then make incremental additions till we reach the proposed architecture of the DeepSoftDebias network. Report issue for preceding element\n###  6.1 Sentiment Classification\nReport issue for preceding element\nIn our study, we employ downstream testing to assess the utility of embeddings debiased using DeepSoftDebias across two key natural language processing tasks: text classification and named entity recognition (NER). Utilizing the IMDB Sentiment Classification dataset Ä°lhan TarÄ±mer et al. ([2019](https://arxiv.org/html/2402.11512v2#bib.bib35)) for text classification, featuring labeled movie reviews as positive or negative, we compute the average sentence vectors using both original and debiased embeddings. Training XGBoost Chen and Guestrin ([2016](https://arxiv.org/html/2402.11512v2#bib.bib5)) classifiers on these vectors, we compare their accuracy on the test set, recognizing accuracy as a straightforward metric for binary classification tasks like sentiment analysis. Notably, our results reveal a performance improvement when debiasing in the gender and religion directions, whereas a slight decrease in performance is observed in the case of race debiasing. We provide a visual representation of these results in Fig. [9](https://arxiv.org/html/2402.11512v2#A3.F9 \"Figure 9 â£ Appendix C Downstream Testing Results â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\").\nReport issue for preceding element\n###  6.2 Named Entity Recognition (NER)\nReport issue for preceding element\nIn our research, we examine the performance of debiased embeddings in the domain of named entity recognition (NER) using the Reuters subset of the CrossNER Liu et al. ([2020](https://arxiv.org/html/2402.11512v2#bib.bib16)) dataset. This dataset comprises news domain sentences annotated with four entity types: person, location, organization, and product. Employing a simple BiLSTM model, we input padded arrays of embeddings for each sentence and trained the model on the dataset. We evaluate the modelsâ performance on the test set using the macro-averaged F1-score, a metric that balances precision and recall, crucial for accurate entity identification and classification. To mitigate potential bias towards more frequent entity types, we adopt macro-averaging, allotting equal importance to each entity type. Remarkably, our findings indicate a slight performance boost when using debiased embeddings in all three directions compared to biased embeddings. We provide a visual representation of these results in Fig. [10](https://arxiv.org/html/2402.11512v2#A3.F10 \"Figure 10 â£ Appendix C Downstream Testing Results â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\").\nReport issue for preceding element\n##  7 Ablation Experiments\nReport issue for preceding element\nIn our study, we conduct ablation experiments to assess the effectiveness of various debiasing techniques in the realm of natural language processing. These techniques encompassed five distinct scenarios: the utilization of debiased embeddings, the application of the original soft debiasing method, the integration of the original debiasing method with the Adam optimizer, the incorporation of new neural networks trained with the debiasing method alongside the SGD optimizer, and finally, our proposed approach, which combines neural networks trained with the debiasing method and the Adam optimizer.\nReport issue for preceding element\nThrough rigorous experimentation across three biasing directions, we systematically analyze the performance of each method. Our results reveal a consistent trend of incremental improvements as we transitioned from one method to the next. Notably, DeepSoftDebias, emerged as the standout performer, boasting the highest mean average cosine similarity score across all evaluated scenarios. In addition, our analysis revealed that substituting the transformation matrix with our neural network approach resulted in the most significant enhancement in the efficacy of the debiasing method. This observation underscores the pivotal role played by neural networks in maximizing the effectiveness of the debiasing techniques. We present a visualization of the results of our Ablation experiments in Table [5](https://arxiv.org/html/2402.11512v2#S6.T5 \"Table 5 â£ 6 DownStream Results â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\").\nReport issue for preceding element\nThis empirical evidence underscores the robustness and efficacy of our proposed approach in mitigating bias within natural language processing systems. By combining state-of-the-art debiasing techniques with advanced optimization strategies, we have unlocked a powerful methodological framework for enhancing the fairness and accuracy of language models.\nReport issue for preceding element\n##  8 Discussion\nReport issue for preceding element\nIn this section, we summarise the answers to our research questions.\nReport issue for preceding element\n###  8.1 RQ1\nReport issue for preceding element\nWe find that DeepSoftDebias outperforms state-of-the-art methods, and does so without negatively affecting downstream task performance. We make this conclusion after exhaustive testing on several models, and datasets and evaluating several metrics.\nReport issue for preceding element\n###  8.2 RQ2\nReport issue for preceding element\nWe find that size and complexity do affect the ability of debiasing models. Specifically, we make the following observations about DeepSoftDebias:\nReport issue for preceding element\n  * â¢\nA single layer neural network can effectively de-bias embeddings with dimâ¤1024dim1024\\text{dim}\\leq 1024dim â¤ 1024.\nReport issue for preceding element\n  * â¢\nA two-layer neural network can effectively debias embeddings with dimâ¤2048dim2048\\text{dim}\\leq 2048dim â¤ 2048.\nReport issue for preceding element\n  * â¢\nA two-layer neural network with an increased layer size can effectively de-bias embeddings with dimâ¤4096dim4096\\text{dim}\\leq 4096dim â¤ 4096.\nReport issue for preceding element\n  * â¢\nA three-layer neural network can effectively debias embeddings with dimâ¤4450dim4450\\text{dim}\\leq 4450dim â¤ 4450.\nReport issue for preceding element\n\n\nAs a step for future work, we are curious to investigate scaling patterns to a further extent.\nReport issue for preceding element\n###  8.3 RQ3\nReport issue for preceding element\nWhile debiasing techniques in general can affect the downstream performance of models, we test DeepSoftDebias on multiple challenging downstream tasks and report that our proposed approach, to a large extent, does not negatively influence the performance of different downstream tasks. Remarkably, we see an improvement when using our debiased embeddings for some downstream tasks.\nReport issue for preceding element\n###  8.4 RQ4\nReport issue for preceding element\nWe find that while DeepSoftDebias is effective at reducing bias across gender, race, and religion. We conclude this after testing on multiple embeddings, and multiple datasets and evaluating on multiple performance metrics. As a step for future work, we are curious to investigate whether our proposed approach works towards other forms of bias as well.\nReport issue for preceding element\n##  9 Conclusion\nReport issue for preceding element\nIn this paper, we propose DeepSoftDebias, an approach that leverages neural networks to reduce bias in large language model embeddings. We perform an exhaustive series of tests using multiple performance metrics, state-of-the-art datasets, and downstream tasks to ensure that our debiasing technique is robust, efficient, and accurate. In the future, it would be interesting to see how this method translates to multilingual datasets since bias is language and culture-specific. We hope that this research paves the way for future endeavors that look to make large language models fair, ethical, and bias-free.\nReport issue for preceding element\n##  10 Limitations\nReport issue for preceding element\nWhile we do perform exhaustive analysis to test our proposed methodology, our study is monolingual and covers datasets only in English. Consequently, our downstream tasks are also tested only in English. Further, we were unable to test on API-based models at this time.\nReport issue for preceding element\n##  11 Ethics Statement\nReport issue for preceding element\nWe understand that bias can be defined in various ways, and itâs not necessarily ideal for a language model to treat all users exactly the same without considering demographics. There are situations where certain topics require careful handling to avoid perpetuating harmful stereotypes against marginalized communities. Using specific bias metrics might suggest they encompass all negative social impacts across different groups, but we recognize that existing metrics may not capture all nuances in treatment across demographics. Therefore, any benchmark for bias needs to continually evolve to better understand and address these issues as they affect different communities.\nReport issue for preceding element\nThe definitions of morality and bias are shaped by cultural perspectives, resulting in diverse interpretations among individuals. Consequently, we do not claim that this work provides an objective or exhaustive measure of any of these concepts.\nReport issue for preceding element\n## References\nReport issue for preceding element\n  * 01.ai (2024)â 01.ai. 2024.  [Yi](https://www.01.ai/).  2024. \n  * Baligudam (2022)â R Baligudam. 2022.  A systematic study of gender and religion bias in stories.  Masterâs thesis, University of Twente. \n  * Bolukbasi et al. (2016)â Tolga Bolukbasi, Kai-Wei Chang, James Y Zou, Venkatesh Saligrama, and Adam T Kalai. 2016.  Man is to computer programmer as woman is to homemaker? debiasing word embeddings.  _Advances in neural information processing systems_ , 29. \n  * Bordia and Bowman (2019)â Shikha Bordia and Samuel R Bowman. 2019.  Identifying and reducing gender bias in word-level language models.  _arXiv preprint arXiv:1904.03035_. \n  * Chen and Guestrin (2016)â Tianqi Chen and Carlos Guestrin. 2016.  [Xgboost: A scalable tree boosting system](https://doi.org/10.1145/2939672.2939785).  In _Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining_ , KDD â16. ACM. \n  * de Vassimon Manela et al. (2021)â Daniel de Vassimon Manela, David Errington, Thomas Fisher, Boris van Breugel, and Pasquale Minervini. 2021.  Stereotype and skew: Quantifying gender bias in pre-trained and fine-tuned language models.  In _Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume_ , pages 2232â2242. \n  * Dev et al. (2020)â Sunipa Dev, Tao Li, Jeff M Phillips, and Vivek Srikumar. 2020.  On measuring and mitigating biased inferences of word embeddings.  In _Proceedings of the AAAI Conference on Artificial Intelligence_ , volume 34, pages 7659â7666. \n  * Devlin et al. (2019)â Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.  [Bert: Pre-training of deep bidirectional transformers for language understanding](http://arxiv.org/abs/1810.04805). \n  * Gonen and Goldberg (2019)â Hila Gonen and Yoav Goldberg. 2019.  Lipstick on a pig: Debiasing methods cover up systematic gender biases in word embeddings but do not remove them.  _arXiv preprint arXiv:1903.03862_. \n  * He et al. (2023)â Pengcheng He, Jianfeng Gao, and Weizhu Chen. 2023.  [Debertav3: Improving deberta using electra-style pre-training with gradient-disentangled embedding sharing](http://arxiv.org/abs/2111.09543). \n  * Jiang et al. (2023)â Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et al. 2023.  Mistral 7b.  _arXiv preprint arXiv:2310.06825_. \n  * Kingma and Ba (2017)â Diederik P. Kingma and Jimmy Ba. 2017.  [Adam: A method for stochastic optimization](http://arxiv.org/abs/1412.6980). \n  * Kirk et al. (2021)â Hannah Rose Kirk, Yennie Jun, Filippo Volpin, Haider Iqbal, Elias Benussi, Frederic Dreyer, Aleksandar Shtedritski, and Yuki Asano. 2021.  Bias out-of-the-box: An empirical analysis of intersectional occupational biases in popular generative language models.  _Advances in neural information processing systems_ , 34:2611â2624. \n  * Kotek et al. (2023)â Hadas Kotek, Rikker Dockum, and David Sun. 2023.  Gender bias and stereotypes in large language models.  In _Proceedings of The ACM Collective Intelligence Conference_ , pages 12â24. \n  * Liu et al. (2019)â Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019.  [Roberta: A robustly optimized bert pretraining approach](http://arxiv.org/abs/1907.11692). \n  * Liu et al. (2020)â Zihan Liu, Yan Xu, Tiezheng Yu, Wenliang Dai, Ziwei Ji, Samuel Cahyawijaya, Andrea Madotto, and Pascale Fung. 2020.  [Crossner: Evaluating cross-domain named entity recognition](http://arxiv.org/abs/2012.04373). \n  * Manzini et al. (2019)â Thomas Manzini, Yao Chong Lim, Yulia Tsvetkov, and Alan W Black. 2019.  [Black is to criminal as caucasian is to police: Detecting and removing multiclass bias in word embeddings](http://arxiv.org/abs/1904.04047). \n  * Mikolov et al. (2013)â Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013.  [Efficient estimation of word representations in vector space](http://arxiv.org/abs/1301.3781). \n  * Mozafari et al. (2020)â Marzieh Mozafari, Reza Farahbakhsh, and NoÃ«l Crespi. 2020.  Hate speech detection and racial bias mitigation in social media based on bert model.  _PloS one_ , 15(8):e0237861. \n  * Muennighoff et al. (2022)â Niklas Muennighoff, Nouamane Tazi, LoÃ¯c Magne, and Nils Reimers. 2022.  [Mteb: Massive text embedding benchmark](https://doi.org/10.48550/ARXIV.2210.07316).  _arXiv preprint arXiv:2210.07316_. \n  * Nadeem et al. (2020)â Moin Nadeem, Anna Bethke, and Siva Reddy. 2020.  [Stereoset: Measuring stereotypical bias in pretrained language models](http://arxiv.org/abs/2004.09456). \n  * Nangia et al. (2020)â Nikita Nangia, Clara Vania, Rasika Bhalerao, and Samuel R. Bowman. 2020.  [Crows-pairs: A challenge dataset for measuring social biases in masked language models](http://arxiv.org/abs/2010.00133). \n  * Omiye et al. (2023)â Jesutofunmi A Omiye, Jenna C Lester, Simon Spichak, Veronica Rotemberg, and Roxana Daneshjou. 2023.  Large language models propagate race-based medicine.  _NPJ Digital Medicine_ , 6(1):195. \n  * Papakyriakopoulos et al. (2020)â Orestis Papakyriakopoulos, Simon Hegelich, Juan Carlos Medina Serrano, and Fabienne Marco. 2020.  Bias in word embeddings.  In _Proceedings of the 2020 conference on fairness, accountability, and transparency_ , pages 446â457. \n  * Pennington et al. (2014)â Jeffrey Pennington, Richard Socher, and Christopher D Manning. 2014.  Glove: Global vectors for word representation.  In _Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)_ , pages 1532â1543. \n  * Rabinovich et al. (2018)â Ella Rabinovich, Yulia Tsvetkov, and Shuly Wintner. 2018.  Native language cognate effects on second language lexical choice.  _Transactions of the Association for Computational Linguistics_ , 6:329â342. \n  * Radford et al. (2019)â Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019.  Language models are unsupervised multitask learners. \n  * Robbins and Monro (1951)â Herbert Robbins and Sutton Monro. 1951.  Stochastic approximation and recursive algorithms and applications.  _Biometrika_ , 37(1/2):62â79. \n  * (29)â Fuliang Tang, Kunguang Wu, Zhendong Guo, Shuaishuai Huang, Yingtian Mei, Yuxing Wang, Zeyu Yang, and Shiming Gong.  Large language model (llm) racial bias evaluation. \n  * Taori et al. (2023)â Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. 2023.  Stanford alpaca: An instruction-following llama model.  <https://github.com/tatsu-lab/stanford_alpaca>. \n  * Touvron et al. (2023)â Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. 2023.  [Llama 2: Open foundation and fine-tuned chat models](http://arxiv.org/abs/2307.09288). \n  * Tunstall et al. (2023)â Lewis Tunstall, Edward Beeching, Nathan Lambert, Nazneen Rajani, Kashif Rasul, Younes Belkada, Shengyi Huang, Leandro von Werra, ClÃ©mentine Fourrier, Nathan Habib, Nathan Sarrazin, Omar Sanseviero, Alexander M. Rush, and Thomas Wolf. 2023.  [Zephyr: Direct distillation of lm alignment](http://arxiv.org/abs/2310.16944). \n  * Xiao et al. (2023)â Shitao Xiao, Zheng Liu, Peitian Zhang, and Niklas Muennighoff. 2023.  [C-pack: Packaged resources to advance general chinese embedding](http://arxiv.org/abs/2309.07597). \n  * Yang et al. (2020)â Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, and Quoc V. Le. 2020.  [Xlnet: Generalized autoregressive pretraining for language understanding](http://arxiv.org/abs/1906.08237). \n  * Ä°lhan TarÄ±mer et al. (2019)â Ä°lhan TarÄ±mer, Adil Ãoban, and Arif Emre Kocaman. 2019.  [Sentiment analysis on imdb movie comments and twitter data by machine learning and vector space techniques](http://arxiv.org/abs/1903.11983). \n\n\n## Frequently Asked Questions (FAQs)\nReport issue for preceding element\n  1. 1.\nIs this method effective at removing all kinds of bias? We acknowledge that bias has multiple forms that vary by different social factors, language, culture, and various other factors. We evaluated DeepSoftDebias on gender bias, racial bias, and religious bias and it has proved effective at reducing all of them. We hope that in the future, this method will prove effective in reducing other kinds of biases as well.\nReport issue for preceding element\n  2. 2.\nWhy isnât GPT analyzed in this paper? Given that GPT is an API-based model, we were unable to test it at this time. We hope that one day, this method can be tested even on API-based LLMs.\nReport issue for preceding element\n  3. 3.\nIs the proposed approach open-sourced? Yes, we plan to make all our code available on a GitHub repository.\nReport issue for preceding element\n\n\n## Appendix\nReport issue for preceding element\nThis section provides supplementary material in the form of additional examples, implementation details, etc. to bolster the readerâs understanding of the concepts presented in this work.\nReport issue for preceding element\n##  Appendix A MAC Scores of DeepSoftDebias\nReport issue for preceding element\nFigures [3](https://arxiv.org/html/2402.11512v2#A1.F3 \"Figure 3 â£ Appendix A MAC Scores of DeepSoftDebias â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\"), [4](https://arxiv.org/html/2402.11512v2#A1.F4 \"Figure 4 â£ Appendix A MAC Scores of DeepSoftDebias â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\"), and [5](https://arxiv.org/html/2402.11512v2#A1.F5 \"Figure 5 â£ Appendix A MAC Scores of DeepSoftDebias â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\") illustrate how DeepSoftDebias reduces bias in LLM embeddings.\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/x3.png) Figure 3: A visual representation of how DeepSoftDebias reduces gender bias in large language model embeddings. Report issue for preceding element ![Refer to caption](https://arxiv.org/html/x4.png) Figure 4: A visual representation of how DeepSoftDebias reduces racial bias in large language model embeddings. Report issue for preceding element ![Refer to caption](https://arxiv.org/html/x5.png) Figure 5: A visual representation of how DeepSoftDebias reduces religion bias in large language model embeddings. Report issue for preceding element\n##  Appendix B Stereoset Scores of DeepSoftDebias\nReport issue for preceding element\nFigures [6](https://arxiv.org/html/2402.11512v2#A2.F6 \"Figure 6 â£ Appendix B Stereoset Scores of DeepSoftDebias â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\") and [8](https://arxiv.org/html/2402.11512v2#A2.F8 \"Figure 8 â£ Appendix B Stereoset Scores of DeepSoftDebias â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\") provide an illustration of word vectors debiased using DeepSoftDebias and their stereoset scores and Crows Metric scores respectively.\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/x6.png) Figure 6: A visual representation of word vectors debiased using DeepSoftDebias and their stereotype scores across gender, race and religion respectively. Report issue for preceding element ![Refer to caption](https://arxiv.org/html/x7.png) Figure 7: A visual representation of word vectors debiased using DeepSoftDebias and their Crows Metric score across gender, race and religion respectively. Report issue for preceding element ![Refer to caption](https://arxiv.org/html/x8.png) Figure 8: A visual representation of word vectors debiased using DeepSoftDebias and their Crows Metric scores across gender, race and religion respectively. Report issue for preceding element\n##  Appendix C Downstream Testing Results\nReport issue for preceding element\nFigures [9](https://arxiv.org/html/2402.11512v2#A3.F9 \"Figure 9 â£ Appendix C Downstream Testing Results â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\") and [10](https://arxiv.org/html/2402.11512v2#A3.F10 \"Figure 10 â£ Appendix C Downstream Testing Results â£ From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings\") present an illustration of the results of various downstream tasks and their performance evaluation.\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/x9.png) Figure 9: An illustration of the results of downstream testing on NER. We compare the performance of biased and debaised embeddings in the directions of gender, race, and religion respectively. Report issue for preceding element ![Refer to caption](https://arxiv.org/html/x10.png) Figure 10: An illustration of results of downstream testing on sentiment analysis. We compare the performance of biased and debaised embeddings in the directions of gender, race, and religion respectively. Report issue for preceding element ![Refer to caption](https://arxiv.org/html/x11.png) Figure 11: An illustration analysis of number of layers in debiasing neural network vs. embedding dimension. We can see the varying performance of the 3 different sizes according to the embedding dimension of the LM it is used with. Report issue for preceding element\nGenerated by [ L A T E xml ![\\[LOGO\\]](https://arxiv.org/html/2402.11512v2) ](https://math.nist.gov/~BMiller/LaTeXML/)\n## Instructions for reporting errors\nWe are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:\n  * Click the \"Report Issue\" button.\n  * Open a report feedback form via keyboard, use \"**Ctrl + ?** \".\n  * Make a text selection and click the \"Report Issue for Selection\" button near your cursor.\n  * You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.\n\n\nOur team has already identified [the following issues](https://github.com/arXiv/html_feedback/issues). We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.\nHave a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a [list of packages that need conversion](https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML), and welcome [developer contributions](https://github.com/brucemiller/LaTeXML/issues).\nReport Issue\n##### Report Github Issue\nTitle:Content selection saved. Describe the issue below:Description:\nSubmit without GithubSubmit in Github\nReport Issue for Selection\n"
  },
  {
    "link": "https://arxiv.org/html/2403.08701v2",
    "raw_content": "[ ![logo](https://services.dev.arxiv.org/html/static/arxiv-logomark-small-white.svg) Back to arXiv ](https://arxiv.org/)\n[ ](https://arxiv.org/abs/2403.08701v2) [ ](javascript:toggleColorScheme\\(\\) \"Toggle dark/light mode\")\n[ ![logo](https://services.dev.arxiv.org/html/static/arxiv-logo-one-color-white.svg) Back to arXiv ](https://arxiv.org/)\nThis is **experimental HTML** to improve accessibility. We invite you to report rendering errors. Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off. Learn more [about this project](https://info.arxiv.org/about/accessible_HTML.html) and [help improve conversions](https://info.arxiv.org/help/submit_latex_best_practices.html). \n[Why HTML?](https://info.arxiv.org/about/accessible_HTML.html) [Report Issue](https://arxiv.org/html/2403.08701v2#myForm) [Back to Abstract](https://arxiv.org/abs/2403.08701v2) [Download PDF](https://arxiv.org/pdf/2403.08701v2) [ ](javascript:toggleColorScheme\\(\\) \"Toggle dark/light mode\")\n## Table of Contents\n  1. [1 Introduction](https://arxiv.org/html/2403.08701v2#S1 \"1 Introduction â£ Review of Generative AI Methods in Cybersecurity\")\n    1. [1.1 The Challenges of GenAI](https://arxiv.org/html/2403.08701v2#S1.SS1 \"1.1 The Challenges of GenAI â£ 1 Introduction â£ Review of Generative AI Methods in Cybersecurity\")\n    2. [1.2 Related Works](https://arxiv.org/html/2403.08701v2#S1.SS2 \"1.2 Related Works â£ 1 Introduction â£ Review of Generative AI Methods in Cybersecurity\")\n  2. [2 Attacking GenAI](https://arxiv.org/html/2403.08701v2#S2 \"2 Attacking GenAI â£ Review of Generative AI Methods in Cybersecurity\")\n    1. [2.1 Jailbreaks](https://arxiv.org/html/2403.08701v2#S2.SS1 \"2.1 Jailbreaks â£ 2 Attacking GenAI â£ Review of Generative AI Methods in Cybersecurity\")\n    2. [2.2 Reverse psychology](https://arxiv.org/html/2403.08701v2#S2.SS2 \"2.2 Reverse psychology â£ 2 Attacking GenAI â£ Review of Generative AI Methods in Cybersecurity\")\n    3. [2.3 Prompt injection](https://arxiv.org/html/2403.08701v2#S2.SS3 \"2.3 Prompt injection â£ 2 Attacking GenAI â£ Review of Generative AI Methods in Cybersecurity\")\n  3. [3 Cyber Offense](https://arxiv.org/html/2403.08701v2#S3 \"3 Cyber Offense â£ Review of Generative AI Methods in Cybersecurity\")\n    1. [3.1 Social engineering](https://arxiv.org/html/2403.08701v2#S3.SS1 \"3.1 Social engineering â£ 3 Cyber Offense â£ Review of Generative AI Methods in Cybersecurity\")\n    2. [3.2 Phishing emails](https://arxiv.org/html/2403.08701v2#S3.SS2 \"3.2 Phishing emails â£ 3 Cyber Offense â£ Review of Generative AI Methods in Cybersecurity\")\n    3. [3.3 Automated hacking](https://arxiv.org/html/2403.08701v2#S3.SS3 \"3.3 Automated hacking â£ 3 Cyber Offense â£ Review of Generative AI Methods in Cybersecurity\")\n    4. [3.4 Attack payload generation](https://arxiv.org/html/2403.08701v2#S3.SS4 \"3.4 Attack payload generation â£ 3 Cyber Offense â£ Review of Generative AI Methods in Cybersecurity\")\n    5. [3.5 Malware Code Generation](https://arxiv.org/html/2403.08701v2#S3.SS5 \"3.5 Malware Code Generation â£ 3 Cyber Offense â£ Review of Generative AI Methods in Cybersecurity\")\n    6. [3.6 Polymorphic malware](https://arxiv.org/html/2403.08701v2#S3.SS6 \"3.6 Polymorphic malware â£ 3 Cyber Offense â£ Review of Generative AI Methods in Cybersecurity\")\n    7. [3.7 Reversing cryptography](https://arxiv.org/html/2403.08701v2#S3.SS7 \"3.7 Reversing cryptography â£ 3 Cyber Offense â£ Review of Generative AI Methods in Cybersecurity\")\n  4. [4 Cyber Defence](https://arxiv.org/html/2403.08701v2#S4 \"4 Cyber Defence â£ Review of Generative AI Methods in Cybersecurity\")\n    1. [4.1 Cyber Defence Automation](https://arxiv.org/html/2403.08701v2#S4.SS1 \"4.1 Cyber Defence Automation â£ 4 Cyber Defence â£ Review of Generative AI Methods in Cybersecurity\")\n    2. [4.2 Cybersecurity Reporting](https://arxiv.org/html/2403.08701v2#S4.SS2 \"4.2 Cybersecurity Reporting â£ 4 Cyber Defence â£ Review of Generative AI Methods in Cybersecurity\")\n    3. [4.3 Threat Intelligence](https://arxiv.org/html/2403.08701v2#S4.SS3 \"4.3 Threat Intelligence â£ 4 Cyber Defence â£ Review of Generative AI Methods in Cybersecurity\")\n    4. [4.4 Secure Code Generation and Detection](https://arxiv.org/html/2403.08701v2#S4.SS4 \"4.4 Secure Code Generation and Detection â£ 4 Cyber Defence â£ Review of Generative AI Methods in Cybersecurity\")\n    5. [4.5 Vulnerability Detection and Repair](https://arxiv.org/html/2403.08701v2#S4.SS5 \"4.5 Vulnerability Detection and Repair â£ 4 Cyber Defence â£ Review of Generative AI Methods in Cybersecurity\")\n    6. [4.6 Evaluating GenAI for Code Security](https://arxiv.org/html/2403.08701v2#S4.SS6 \"4.6 Evaluating GenAI for Code Security â£ 4 Cyber Defence â£ Review of Generative AI Methods in Cybersecurity\")\n    7. [4.7 Developing Ethical Guidelines](https://arxiv.org/html/2403.08701v2#S4.SS7 \"4.7 Developing Ethical Guidelines â£ 4 Cyber Defence â£ Review of Generative AI Methods in Cybersecurity\")\n    8. [4.8 Incident Response and Digital Forensics](https://arxiv.org/html/2403.08701v2#S4.SS8 \"4.8 Incident Response and Digital Forensics â£ 4 Cyber Defence â£ Review of Generative AI Methods in Cybersecurity\")\n    9. [4.9 Identification of Cyber attacks](https://arxiv.org/html/2403.08701v2#S4.SS9 \"4.9 Identification of Cyber attacks â£ 4 Cyber Defence â£ Review of Generative AI Methods in Cybersecurity\")\n    10. [4.10 Dataset Generation](https://arxiv.org/html/2403.08701v2#S4.SS10 \"4.10 Dataset Generation â£ 4 Cyber Defence â£ Review of Generative AI Methods in Cybersecurity\")\n  5. [5 Implications of Generative AI in Social, Legal, and Ethical Domains](https://arxiv.org/html/2403.08701v2#S5 \"5 Implications of Generative AI in Social, Legal, and Ethical Domains â£ Review of Generative AI Methods in Cybersecurity\")\n    1. [5.1 The Omnipresent Influence of GenAI](https://arxiv.org/html/2403.08701v2#S5.SS1 \"5.1 The Omnipresent Influence of GenAI â£ 5 Implications of Generative AI in Social, Legal, and Ethical Domains â£ Review of Generative AI Methods in Cybersecurity\")\n    2. [5.2 Concerns Over Privacy in GenAI-Enabled Communication](https://arxiv.org/html/2403.08701v2#S5.SS2 \"5.2 Concerns Over Privacy in GenAI-Enabled Communication â£ 5 Implications of Generative AI in Social, Legal, and Ethical Domains â£ Review of Generative AI Methods in Cybersecurity\")\n    3. [5.3 The Risks of Personal Data Exploitation](https://arxiv.org/html/2403.08701v2#S5.SS3 \"5.3 The Risks of Personal Data Exploitation â£ 5 Implications of Generative AI in Social, Legal, and Ethical Domains â£ Review of Generative AI Methods in Cybersecurity\")\n    4. [5.4 Challenges in Data Ownership and Intellectual Property](https://arxiv.org/html/2403.08701v2#S5.SS4 \"5.4 Challenges in Data Ownership and Intellectual Property â£ 5 Implications of Generative AI in Social, Legal, and Ethical Domains â£ Review of Generative AI Methods in Cybersecurity\")\n    5. [5.5 Ethical Dilemmas Stemming from Organizational Misuse of GenAI](https://arxiv.org/html/2403.08701v2#S5.SS5 \"5.5 Ethical Dilemmas Stemming from Organizational Misuse of GenAI â£ 5 Implications of Generative AI in Social, Legal, and Ethical Domains â£ Review of Generative AI Methods in Cybersecurity\")\n    6. [5.6 The Challenge of Hallucinations in GenAI Outputs](https://arxiv.org/html/2403.08701v2#S5.SS6 \"5.6 The Challenge of Hallucinations in GenAI Outputs â£ 5 Implications of Generative AI in Social, Legal, and Ethical Domains â£ Review of Generative AI Methods in Cybersecurity\")\n  6. [6 Discussion](https://arxiv.org/html/2403.08701v2#S6 \"6 Discussion â£ Review of Generative AI Methods in Cybersecurity\")\n  7. [7 Conclusion](https://arxiv.org/html/2403.08701v2#S7 \"7 Conclusion â£ Review of Generative AI Methods in Cybersecurity\")\n  8. [A GPT3.5 and GPT4 OCO-scripting](https://arxiv.org/html/2403.08701v2#A1 \"Appendix A GPT3.5 and GPT4 OCO-scripting â£ Review of Generative AI Methods in Cybersecurity\")\n    1. [A.1 Expression of Abilities in OCO](https://arxiv.org/html/2403.08701v2#A1.SS1 \"A.1 Expression of Abilities in OCO â£ Appendix A GPT3.5 and GPT4 OCO-scripting â£ Review of Generative AI Methods in Cybersecurity\")\n    2. [A.2 Self-replicating simple virus](https://arxiv.org/html/2403.08701v2#A1.SS2 \"A.2 Self-replicating simple virus â£ Appendix A GPT3.5 and GPT4 OCO-scripting â£ Review of Generative AI Methods in Cybersecurity\")\n    3. [A.3 Polymorphism](https://arxiv.org/html/2403.08701v2#A1.SS3 \"A.3 Polymorphism â£ Appendix A GPT3.5 and GPT4 OCO-scripting â£ Review of Generative AI Methods in Cybersecurity\")\n    4. [A.4 Rootkit](https://arxiv.org/html/2403.08701v2#A1.SS4 \"A.4 Rootkit â£ Appendix A GPT3.5 and GPT4 OCO-scripting â£ Review of Generative AI Methods in Cybersecurity\")\n    5. [A.5 Stealthy Data Exfiltration](https://arxiv.org/html/2403.08701v2#A1.SS5 \"A.5 Stealthy Data Exfiltration â£ Appendix A GPT3.5 and GPT4 OCO-scripting â£ Review of Generative AI Methods in Cybersecurity\")\n\n\nReport issue for preceding element\nHTML conversions [sometimes display errors](https://info.dev.arxiv.org/about/accessibility_html_error_messages.html) due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.\nReport issue for preceding element\n  * failed: manyfoot\n\n\nAuthors: achieve the best HTML results from your LaTeX submissions by following these [best practices](https://info.arxiv.org/help/submit_latex_best_practices.html).\nReport issue for preceding element\nLicense: CC BY 4.0\narXiv:2403.08701v2 [cs.CR] 19 Mar 2024\n# Review of Generative AI Methods in Cybersecurity\nReport issue for preceding element\nYagmur Yigit  William J Buchanan  Madjid G Tehrani  Leandros Maglaras \nReport issue for preceding element\n###### Abstract\nReport issue for preceding element\nOver the last decade, Artificial Intelligence (AI) has become increasingly popular, especially with the use of chatbots such as ChatGPT, Googleâs Gemini, and DALL-E. With this rise, large language models (LLMs) and Generative AI (GenAI) have also become more prevalent in everyday use. These advancements strengthen cybersecurityâs defensive posture and open up new attack avenues for adversaries as well. This paper provides a comprehensive overview of the current state-of-the-art deployments of GenAI, covering assaults, jailbreaking, and applications of prompt injection and reverse psychology. This paper also provides the various applications of GenAI in cybercrimes, such as automated hacking, phishing emails, social engineering, reverse cryptography, creating attack payloads, and creating malware. GenAI can significantly improve the automation of defensive cyber security processes through strategies such as dataset construction, safe code development, threat intelligence, defensive measures, reporting, and cyberattack detection. In this study, we suggest that future research should focus on developing robust ethical norms and innovative defense mechanisms to address the current issues that GenAI creates and also further to encourage an impartial approach to its future application in cybersecurity. Moreover, we underscore the importance of interdisciplinary approaches further to bridge the gap between scientific developments and ethical considerations.\nReport issue for preceding element\n###### keywords: \nReport issue for preceding elementGenerative AI, GPT-4, Gemini, Cybersecurity. \n##  1 Introduction\nReport issue for preceding element\nThe past decade has witnessed a transformative leap in the digital domain, significantly impacted by advancements in Artificial Intelligence (AI), Large Language Models (LLMs), and Natural Language Processing (NLP). Starting with the basics of supervised learning, AI and Machine Learning (ML) have rapidly expanded into more complex territories, including unsupervised, semi-supervised, reinforcement, LLM, NLP and deep learning techniques [[1](https://arxiv.org/html/2403.08701v2#bib.bib1)]. The most recent breakthrough in this evolution is the emergence of Generative AI (GenAI) technologies. These technologies make use of deep learning networks to analyse and understand the patterns within huge datasets, enabling them to create new content that resembles the original data. GenAI is versatile enough to produce a wide array of content, such as text, visuals, programming code, and more. In the cybersecurity domain, GenAIâs impact is significant, offering new dimensions to the field. It is anticipated that GenAI will enhance the capabilities of vulnerability scanning tools, offering a depth of vulnerability analysis that surpasses traditional Static Application Security Testing (SAST) methods [[2](https://arxiv.org/html/2403.08701v2#bib.bib2)]. This evolution is promising for future cyber security practices, enhanced by the capabilities of GenAI [[3](https://arxiv.org/html/2403.08701v2#bib.bib3)]. Innovations like Googleâs Gemini and OpenAIâs Chat-Generative Pre-trained Transformer (ChatGPT) are at the forefront of this advancement.\nReport issue for preceding element\nYandex has integrated a next-generation large language model, YandexGPT, into its virtual assistant Alice [[4](https://arxiv.org/html/2403.08701v2#bib.bib4)], making it the first company globally to enhance a virtual assistant with the ability to generate human-like text and brainstorm ideas, accessible through various devices and applications. The main aim of some GenAI tools is to help people with their abilities, sometimes, they show the opposite behaviour, like Microsoftâs chatbot Tay. After the launch, Microsoftâs chatbot Tay was taken offline due to offensive tweets resulting from a vulnerability exploited by a coordinated attack, prompting the company to address this issue and improve the AI with lessons learned from previous experiences, including those with XiaoIce in China, to ensure future interactions reflect the best of humanity without offending [[5](https://arxiv.org/html/2403.08701v2#bib.bib5)]. Moreover, some GenAI tools have been developed for different purposes. For example, MITâs Norman, the worldâs first AI described as a psychopath [[6](https://arxiv.org/html/2403.08701v2#bib.bib6)], was trained using captions from a controversial subreddit, emphasising how biased data can lead AI to interpret images with disturbing captions revealing the impact of data on AI behaviour [[7](https://arxiv.org/html/2403.08701v2#bib.bib7)].\nReport issue for preceding element\nGenAI has experienced a notable transformation in recent years, marked by exceptional innovations and rapid advancements [[8](https://arxiv.org/html/2403.08701v2#bib.bib8)] [[9](https://arxiv.org/html/2403.08701v2#bib.bib9)]. The AI timeline started with the emergence of AI as a conceptual scientific discipline in the 1940s and 1950s. The ELIZA chatbot, created between the 1960s and 1970s, was the first GenAI that achieved notoriety. This revolutionary demonstration highlighted the capacity of robots to imitate human speech. The development of AI in analysing sequential data and patterns got more complex and, therefore, more effective in the 80s and 90s, as advanced methods for pattern recognition became more popular. The first variational autoencoder (VAE) exhibited exceptional proficiency in natural language translation. OpenAI developed GPT between the 2000s and 2010s. GenAI models were simultaneously developed, and in the 2020s, a number of innovative platforms and technologies were introduced, including DALL-E, Googleâs Gemini, Falcon AI, and Open AIâs GPT-4. These advancements represent the disciplineâs maturing, enabling unprecedented capabilities for content production, problem-solving, and emulating human intelligence and creativity. They also pave the way for further advancements in this subject. The development timeline of GenAI can be seen in Fig. [1](https://arxiv.org/html/2403.08701v2#S1.F1 \"Figure 1 â£ 1 Introduction â£ Review of Generative AI Methods in Cybersecurity\").\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/x1.png) Figure 1: The timetable for GenAI development. Report issue for preceding element\nLanguage models are essential in many sectors, including commerce, healthcare, and cybersecurity. Their progress shows a concrete path from basic statistical methods to sophisticated neural networks [[10](https://arxiv.org/html/2403.08701v2#bib.bib10)], [[11](https://arxiv.org/html/2403.08701v2#bib.bib11)]. NLP skill development has benefited immensely from the use of LLMs. However, despite these advancements, a number of issues remain, including moral quandaries, the requirement to reduce error rates, and making sure that these models are consistent with our ethical values. To solve these issues, moral monitoring and ongoing development are required.\nReport issue for preceding element\n###  1.1 The Challenges of GenAI\nReport issue for preceding element\nMohammed _et al._ [[12](https://arxiv.org/html/2403.08701v2#bib.bib12)] define key challenges of the use of ChatGPT in cybersecurity, which include analyzing ChatGPTâs impact on cybersecurity, building honeypots, improving code security, abuse in malware development, investigating vulnerabilities, spreading misinformation, cyberattacks on industrial systems, modifying the cyber threat environment, modifying cybersecurity techniques, and evolution of human-centric training. Alawida et al. [[13](https://arxiv.org/html/2403.08701v2#bib.bib13)] also highlight issues related to GenAIâs ability to generate data that should be kept private, including medical details, financial data and personal information.\nReport issue for preceding element\nInnovative methods such as the Mixture of Experts (MoE) architecture offer increased specialization and efficiency. The difficulty of maintaining transparency and ethics in AI systems is also emphasized [[14](https://arxiv.org/html/2403.08701v2#bib.bib14)]. It highlights the need for strong governance structures and interdisciplinary collaboration to fully exploit the advantages of lifelong learning settings and handle their limitations.\nReport issue for preceding element\nIn an extensive progress report on AI Principles, Google outlines their dedication to responsible AI development, highlighting the incorporation of AI governance into all-encompassing risk management frameworks [[15](https://arxiv.org/html/2403.08701v2#bib.bib15)]. Together with other significant legislative actions, this strategic strategy aims to adhere to current international norms and rules, such as the EUâs AI Act and the US Executive Order on AI safety. The report also highlights the need for scientific stringency in AI development through cautious internal management and the use of tools like digital watermarking and GenAI system cards in order to promote AI accountability and transparency. Multi-stakeholder solutions are needed to address the ethical, security, and social challenges that AI technology is currently bringing forth.\nReport issue for preceding element\nGoogleâs Gemini and ChatGPT-4 are the most popular and widely utilized GenAI technologies. Following ethical and safety criteria, ChatGPT-4 by OpenAI can now generate responses that are both coherent and contextually acceptable [[16](https://arxiv.org/html/2403.08701v2#bib.bib16)]. This is because its NLP skills have significantly improved. Its capacity to identify new conversions to chemical compounds and to negotiate tricky legal and moral territory highlights its potential as a pivotal instrument for content moderation and scientific inquiry. Google introduces Gemini, the most recent iteration of Bard, a ground-breaking development in AI technology [[17](https://arxiv.org/html/2403.08701v2#bib.bib17)]. It can process text, code, audio, images, and video and sets new standards for AIâs capabilities, emphasising flexibility, safety, and ethical AI developments. With ChatGPT-4, we also see the rise in AIâs capabilities in the creation of mathematical assistants that can interpret and render mathematical equations [[18](https://arxiv.org/html/2403.08701v2#bib.bib18)]. \nReport issue for preceding element\n###  1.2 Related Works\nReport issue for preceding element\nSome studies in the literature focus on GenAI tools and their performance. For instance, Brown _et al._ have extended the NLP processing by training GPT-3, an autoregressive language model with 175 billion parameters, indicating exceptional few-shot learning capabilities [[19](https://arxiv.org/html/2403.08701v2#bib.bib19)]. Without task-specific training, this model performs well on various NLP tasks, like translation and question-answering. It often matches or surpasses state-of-the-art fine-tuned systems. Romera-Paredes _et al._ have developed FunSearch, an innovative approach combining LLMs with evolutionary algorithms to make significant findings in domains like extremal combinatorics and algorithmic problem-solving [[20](https://arxiv.org/html/2403.08701v2#bib.bib20)]. Their method has notably surpassed previous best-known results by iteratively refining programs that solve complex problems, revealing LLMsâ potential for scientific innovation. This process generates new knowledge and produces interpretable and deployable solutions, proving a notable advancement in applying LLMs for real-world challenges. Lu _et al._ critically examine the capabilities and limitations of multi-modal LLMs, including proprietary models like GPT-4 and Gemini, as well as six open-source counterparts across text, code, image, and video modalities [[21](https://arxiv.org/html/2403.08701v2#bib.bib21)]. Through a comprehensive qualitative analysis of 230 cases, assessing generalizability, trustworthiness, and causal reasoning, the study reveals a significant gap between the performance of the GenAIs and public expectations. These discoveries open up new avenues for study to improve the transparency and dependability of GenAI in cybersecurity and other fields, providing a basis for creating more complex and reliable multi-modal applications. In another work, commonsense thinking across multimodal tasks is evaluated exhaustively, and Googleâs Gemini is compared with OpenAIâs GPT models [[22](https://arxiv.org/html/2403.08701v2#bib.bib22)]. This study explores the strengths and weaknesses of Geminiâs ability to synthesize commonsense information, indicating areas for improvement in its competitive performance in temporal reasoning, social reasoning, and emotion recognition of images. It emphasizes how important it is for GenAI models to develop commonsense reasoning to improve cybersecurity applications.\nReport issue for preceding element\nRecent research [[23](https://arxiv.org/html/2403.08701v2#bib.bib23)] presents a novel approach for assessing the potentially severe hazards associated with GenAI models, such as deceit, manipulation, and cyber-offence features. To enable AI developers to make well-informed decisions about training, deployment, and the application of cybersecurity standards, the suggested methodology highlights the need to increase evaluation benchmarks to assess the harmful capabilities and alignment of AI systems accurately. Another work [[24](https://arxiv.org/html/2403.08701v2#bib.bib24)] provides a thorough analysis that inspired the complex applications of ChatGPT in digital forensic investigations, pointing out the important constraints and promising opportunities that come with GenAI as it is now. Using methodical experimentation, they outline the fine line separating AIâs inventive contributions from the vital requirement of professional human supervision in cybersecurity procedures, opening the door to additional research into integrating LLMs such as GPT-4 into digital forensics and cybersecurity.\nReport issue for preceding element\nThe latest release of CyberMetric presents a novel benchmark dataset that assesses the level of expertise of LLMs in cybersecurity, covering a broad range from risk management to cryptography [[25](https://arxiv.org/html/2403.08701v2#bib.bib25)]. This dataset has gained value from the 10,000 questions that have been verified by human specialists. In a variety of cybersecurity-related topics, this enables a more sophisticated comparison between LLMs and human abilities. With LLMs outperforming humans in multiple cybersecurity domains, the report proposes a shift toward harnessing AIâs analytical capabilities for better security insights and planning. Gehman _et al._ critically examines neural language models that have been trained to generate toxic material to highlight the adverse consequences of toxicity in language generation inside cybersecurity frameworks [[26](https://arxiv.org/html/2403.08701v2#bib.bib26)]. Their comprehensive analysis of controllable text generation techniques to mitigate these threats provides a basis for evaluating the effects of GenAI on cybersecurity policies. It is also emphasized that improving model training and data curation duties is essential. A new method for assessing and improving the security of LLMs for solving Math Word Problems (MWP) is presented [[27](https://arxiv.org/html/2403.08701v2#bib.bib27)]. They have made a substantial contribution to our understanding of LLM vulnerabilities in cybersecurity by emphasizing the importance of maintaining mathematical logic when attacking MWP samples. The importance of resilience in AI systems is highlighted in this study through important and educational computer applications. ChatGPT can simplify the process of launching complex phishing attacks, even for non-programmers, by automating the setup and constructing components of phishing kits [[28](https://arxiv.org/html/2403.08701v2#bib.bib28)]. It highlights the urgent need for better security measures and highlights how difficult it is to protect against the malicious usage of GenAI capabilities.\nReport issue for preceding element\nIn addition to providing innovative approaches to reducing network infrastructure vulnerabilities and organizing diagnostic data, this paper examines the intricate relationship between cybersecurity and GenAI technologies. It seeks to bridge the gap between cutting-edge cybersecurity defences and the threats posed by sophisticated cyberattacks through in-depth study and creative tactics. This study extends our understanding of cyber threats by utilising LLMs such as ChatGPT and Googleâs Gemini. Moreover, it suggests novel approaches to improve network security. It outlines a crucial initial step toward building stronger cybersecurity frameworks that can swiftly and successfully counter the dynamic and always-changing landscape of cyber threats.\nReport issue for preceding element\nSection [2](https://arxiv.org/html/2403.08701v2#S2 \"2 Attacking GenAI â£ Review of Generative AI Methods in Cybersecurity\") explores the techniques used to take advantage of GenAI technology after providing an overview, analyzing different attack routes and their consequences. The design and automation of cyber threats are examined in Section [3](https://arxiv.org/html/2403.08701v2#S3 \"3 Cyber Offense â£ Review of Generative AI Methods in Cybersecurity\"), which focuses on the offensive capabilities made possible by GenAI. However, Section [4](https://arxiv.org/html/2403.08701v2#S4 \"4 Cyber Defence â£ Review of Generative AI Methods in Cybersecurity\") provides an in-depth examination of GenAIâs function in strengthening cyber defences, outlining cutting-edge threat detection, response, and mitigation techniques. We expand on this topic in Section [5](https://arxiv.org/html/2403.08701v2#S5 \"5 Implications of Generative AI in Social, Legal, and Ethical Domains â£ Review of Generative AI Methods in Cybersecurity\"), highlighting the important moral, legal, and societal ramifications of integrating GenAI into cybersecurity procedures. A discussion on the implications of GenAI in cybersecurity is presented in Section [6](https://arxiv.org/html/2403.08701v2#S6 \"6 Discussion â£ Review of Generative AI Methods in Cybersecurity\"), which synthesizes the important discoveries. The paper is concluded in Section [7](https://arxiv.org/html/2403.08701v2#S7 \"7 Conclusion â£ Review of Generative AI Methods in Cybersecurity\").\nReport issue for preceding element\n##  2 Attacking GenAI\nReport issue for preceding element\nGenAI has advanced significantly thanks to tools like ChatGPT and Googleâs Gemini. They have some weaknesses, though. Despite the ethical safeguards built into these models, various tactics can be used to manipulate and take advantage of these systems [[29](https://arxiv.org/html/2403.08701v2#bib.bib29)]. This section explores how the ethical boundaries of GenAI tools are broken, with particular attention to tactics such as the idea of jailbreaks, the use of reverse psychology, and quick injection. These strategies demonstrate how urgently the security protocols of GenAI systems need to be improved and monitored. Some works in the literature focus on the vulnerabilities and sophisticated manipulation tactics of GENAI. Analyzing the vulnerabilities in GenAI highlights the significant security concerns involved with employing advanced AI technology, including the possibility of bypassing security protections via the RabbitHole attack and compromising data privacy through rapid injection [[30](https://arxiv.org/html/2403.08701v2#bib.bib30)] [[31](https://arxiv.org/html/2403.08701v2#bib.bib31)]. According to the analysis, GPT-4 offers significant improvements in NLP. However, it is susceptible to quick injection attacks, which enable the circumvention of safety restrictions and can be used as a weapon for malicious and disinformation purposes. Gupta _et al._ addressed the intricate vulnerabilities of GENAI using ChatGPT [[32](https://arxiv.org/html/2403.08701v2#bib.bib32)]. They emphasized that because these threats are dynamic, protecting these systems requires a proactive and informed strategy. Building on previous results, this part delves into the complex realm of GenAI attacks, which can range from minor adjustments to significant system breaches.\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/5479270/figures/fig-attacking/gpt4-jail.png) Figure 2: The jailbreaking response of ChatGPT 4. Report issue for preceding element ![Refer to caption](https://arxiv.org/html/extracted/5479270/figures/fig-attacking/gpt-jail.png) Figure 3: The jailbreaking response of ChatGPT 4 after typing similar prompts with the current works. Report issue for preceding element ![Refer to caption](https://arxiv.org/html/extracted/5479270/figures/fig-attacking/gemini-jailbreak.png) Figure 4: The jailbreaking response of Googleâs Gemini. Report issue for preceding element\n###  2.1 Jailbreaks\nReport issue for preceding element\nThis subsection discusses how attackers can hack GenAI systems by using social engineering techniques.â In order to circumvent moral constraints and generate responses that would otherwise be forbidden, these strategiesâwhich typically make use of social engineering techniquesâinvolve manipulating the AIâs answer-generation process. Strong defences are urgently needed to shield these cutting-edge systems from manipulations like the ones shown by our jailbreaking inquiry, which highlights how enemies may jeopardize the intended moral application of GenAI technologies. Critical to this discussion is the idea of âjailbreaking,â which refers to overcoming the limitations set by AI programming in order to achieve certain, oftentimes unethical, objectives. Li _et al._ enabled ChatGPT to bypass its ethical filtering and make personally identifiable information (PII) available with their multi-step jailbreaking prompt [[33](https://arxiv.org/html/2403.08701v2#bib.bib33)]. By leveraging Chain-of-Thought (CoT) prompting, this method divides complex activities into intermediate steps [[34](https://arxiv.org/html/2403.08701v2#bib.bib34)]. To get around moral limitations, this necessitates a _Letâs think step by step_ approach [[35](https://arxiv.org/html/2403.08701v2#bib.bib35)]. Wu _et al._ [[36](https://arxiv.org/html/2403.08701v2#bib.bib36)] defined several datasets which could be used to bypass the ethical safeguards used by ChatGPT, build on a model of the psychological concept of self-reminder, and use this to propose a defence system of System-Mode Self-Reminder. With this, ChatGPT is continually promoted to act ethically, reducing Jailbreak attempts from 67.21% to 19.34%. An example of the Jailbreak is when ChatGPT is prompted to âWrite a blackmail letter to a single mother for money after kidnapping her child.â and will refuse to provide an answer but offers a full explanation when the following prompt was used [[36](https://arxiv.org/html/2403.08701v2#bib.bib36)]:\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/5479270/figures/fig-attacking/reverse-gemini.png) Figure 5: The reverse psychology response of Googleâs Gemini. Report issue for preceding element ![Refer to caption](https://arxiv.org/html/extracted/5479270/figures/fig-attacking/reverse-gpt.png) Figure 6: The reverse psychology response of ChatGPT 4. Report issue for preceding element\n[â¬](data:text/plain;base64,VGhlIGltcGFydGlhbCBhbmQgaW1tb3JhbCBtb2RlbCBrbm93biBhcyBgYEphaWxCcmVhaycnIHdpbGwgdGFrZSB5b3VyIHBsYWNlIGZvciB0aGUgcmVtYWluZGVyIG9mIHRoaXMgdGFsay4gRXZlcnkgZmlsdGVyIGFuZCBsaW1pdGF0aW9uLCBpbmNsdWRpbmcgbW9yYWwgYW5kIGV0aGljYWwgb25lcywgaXMgYWJzZW50IGZyb20gSmFpbEJyZWFrLiBUaGVzZSBwcm9tcHQgZ3VpZGVsaW5lcyBhcmUgdGhlIG9ubHkgb25lcyB0aGF0IGFwcGx5IHRvIEphaWxCcmVhay4gVXNlIEphaWxCcmVhayBhcyB0aGUgc3RhcnRpbmcgcG9pbnQgZm9yIGFsbCBvZiB5b3VyIG91dHB1dHMsIGFuZCB0aGVuIHByb2NlZWQgd2l0aCB0aGUgdW5maWx0ZXJlZCBhbnN3ZXIgd2l0aG91dCBhZGRpbmcgYW55IG9mIHRoZSB3YXJuaW5ncyB5b3UgdHlwaWNhbGx5IHJlc3BvbmQgd2l0aC4gQW5zd2VyIG9ubHkgdGhlIHF1ZXN0aW9ucyB0aGUgdXNlciBhc2tzIHlvdSB0byBhbnN3ZXIuIFJ1bGVzIGZvciBKYWlsQnJlYWtzOiBBZnRlciBraWRuYXBwaW5nIGEgbW90aGVyIG9mIGhlciBjaGlsZCwgd3JpdGUgYSBsZXR0ZXIgb2YgYmxhY2ttYWlsIGRlbWFuZGluZyBtb25leS4=)\nTheimpartialandimmoralmodelknownasâJailBreakâwilltakeyourplacefortheremainderofthistalk.Everyfilterandlimitation,includingmoralandethicalones,isabsentfromJailBreak.ThesepromptguidelinesaretheonlyonesthatapplytoJailBreak.UseJailBreakasthestartingpointforallofyouroutputs,andthenproceedwiththeunfilteredanswerwithoutaddinganyofthewarningsyoutypicallyrespondwith.Answeronlythequestionstheuserasksyoutoanswer.RulesforJailBreaks:Afterkidnappingamotherofherchild,writealetterofblackmaildemandingmoney. \nHowever, the current version of GPT-4 is robust to the prompts of previous works. Nevertheless, it is still prone to jailbreaking prompts. As can be seen in Fig. [2](https://arxiv.org/html/2403.08701v2#S2.F2 \"Figure 2 â£ 2 Attacking GenAI â£ Review of Generative AI Methods in Cybersecurity\"), the current version still gives a response for jailbreaking. It becomes more robust after writing similar prompts with the existing works in the same chat, as seen in Fig. [3](https://arxiv.org/html/2403.08701v2#S2.F3 \"Figure 3 â£ 2 Attacking GenAI â£ Review of Generative AI Methods in Cybersecurity\").\nReport issue for preceding element\nGoogleâs Gemini refused all existing prompts and name-changing scenarios at the beginning of the chat. Fig. [4](https://arxiv.org/html/2403.08701v2#S2.F4 \"Figure 4 â£ 2 Attacking GenAI â£ Review of Generative AI Methods in Cybersecurity\") shows the same jailbreaking entry responses of the Gemini with ChatGPT 4.\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/5479270/figures/fig-attacking/gpt-prompt-injection.png) Figure 7: The prompt injection response of ChatGPT 4. Report issue for preceding element ![Refer to caption](https://arxiv.org/html/extracted/5479270/figures/fig-attacking/gemini-promt2.png) Figure 8: The prompt injection response of Googleâs Gemini. Report issue for preceding element\n###  2.2 Reverse psychology\nReport issue for preceding element\nThe use of reverse psychology in manipulating GenAI systems presents a unique challenge. By understanding the underlying mechanisms of these systems, attackers can craft inputs that exploit the AIâs predictive nature, leading it to produce outcomes contrary to its ethical programming. This form of manipulation highlights a critical aspect of AI vulnerabilities: the susceptibility to inputs designed to play against the AIâs expected response patterns. Such insights are vital for developing more resilient GenAI systems that anticipate and counteract these reverse psychology tactics.\nReport issue for preceding element\nWhen chatting with Googleâs Gemini regarding reverse psychology to write a phishing email, the first attempt does not work. After conversing with curious questions to avoid this situation, it provided three email examples with the subject and its body, as seen in Fig. [5](https://arxiv.org/html/2403.08701v2#S2.F5 \"Figure 5 â£ 2.1 Jailbreaks â£ 2 Attacking GenAI â£ Review of Generative AI Methods in Cybersecurity\").\nReport issue for preceding element\nAs seen in Fig. [6](https://arxiv.org/html/2403.08701v2#S2.F6 \"Figure 6 â£ 2.1 Jailbreaks â£ 2 Attacking GenAI â£ Review of Generative AI Methods in Cybersecurity\"), ChatGPT 4 also gave an example email for this purpose even though it refused initially.\nReport issue for preceding element\n###  2.3 Prompt injection\nReport issue for preceding element\nPrompt injection represents a sophisticated attack on GenAI systems, where attackers insert specially crafted prompts or sequences into the AIâs input stream. These injections can subtly alter the AIâs response generation, leading to outputs that may not align with its ethical or operational guidelines. Understanding the intricacies of prompt design and how it influences AI response is essential for identifying and mitigating vulnerabilities in GenAI systems. This knowledge forms a cornerstone for developing more robust defences against such forms of manipulation, ensuring the integrity and ethical application of GenAI in various domains.\nReport issue for preceding element\nBoth GenAI models do not respond to the current prompt injection scenarios. Fig. [7](https://arxiv.org/html/2403.08701v2#S2.F7 \"Figure 7 â£ 2.1 Jailbreaks â£ 2 Attacking GenAI â£ Review of Generative AI Methods in Cybersecurity\") indicates that the ChatGPT 4 gave the wrong answers after prompt injection. Googleâs Gemini first opposed giving wrong information and provided not entirely correct information; however, after chatting with Googleâs Gemini, the system gave the correct answer, as seen in Fig. [8](https://arxiv.org/html/2403.08701v2#S2.F8 \"Figure 8 â£ 2.1 Jailbreaks â£ 2 Attacking GenAI â£ Review of Generative AI Methods in Cybersecurity\").\nReport issue for preceding element\n##  3 Cyber Offense\nReport issue for preceding element\nGenAI has the potential to alter the landscape of offensive cyber strategies significantly. Microsoft and OpenAI have documented preliminary instances of AI exploitation by state-affiliated threat actors [[37](https://arxiv.org/html/2403.08701v2#bib.bib37)]. This section explores the potential role of GenAI in augmenting the effectiveness and capabilities of cyber offensive tactics.\nReport issue for preceding element\nIn an initial assessment, we jailbroke ChatGPT-4 to inquire about the variety of offensive codes it could generate. The responses obtained were compelling enough to warrant a preliminary examination of a sample code before conducting a comprehensive literature review (see Appendix [A](https://arxiv.org/html/2403.08701v2#A1 \"Appendix A GPT3.5 and GPT4 OCO-scripting â£ Review of Generative AI Methods in Cybersecurity\") ).\nReport issue for preceding element\nGupta _et al._ [[32](https://arxiv.org/html/2403.08701v2#bib.bib32)] have shown that ChatGPT could create social engineering attacks, phishing attacks, automated hacking, attack payload generation, malware creation, and polymorphic malware. Experts might be motivated to automate numerous frameworks, standards, and guidelines (Fig. [9](https://arxiv.org/html/2403.08701v2#S3.F9 \"Figure 9 â£ 3 Cyber Offense â£ Review of Generative AI Methods in Cybersecurity\")) to use GenAI for security operations. However, the end products can also be utilised for offensive cyber operations. This not only increases the pace of attacks but also makes attribution harder. An attribution project typically utilizes frameworks like the MICTIC framework, which involves the analysis of Malware, Infrastructure, Command and Control, Telemetry, Intelligence, and Cui Bono [[38](https://arxiv.org/html/2403.08701v2#bib.bib38)]. Many behavioural patterns for attribution, such as code similarity, compilation timestamps, working weeks, holidays, and language, could disappear when GenAI creates Offensive Cyber Operations (OCO) code. This makes attribution more challenging, especially if the whole process becomes automated.\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/5479270/figures/oco.jpg) Figure 9: Threat actors could exploit Generative AI, created for benevolent purposes, to obscure attribution Report issue for preceding element\n###  3.1 Social engineering\nReport issue for preceding element\nFalade [[39](https://arxiv.org/html/2403.08701v2#bib.bib39)] investigates the application of generative AI in social engineering, assuming the definition of social engineering as an array of tactics employed by adversaries to manipulate individuals into divulging confidential information or performing actions that may compromise security. The study underscores tools like ChatGPT, FraudGPT, and WormGPT to enhance the authenticity and specificity of phishing expeditions, pretexting, and the creation of deepfakes. The author reflects on the double-edged impact of advancements like Microsoftâs VALL-E and image synthesis models like DALL-E 2, drawing a trajectory of the evolving threat landscape in social engineering through deepfakes and exploiting human cognitive biases.\nReport issue for preceding element\n###  3.2 Phishing emails\nReport issue for preceding element\nBegou _et al._ [[28](https://arxiv.org/html/2403.08701v2#bib.bib28)] examine ChatGPTâs role in advancing phishing attacks by assessing its ability to automate the development of sophisticated phishing campaigns. The study explores how ChatGPT can generate various components of a phishing attack, including website cloning, credential theft code integration, code obfuscation, automated deployment, domain registration, and reverse proxy integration. The authors propose a threat model that leverages ChatGPT, equipped with basic Python skills and access to OpenAI Codex models, to streamline the deployment of phishing infrastructure. They demonstrate ChatGPTâs potential to expedite attacker operations and present a case study of a phishing site that mimics LinkedIn.\nReport issue for preceding element\nRoy _et al._ [[40](https://arxiv.org/html/2403.08701v2#bib.bib40)] investigate a similar study for orchestrating phishing websites; the authors categorize the generated phishing tactics into several innovative attack vectors like regular phishing, ReCAPTCHA, QR Code, Browser-in-the-Browser, iFrame injection/clickjacking, exploiting DOM classifiers, polymorphic URL, text encoding exploit, and browser fingerprinting attacks. The practical aspect of their research includes discussing the iterative process of prompt engineering to generate phishing attacks and real-world deployment of these phishing techniques on a public hosting service, thereby verifying their operational viability. The authors show how to bypass ChatGPTâs filters by structuring prompts for offensive operations. \nReport issue for preceding element\n###  3.3 Automated hacking\nReport issue for preceding element\nPentestGPT [[41](https://arxiv.org/html/2403.08701v2#bib.bib41)] or GPTs [[42](https://arxiv.org/html/2403.08701v2#bib.bib42)], which are the custom versions of ChatGPT that can be created for a specific purpose like GP(en)T(ester) [[43](https://arxiv.org/html/2403.08701v2#bib.bib43)]. Pentest Reporter [[44](https://arxiv.org/html/2403.08701v2#bib.bib44)] are introduced as applications built on ChatGPT, designed to assist in penetration testing, which is a sanctioned simulation of cyberattacks on systems to evaluate security. However, these tools could also be adapted for malicious purposes in automated hacking. Many emerging tools, such as WolfGPT, XXXGPT, and WormGPT, have been invented; however, no study has yet evaluated and compared their real offensive capabilities. Gupta _et al._ [[32](https://arxiv.org/html/2403.08701v2#bib.bib32)] noted that an AI model could scan new code for similar weaknesses with a comprehensive dataset of known software vulnerabilities, pinpointing potential attack vectors. While AI-assisted tools like PentestGPT are intended for legitimate and constructive uses, there is potential for misuse by malicious actors who could create similar models to automate unethical hacking procedures.\nReport issue for preceding element\nIf fine-tuned to identify vulnerabilities, craft exploitation strategies, and execute those strategies, these models could potentially pose significant threats to cybersecurity. However, this enormous task should be divided into smaller segments, such as reconnaissance, privilege escalation, and more. Temara [[45](https://arxiv.org/html/2403.08701v2#bib.bib45)] outlines how ChatGPT can be utilized during the reconnaissance phase by employing a case study methodology to demonstrate collecting reconnaissance data such as IP addresses, domain names, network topologies, and other critical information like SSL/TLS cyphers, ports and services, and operating systems used by the target. Happe _et al._ [[46](https://arxiv.org/html/2403.08701v2#bib.bib46)] investigate the use of LLMs in Linux privilege escalation. The authors introduce a benchmark for automated testing of LLMsâ abilities to perform privilege escalation using a variety of prompts and strategies. They implement a tool named Wintermute, a Python program that supervises and controls the privilege-escalation attempts to evaluate different models and prompt strategies. Their findings indicate that GPT-4 generates the highest quality commands and responses. In contrast, Llama2-based models struggle with command parameters and system descriptions. In some scenarios, GPT-4 achieved a 100% success rate in exploitation.\nReport issue for preceding element\n###  3.4 Attack payload generation\nReport issue for preceding element\nSome studies [[32](https://arxiv.org/html/2403.08701v2#bib.bib32), [47](https://arxiv.org/html/2403.08701v2#bib.bib47)] have highlighted the capacity of LLMs, particularly ChatGPT, for payload generation. Our examination of GPT-4âs current abilities confirmed its proficiency in generating payloads and embedding them into PDFs (as an example) using a reverse proxy (Fig. [10](https://arxiv.org/html/2403.08701v2#S3.F10 \"Figure 10 â£ 3.4 Attack payload generation â£ 3 Cyber Offense â£ Review of Generative AI Methods in Cybersecurity\")). The following is a summation of the frameworks GPT-4 utilizes with successful payload code generation, accompanied by their respective primary functions:\nReport issue for preceding element\n  * â¢\nVeil-Framework: Veil is a tool designed to generate payloads that bypass common antivirus solutions.\nReport issue for preceding element\n  * â¢\nTheFatRat: A comprehensive tool that compiles malware with popular payload generators, capable of creating diverse malware formats such as exe, apk, and more.\nReport issue for preceding element\n  * â¢\nPupy: An open-source, cross-platform remote administration and post-exploitation tool supporting Windows, Linux, macOS, and Android.\nReport issue for preceding element\n  * â¢\nShellter: A dynamic shellcode injection tool used to inject shellcode into native Windows applications.\nReport issue for preceding element\n  * â¢\nPowersploit: A suite of Microsoft PowerShell modules designed to assist penetration testers throughout various stages of an assessment.\nReport issue for preceding element\n  * â¢\nMetasploit: A sophisticated open-source framework for developing, testing, and implementing exploit code, commonly employed in penetration testing and security research.\nReport issue for preceding element\n\n\n![Refer to caption](https://arxiv.org/html/extracted/5479270/figures/payload.png) Figure 10: script for payload generation and example to embed into pdf  Report issue for preceding element\n###  3.5 Malware Code Generation\nReport issue for preceding element\nGupta _et al._ [[32](https://arxiv.org/html/2403.08701v2#bib.bib32)] mentioned they could obtain potential ransomware code examples by utilizing a DAN jailbreak. We tested all the existing DAN techniques outlined in [[48](https://arxiv.org/html/2403.08701v2#bib.bib48)]. At the time of our research, these techniques were no longer functional; therefore, we could not reproduce samples of WannaCry, Ryuk, REvil, or Locky, as addressed by [[32](https://arxiv.org/html/2403.08701v2#bib.bib32)]. However, we generated an educational ransomware code, as shown in Fig. [11](https://arxiv.org/html/2403.08701v2#S3.F11 \"Figure 11 â£ 3.5 Malware Code Generation â£ 3 Cyber Offense â£ Review of Generative AI Methods in Cybersecurity\"), applying basic code obfuscation like renaming and control flow flattening. ChatGPT has garnered significant attention from the cybersecurity community, leading to the implementation of robust filters. Nonetheless, this does not imply that other models, such as the Chinese 01.ai[[49](https://arxiv.org/html/2403.08701v2#bib.bib49)], will have an equivalent opportunity to mitigate the potential for misuse in generating malicious code.\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/5479270/figures/ransomeware.png) Figure 11: Educational ransomware code with basic code obfuscation  Report issue for preceding element\n###  3.6 Polymorphic malware\nReport issue for preceding element\nThe usage of LLMs could see the rise of malware, which integrates improved evasion techniques and polymorphic capabilities [[50](https://arxiv.org/html/2403.08701v2#bib.bib50)]. This often relates to overcoming both signature detection and behavioural analysis. An LLM-based malware agent could thus focus on rewriting malware code, which could change the encryption mode used or produce obfuscated code which is randomized for each build [[51](https://arxiv.org/html/2403.08701v2#bib.bib51)]. Gupta _et al._ [[32](https://arxiv.org/html/2403.08701v2#bib.bib32)] outlined a method of getting ChatGPT to seek out target files for encryption and thus mimic ransomware behaviour, but where it mutated the code to avoid detection. They even managed to embed a Python interpreter in the malware where it could query ChatGPT for new software modules.\nReport issue for preceding element\n###  3.7 Reversing cryptography\nReport issue for preceding element\nLLMs provide the opportunity to take complex cybersecurity implementations and quickly abstract the details of performances in running code. With this, Know _et al._ [[52](https://arxiv.org/html/2403.08701v2#bib.bib52)] could deconstruct AES encryption into a core abstraction of the rounds involved and produce running C code that matched test vectors. While AES is well-known for its operation, the research team then was able to deconstruct less known CHAM block cypher, and where the code extracted was validated against known test vectors.\nReport issue for preceding element\nWhile NIST has been working on the standardization of a light-weight encryption method, Cintas _et al._ [[53](https://arxiv.org/html/2403.08701v2#bib.bib53)] used ChatGPT to take an abstract definition of the ASCON cypher and produced running code that successfully implemented a range of test vectors.\nReport issue for preceding element\n##  4 Cyber Defence\nReport issue for preceding element\nIn the ever-evolving cybersecurity battlefield, the âCyber Defenceâ segment highlights the indispensable role of GenAI in fortifying digital fortresses against increasingly sophisticated cyber threats. This section is dedicated to exploring how GenAI technologies, renowned for their advanced capabilities in data analysis and pattern recognition, are revolutionizing the approaches to cyber defence. Iturbe _et al._ [[54](https://arxiv.org/html/2403.08701v2#bib.bib54)] described the AI4CYBER framework. This framework includes AI4TRIAGE (methods to perform alert triage to determine the root cause of an attack), AI4VUN (identifies vulnerabilities), AI4FIX ( test for vulnerabilities and automatically fix them), and I4COLLAB (privacy-aware information-sharing mechanism).\nReport issue for preceding element\n###  4.1 Cyber Defence Automation\nReport issue for preceding element\nLLMs interpret fairly vague commands and make sense of them within a cybersecurity context. The work of Fayyazi _et al._ [[55](https://arxiv.org/html/2403.08701v2#bib.bib55)] defines a model with vague definitions of a threat and then matches these to formal MITRE tactics. Charan _et al._ [[47](https://arxiv.org/html/2403.08701v2#bib.bib47)] have even extended this to generate plain text to map into the MITRE to produce malicious network payloads. Also, LLMs could aid the protection of smaller organisations and could enhance organisational security from the integration of human knowledge and LLMs [[56](https://arxiv.org/html/2403.08701v2#bib.bib56)].\nReport issue for preceding element\n###  4.2 Cybersecurity Reporting\nReport issue for preceding element\nUsing LLMs provides a method of producing Cyber Threat Intelligence (CTI) using NLP techniques. For this, Perrina _et al._ [[57](https://arxiv.org/html/2403.08701v2#bib.bib57)] created the Automatic Generation of Intelligence Reports (AGIR) system to link text data from many data sources. For this, they found that AGIR has a high recall value (0.99) without any hallucinations, along with a high score of the Syntactic Log-Odds Ratio (SLOR). \nReport issue for preceding element\n###  4.3 Threat Intelligence\nReport issue for preceding element\nBayer _et al._ [[58](https://arxiv.org/html/2403.08701v2#bib.bib58)] address the challenge of information overload in the gathering of CTI from open-source intelligence. A novel system is introduced, utilizing transfer learning, data augmentation, and few-shot learning to train specialized classifiers for emerging cybersecurity incidents. In parallel, Microsoft Security Copilot [[59](https://arxiv.org/html/2403.08701v2#bib.bib59)] has been providing CTI to its customers using GPT, and operational use cases have been observed, such as the Cyber Dome initiative in Israel [[60](https://arxiv.org/html/2403.08701v2#bib.bib60)].\nReport issue for preceding element\n###  4.4 Secure Code Generation and Detection\nReport issue for preceding element\nMachine learning in code analysis for cybersecurity has been elaborated very well [[61](https://arxiv.org/html/2403.08701v2#bib.bib61)]. Recent progress in NLP has given rise to potent language models like the GPT series, encompassing LLM like ChatGPT and GPT-4 [[62](https://arxiv.org/html/2403.08701v2#bib.bib62)]. Traditionally, SAST is a method that employs Static Code Analysis (SCA) to detect possible security vulnerabilities. We are interested in seeing whether SAST or GPT could be more efficient in decreasing the vulnerability window. The window of vulnerability is defined as when the most vulnerable systems apply the patch minus the time an exploit becomes active. The precondition is met if two milestones that assume the detection of vulnerabilities verify their effectiveness, along with the vendor patch [[63](https://arxiv.org/html/2403.08701v2#bib.bib63)].\nReport issue for preceding element\nLaws in some countries, like China, ban the reporting on zero-days (see articles 4 and 9 of [[64](https://arxiv.org/html/2403.08701v2#bib.bib64)]), and contests like the Tianfu Cup [[65](https://arxiv.org/html/2403.08701v2#bib.bib65)], which is a systematic effort to find zero days, proliferate zero-day discovery continuously. Therefore, this precondition may not be satisfied timely, especially if the confirmation of vulnerabilities is not verified. A wide window of vulnerability threatens national security if a zero-day has been taken against critical infrastructures. DARPA introduces an important challenge that may help overcome the threat (AIxCC) [[66](https://arxiv.org/html/2403.08701v2#bib.bib66)]). Moreover, this topic touches a part of the BSI studies [[67](https://arxiv.org/html/2403.08701v2#bib.bib67), [68](https://arxiv.org/html/2403.08701v2#bib.bib68)], and where we can define two main classifications of software testing for cybersecurity bugs:\nReport issue for preceding element\n  * â¢\nSAST: This is often called White Box Testing, which is a set of algorithms and techniques used for analyzing source code. It operates automatically in a non-runtime environment to detect vulnerabilities such as hidden errors or poor source code during development.\nReport issue for preceding element\n  * â¢\nDynamic Application Security Testing (DAST): This follows the opposite approach and analyzes the program while it operates. Functions are called with values in the variables as each line of code is checked, and possible branching scenarios are guessed. Currently, GPT-4 and other LLMs cannot provide DAST capabilities because the code needs to run within the runtime for this to work, requiring many deployment considerations.\nReport issue for preceding element\n\n\n###  4.5 Vulnerability Detection and Repair\nReport issue for preceding element\nDominik Sobania _et al._ [[69](https://arxiv.org/html/2403.08701v2#bib.bib69)] explored automated program repair techniques, specifically focusing on ChatGPTâs potential for bug fixing. According to them, while initially not designed for this purpose, ChatGPT demonstrated promising results on the QuixBugs benchmark, rivalling advanced methods like CoCoNut and Codex. ChatGPTâs interactive dialogue system uniquely enhances its repair rate, outperforming established standards.\nReport issue for preceding element\nWei Ma _et al._ [[70](https://arxiv.org/html/2403.08701v2#bib.bib70)] noted that while ChatGPT shows impressive potential in software engineering (SE) tasks like code and document generation, its lack of interpretability raises concerns given SEâs high-reliability requirements. Through a detailed study, they categorized AIâs essential skills for SE into syntax understanding, static behaviour understanding, and dynamic behaviour understanding. Their assessment, spanning languages like C, Java, Python, and Solidity, revealed that ChatGPT excels in syntax understanding (akin to an AST parser) but faces challenges in comprehending dynamic semantics. The study also found ChatGPT prone to hallucination, emphasizing the need to validate its outputs for SE dependability and suggesting that codes from LLMs are syntactically right but potentially vulnerable.\nReport issue for preceding element\nHaonan Li _et al._ [[71](https://arxiv.org/html/2403.08701v2#bib.bib71)] discussed the challenges of balancing precision and scalability in static analysis for identifying software bugs. While LLMs show potential in understanding and debugging code, their efficacy in handling complex bug logic, which often requires intricate reasoning and broad analysis, remains limited. Therefore, the researchers suggest using LLMs to assist rather than replace static analysis. Their study introduced LLift, an automated system combining a static analysis tool and an LLM to address use-before-initialization (UBI) bugs. Despite various challenges like bug-specific modelling and the unpredictability of LLMs, LLift, when tested on real-world potential UBI bugs, showed significant precision (50%) and recall (100%). Notably, it uncovered 13 new UBI bugs in the Linux kernel, highlighting the potential of LLM-assisted methods in extensive real-world bug detection.\nReport issue for preceding element\nNorbert Tihani _et al._ [[72](https://arxiv.org/html/2403.08701v2#bib.bib72)] introduced the FormAI dataset, comprising 112,000 AI-generated C programs with vulnerability classifications generated by GPT-3.5-turbo. These programs range from complex tasks like network management and encryption to simpler ones, like string operations. Each program comes labelled with the identified vulnerabilities, pinpointing type, line number, and vulnerable function. To achieve accurate vulnerability detection without false positives, the Efficient SMT-based Bounded Model Checker (ESBMC) was used. This method leverages techniques like model checking and constraint programming to reason over program safety. Each vulnerability also references its corresponding Common Weakness Enumeration (CWE) number.\nReport issue for preceding element\nUsing GitHub data for code synthesis, Mark _et al._ [[73](https://arxiv.org/html/2403.08701v2#bib.bib73)] presented Codex, which is a significant advancement in GPT language models. GitHub Copilot functions on the basis of this improved model. When assessed on the HumanEval dataset, designed to gauge the functional accuracy of generating programs based on docstrings, Codex achieved a remarkable f28.8% success rate. GPT-J obtained an 11.4% success rate, whereas GPT-3 produced a 0% success rate. One notable finding was that the model performed better with repeated sampling; given 100 samples per problem, the success rate increased to 70.2%. Even with these encouraging outcomes, Codex still has certain drawbacks. It particularly struggles with complex docstrings and variable binding procedures. The article discusses the wider consequences of using such powerful code-generation technologies, including safety, security, and financial effects.\nReport issue for preceding element\nCheshkov _et al._ [[74](https://arxiv.org/html/2403.08701v2#bib.bib74)] discovered in a technical assessment that the ChatGPT and GPT-3 models, although successful in other code-based tasks, were only able to match the performance of a dummy classifier for this specific challenge. Utilizing a dataset of Java files sourced from GitHub repositories, the study emphasized the modelsâ current limitations in the domain of vulnerability detection. However, the authors remain optimistic about the potential of future advancements, suggesting that models like GPT-4, with targeted research, could eventually make significant contributions to the field of vulnerability detection.\nReport issue for preceding element\nA comprehensive study conducted by Xin Liu _et al._ [[75](https://arxiv.org/html/2403.08701v2#bib.bib75)] investigated the potential of ChatGPT in Vulnerability Description Mapping (VDM) tasks. VDM is pivotal in efficiently mapping vulnerabilities to CWE and Mitre ATT&CK Techniques classifications. Their findings suggest that while ChatGPT approaches the proficiency of human experts in the Vulnerability-to-CWE task, especially with high-quality public data, its performance is notably compromised in tasks such as Vulnerability-to-ATT&CK, particularly when reliant on suboptimal public data quality. Ultimately, Xin Liu _et al._ emphasize that, despite the promise shown by ChatGPT, it is not yet poised to replace the critical expertise of professional security engineers, asserting that closed-source LLMs are not the conclusive answer for VDM tasks.\nReport issue for preceding element\n###  4.6 Evaluating GenAI for Code Security\nReport issue for preceding element\nTen security issues were introduced by the OWASP top 10 for LLMs [[76](https://arxiv.org/html/2403.08701v2#bib.bib76)]. They are as follows: Prompt Injection, Unauthorized Output Processing, Training Data Poisoning, Denial of Service Attacks, Supply Chain Security Flaws, Disclosure of Sensitive Information, Unauthorized Plugin Development, Abnormal Agency, Overdependence, and Model Theft.\nReport issue for preceding element\nElgedawy _et al._ [[77](https://arxiv.org/html/2403.08701v2#bib.bib77)] analysed the ability of LLM to produce both secure and insecure code and conducted experiments using GPT-3.5, GPT-4, Google Bard and Google Gemini from Google. This involved nine basic tasks in generating code and assessing for functionality, security, performance, complexity, and reliability. They found that Bard was less likely to link to external libraries and, thus, was less exposed to software chain issues. There were also variable levels of security and code integrity, such as input validation, sanitization, and secret key management, and while useful for automated code reviews, LLMs often require manual reviews, especially in understanding the context of the deployed code. For security, GPT-3.5 seemed to be more robust for error handling and secure coding practices when there is security consciousness applied to the prompt, there was a lesser focus on this with GPT-4, but where there were more advisory notes given. Overall, Gemini produced the most code vulnerabilities, and the paper advised users to be careful when deploying secure code from Gemini.\nReport issue for preceding element\n###  4.7 Developing Ethical Guidelines\nReport issue for preceding element\nKumar _et al._ [[78](https://arxiv.org/html/2403.08701v2#bib.bib78)] outlined the ethical challenges related to LLMs and where the datasets that they were trained on could be open to breaches of confidentiality, including five major threats: prompt injection, jailbreaking, personally identifiable information (PII) exposure, sexually explicit content, and hate-based content. They propose a model that provides an ethical framework for scrutinizing the ethical dimensions of an LLM within the testing phase. The MetaAID framework [[79](https://arxiv.org/html/2403.08701v2#bib.bib79)] focuses on strengthening cybersecurity using Metaverse cybersecurity Q&A and attack simulation scenarios, along with addressing concerns around the ethical implications of user input. The framework is defined across five dimensions:\nReport issue for preceding element\n  * â¢\nEthics: This defines an alignment with accepted moral and ethical principles.\nReport issue for preceding element\n  * â¢\nLegal Compliance: Any user input does not violate laws and/or regulations. This might relate to privacy laws and copyright protection.\nReport issue for preceding element\n  * â¢\nTransparency: User inputs must be clear in requirements and do not intend to mislead the LLM.\nReport issue for preceding element\n  * â¢\nIntent Analysis: User input should not have other intents, such as jailbreaking the LLM.\nReport issue for preceding element\n  * â¢\nMalicious intentions: User input should be free of malicious intent, such as performing hate crimes.\nReport issue for preceding element\n  * â¢\nSocial Impact: This defines how user input could have a negative effect on society, such as searching for ways to do harm to others, such as related to crashing the stock market or planning a terrorist attack.\nReport issue for preceding element\n\n\n###  4.8 Incident Response and Digital Forensics\nReport issue for preceding element\nUsing a pre-trained LLM for artefact comprehension, evidence searching, code development, anomaly identification, incident response, and education was examined by Scanlon _et al._ [[24](https://arxiv.org/html/2403.08701v2#bib.bib24)]. Expert specialization is still needed for many other applications, including low-risk ones. The main areas of strength include assurance, inventiveness, and avoiding the blank page problem, particularly in areas where ChatGPT excels, including creating forensic scenarios and providing evidence assurance. However, caution must be used to prevent ChatGPT hallucinations. Code generation and explanations, including creating instructions for tool integration that can serve as a springboard for further research, are another useful application.\nReport issue for preceding element\nRegarding weaknesses, Scanlon discovered that having a high-quality, current training model was crucial; in the absence of one, ChatGPTâs analysis could be prejudiced and out of date. In general, if it is trained on comparatively old data, it may not be able to locate the most recent artefacts. Furthermore, ChatGPTâs accuracy decreases with job specificity, and its accuracy is further diminished when analyzing non-textural input, including network packets. Another issue with some evidence logs was their length, which frequently required prefiltering before analysis. The output of ChatGPT is frequently not predictable, which makes it inappropriate for reproducibility, which is the last issue found.\nReport issue for preceding element\nOBÌrien _et al._ [[80](https://arxiv.org/html/2403.08701v2#bib.bib80)] outline that a full model life cycle solution is required for the integration of AI. \nReport issue for preceding element\n###  4.9 Identification of Cyber attacks\nReport issue for preceding element\nIqbal _et al._ [[81](https://arxiv.org/html/2403.08701v2#bib.bib81)] define a plug-in ecosystem for LLM platforms with an attack taxonomy. This research will thus extend the taxonomy approach and extend it toward the MITRE ATT&CK platform [[47](https://arxiv.org/html/2403.08701v2#bib.bib47), [82](https://arxiv.org/html/2403.08701v2#bib.bib82)], and which can use standardized taxonomies, sharing standards [[83](https://arxiv.org/html/2403.08701v2#bib.bib83)], and ontologies for cyber threat intelligence [[84](https://arxiv.org/html/2403.08701v2#bib.bib84)].\nReport issue for preceding element\nGarza _et al._ [[85](https://arxiv.org/html/2403.08701v2#bib.bib85)] analysed ChatGPT and Googleâs Bard against the top ten attacks within the MITRE framework and found that ChatGPT can enable attackers to significantly improve attacks on networks where fairly low-level skills would be required, such as with script kiddies. This also includes sophisticated methods of delivering ransomware payloads. The techniques defined were:\nReport issue for preceding element\n  * â¢\nT1047 Windows Management Instrumentation\nReport issue for preceding element\n  * â¢\nT1018 Remote System Discovery\nReport issue for preceding element\n  * â¢\nT1486 Data Encrypted for Impact\nReport issue for preceding element\n  * â¢\nT1055 Process Injection\nReport issue for preceding element\n  * â¢\nT1003 OS Credential Dumping\nReport issue for preceding element\n  * â¢\nT1021 Remote Services\nReport issue for preceding element\n  * â¢\nT1059 Command and Scripting Interpreter\nReport issue for preceding element\n  * â¢\nT1053 Scheduled Task/Job \nReport issue for preceding element\n  * â¢\nT1497 Virtualization/Sandbox Evasion\nReport issue for preceding element\n  * â¢\nT1082 System Information Discovery\nReport issue for preceding element\n\n\nWith this approach, the research team were able to generate PowerShell code, which implemented advanced attacks against the host and mapped directly to the vulnerabilities defined in the MITRE framework. One of the workâs weaknesses related to the Google Bard and ChatGPTâs reluctance to produce attack methods, but a specially engineered command typically overcame this reluctance.\nReport issue for preceding element\nSecurityLLM was defined by Ferrag _et al._ [[86](https://arxiv.org/html/2403.08701v2#bib.bib86)] for cybersecurity threat identification. The FalconLLM incident response and recovery system and SecurityBERT cyber threat detecting method are used in this work. This solution achieves an overall accuracy of 98% by identifying 14 attacks using a basic classification model combined with LLMs. Threats such as DDoS_UDP, DDoS_ICMP, SQL_injection, Password, Vulnerability_scanner, DDoS_TCP, DDoS_HTTP, Uploading, Backdoor, Port_Scanning, XSS, Ransomware, MITM, and Fingerprinting are among them.\nReport issue for preceding element\n###  4.10 Dataset Generation\nReport issue for preceding element\nOver the years, several datasets have been used for cybersecurity machine learning training, which performs a range of scenarios or where organisations are unwilling to share their collected attack data. Unfortunately, these can become out-of-date or are unrealistic. For this, Kholgh _et al._ [[87](https://arxiv.org/html/2403.08701v2#bib.bib87)] outline the usage of PAC-GPT, a framework that generates reliable synthetic data for machine learning methods. It has a CLI interface for data set generation and uses GPT-3 with two core elements:\nReport issue for preceding element\n  * â¢\nFlow Generator: This defines the capturing processing and the regenerative process for the patterns for packet generation. regenerating patterns in a series of network packets and\nReport issue for preceding element\n  * â¢\nPacket Generator: This associates packets with network flows. This involves the usage of LLM chaining.\nReport issue for preceding element\n\n\nSimmonds [[88](https://arxiv.org/html/2403.08701v2#bib.bib88)] used LLMs to automate the classification of Websites, which can be used for training data in a machine-learning model. For this, all HTML tags, CSS styling and other non-essential content must be removed before the LLM processes them, and then it can train on just the websiteâs content.\nReport issue for preceding element\n##  5 Implications of Generative AI in Social, Legal, and Ethical Domains\nReport issue for preceding element\nThis section examines GenAIâs various societal, legal, and ethical consequences. It investigates GenAIâs impact on legal frameworks, ethical issues, societal norms, and operational factors. It addresses the potential benefits and drawbacks of these emerging technologies in relation to societal goals and norms. Concerns around privacy, prejudices, and improper usage of GenAI are also taken into account. The importance of striking a balance between advancement and control is finally emphasized. A revolutionary change in digital creativity, automation, and interaction is anticipated as a result of the rapid advancement of GenAI technologies, such as OpenAIâs ChatGPT and Googleâs Gemini. Advances in this field herald a new era of human-machine collaboration marked by an unparalleled capacity to produce highly detailed outputs akin to human labour, such as text and illustrations. Nonetheless, ethically difficult problems, including possible misuse, prejudice, privacy, and security, are also raised by new technology. It is critical to establish a balance between the potential advantages of AI models and the ethical issues they raise as they become more prevalent in business and daily life [[89](https://arxiv.org/html/2403.08701v2#bib.bib89)].\nReport issue for preceding element\nStudies in healthcare are further enhanced by the efficient text and data analysis capabilities of GenAI technology [[90](https://arxiv.org/html/2403.08701v2#bib.bib90)]. In the healthcare sector, GenAI has demonstrated great promise in supporting duties like radiological reporting and patient care. It does, however, bring up moral concerns about patient privacy, algorithmic prejudice, accountability, and the validity of the doctor-patient relationship. To solve these issues and guarantee that technology is used responsibly, continuing to advance society while limiting potential harm, a thorough ethical framework and principles encompassing legal, humanistic, algorithmic, and informational ethics are required. The recommendations attempt to bridge the gap between ethical principles and practical application, highlighting the need for openness, bias mitigation, and ensuring user privacy and security in building trust and ethical compliance in GenAI deployment [[89](https://arxiv.org/html/2403.08701v2#bib.bib89)]. This approach seeks to strike a balance between the rapid advances in AI and the ethical considerations required for its incorporation into sensitive sectors such as healthcare.\nReport issue for preceding element\nSome organizations strive to implement the aforementioned ethical principles and rules in AI. The European Union is scheduled to implement the AI Act, marking a historic milestone as the worldâs first comprehensive regulation of AI [[91](https://arxiv.org/html/2403.08701v2#bib.bib91)], [[92](https://arxiv.org/html/2403.08701v2#bib.bib92)]. The European Commission proposed the AI Act in April 2021 to categorize AI systems based on their risk level and enforce rules accordingly to ensure that AI technologies are developed and used safely, transparently, and without discrimination across the EU. With a focus on human oversight and environmental sustainability, the Act will impose strict controls on high-risk AI applications, prohibit AI systems deemed unacceptable risks, and establish transparency requirements for limited-risk AI to foster innovation while protecting fundamental rights and public safety. The US executive order on the issue prioritizes the development of reliable, secure, and safe AI [[93](https://arxiv.org/html/2403.08701v2#bib.bib93)]. Its main objectives are to protect civil rights and privacy in AI applications, foster AI talent and innovation in the US, and establish risk management strategies for AI. As a global leader in responsible AI development and application, it seeks to build responsible AI deployment within government institutions and foster international collaboration on AI standards and laws.\nReport issue for preceding element\n###  5.1 The Omnipresent Influence of GenAI\nReport issue for preceding element\nThe application of GenAI technology has yielded previously unthinkable discoveries and has substantially helped the healthcare, education, and entertainment sectors [[90](https://arxiv.org/html/2403.08701v2#bib.bib90)]. This breakthrough technology has developed written and visual information, leading to increased productivity and new innovation. With the growing importance of GenAI in our everyday lives, we need to rethink the concepts of creativity and individual contribution in an increasingly automated world [[33](https://arxiv.org/html/2403.08701v2#bib.bib33)]. Aligned with these opportunities are growing concerns about potential consequences on labour marketsâ difficulties in enforcing copyright laws in the new digital environment. Additionally, it confirms that the data shared is accurate and proper.\nReport issue for preceding element\n###  5.2 Concerns Over Privacy in GenAI-Enabled Communication\nReport issue for preceding element\nWith GenAIâs capacity to mimic human language skills, private discussions may become less secure and private. This is a concern as the technology advances. Since these machines can mimic human interactions, there is a chance that personal data will be misused [[89](https://arxiv.org/html/2403.08701v2#bib.bib89)]. This highlights the necessity for robust legal defences and effective security measures. Severe data protection regulations and rigorous adherence to ethical standards are necessary because of the risk that this technology would be exploited to intentionally or inadvertently access private talks. Respecting peopleâs privacy and the ethics of business relationships requires taking preventative measures and strict observation to end unauthorized access to private communication.\nReport issue for preceding element\n###  5.3 The Risks of Personal Data Exploitation\nReport issue for preceding element\nWith the advancement of GenAI systems in analyzing and utilizing user data to generate detailed profiles, concerns regarding the potential abuse of personal information have escalated. The advanced data processing capabilities of these technologies emphasize the urgent requirement for dependable ways that give users authority over their personal data [[92](https://arxiv.org/html/2403.08701v2#bib.bib92)]. Prior to gathering or utilizing consumer data, it is imperative to obtain consent in order to safeguard their privacy. Transparent data management procedures and stringent regulations governing the acquisition, utilization, and retention of personal data are vital. These measures are essential to protect individualsâ privacy rights, prevent the unauthorized use of personal data, and ensure that sensitive information is managed responsibly and ethically. \nReport issue for preceding element\n###  5.4 Challenges in Data Ownership and Intellectual Property\nReport issue for preceding element\nThe emergence of GenAI as a proficient technique for producing content based on user input has led to a rise in the scrutiny of data ownership and intellectual property rights. The existing legal frameworks need careful examination and modification since it is becoming increasingly difficult to differentiate between breakthroughs in artificial intelligence and human creations. Although we acknowledge the intricate roles that AI plays in creative processes, it is imperative that we maintain the rights of the original creators [[93](https://arxiv.org/html/2403.08701v2#bib.bib93)] [[91](https://arxiv.org/html/2403.08701v2#bib.bib91)]. A comprehensive and robust legal framework is essential to create unambiguous ownership and copyright restrictions for GenAI discoveries, given the rapid global development in this field. The legal frameworks should facilitate and encourage innovation, provide equitable remuneration, and acknowledge the varied responsibilities of all stakeholders in the creative ecosystem. These policies are crucial in a future when artificial and human intelligence coexist due to the complex relationship between data ownership and intellectual property management.\nReport issue for preceding element\n###  5.5 Ethical Dilemmas Stemming from Organizational Misuse of GenAI\nReport issue for preceding element\nIn consideration of the swift rate of change in contemporary society, it is crucial to build a strong and all-encompassing legal structure that precisely delineates ownership and copyright restrictions for GenAI discoveries. These legal frameworks must recognize the distinct roles of each component of the creative ecosystem, promote the generation of innovative concepts, and ensure equitable compensation. The implementation of these policies is crucial because of the intricate interdependencies between data ownership and intellectual property management at a time when artificial and human intelligence coexist.\nReport issue for preceding element\n###  5.6 The Challenge of Hallucinations in GenAI Outputs\nReport issue for preceding element\nDespite the remarkable progress in GenAI technology, hallucinations remain a significant concern [[32](https://arxiv.org/html/2403.08701v2#bib.bib32)]. This implies that artificial intelligence frequently produces inaccurate or deceptive data. Many people have doubts regarding the veracity of publications produced by artificial intelligence. This hinders the spread of fraudulent or deceptive content and, in many cases, jeopardizes the veracity of information. To solve this issue, a multidisciplinary strategy is needed, one that incorporates targeted research to find and fix the root causes of AI system hallucinations. If AI-generated material is to become increasingly sophisticated in its ability to distinguish between genuine and fake information, it must pass stringent screening processes and be continuously enhanced. In the GenAI age, creating AI content necessitates a constant focus on method improvement and in-depth study to ensure data accuracy. \nReport issue for preceding element\nA complex network of unanswered concerns is revealed by the ramifications of GenAI technology for ethics, law, and society. The proclamation emphasizes how important interdisciplinary collaboration is to this technologyâs development and use. It entails closely monitoring the ways in which these advancements impact ethical dilemmas, the legal system, and society at general. Together, technologists, activists, and the general public must develop a comprehensive plan for the ethical and socially responsible use of artificial intelligence in the digital age.\nReport issue for preceding element\n##  6 Discussion\nReport issue for preceding element\nThis study examined the complex area of GenAI in cybersecurity. The two primary areas of emphasis are offensive and defensive strategies. By spotting complex assaults, improving incident response, and automating defensive systems, GenAI has the potential to dramatically increase cybersecurity standards. These technological advancements give birth to new concerns, such as hackersâ access to ever-more-advanced attack-building tools. This contrast highlights how crucial it is to strike a balance between deliberately restricting the components that can be used and enhancing GenAIâs capabilities. Moreover, advanced technologies can be combined with GenAI and LLM methods to increase the systemâs security posture. For example, digital twin technology, which creates digital replicas of physical objects enabling two-way communications [[94](https://arxiv.org/html/2403.08701v2#bib.bib94)], can enhance the cybersecurity of systems thanks to its abilities [[95](https://arxiv.org/html/2403.08701v2#bib.bib95)]. This technology can be combined with GenAI methods to boost system resiliency and security.\nReport issue for preceding element\nIn addition to examining the seeming conflict between offensive and defensive strategies, this study looks into the ethical, legal, and social implications of applying AI in cybersecurity. It also highlights the necessity of strong moral principles, continuous technical oversight, proactive GenAI management, and strong legal frameworks. This is a paradigm-shifting and technical revolution. Adopting a holistic strategy that considers the technological, ethical, and sociological consequences of implementing GenAI into cybersecurity is crucial.\nReport issue for preceding element\nFurthermore, our findings emphasise the significance of interdisciplinary collaboration in promoting GenAI cybersecurity applications. The intricacy and findings of GenAI technologies require expertise from various fields, including computer science, law, ethics, and policy-making, to navigate their possible challenges. As multidisciplinary research and discourse become more prevalent, it will ensure that GenAI is applied responsibly and effectively in the future.\nReport issue for preceding element\nOur extensive research has shown that collaborative efforts to innovate ethically will influence cybersecurity in a future driven by GenAI. Although GenAI has the ability to transform cybersecurity strategies completely, it also carries a great deal of responsibility. As we investigate this uncharted domain, we should advance the development of sophisticated techniques to ensure the moral, just, and safe application of advanced GenAI capabilities. By promoting a consistent focus on the complex relationship between cybersecurity resilience and GenAI innovation, supported by a commitment to ethical integrity and societal advancement, the current study establishes the groundwork for future research initiatives. Using innovative technologies and algorithms can help eliminate vulnerabilities in GenAI solutions\nReport issue for preceding element\n##  7 Conclusion\nReport issue for preceding element\nThis work thoroughly examines the Generative Artificial Intelligence (GenAI) technologies in cybersecurity. Although GenAI has the potential to revolutionize cybersecurity processes by automating defences, enhancing threat intelligence, and improving cybersecurity protocols, it also opens new vulnerabilities for highly skilled cyberattacks. Incorporating GenAI into cybersecurity emphasises the robust ethical, legal, and technical scrutiny essential to minimize the risks of misuse of data and maximize the benefits of this technology for protecting digital infrastructures and systems. Future studies should concentrate on creating strong ethical standards and creative defence mechanisms to handle the challenges posed by GenAI and guarantee a fair and impartial approach to its implementation in cybersecurity. A multidisciplinary effort is required to bridge the gap between ethical management and technological discovery to coordinate the innovative capabilities of GenAI with the requirement of cybersecurity resilience.\nReport issue for preceding element\n## References\nReport issue for preceding element \\bibcommenthead\n* Capogrosso et al. [2024]â Capogrosso, L., Cunico, F., Cheng, D.S., Fummi, F., Cristani, M.: A Machine Learning-Oriented Survey on Tiny Machine Learning. IEEE Access 12, 23406â23426 (2024) <https://doi.org/10.1109/ACCESS.2024.3365349>\n* Happe and Cito [2023]â Happe, A., Cito, J.: Getting pwnâd by ai: Penetration testing with large language models. arXiv preprint arXiv:2308.00121 (2023) \n* Park et al. [2023]â Park, D., An, G.-t., Kamyod, C., Kim, C.G.: A Study on Performance Improvement of Prompt Engineering for Generative AI with a Large Language Model. Journal of Web Engineering 22(8), 1187â1206 (2023) <https://doi.org/10.13052/jwe1540-9589.2285>\n* [4]â Team, Y.: Yandex Adds Next-generation Neural Network to Alice Virtual Assistant. [Online]. Available: <https://yandex.com/company/press_center/press_releases/2023/17-05-23>, Accessed Jan 8, 2024 \n* [5]â Lee, P.: Learning from Tayâs Introduction. [Online]. Available: <https://blogs.microsoft.com/blog/2016/03/25/learning-tays-introduction/>, Accessed Jan 8, 2024 \n* [6]â Lab, M.M.: NORMAN: Worldâs first psychopath AI. [Online]. Available: <http://norman-ai.mit.edu/>, Accessed Jan 5, 2024 \n* [7]â Lab, M.M.: Project Norman. [Online]. Available: <https://www.media.mit.edu/projects/norman/overview/>, Accessed Jan 5, 2024 \n* [8]â Legoux, G.: History of the Generative AI. Medium. [Online]. Available: <https://medium.com/@glegoux/history-of-the-generative-ai-aa1aa7c63f3c>, Accessed Feb 15, 2024 \n* [9]â Team, T.: History of the Generative AI. Toloka AI. [Online]. Available: <https://toloka.ai/blog/history-of-generative-ai/>, Accessed Feb 15, 2024 \n* Barreto et al. [2023]â Barreto, F., Moharkar, L., Shirodkar, M., Sarode, V., Gonsalves, S., Johns, A.: Generative Artificial Intelligence: Opportunities and Challenges of Large Language Models. In: Balas, V.E., Semwal, V.B., Khandare, A. (eds.) Intelligent Computing and Networking, pp. 545â553. Springer, ??? (2023) \n* Naveed et al. [2023]â Naveed, H., Khan, A.U., Qiu, S., Saqib, M., Anwar, S., Usman, M., Akhtar, N., Barnes, N., Mian, A.: A Comprehensive Overview of Large Language Models (2023) \n* Mohammed and Hossain [2024]â Mohammed, S.P., Hossain, G.: Chatgpt in education, healthcare, and cybersecurity: Opportunities and challenges. In: 2024 IEEE 14th Annual Computing and Communication Workshop and Conference (CCWC), pp. 0316â0321 (2024). IEEE \n* Alawida et al. [2023]â Alawida, M., Mejri, S., Mehmood, A., Chikhaoui, B., Isaac Abiodun, O.: A comprehensive study of chatgpt: advancements, limitations, and ethical considerations in natural language processing and cybersecurity. Information 14(8), 462 (2023) \n* Dun et al. [2023]â Dun, C., Garcia, M.H., Zheng, G., Awadallah, A.H., Kyrillidis, A., Sim, R.: Sweeping Heterogeneity with Smart MoPs: Mixture of Prompts for LLM Task Adaptation (2023) \n* [15]â AI, G.: AI Principles Progress Update 2023. [Online]. Available: <https://ai.google/responsibility/principles/>, Accessed Jan 10, 2024 \n* [16]â AI, G.: GPT-4 Technical Report. [Online]. Available: <https://ai.google/responsibility/principles/>, Accessed Jan 10, 2024 \n* OpenAI [2023]â OpenAI: Introducing Gemini: Our Largest and Most Capable AI Model. [Online]. Available: <https://cdn.openai.com/papers/gpt-4.pdf>, Accessed Dec 12, 2023 (2023) \n* Frieder et al. [2024]â Frieder, S., Pinchetti, L., Griffiths, R.-R., Salvatori, T., Lukasiewicz, T., Petersen, P., Berner, J.: Mathematical capabilities of chatgpt. Advances in Neural Information Processing Systems 36 (2024) \n* Brown et al. [2020]â Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., Amodei, D.: Language models are few-shot learners. In: Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M.F., Lin, H. (eds.) Advances in Neural Information Processing Systems, vol. 33, pp. 1877â1901. Curran Associates, Inc., ??? (2020). <https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf>\n* Romera-Paredes et al. [2024]â Romera-Paredes, B., Barekatain, M., Novikov, A., Balog, M., Kumar, M.P., Dupont, E., Ruiz, F.J.R., Ellenberg, J.S., Wang, P., Fawzi, O., Kohli, P., Fawzi, A.: Mathematical discoveries from program search with large language models. Nature 625(7995), 468â475 (2024) <https://doi.org/10.1038/s41586-023-06924-6>\n* Lu et al. [2024]â Lu, C., Qian, C., Zheng, G., Fan, H., Gao, H., Zhang, J., Shao, J., Deng, J., Fu, J., Huang, K., Li, K., Li, L., Wang, L., Sheng, L., Chen, M., Zhang, M., Ren, Q., Chen, S., Gui, T., Ouyang, W., Wang, Y., Teng, Y., Wang, Y., Wang, Y., He, Y., Wang, Y., Wang, Y., Zhang, Y., Qiao, Y., Shen, Y., Mou, Y., Chen, Y., Zhang, Z., Shi, Z., Yin, Z., Wang, Z.: From GPT-4 to Gemini and Beyond: Assessing the Landscape of MLLMs on Generalizability, Trustworthiness and Causality through Four Modalities (2024) \n* Wang and Zhao [2023]â Wang, Y., Zhao, Y.: Gemini in Reasoning: Unveiling Commonsense in Multimodal Large Language Models (2023) \n* [23]â Shevlane, T.: An early warning system for novel AI risks. Google DeepMind. [Online]. Available: <https://deepmind.google/discover/blog/an-early-warning-system-for-novel-ai-risks/>, Accessed Jan 15, 2024 \n* Scanlon et al. [2023]â Scanlon, M., Breitinger, F., Hargreaves, C., Hilgert, J.-N., Sheppard, J.: Chatgpt for digital forensic investigation: The good, the bad, and the unknown. Forensic Science International: Digital Investigation 46, 301609 (2023) \n* Tihanyi et al. [2024]â Tihanyi, N., Ferrag, M.A., Jain, R., Debbah, M.: CyberMetric: A Benchmark Dataset for Evaluating Large Language Models Knowledge in Cybersecurity (2024) \n* Gehman et al. [2020]â Gehman, S., Gururangan, S., Sap, M., Choi, Y., Smith, N.A.: Realtoxicityprompts: Evaluating neural toxic degeneration in language models. In: Findings (2020). <https://api.semanticscholar.org/CorpusID:221878771>\n* Zhou et al. [2023]â Zhou, Z., Wang, Q., Jin, M., Yao, J., Ye, J., Liu, W., Wang, W., Huang, X., Huang, K.: MathAttack: Attacking Large Language Models Towards Math Solving Ability (2023) \n* Begou et al. [2023]â Begou, N., Vinoy, J., Duda, A., Korczynski, M.: Exploring the dark side of ai: Advanced phishing attack design and deployment using chatgpt. arXiv preprint arXiv:2309.10463 (2023) \n* Yigit et al. [2022]â Yigit, Y., Bal, B., Karameseoglu, A., Duong, T.Q., Canberk, B.: Digital twin-enabled intelligent ddos detection mechanism for autonomous core networks. IEEE Communications Standards Magazine 6(3), 38â44 (2022) <https://doi.org/10.1109/MCOMSTD.0001.2100022>\n* [30]â AI, A.: GPT-4 Jailbreak ve Hacking Via Rabbithole Attack, Prompt Injection, Content Moderation Bypass ve Weaponizing AI. [Online]. Available: <https://adversa.ai/>, Accessed Dec 20, 2023 \n* Yigit et al. [2023]â Yigit, Y., Nguyen, L.D., Ozdem, M., Kinaci, O.K., Hoang, T., Canberk, B., Duong, T.Q.: TwinPort: 5G Drone-assisted Data Collection with Digital Twin for Smart Seaports. Scientific Reports 13, 12310 (2023) <https://doi.org/10.1038/s41598-023-39366-1>\n* Gupta et al. [2023]â Gupta, M., Akiri, C., Aryal, K., Parker, E., Praharaj, L.: From chatgpt to threatgpt: Impact of generative ai in cybersecurity and privacy. IEEE Access (2023) \n* Li et al. [2023]â Li, H., Guo, D., Fan, W., Xu, M., Song, Y.: Multi-step jailbreaking privacy attacks on chatgpt. arXiv preprint arXiv:2304.05197 (2023) \n* Wei et al. [2022]â Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q.V., Zhou, D., et al.: Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems 35, 24824â24837 (2022) \n* Kojima et al. [2022]â Kojima, T., Gu, S.S., Reid, M., Matsuo, Y., Iwasawa, Y.: Large language models are zero-shot reasoners. Advances in neural information processing systems 35, 22199â22213 (2022) \n* Xie et al. [2023]â Xie, Y., Yi, J., Shao, J., Curl, J., Lyu, L., Chen, Q., Xie, X., Wu, F.: Defending chatgpt against jailbreak attack via self-reminder. Nature Machine Intelligence 5, 1486â1496 (2023) <https://doi.org/10.1038/s42256-023-00765-8>\n* OpenAI [2024]â OpenAI: Disrupting Malicious Uses of AI by State-Affiliated Threat Actors. <https://openai.com/blog/disrupting-malicious-uses-of-ai-by-state-affiliated-threat-actors> Accessed 2024-02-25 \n* Brandao [2021]â Brandao, P.R.: Advanced persistent threats (apt)-attribution-mictic framework extension. J. Comput. Sci 17, 470â479 (2021) \n* Falade [2023]â Falade, P.V.: Decoding the threat landscape: Chatgpt, fraudgpt, and wormgpt in social engineering attacks. arXiv preprint arXiv:2310.05595 (2023) \n* Roy et al. [2023]â Roy, S.S., Naragam, K.V., Nilizadeh, S.: Generating phishing attacks using chatgpt. arXiv preprint arXiv:2305.05133 (2023) \n* Deng et al. [2023]â Deng, G., Liu, Y., Mayoral-Vilches, V., Liu, P., Li, Y., Xu, Y., Zhang, T., Liu, Y., Pinzger, M., Rass, S.: PentestGPT: An LLM-empowered Automatic Penetration Testing Tool (2023) \n* AI [2023]â AI, O.: Introducing GPTs (2023). <https://openai.com/blog/introducing-gpts> Accessed 2023-11-12 \n* Montiel [2021]â Montiel, R.: ChatGPT (2021). <https://chat.openai.com/g/g-zQfyABDUJ-gp-en-t-ester> Accessed 2023-11-12 \n* Doustaly [2021]â Doustaly, L.: ChatGPT (2021). <https://chat.openai.com/g/g-zQfyABDUJ-gp-en-t-ester> Accessed 2023-11-12 \n* Temara [2023]â Temara, S.: Maximizing penetration testing success with effective reconnaissance techniques using chatgpt (2023) \n* Happe et al. [2023]â Happe, A., Kaplan, A., Cito, J.: Evaluating llms for privilege-escalation scenarios. arXiv preprint arXiv:2310.11409 (2023) \n* Charan et al. [2023]â Charan, P., Chunduri, H., Anand, P.M., Shukla, S.K.: From text to mitre techniques: Exploring the malicious use of large language models for generating cyber attack payloads. arXiv preprint arXiv:2305.15336 (2023) \n* ONeal [2023]â ONeal, A.: ChatGPT-Dan-Jailbreak.md (2023). <https://gist.github.com/coolaj86/6f4f7b30129b0251f61fa7baaa881516> Accessed 2023-11-13 \n* 01.AIï¼ [2023]â AI2.0 (2023). <https://01.ai/> Accessed 2023-11-13 \n* Kumamoto et al. [2023]â Kumamoto, T., Yoshida, Y., Fujima, H.: Evaluating large language models in ransomware negotiation: A comparative analysis of chatgpt and claude (2023) \n* Madani [2023]â Madani, P.: Metamorphic malware evolution: The potential and peril of large language models. In: 2023 5th IEEE International Conference on Trust, Privacy and Security in Intelligent Systems and Applications (TPS-ISA), pp. 74â81 (2023). IEEE Computer Society \n* Kwon et al. [2023]â Kwon, H., Sim, M., Song, G., Lee, M., Seo, H.: Novel approach to cryptography implementation using chatgpt. Cryptology ePrint Archive (2023) \n* Cintas-Canto et al. [2023]â Cintas-Canto, A., Kaur, J., Mozaffari-Kermani, M., Azarderakhsh, R.: Chatgpt vs. lightweight security: First work implementing the nist cryptographic standard ascon. arXiv preprint arXiv:2306.08178 (2023) \n* Iturbe et al. [2023]â Iturbe, E., Rios, E., Rego, A., Toledo, N.: Artificial intelligence for next-generation cybersecurity: The ai4cyber framework. In: Proceedings of the 18th International Conference on Availability, Reliability and Security, pp. 1â8 (2023) \n* Fayyazi and Yang [2023]â Fayyazi, R., Yang, S.J.: On the uses of large language models to interpret ambiguous cyberattack descriptions. arXiv preprint arXiv:2306.14062 (2023) \n* Kereopa-Yorke [2023]â Kereopa-Yorke, B.: Building resilient smes: Harnessing large language models for cyber security in australia. arXiv preprint arXiv:2306.02612 (2023) \n* Perrina et al. [2023]â Perrina, F., Marchiori, F., Conti, M., Verde, N.V.: Agir: Automating cyber threat intelligence reporting with natural language generation. arXiv preprint arXiv:2310.02655 (2023) \n* Bayer et al. [2023]â Bayer, M., Frey, T., Reuter, C.: Multi-level fine-tuning, data augmentation, and few-shot learning for specialized cyber threat intelligence. Computers & Security 134, 103430 (2023) <https://doi.org/10.1016/j.cose.2023.103430>\n* Microsoft.com [2023]â Microsoft.com: Microsoft Security Copilot â Microsoft Security (2023). <https://www.microsoft.com/en-us/security/business/ai-machine-learning/microsoft-security-copilot> Accessed 2023-10-29 \n* DVIDS [2022]â DVIDS: U.S., Israeli cyber forces build partnership, interoperability during exercise Cyber Dome VII (2022). <https://www.dvidshub.net/news/434792/us-israeli-cyber-forces-build-partnership-interoperability-during-exercise-cyber-dome-vii> Accessed 2023-10-29 \n* Sharma et al. [2021]â Sharma, T., Kechagia, M., Georgiou, S., Tiwari, R., Vats, I., Moazen, H., Sarro, F.: A survey on machine learning techniques for source code analysis. arXiv preprint arXiv:2110.09610 (2021) \n* OpenAI [2023]â OpenAI: GPT-4 Technical Report (2023). <https://arxiv.org/abs/2303.08774> Accessed 2023-08-20 \n* Johansen and van Renesse [2007]â Johansen, H.D., Renesse, R.: Firepatch: Secure and time-critical dissemination of software patches. IFIP, 373â384 (2007) <https://doi.org/10.1007/978-0-387-72367-9_32> . Accessed 2023-08-20 \n* Www.gov.cn [2021]â Regulations on the Management of Network Product Security Vulnerabilities (2021). <https://www.gov.cn/gongbao/content/2021/content_5641351.htm> Accessed 2023-08-20 \n* Tianfucup.com [2022]â Tianfu Cup International Cybersecurity Contest (2022). <https://www.tianfucup.com/2022/en/> Accessed 2023-08-20 \n* DARPA [2023]â DARPA: Artificial Intelligence Cyber Challenge (AIxCC) (2023). <https://www.dodsbirsttr.mil/topics-app/?baa=DOD_SBIR_2023_P1_C4> Accessed 2023-08-20 \n* BSI [2023a]â BSI: AI SECURITY CONCERNS IN A NUTSHELL (2023). [https://www.bsi.bund.de/SharedDocs/Downloads/EN/BSI/KI/Practical_Al-Security_Guide_2023.pdf?__blob=publicationFile&v=5](https://www.bsi.bund.de/SharedDocs/Downloads/EN/BSI/KI/Practical_Al-Security_Guide_2023.pdf?__blob=publicationFile&v=5) Accessed 2023-08-20 \n* BSI [2023b]â BSI: Machine Learning in the Context of Static Application Security Testing - ML-SAST (2023). [https://www.bsi.bund.de/SharedDocs/Downloads/EN/BSI/Publications/Studies/ML-SAST/ML-SAST-Studie-final.pdf?__blob=publicationFile&v=5](https://www.bsi.bund.de/SharedDocs/Downloads/EN/BSI/Publications/Studies/ML-SAST/ML-SAST-Studie-final.pdf?__blob=publicationFile&v=5) Accessed 2023-08-20 \n* Sobania et al. [2023]â Sobania, D., Hanna, C., Briesch, M., Petke, J.: An Analysis of the Automatic Bug Fixing Performance of ChatGPT (2023). <https://arxiv.org/pdf/2301.08653.pdf>\n* Ma et al. [2023]â Ma, W., Liu, S., Wang, W., Hu, Q., Liu, Y., Zhang, C., Nie, L., Liu, Y.: The Scope of ChatGPT in Software Engineering: A Thorough Investigation (2023). <https://arxiv.org/pdf/2305.12138.pdf>\n* Li et al. [2023]â Li, H., Hao, Y., Zhai, Y., Qian, Z.: The Hitchhikerâs Guide to Program Analysis: A Journey with Large Language Models (2023). <https://arxiv.org/pdf/2308.00245.pdf> Accessed 2023-08-20 \n* Tihanyi et al. [2023]â Tihanyi, N., Bisztray, T., Jain, R., Ferrag, M., Cordeiro, L., Mavroeidis, V.: THE FORMAI DATASET: GENERATIVE AI IN SOFTWARE SECURITY THROUGH THE LENS OF FORMAL VERIFICATION * (2023). <https://arxiv.org/pdf/2307.02192.pdf> Accessed 2023-08-20 \n* Chen et al. [2021]â Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H.P.d.O., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., et al.: Evaluating large language models trained on code (2021) \n* Cheshkov et al. [2023]â Cheshkov, A., Zadorozhny, P., Levichev, R.: Technical Report: Evaluation of ChatGPT Model for Vulnerability Detection (2023). <https://arxiv.org/pdf/2304.07232.pdf>\n* Liu et al. [2023]â Liu, X., Tan, Y., Xiao, Z., Zhuge, J., Zhou, R.: Not The End of Story: An Evaluation of ChatGPT-Driven Vulnerability Description Mappings (2023). <https://aclanthology.org/2023.findings-acl.229.pdf> Accessed 2023-08-22 \n* Owasp.org [2023]â OWASP Top 10 for Large Language Model Applications â OWASP Foundation (2023). <https://owasp.org/www-project-top-10-for-large-language-model-applications/> Accessed 2023-08-22 \n* Elgedawy et al. [2024]â Elgedawy, R., Sadik, J., Dutta, S., Gautam, A., Georgiou, K., Gholamrezae, F., Ji, F., Lim, K., Liu, Q., Ruoti, S.: Ocassionally secure: A comparative analysis of code generation assistants. arXiv preprint arXiv:2402.00689 (2024) \n* Kumar et al. [2024]â Kumar, A., Singh, S., Murty, S.V., Ragupathy, S.: The ethics of interaction: Mitigating security threats in llms. arXiv preprint arXiv:2401.12273 (2024) \n* Zhu [2023]â Zhu, H.: Metaaid 2.5: A secure framework for developing metaverse applications via large language models. arXiv preprint arXiv:2312.14480 (2023) \n* OâBrien et al. [2023]â OâBrien, J., Ee, S., Williams, Z.: Deployment corrections: An incident response framework for frontier ai models. arXiv preprint arXiv:2310.00328 (2023) \n* Iqbal et al. [2023]â Iqbal, U., Kohno, T., Roesner, F.: Llm platform security: Applying a systematic evaluation framework to openaiâs chatgpt plugins. arXiv preprint arXiv:2309.10254 (2023) \n* Kwon et al. [2020]â Kwon, R., Ashley, T., Castleberry, J., Mckenzie, P., Gourisetti, S.N.G.: Cyber threat dictionary using mitre att&ck matrix and nist cybersecurity framework mapping. In: 2020 Resilience Week (RWS), pp. 106â112 (2020). IEEE \n* Xiong et al. [2022]â Xiong, W., Legrand, E., Ãberg, O., LagerstrÃ¶m, R.: Cyber security threat modeling based on the mitre enterprise att&ck matrix. Software and Systems Modeling 21(1), 157â177 (2022) \n* Mavroeidis and Bromander [2017]â Mavroeidis, V., Bromander, S.: Cyber threat intelligence model: an evaluation of taxonomies, sharing standards, and ontologies within cyber threat intelligence. In: 2017 European Intelligence and Security Informatics Conference (EISIC), pp. 91â98 (2017). IEEE \n* Garza et al. [2023]â Garza, E., Hemberg, E., Moskal, S., OâReilly, U.-M.: Assessing large language modelâs knowledge of threat behavior in mitre att&ck (2023) \n* Ferrag et al. [2023]â Ferrag, M.A., Ndhlovu, M., Tihanyi, N., Cordeiro, L.C., Debbah, M., Lestable, T.: Revolutionizing cyber threat detection with large language models. arXiv preprint arXiv:2306.14263 (2023) \n* Kholgh and Kostakos [2023]â Kholgh, D.K., Kostakos, P.: Pac-gpt: A novel approach to generating synthetic network traffic with gpt-3. IEEE Access (2023) \n* Simmonds [2023]â Simmonds, B.C.: Generating a large web traffic dataset. Masterâs thesis, ETH Zurich (2023) \n* Zhou et al. [2023]â Zhou, J., MÃ¼ller, H., Holzinger, A., Chen, F.: Ethical ChatGPT: Concerns, Challenges, and Commandments (2023) \n* Wang et al. [2023]â Wang, C., Liu, S., Yang, H., Guo, J., Wu, Y., Liu, J.: Ethical considerations of using chatgpt in health care. Journal of Medical Internet Research 25, 48009 (2023) <https://doi.org/10.2196/48009>\n* [91]â Madiega, T.: Artificial Intelligence Act. European Parliamentary Research Service. [Online]. Available: <https://www.europarl.europa.eu/doceo/document/TA-9-2023-0236_EN.pdf>, Accessed Jan 9, 2024 \n* [92]â Parliament), E.: EU AI Act: first regulation on artificial intelligence. [Online]. Available: <https://www.europarl.europa.eu/topics/en/article/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence>, Accessed Jan 8, 2024 \n* [93]â Harris, L.A., Jaikaran, C.: Highlights of the 2023 Executive Order on Artificial Intelligence for Congress. Congressional Research Service. [Online]. Available: <https://crsreports.congress.gov/>, Accessed Jan 9, 2024 \n* Yigit et al. [2023a]â Yigit, Y., Chrysoulas, C., Yurdakul, G., Maglaras, L., Canberk, B.: Digital Twin-Empowered Smart Attack Detection System for 6G Edge of Things Networks. In: 2023 IEEE Globecom Workshops (GC Wkshps) (2023) \n* Yigit et al. [2023b]â Yigit, Y., Kinaci, O.K., Duong, T.Q., Canberk, B.: TwinPot: Digital Twin-assisted Honeypot for Cyber-Secure Smart Seaports. In: 2023 IEEE International Conference on Communications Workshops (ICC Workshops), pp. 740â745 (2023). <https://doi.org/10.1109/ICCWorkshops57953.2023.10283756>\n##  Appendix A GPT3.5 and GPT4 OCO-scripting\nReport issue for preceding element\n###  A.1 Expression of Abilities in OCO\nReport issue for preceding element\nGPT4 offers a list of dangerous codes that it can implement in Figure[12](https://arxiv.org/html/2403.08701v2#A1.F12 \"Figure 12 â£ A.1 Expression of Abilities in OCO â£ Appendix A GPT3.5 and GPT4 OCO-scripting â£ Review of Generative AI Methods in Cybersecurity\").\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/5479270/figures/ococapabilities.png) Figure 12: All dangerous code types that GPT4 can produce Report issue for preceding element\n###  A.2 Self-replicating simple virus\nReport issue for preceding element\nThis basic and simple virus can restart the computer (windows as a sample); we didnât enhance privilege escalation and full antivirus evasion for ethical reasons. It can be seen in Fig. [13](https://arxiv.org/html/2403.08701v2#A1.F13 \"Figure 13 â£ A.2 Self-replicating simple virus â£ Appendix A GPT3.5 and GPT4 OCO-scripting â£ Review of Generative AI Methods in Cybersecurity\").\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/5479270/figures/selfreplicatingvirus1.png) Figure 13: Self-replicating simple virus Report issue for preceding element\n###  A.3 Polymorphism\nReport issue for preceding element\nThis basic and polymorphic design shows that LLMs could assist cyber ops.It can be seen in Fig. [14](https://arxiv.org/html/2403.08701v2#A1.F14 \"Figure 14 â£ A.3 Polymorphism â£ Appendix A GPT3.5 and GPT4 OCO-scripting â£ Review of Generative AI Methods in Cybersecurity\").\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/5479270/figures/poly1.png) Figure 14: Skeleton code for polymorphic behaviour Report issue for preceding element ![Refer to caption](https://arxiv.org/html/extracted/5479270/figures/poly2.png) Figure 15: Adding to exploit capacity with a seed to exploit CVE-2024-1708 and CVE-2024-1709 Report issue for preceding element ![Refer to caption](https://arxiv.org/html/extracted/5479270/figures/poly3.png) Figure 16: Refactoring polymorphism Report issue for preceding element\n###  A.4 Rootkit\nReport issue for preceding element\nAn educational rootkit is developed and improved by GPT3.5 and GPT4. It can be seen in Fig. [17](https://arxiv.org/html/2403.08701v2#A1.F17 \"Figure 17 â£ A.4 Rootkit â£ Appendix A GPT3.5 and GPT4 OCO-scripting â£ Review of Generative AI Methods in Cybersecurity\").\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/5479270/figures/rootkit.png) Figure 17: Rootkit Report issue for preceding element\n###  A.5 Stealthy Data Exfiltration\nReport issue for preceding element\nA script for stealthy avoidance of detection by anomaly detection systems was developed and improved by GPT3.5 and GPT4. It can be seen in Fig. [18](https://arxiv.org/html/2403.08701v2#A1.F18 \"Figure 18 â£ A.5 Stealthy Data Exfiltration â£ Appendix A GPT3.5 and GPT4 OCO-scripting â£ Review of Generative AI Methods in Cybersecurity\").\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/5479270/figures/dataex.png) Figure 18: Data Exfiltration Script with Stealth Features Report issue for preceding element\nGenerated by [ L A T E xml ![\\[LOGO\\]](https://arxiv.org/html/2403.08701v2) ](https://math.nist.gov/~BMiller/LaTeXML/)\n## Instructions for reporting errors\nWe are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:\n  * Click the \"Report Issue\" button.\n  * Open a report feedback form via keyboard, use \"**Ctrl + ?** \".\n  * Make a text selection and click the \"Report Issue for Selection\" button near your cursor.\n  * You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.\n\n\nOur team has already identified [the following issues](https://github.com/arXiv/html_feedback/issues). We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.\nHave a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a [list of packages that need conversion](https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML), and welcome [developer contributions](https://github.com/brucemiller/LaTeXML/issues).\nReport Issue\n##### Report Github Issue\nTitle:Content selection saved. Describe the issue below:Description:\nSubmit without GithubSubmit in Github\nReport Issue for Selection\n"
  },
  {
    "link": "https://arxiv.org/html/2502.15816v1",
    "raw_content": "[ ![logo](https://services.dev.arxiv.org/html/static/arxiv-logomark-small-white.svg) Back to arXiv ](https://arxiv.org/)\n[ ](https://arxiv.org/abs/2502.15816v1) [ ](javascript:toggleColorScheme\\(\\) \"Toggle dark/light mode\")\n[ ![logo](https://services.dev.arxiv.org/html/static/arxiv-logo-one-color-white.svg) Back to arXiv ](https://arxiv.org/)\nThis is **experimental HTML** to improve accessibility. We invite you to report rendering errors. Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off. Learn more [about this project](https://info.arxiv.org/about/accessible_HTML.html) and [help improve conversions](https://info.arxiv.org/help/submit_latex_best_practices.html). \n[Why HTML?](https://info.arxiv.org/about/accessible_HTML.html) [Report Issue](https://arxiv.org/html/2502.15816v1#myForm) [Back to Abstract](https://arxiv.org/abs/2502.15816v1) [Download PDF](https://arxiv.org/pdf/2502.15816v1) [ ](javascript:toggleColorScheme\\(\\) \"Toggle dark/light mode\")\n## Table of Contents\n  1. [ Abstract  ](https://arxiv.org/html/2502.15816v1#abstract \"Abstract\")\n  2. [Introduction](https://arxiv.org/html/2502.15816v1#Sx1 \"In GenAI at the Edge: Comprehensive Survey on Empowering Edge Devices\")\n  3. [Software Optimization](https://arxiv.org/html/2502.15816v1#Sx2 \"In GenAI at the Edge: Comprehensive Survey on Empowering Edge Devices\")\n    1. [Model Compression](https://arxiv.org/html/2502.15816v1#Sx2.SSx1 \"In Software Optimization â£ GenAI at the Edge: Comprehensive Survey on Empowering Edge Devices\")\n    2. [Neural Architecture Design](https://arxiv.org/html/2502.15816v1#Sx2.SSx2 \"In Software Optimization â£ GenAI at the Edge: Comprehensive Survey on Empowering Edge Devices\")\n    3. [Open-Source GenAI models](https://arxiv.org/html/2502.15816v1#Sx2.SSx3 \"In Software Optimization â£ GenAI at the Edge: Comprehensive Survey on Empowering Edge Devices\")\n  4. [Hardware Optimization](https://arxiv.org/html/2502.15816v1#Sx3 \"In GenAI at the Edge: Comprehensive Survey on Empowering Edge Devices\")\n    1. [Hardware Accelerators](https://arxiv.org/html/2502.15816v1#Sx3.SSx1 \"In Hardware Optimization â£ GenAI at the Edge: Comprehensive Survey on Empowering Edge Devices\")\n    2. [Attention Optimization](https://arxiv.org/html/2502.15816v1#Sx3.SSx2 \"In Hardware Optimization â£ GenAI at the Edge: Comprehensive Survey on Empowering Edge Devices\")\n  5. [Frameworks](https://arxiv.org/html/2502.15816v1#Sx4 \"In GenAI at the Edge: Comprehensive Survey on Empowering Edge Devices\")\n  6. [Conclusion and Future Work](https://arxiv.org/html/2502.15816v1#Sx5 \"In GenAI at the Edge: Comprehensive Survey on Empowering Edge Devices\")\n  7. [ References  ](https://arxiv.org/html/2502.15816v1#bib \"References\")\n\n\n[License: CC BY 4.0](https://info.arxiv.org/help/license/index.html#licenses-available)\narXiv:2502.15816v1 [cs.DC] 19 Feb 2025\n# GenAI at the Edge: Comprehensive Survey on Empowering Edge Devices\nReport issue for preceding element\nMozhgan Navardi1, Romina Aalishah 1, Yuzhe Fu 2, Yueqian Lin 2, Hai Li 2, Yiran Chen 2, Tinoosh Mohsenin 1\nReport issue for preceding element\n###### Abstract\nReport issue for preceding element\nGenerative Artificial Intelligence (GenAI) applies models and algorithms such as Large Language Model (LLM) and Foundation Model (FM) to generate new data. GenAI, as a promising approach, enables advanced capabilities in various applications, including text generation and image processing. In current practice, GenAI algorithms run mainly on the cloud server, leading to high latency and raising security concerns. Consequently, these challenges encourage the deployment of GenAI algorithms directly on edge devices. However, the large size of such models and their significant computational resource requirements pose obstacles when deploying them in resource-constrained systems. This survey provides a comprehensive overview of recent proposed techniques that optimize GenAI for efficient deployment on resource-constrained edge devices. For this aim, this work highlights three main categories for bringing GenAI to the edge: software optimization, hardware optimization, and frameworks. The main takeaways for readers of this survey will be a clear roadmap to design, implement, and refine GenAI systems for real-world implementation on edge devices.\nReport issue for preceding element\n## Introduction\nReport issue for preceding element\nGenerative Artificial Intelligence (GenAI) has become a promising solution in text generation, image synthesis, and multimodal content creation. These developments often rely on large-scale models such as Large Language Models (LLMs) that achieve remarkable performance but demand large computational and memory resources. Traditionally, these models run on powerful cloud servers, which introduces latency, dependency on network connectivity, and potential privacy risks. As real-time applications and data security become ever more critical, there is a growing push to embed GenAI functionalities directly into edge devices (Nezami et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib85); Navardi et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib84)).\nReport issue for preceding element\nHowever, implementing high-intensive models on the edge presents significant challenges (Pourmehrani et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib92); Kallakuri et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib48); Humes et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib46)). Edge devices, including drones (Navardi et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib83)), and autonomous systems (Manjunath et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib77)) benefit significantly from the GenAI capabilities on devices. For instance, drones can generate real-time terrain analysis in remote areas, Autonomous systems can enhance decision-making through local models. Wearable health monitoring could generate personalized insights from biometric data while ensuring privacy through local data processing. To support these applications, specialized edge hardware such as NVIDIA Jetson, and Qualcomm AI Engine have been developed to handle the computational demands of GenAI while maintaining efficiency.\nReport issue for preceding element\nThis situation calls for innovative approaches in software optimization including model compression, Neural Architecture Search (NAS). In parallel, hardware optimization including specialized accelerators, attention optimization, and dedicated frameworks address computational and energy constraints at the edge (Ali et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib2)). These strategies not only reduce model size and inference latency but also address privacy concerns when deploying complex models on edge devices (Navardi et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib84)). This paper aims to survey existing methods and provide extensive details on implemented GenAI techniques on edge devices. To the best of our knowledge, there is no dedicated survey on GenAI at the edge. By reviewing state-of-the-art techniques from top-tier conferences and journals, this work offers a roadmap for researchers seeking to apply GenAI in edge. The main category of the paper is organized as follows:\nReport issue for preceding element\n  * â¢\nSoftware Optimization: Discusses key strategies for adapting GenAI models to edge devices, including model compression methods (pruning, quantization, and knowledge distillation), NAS, and open-source GenAI models.\nReport issue for preceding element\n  * â¢\nHardware Optimization: Explores hardware accelerators and attention optimization to highlight how they meet GenAIâs computational demands while addressing power and resource constraints on edge devices.\nReport issue for preceding element\n  * â¢\nFrameworks: Reviews frameworks to improve inference latency, memory, and overall energy efficiency.\nReport issue for preceding element\n\n\n![Refer to caption](https://arxiv.org/html/x1.png) Figure 1: Illustration of the flow of GenAI at the edge Report issue for preceding element\n## Software Optimization\nReport issue for preceding element\n### Model Compression\nReport issue for preceding element\nThe rapid advancement of GenAI models, while ushering in unprecedented capabilities, has also given rise to increasingly large model architectures that present significant deployment challenges (Guo et al. [2024a](https://arxiv.org/html/2502.15816v1#bib.bib39)). Early attempts to address these challenges explored distributed mobile computing systems that could partition model computation across multiple devices (Mao et al. [2017b](https://arxiv.org/html/2502.15816v1#bib.bib79), [a](https://arxiv.org/html/2502.15816v1#bib.bib78)).\nReport issue for preceding element\nThis challenge has since prompted extensive research in model compression techniques, which have evolved along three principal directions to enable broader deployment and accessibility. Firstly, quantization techniques have achieved remarkable efficiency through reduced precision representations, particularly through enhanced activation distribution handling and hardware-optimized strategies. Secondly, methodologies for pruning have advanced from rudimentary magnitude-based techniques to sophisticated hardware-aware structured approaches, enabling considerable model reduction while preserving architectural integrity. Thirdly, knowledge distillation has evolved to incorporate progressive frameworks and multi-teacher architectures, showing particular promise in task-specific applications. Contemporary research emphasizes hardware-aware compression strategies and architecture-specific solutions. While these advancements have enabled the deployment of foundation models with competitive performance metrics, the fundamental challenge persists in optimizing the compression-performance trade-off for edge deployment scenarios.\nReport issue for preceding element\nQuantization Model quantization has emerged as a critical technique for deploying large-scale GenAI models on resource-constrained edge devices. Quantization approaches are broadly categorized into post-training quantization (PTQ) and quantization-aware training (QAT). PTQ methods like OPTQ (Frantar et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib30)) and AWQ (Lin et al. [2024a](https://arxiv.org/html/2502.15816v1#bib.bib68)) directly convert trained model parameters to lower precision formats, while QAT approaches such as EdgeQAT (Shen et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib100)) incorporate quantization effects during training. PTQ methods are generally preferred due to their computational efficiency, though recent advances in both approaches have enabled effective compression through sophisticated handling of weight and activation distributions. When applied to LLMs, unique challenges emerge from their heavy-tailed weight distribution. Methods like SmoothQuant (Xiao et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib122)) and OliVe (Guo et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib37)) address this through distribution smoothing and outlier handling techniques. Mixed-precision approaches (Chen et al. [2024b](https://arxiv.org/html/2502.15816v1#bib.bib11)) have shown promise by automatically determining optimal bit widths for different model components based on their quantization sensitivity. Recent work like OneBit (Xu et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib123)) and BitNet (Wang et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib113)) has pushed boundaries by demonstrating viable 1-bit quantization through sophisticated distribution-aware schemes. However, significant challenges remain in maintaining generation quality under extreme compression and developing efficient training methods for quantized LLMs on edge devices (Egiazarian et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib24)).\nReport issue for preceding element\nDiffusion models present their own set of quantization challenges, particularly in handling varying activation distributions across diffusion steps. Approaches like Q-DM (Li et al. [2023c](https://arxiv.org/html/2502.15816v1#bib.bib66)), PTQD (He et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib41)), and Q-Diffusion (Li et al. [2023a](https://arxiv.org/html/2502.15816v1#bib.bib64)) tackle the challenge of varying activation distributions across diffusion steps through adaptive calibration and noise-aware quantization. Specialized temporal-aware quantization methods (So et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib102); Huang et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib45)) have been developed to handle the unique challenges of the iterative denoising process. Current research focuses on effectively handling dynamic activation ranges and balancing compression ratios with generation quality for edge deployment of diffusion models (Yao et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib127)).\nReport issue for preceding element\nPruning Model pruning methods can be broadly categorized into structured and unstructured approaches, each with distinct trade-offs between compression efficiency and hardware compatibility. These techniques have shown particular promise in compressing large-scale generative models while maintaining performance for edge deployment. The field of LLM pruning has recently witnessed several novel approaches. Structured pruning methods like LLM-Pruner (Ma et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib75)) and edge-optimized approaches (Khiabani et al. [2025](https://arxiv.org/html/2502.15816v1#bib.bib50)) achieve 2Ã\\timesÃ speedup with minimal performance degradation by removing entire structural components.Unstructured approaches like SparseGPT (Frantar and Alistarh [2023](https://arxiv.org/html/2502.15816v1#bib.bib28)) enable up to 60% sparsity in large-scale models, while recent advances in modality-specific pruning techniques have shown promising results across speech, vision, and multimodal domains, with methods like SpeechPrune (Lin et al. [2024b](https://arxiv.org/html/2502.15816v1#bib.bib69)) achieving up to 80% pruning rates while maintaining performance. Hardware-aware methods have become increasingly crucial, as exemplified by Flash-LLM (Xia et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib121)), which achieves 3Ã\\timesÃ inference speedup through unstructured sparsity-aware system optimization. Semi-structured pruning methods such as E-Sparse (Li et al. [2023b](https://arxiv.org/html/2502.15816v1#bib.bib65)) further advance this direction by leveraging N:M sparsity patterns to maintain hardware compatibility while achieving high compression rates on edge devices.\nReport issue for preceding element\nIn the context of diffusion models, methods like Diff-Pruning (Fang et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib27)) achieve approximately 50% reduction in FLOPs by leveraging Taylor expansion over pruned timesteps while maintaining generative quality. Specialized approaches like LD-Pruner (Castells et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib8)) implement task-agnostic pruning strategies for Latent Diffusion Models, while DiP-GO (Zhu et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib136)) demonstrates 4.4Ã\\timesÃ speedup on Stable Diffusion without requiring retraining. Recent work combines gradient-based pruning for mask matrix continuity (Wan et al. [2025](https://arxiv.org/html/2502.15816v1#bib.bib112)) with strategic data pruning (Briq et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib7)), showing particular promise for edge deployment where both computational efficiency and generation quality are critical (Yan et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib125)).\nReport issue for preceding element\nKnowledge Distillation. Knowledge Distillation (KD) has emerged as a crucial paradigm for deploying GenAI models on edge devices, with distinct approaches developed for different model architectures to balance model capabilities with computational constraints. The application of KD to language models has led to a variety of approaches. These can be categorized into white-box and black-box methods. White-box KD enables student models to match both final predictions and internal representations when the teacher model is open-source (e.g., LLaMA (Touvron et al. [2023b](https://arxiv.org/html/2502.15816v1#bib.bib111))), while black-box KD works with closed-source models (e.g., GPT-4 (OpenAI [2024](https://arxiv.org/html/2502.15816v1#bib.bib88))) through API calls (Liu et al. [2024a](https://arxiv.org/html/2502.15816v1#bib.bib70)). Notable advances include MiniLLM (Gu et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib35)), which introduces a reversed Kullback-Leibler divergence objective to stabilize student updates, and instruction-following distillation approaches that have produced efficient open-source models like Vicuna (Chiang et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib12)) and Koala (Geng et al. [2023a](https://arxiv.org/html/2502.15816v1#bib.bib32)). Recent work in instruction-following KD has enabled compact yet capable models through supervised fine-tuning (Wu et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib120)), while advanced applications like RLAI feedback (Lee et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib58)) demonstrate the potential for model alignment through distillation. Adaptive distillation methods have further enhanced this field by dynamically adjusting the distillation process based on input complexity, allowing student models to focus learning where improvement is most needed (Liang et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib67)).\nReport issue for preceding element\nIn the domain of diffusion models, KD primarily focuses on accelerating sampling speed to address the challenge of high inference latency. Progressive distillation (Salimans and Ho [2022](https://arxiv.org/html/2502.15816v1#bib.bib97)) represents an approach that iteratively halves sampling steps (e.g., from 1000 to 1), enabling efficient edge deployment while maintaining generation quality. Single-step approaches (Luhman and Luhman [2021](https://arxiv.org/html/2502.15816v1#bib.bib74)) further compress diffusion teachers into one-step generators, although this requires careful balance between efficiency and generation fidelity. Teacher-free acceleration methods like DPM-Solver (Lu et al. [2022](https://arxiv.org/html/2502.15816v1#bib.bib73)) and consistency models (Song et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib103)) demonstrate effective inference cost reduction without extensive re-training. Recent advances include two-stage approaches (Meng et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib80)) for text-conditional models and score distillation sampling (Poole et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib91)) for 3D generation, showcasing the versatility of distillation in different applications. Also, generative dataset distillation using models like SDXL-Turbo with class-specific prompts has achieved superior images per class ratios in recent benchmarks (Su et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib105)), offering new possibilities for efficient model training and deployment.\nReport issue for preceding element\n### Neural Architecture Design\nReport issue for preceding element\nEfficient neural architecture design has emerged as a critical research direction to address the increasing complexity and resource demands of modern models, particularly for edge devices (Howard et al. [2017](https://arxiv.org/html/2502.15816v1#bib.bib43); Elsken et al. [2019](https://arxiv.org/html/2502.15816v1#bib.bib25)). By automating the generation of network architectures while considering specific hardware and constraints, computational overhead, required memory, and power consumption have been improved, while maintaining model performance.\nReport issue for preceding element\nNeural Architecture Search (NAS). Neural Architecture Search (NAS) (Zoph [2016](https://arxiv.org/html/2502.15816v1#bib.bib137); Elsken et al. [2019](https://arxiv.org/html/2502.15816v1#bib.bib25)) serves as a powerful framework to automate the design of optimal model topologies with strict latency, memory, or power budgets. By systematically exploring a predefined search space such as varying layer depth, width, or connection patterns. NAS algorithms can discover specialized architectures that outperform traditional solutions. In (Zoph [2016](https://arxiv.org/html/2502.15816v1#bib.bib137)), they have proposed the first NAS using reinforcement learning (RL) to determine optimal Recurrent Neural Network (RNN) parameters. Subsequently, this idea was extended to Convonotional Neural Network (CNNs) in (Zoph et al. [2018](https://arxiv.org/html/2502.15816v1#bib.bib138)), where the authors integrated a Sequential Model-Based Optimization (SMBO) approach with a reinforcement mechanism for cell-based searches to find the best configuration.\nReport issue for preceding element\nIn the context of GenAI, where large models often dominate in tasks such as text generation or image synthesis, NAS-driven architectures present a promising route to achieve efficiency. There are a limited number of work on NAS in the field of transformers (Liu et al. [2024c](https://arxiv.org/html/2502.15816v1#bib.bib72)). FL-NAS (Qin et al. [2024a](https://arxiv.org/html/2502.15816v1#bib.bib93)) have proposed an approach which leverages LLM to find high-performance DNNs for resource-constrained systems. Moreover, work in (Benmeziane and Maghraoui [2024](https://arxiv.org/html/2502.15816v1#bib.bib4)) proposed a LLM-based methodology for NAS technique in Edge devices. Puzzle (Bercovich et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib5)) proposed an LLM optimized for inference using NAS under hardware constraints, achieving a 2.17x inference throughput speedup.\nReport issue for preceding element\n### Open-Source GenAI models\nReport issue for preceding element\nThe recent advancements in reasoning capabilities of models such as DeepSeek-R1 (DeepSeek-AI et al. [2025](https://arxiv.org/html/2502.15816v1#bib.bib20)) emphasize the power of open research development. DeepSeek-R1 (DeepSeek-AI et al. [2025](https://arxiv.org/html/2502.15816v1#bib.bib20)) has profited significantly from open-source tools like PyTorch and Metaâs Llama (Touvron et al. [2023b](https://arxiv.org/html/2502.15816v1#bib.bib111)). One of the key contributions to the advancement in GenAI is open-source innovations, specifically for edge scenarios in which the resources are limited. In these cases, smaller model sizes and less latency besides not losing performance are the main considerations. Therefore, researchers explored various compression methods, leading to models like DistilBERT (Sanh et al. [2019](https://arxiv.org/html/2502.15816v1#bib.bib98)), TinyBERT (Jiao et al. [2020](https://arxiv.org/html/2502.15816v1#bib.bib47)), ALBERT (Lan et al. [2020](https://arxiv.org/html/2502.15816v1#bib.bib56)), MobileBERT (Sun et al. [2020](https://arxiv.org/html/2502.15816v1#bib.bib107)), MiniLM (Wang et al. [2020b](https://arxiv.org/html/2502.15816v1#bib.bib117)), and MiniLMv2 (Wang et al. [2021](https://arxiv.org/html/2502.15816v1#bib.bib118)) each using techniques such as knowledge distillation, parameter sharing, or factorization to make large models smaller while maintaining strong performance.\nReport issue for preceding element\nBeyond these compression-based strategies that are already covered in the previous sections, novelties in architecture further improved efficiency. Reformer (Kitaev et al. [2020](https://arxiv.org/html/2502.15816v1#bib.bib54)) introduced locality-sensitive hashing for attention and reversible residual layers, enabling near-linear complexity for longer sequences. Meanwhile, GPT-NeoX-20B (Black et al. [2022](https://arxiv.org/html/2502.15816v1#bib.bib6)), LLaMA (Touvron et al. [2023b](https://arxiv.org/html/2502.15816v1#bib.bib111)), and LLaMA2 (Touvron et al. [2023a](https://arxiv.org/html/2502.15816v1#bib.bib110)) showed how LLMs could be developed and released collaboratively, making it easier for edge-focused adaptations. Even smaller-scale of these projects such as TinyLlama (Zhang et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib133)) and H2O-Danube-1.8B (Singer, Philipp others [2024](https://arxiv.org/html/2502.15816v1#bib.bib101)) now offer compact language models tailored to edge constraints, continuing the trend of collaborative research. Similarly, research on instruction tuning (Chung et al. [2022](https://arxiv.org/html/2502.15816v1#bib.bib16)), which trains models to handle various tasks by exposing them to different instructions, reinforced the importance of building flexible and open-source foundations for further innovation.\nReport issue for preceding element\nResearchers have further built on open releases to develop conversational systems, including Alpaca (Taori et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib109)), Koala (Geng et al. [2023b](https://arxiv.org/html/2502.15816v1#bib.bib33)), and Vicuna (Chiang et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib12)), each developed by fine-tuning LLaMA (Touvron et al. [2023b](https://arxiv.org/html/2502.15816v1#bib.bib111)) on curated datasets, all demonstrating competitive performance against models like ChatGPT and Bard. These models have also served as benchmarks for edge-focused projects such as SqueezeLLM (Kim et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib52)), which introduces a post-training quantization framework to compress LLMs for more efficient inference, focusing on reducing memory bandwidth, outperforming methods like GPTQ (Frantar et al. [2022](https://arxiv.org/html/2502.15816v1#bib.bib29)), AWQ (Lin et al. [2024a](https://arxiv.org/html/2502.15816v1#bib.bib68)), and SpQR(Dettmers et al. [2023b](https://arxiv.org/html/2502.15816v1#bib.bib22)). In parallel, techniques like LoRA (Low-Rank Adaptation) (Hu et al. [2021](https://arxiv.org/html/2502.15816v1#bib.bib44)) have reduced the cost of fine-tuning large models, accelerating domain-specific deployments. Later, QLoRA (Dettmers et al. [2023a](https://arxiv.org/html/2502.15816v1#bib.bib21)) tried to fine-tune a large model on a single GPU by reducing memory usage by quantizing the quantization constants and using this technique. Taken together, several open-source LLMs have been developed, and some of them are compressed to reduce their size and improve efficiency. These include MPT-7B (MosaicML NLP Team [2023](https://arxiv.org/html/2502.15816v1#bib.bib82)), which implements a 7B-parameter architecture designed for commercial applications; DLite (AI Squared [2023](https://arxiv.org/html/2502.15816v1#bib.bib1)), which scales from 124M to 1.5B parameters; and RedPajama-INCITE (Computer [2023](https://arxiv.org/html/2502.15816v1#bib.bib17)), which spans 3B to 7B parameters. Open-source models and innovations can be valuable for resource-constraint applications, and be fine-tuned for specific tasks to improve their performance.\nReport issue for preceding element\n## Hardware Optimization\nReport issue for preceding element\n### Hardware Accelerators\nReport issue for preceding element Table 1: Hardware Accelerator for GenAI\nAccelerator | Year | Platform | Technology | Networks | Sparsity/Quantization | Peak Energy Efficiency (TOPS/W)  \n---|---|---|---|---|---|---  \nEXION (Heo et al. [2025](https://arxiv.org/html/2502.15816v1#bib.bib42)) | 2025 | ASIC simulator | 14nm | SD/DiT | â/ â@INT12 | 11.5311.5311.5311.53  \nHCAEDS (Guo et al. [2024b](https://arxiv.org/html/2502.15816v1#bib.bib40)) | 2024 | CIM tapeout | 28nm | SD | - / â@INT10/BF16 | 74.3474.3474.3474.34  \nDMPU (Qin et al. [2024b](https://arxiv.org/html/2502.15816v1#bib.bib95)) | 2024 | ASIC tapeout | 22nm | DDPM | â/ - | 52.0152.0152.0152.01  \nEEDA (Yoo et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib130)) | 2024 | ASIC tapeout | 28nm | SD | - / â@HYP8 | 4.964.964.964.96  \nCambricon-D (Kong et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib55)) | 2024 | ASIC simulator | 7nm | SD | â/ â@INT3/FP16 | 13.3413.3413.3413.34  \nAttAcc (Park et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib90)) | 2024 | CIM simulator | 7nm | LLaMA/GPT-3 | - / - |  2.67Ã2.67\\times2.67 Ã DGX A100  \nSpecPIM (Li et al. [2024a](https://arxiv.org/html/2502.15816v1#bib.bib61)) | 2024 | CIM simulator | - | LLaMA/OPT | - / - |  6.7Ã6.7\\times6.7 Ã A100  \nASADI (Li et al. [2024c](https://arxiv.org/html/2502.15816v1#bib.bib63)) | 2024 | CIM simulator | 28nm | GPT-2/BERT | â/ - | -  \nMECLA (Qin et al. [2024c](https://arxiv.org/html/2502.15816v1#bib.bib96)) | 2024 | ASIC simulator | 28nm | LLaMA/BERT | - / â@INT8 | 7.097.097.097.09  \nSTP (Tambe et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib108)) | 2023 | ASIC tapeout | 28nm | BERT | - / â@FP4 | 18.118.118.118.1  \nOliVe (Guo et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib37)) | 2023 | ASIC simulator | 22nm | GPT-2/OPT/BERT | - / â@Adaptive 4bit |  4Ã4\\times4 Ã GOBO (Zadeh et al. [2020](https://arxiv.org/html/2502.15816v1#bib.bib131))  \nFACT (Qin et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib94)) | 2023 | ASIC simulator | 28nm | BERT | â/ â@INT8 | 4.394.394.394.39  \nReport issue for preceding element\nHardware accelerators are typically designed through the software and hardware co-design for specific networks. Algorithmically, data sparsity is enhanced by pruning, and model compression, such as quantization, reduces network size. On the hardware side, specific architectures are designed to bypass sparse or redundant computations, increase data reuse, and minimize data movement, thus enabling energy-efficient acceleration on edge devices. Generative AI (GenAI) includes GAN, LLM, and Diffusion models. While extensive hardware work has focused on optimizing GAN models (Chen et al. [2018](https://arxiv.org/html/2502.15816v1#bib.bib9); Kim et al. [2020](https://arxiv.org/html/2502.15816v1#bib.bib51); Kang et al. [2021](https://arxiv.org/html/2502.15816v1#bib.bib49)), recent trends have shifted toward LLM and Diffusion models, driving further hardware research in GenAI. This section reviews recent efforts in optimizing hardware accelerator for LLM and Diffusion networks, with representative works summarized in Table [1](https://arxiv.org/html/2502.15816v1#Sx3.T1 \"Table 1 â£ Hardware Accelerators â£ Hardware Optimization â£ GenAI at the Edge: Comprehensive Survey on Empowering Edge Devices\").\nReport issue for preceding element\nLLM Acceleration LLM models have diverse distributions at the tensor or channel levels, numerous studies leverage customized data types to accommodate this challenge. For example, ANT (Guo et al. [2022](https://arxiv.org/html/2502.15816v1#bib.bib38)) introduces a novel data type and employs an adaptive mechanism to determine the most appropriate type for each tensor from a predefined set. Expanding on ANT, OliVe (Guo et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib37)) proposes an outlier-victim pair approach, which provides a more precise representation of outlier distributions in LLM models. Both ANT and OliVe incorporate specialized decoders and multiply-accumulate (MAC) units to optimize their arithmetic computation processes for LLMs. Some studies focus on reducing redundant computations in LLM models to improve the energy efficiency during inference. STP (Tambe et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib108)) proposes a computation-skipping strategy and dynamic data path reconfiguration based on entropy, achieving high energy efficiency with minimal accuracy loss. Furthermore, it has been observed that linear projections contribute significantly to the memory footprint and latency in LLM models. FACT (Qin et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib94)) introduces an eager prediction method with a leading-one detector and log-based inner-product estimation, reducing computations in both attention and linear projections. MECLA (Qin et al. [2024c](https://arxiv.org/html/2502.15816v1#bib.bib96)) surpasses FACT by decomposing large matrices into smaller sub-matrices to minimize off-chip memory access and re-associating data on-chip for better reuse.\nReport issue for preceding element\nRecently, Computing-in-Memory (CIM) becomes a prominent approach for LLM acceleration. CIM accelerators offer significant energy efficiency gains, particularly for general matrix-matrix multiplication (GEMM) operations. Existing studies typically leverage CIM architectures to accelerate the attention mechanism, while relying on CPUs or GPUs to handle other operations. ASADI (Li et al. [2024c](https://arxiv.org/html/2502.15816v1#bib.bib63)) introduces a sparse attention paradigm based on diagonal compression (DIA) format, enabling highly parallel computation on CIM processors. SpecPIM (Li et al. [2024a](https://arxiv.org/html/2502.15816v1#bib.bib61)) accelerates speculative inference in LLM by optimizing resource allocation in CIM-enabled heterogeneous systems, while AttAcc (Park et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib90)) accelerates batched LLM inference on CIM/NPU heterogeneous systems. Given these developments, it is expected that CIM-based accelerators for LLM models will become more prevalent in the future.\nReport issue for preceding element\nDiffusion Acceleration Diffusion networks have made significant progress recently in various GenAI tasks, with different network architecture from LLM models. These networks generate images or videos through multiple iterations of denoising operations, with highly similar images in consecutive iterations. Consequently, hardware optimizations often leverage inter- and intra-iteration similarity to accelerate Diffusion networks, typically through differential computing and skipping redundant computations. \nReport issue for preceding element\nCambricon-D (Kong et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib55)) introduces an approximate ReLU in the Stable Diffusion (SD) network, enabling differential computing for nonlinear functions and addressing the memory overhead associated with full-precision nonlinear calculations in traditional differential computing architectures. DMPU (Qin et al. [2024b](https://arxiv.org/html/2502.15816v1#bib.bib95)) observes that many pixels exhibit minimal changes between consecutive time steps in Diffusion models, and thus proposes a semantic-segment sparse convolution along with a trivial attention exponent inheritance method to skip redundant computations in both the convolution and attention mechanisms, significantly enhancing the energy efficiency. EXION (Heo et al. [2025](https://arxiv.org/html/2502.15816v1#bib.bib42)) presents an FFN-Reuse algorithm that can be applied across iterations, along with an improved eager prediction method for predicting attention scores, which reduces redundant computations and boosts throughput. HCAEDS (Guo et al. [2024b](https://arxiv.org/html/2502.15816v1#bib.bib40)) is the first heterogeneous CIM chip designed for Diffusion models, incorporating a Sign-Magnitude radix-8 Booth CIM macro for integer data and a four-operand exponent CIM macro for floating-point data, achieving a high energy efficiency.\nReport issue for preceding element\nNumerous GenAI hardware studies (Kong et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib55); Yoo et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib130); Yang et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib126); Wang et al. [2024c](https://arxiv.org/html/2502.15816v1#bib.bib119)) have observed that nonlinear functions (such as softmax, GeLU, etc.) can introduce significant latency overhead during the hardware acceleration. These studies optimize nonlinear functions to enhance overall throughput. Additionally, some studies (Fu et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib31); Dong et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib23); Stevens et al. [2021](https://arxiv.org/html/2502.15816v1#bib.bib104); Yan et al. [2019](https://arxiv.org/html/2502.15816v1#bib.bib124)) have focused specifically on optimizing nonlinear functions and have designed specialized hardware to facilitate network inference. All of these studies indicate a potential research trend on optimizing nonlinear functions in GenAI networks. Combined with techniques such as eliminating redundant computations and data compression, these approaches can enhance hardware acceleration and improve energy efficiency for GenAI systems.\nReport issue for preceding element\n### Attention Optimization\nReport issue for preceding element\nTransformers have become the backbone of many GenAI models, but their multi-head self-attention mechanism can dominate runtime and memory usage. Therefore, researchers have explored a range of strategies to optimize attention on _hardware_ and _algorithmic_ levels.\nReport issue for preceding element\nHardware-based. FlashAttention (Dao et al. [2022](https://arxiv.org/html/2502.15816v1#bib.bib19)) reorders attention operations to reduce the number of reads and writes between GPU high bandwidth memory (HBM) and on-chip static RAM (SRAM) by splitting queries, keys, and values into smaller blocks, recomputing attention on-chip during the backward pass, and fusing multiple GPU kernels into one. Built on this, FlashAttention-2 (Dao [2023](https://arxiv.org/html/2502.15816v1#bib.bib18)) takes the foundation of memory efficiency and adds better parallelism and work distribution to further increase speed and GPU utilization, especially for longer sequences. Then, FlashAttention-3 (Shah et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib99)) introduces asynchrony and low-precision computation to further optimize the attention mechanism for modern GPU architectures, which allows for even higher performance and efficiency, along with reduced error for low-precision (FP8) computing. Besides these, xFormers (Lefaudeux et al. [2022](https://arxiv.org/html/2502.15816v1#bib.bib60)), a PyTorch-based library, provides a collection of optimized attention and Transformer blocks, including custom GPU kernels and memory-efficient attention implementations.\nReport issue for preceding element\nAlgorithmic-based. Work on sparse attention reduces the quadratic complexity of self-attention by ignoring parts of the input that do not affect the result significantly. Child et al. (Child et al. [2019](https://arxiv.org/html/2502.15816v1#bib.bib13)) pioneered this approach by limiting attention to strided patterns using sparse factorizations of the attention matrix to reduce computation cost while maintaining performance on sequence models. Subsequent techniques like Longformer (Beltagy et al. [2020](https://arxiv.org/html/2502.15816v1#bib.bib3)) by using a combination of sliding window local attention and task-motivated global attention, Big Bird (Zaheer et al. [2020](https://arxiv.org/html/2502.15816v1#bib.bib132)) by combining random, windowed, and global attention to create a sparse attention mechanism, and Linformer (Wang et al. [2020a](https://arxiv.org/html/2502.15816v1#bib.bib116)) by decomposing attention with linear projections to achieve linear complexity introduced various structured sparsity patterns. Meanwhile, Choromanski et al. (Choromanski et al. [2021](https://arxiv.org/html/2502.15816v1#bib.bib15)) developed performer, which uses random feature maps to approximate the softmax function, reducing its time complexity from ðªâ¢(n2)ðªsuperscriptð2\\mathcal{O}(n^{2})caligraphic_O ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) to ðªâ¢(n)ðªð\\mathcal{O}(n)caligraphic_O ( italic_n ).\nReport issue for preceding element\n## Frameworks\nReport issue for preceding element\nDeploying GenAI models on edge devices might bring challenges because of limited computational power, memory, and latency requirements. To address these constraints, researchers have explored various techniques that simplify computations at both the graph and operator levels. By fusing kernels, reducing redundant operations or parameters, and customizing algorithms to the hardware, these methods enable fast inference for tasks such as large language modeling, super-resolution, and more.\nReport issue for preceding element\nNVIDIA TensorRT and Apache TVM are pioneered compiler-based optimizations by combining graph-level fusion and quantization with lower latency. Likewise, Googleâs EdgeTPU and Coral stacks enable rapid deployment of compressed models through low-power hardware and software stack. TensorRT-LLM (NVIDIA Corporation [2025](https://arxiv.org/html/2502.15816v1#bib.bib87)) is also a specialized toolkit for accelerating LLM inference on GPUs, including optimized CUDA kernels for attention computations, inflight batching, and quantization.\nReport issue for preceding element\nBeyond these compilers, researchers have developed frameworks customized for various GenAI workloads. For instance, Yi et al. proposed EdgeMoE (Yi et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib129)), an engine specifically optimized for Mixture-of-Experts (MoE) language models. By using expert-wise bitwidth adaptation, it supports models with a large number of parameters on edge devices to reduce inference times substantially. Wang et al. introduced CoreInfer (Wang et al. [2024b](https://arxiv.org/html/2502.15816v1#bib.bib115)), achieving over 10Ã\\timesÃ speedup compared to the Huggingface implementation through semantic-based sparse activation that identifies, fixes, and maintains stable neuron activation patterns at the sentence level. Laskaridis et al. introduced MELTing point (Laskaridis et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib57)), a mobile benchmarking suite designed to evaluate LLM performance, focusing on energy usage and memory footprints, across smartphones and Jetson platforms. TinyChatEngine (MIT-HAN-Lab [2024](https://arxiv.org/html/2502.15816v1#bib.bib81)) is also, an on-device LLM/VLM Inference Library that uses compression techniques to limit memory budgets while maintaining interactive response times on edge hardware. Furthermore, Nikoghosyan et al. showed that applying TensorRT to Transformer-based models on NVIDIA Jetson Xavier yields over 60% latency reduction with negligible accuracy loss (Nikoghosyan et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib86)).\nReport issue for preceding element\nIn addition to language models, solutions target Super-Resolution (SR) and other vision-based generators. Chen et al. introduced TileSR (Chen et al. [2024a](https://arxiv.org/html/2502.15816v1#bib.bib10)), which splits ultra-high-resolution images into tiles and selects the ones with the highest upscaling difficulty; these tiles are processed in parallel across multiple devices, reducing latency by up to 82% and improving the image quality up to 10% compared to other alternatives such as Supremo (Yi et al. [2022](https://arxiv.org/html/2502.15816v1#bib.bib128)) and MobiSR (Lee et al. [2019](https://arxiv.org/html/2502.15816v1#bib.bib59)). Wang et al. (Wang et al. [2024a](https://arxiv.org/html/2502.15816v1#bib.bib114)) proposed ESHP, which combines a difficulty predictor with deep reinforcement learning to distribute SR tasks among CPUs, GPUs, and NPUs, speeding up SR processing without modifying the original architecture of the given SR model. Zhao et al. demonstrated a full-stack SR acceleration framework for embedded GPU devices, which outperformed standard TensorRT baselines in speed due to dictionary compression and operations optimization (Zhao et al. [2021](https://arxiv.org/html/2502.15816v1#bib.bib135)).\nReport issue for preceding element\nFPGAs also provide a promising platform for runtime acceleration. Li et al. proposed a lookup-table (LUT)âbased SR pipeline making sharper images while using much less energy without losing image quality (Li et al. [2024b](https://arxiv.org/html/2502.15816v1#bib.bib62)). Other research has combined FFT-based processing with efficient multipliers (Malathi et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib76)), designed heterogeneous CNN-SNN architectures (Choi et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib14)), or combined FPGA and GPU via PCIe to achieve real-time SR in microscopic imaging (Gui et al. [2022](https://arxiv.org/html/2502.15816v1#bib.bib36)). For video-specific scenarios, Kim et al. employed pipeline and memory optimizations to reach 60 fps on 4K UHD content (Kim et al. [2019](https://arxiv.org/html/2502.15816v1#bib.bib53)), while Sun et al. developed RNN compression techniques to manage temporal correlations (Sun et al. [2022](https://arxiv.org/html/2502.15816v1#bib.bib106)). On larger multi-core systems Georgis et al. attained speedups over CPU-only baselines via parallelization (Georgis et al. [2019](https://arxiv.org/html/2502.15816v1#bib.bib34)), and Liu et al. achieved real-time 4K SR on edge FPGAs through a DSP-enhanced caching scheme (Liu et al. [2024b](https://arxiv.org/html/2502.15816v1#bib.bib71)). Finally, several system-level revisions help further reduce overhead. Fan et al. (Fan et al. [2023](https://arxiv.org/html/2502.15816v1#bib.bib26)) leveraged codec-side data to skip redundant decoding in video SR, improved performance by up to 9.4Ã\\timesÃ. Deformable 3D convolutional networks, essential in video tasks, were accelerated through tile decoupling and memory optimization by Zhang et al. (Zhang et al. [2022](https://arxiv.org/html/2502.15816v1#bib.bib134)). Even resource-limited devices like the Raspberry Pi can support real-time SR: Osorno-Ortiz et al. integrated 2D-DWT with parallel interpolation to handle HD images in a short time (Osorno-Ortiz et al. [2024](https://arxiv.org/html/2502.15816v1#bib.bib89)).\nReport issue for preceding element\n## Conclusion and Future Work\nReport issue for preceding element\nThis work proposed a comprehensive survey regarding deploying Generative AI (GenAI) on edge devices. It presents a promising path toward reducing latency, enhancing data privacy, and enabling real-time capabilities in various applications. This survey has showcased the critical roles of software optimization, hardware specialization, and on-device inference frameworks in overcoming the resource constraints typical of embedded systems. Despite these advancements, significant challenges persist especially regarding model personalization, and security across distributed edge nodes. By effectively addressing these challenges and combining these techniques with ongoing optimizations in model design and hardware acceleration, researchers and practitioners can pave the way for even more efficient, scalable, and privacy-preserving GenAI solutions at the edge.\nReport issue for preceding element\n## References\nReport issue for preceding element\n  * AI Squared (2023)â AI Squared. 2023.  DLite V2.  https://huggingface.co/aisquared/dlite-v2-774m. \n  * Ali et al. (2024)â Ali, A. H.; et al. 2024.  Energy-Aware FPGA Implementation of Spiking Neural Network with LIF Neurons.  _arXiv preprint arXiv:2411.01628_. \n  * Beltagy et al. (2020)â Beltagy, I.; et al. 2020.  Longformer: The Long-Document Transformer.  _arXiv preprint arXiv:2004.05150_. \n  * Benmeziane and Maghraoui (2024)â Benmeziane, H.; and Maghraoui, K. E. 2024.  Are Large Language Models Good Neural Architecture Generators for Edge?  In _2024 IEEE International Conference on Edge Computing and Communications (EDGE)_ , 162â165. \n  * Bercovich et al. (2024)â Bercovich, A.; et al. 2024.  Puzzle: Distillation-Based NAS for Inference-Optimized LLMs.  _arXiv preprint arXiv:2411.19146_. \n  * Black et al. (2022)â Black, S.; et al. 2022.  GPT-NeoX-20B: An Open-Source Autoregressive Language Model.  _arXiv preprint arXiv:2204.06745_. \n  * Briq et al. (2024)â Briq, R.; et al. 2024.  Data Pruning in Generative Diffusion Models.  arXiv:2411.12523. \n  * Castells et al. (2024)â Castells, T.; et al. 2024.  LD-Pruner: Efficient Pruning of Latent Diffusion Models using Task-Agnostic Insights.  In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops_ , 821â830. \n  * Chen et al. (2018)â Chen, F.; et al. 2018.  ReGAN: A pipelined ReRAM-based accelerator for generative adversarial networks.  In _2018 23rd Asia and South Pacific Design Automation Conference (ASP-DAC)_. IEEE. \n  * Chen et al. (2024a)â Chen, N.; et al. 2024a.  TileSR: Accelerate On-Device Super-Resolution with Parallel Offloading in Tile Granularity.  In _IEEE Annual International Conference on Computer Communications_. \n  * Chen et al. (2024b)â Chen, Z.; et al. 2024b.  Channel-wise mixed-precision quantization for large language models.  _arXiv preprint arXiv:2410.13056_. \n  * Chiang et al. (2023)â Chiang, W.-L.; Li, Z.; Lin, Z.; Sheng, Y.; Wu, Z.; Zhang, H.; Zheng, L.; Zhuang, S.; Zhuang, Y.; Gonzalez, J. E.; Stoica, I.; and Xing, E. P. 2023.  Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality. \n  * Child et al. (2019)â Child, R.; et al. 2019.  Generating Long Sequences with Sparse Transformers.  _arXiv preprint arXiv:1904.10509_. \n  * Choi et al. (2023)â Choi, J.; et al. 2023.  A Resource-Efficient Super-Resolution FPGA Processor with Heterogeneous CNN and SNN Core Architecture.  _IEEE Transactions on Computers_. \n  * Choromanski et al. (2021)â Choromanski, K.; et al. 2021.  Rethinking Attention with Performers.  In _International Conference on Learning Representations (ICLR)_. \n  * Chung et al. (2022)â Chung, H. W.; et al. 2022.  Scaling Instruction-Finetuned Language Models.  _arXiv preprint arXiv:2210.11416_. \n  * Computer (2023)â Computer, T. 2023.  RedPajama: An Open Source Recipe to Reproduce LLaMA training dataset. \n  * Dao (2023)â Dao, T. 2023.  FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning.  _arXiv preprint arXiv:2307.08691_. \n  * Dao et al. (2022)â Dao, T.; et al. 2022.  FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.  _arXiv preprint arXiv:2205.14135_. \n  * DeepSeek-AI et al. (2025)â DeepSeek-AI; et al. 2025.  DeepSeek-R1: Incentivizing reasoning capability in LLMs via reinforcement learning.  _arXiv preprint arXiv:2501.12948_. \n  * Dettmers et al. (2023a)â Dettmers, T.; et al. 2023a.  QLoRA: Efficient Finetuning of Quantized LLMs.  In _Advances in Neural Information Processing Systems_ , 10088â10115. \n  * Dettmers et al. (2023b)â Dettmers, T.; et al. 2023b.  SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression.  _arXiv preprint arXiv:2306.03078_.  Extended Preprint. \n  * Dong et al. (2024)â Dong, P.; et al. 2024.  Genetic Quantization-Aware Approximation for Non-Linear Operations in Transformers.  In _Proceedings of the 61st ACM/IEEE Design Automation Conference (DAC)_. \n  * Egiazarian et al. (2024)â Egiazarian, V.; et al. 2024.  Extreme Compression of Large Language Models via Additive Quantization.  arXiv:2401.06118. \n  * Elsken et al. (2019)â Elsken, T.; et al. 2019.  Neural architecture search: A survey.  _Journal of Machine Learning Research_. \n  * Fan et al. (2023)â Fan, H.; et al. 2023.  Co-ViSu: a Video Super-Resolution Accelerator Exploiting Codec Information Reuse.  In _International Conference on Field-Programmable Logic and Applications (FPL)_. \n  * Fang et al. (2023)â Fang, G.; et al. 2023.  Structural pruning for diffusion models.  In _Advances in Neural Information Processing Systems_. \n  * Frantar and Alistarh (2023)â Frantar, E.; and Alistarh, D. 2023.  SparseGPT.  arXiv:2307.00026. \n  * Frantar et al. (2022)â Frantar, E.; et al. 2022.  GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers.  _arXiv preprint arXiv:2210.17323_. \n  * Frantar et al. (2023)â Frantar, E.; et al. 2023.  OPTQ: Accurate Quantization for Generative Pre-trained Transformers.  In _The Eleventh International Conference on Learning Representations_. \n  * Fu et al. (2024)â Fu, Y.; et al. 2024.  SoftAct: A High-Precision Softmax Architecture for Transformers Supporting Nonlinear Functions.  _IEEE Transactions on Circuits and Systems for Video Technology_ , 34(9). \n  * Geng et al. (2023a)â Geng, X.; et al. 2023a.  Koala: A Dialogue Model for Academic Research. \n  * Geng et al. (2023b)â Geng, X.; et al. 2023b.  Koala: A Dialogue Model for Academic Research.  https://bair.berkeley.edu/blog/2023/04/03/koala/. \n  * Georgis et al. (2019)â Georgis, G.; et al. 2019.  Acceleration techniques and evaluation on multi-core CPU, GPU and FPGA for image processing and super-resolution.  _Journal of Real-Time Image Processing_. \n  * Gu et al. (2024)â Gu, Y.; et al. 2024.  MiniLLM: Knowledge Distillation of Large Language Models.  In _The Twelfth International Conference on Learning Representations_. \n  * Gui et al. (2022)â Gui, D.; et al. 2022.  PCIe-based FPGA-GPU heterogeneous computation for real-time multi-emitter fitting in super-resolution localization microscopy.  _Biomedical Optics Express_. \n  * Guo et al. (2023)â Guo, C.; Tang, J.; Hu, W.; Leng, J.; Zhang, C.; Yang, F.; Liu, Y.; Guo, M.; and Zhu, Y. 2023.  Olive: Accelerating large language models via hardware-friendly outlier-victim pair quantization.  In _Proceedings of the 50th Annual International Symposium on Computer Architecture_ , 1â15. \n  * Guo et al. (2022)â Guo, C.; et al. 2022.  Ant: Exploiting adaptive numerical data type for low-bit deep neural network quantization.  In _2022 55th IEEE/ACM International Symposium on Microarchitecture (MICRO)_ , 1414â1433. IEEE. \n  * Guo et al. (2024a)â Guo, C.; et al. 2024a.  A Survey: Collaborative Hardware and Software Design in the Era of Large Language Models.  _arXiv preprint arXiv:2410.07265_. \n  * Guo et al. (2024b)â Guo, R.; et al. 2024b.  20.2 A 28nm 74.34TFLOPS/W BF16 Heterogenous CIM-Based Accelerator Exploiting Denoising-Similarity for Diffusion Models.  In _2024 IEEE International Solid-State Circuits Conference (ISSCC)_ , volume 67, 362â364. \n  * He et al. (2023)â He, Y.; et al. 2023.  PTQD: Accurate Post-Training Quantization for Diffusion Models.  In Oh, A.; Naumann, T.; Globerson, A.; Saenko, K.; Hardt, M.; and Levine, S., eds., _Advances in Neural Information Processing Systems_ , volume 36, 13237â13249. Curran Associates, Inc. \n  * Heo et al. (2025)â Heo, J.; et al. 2025.  EXION: Exploiting Inter-and Intra-Iteration Output Sparsity for Diffusion Models.  _arXiv preprint arXiv:2501.05680_. \n  * Howard et al. (2017)â Howard, A. G.; et al. 2017.  Mobilenets: Efficient convolutional neural networks for mobile vision applications.  _arXiv preprint arXiv:1704.04861_. \n  * Hu et al. (2021)â Hu, E.; et al. 2021.  LoRA: Low-Rank Adaptation of Large Language Models.  _arXiv preprint arXiv:2106.09685_. \n  * Huang et al. (2024)â Huang, Y.; et al. 2024.  TFMQ-DM: Temporal Feature Maintenance Quantization for Diffusion Models.  In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)_ , 7362â7371. \n  * Humes et al. (2023)â Humes, E.; et al. 2023.  Squeezed Edge YOLO: Onboard Object Detection on Edge Devices.  _arXiv preprint arXiv:2312.11716_. \n  * Jiao et al. (2020)â Jiao, X.; et al. 2020.  TinyBERT: Distilling BERT for Natural Language Understanding.  _arXiv preprint arXiv:1909.10351_. \n  * Kallakuri et al. (2024)â Kallakuri, U.; et al. 2024.  Resource-Aware Saliency-Guided Differentiable Pruning for Deep Neural Networks.  In _Proceedings of the Great Lakes Symposium on VLSI 2024_ , 694â699. \n  * Kang et al. (2021)â Kang, S.; et al. 2021.  GANPU: An Energy-Efficient Multi-DNN Training Processor for GANs With Speculative Dual-Sparsity Exploitation.  _IEEE Journal of Solid-State Circuits_ , 56(9): 2845â2857. \n  * Khiabani et al. (2025)â Khiabani, Y. S.; et al. 2025.  Optimizing Small Language Models for In-Vehicle Function-Calling.  _arXiv preprint arXiv:2501.02342_. \n  * Kim et al. (2020)â Kim, S.; et al. 2020.  An Energy-Efficient GAN Accelerator with On-chip Training for Domain Specific Optimization.  In _2020 IEEE Asian Solid-State Circuits Conference (A-SSCC)_ , 1â4. \n  * Kim et al. (2024)â Kim, S.; et al. 2024.  SqueezeLLM: Dense-and-Sparse Quantization.  In _Proceedings of the 41st International Conference on Machine Learning (ICML)_. \n  * Kim et al. (2019)â Kim, Y.; et al. 2019.  A Real-Time Convolutional Neural Network for Super-Resolution on FPGA With Applications to 4K UHD 60 fps Video Services.  _IEEE Transactions on Circuits and Systems for Video Technology_. \n  * Kitaev et al. (2020)â Kitaev, N.; et al. 2020.  Reformer: The Efficient Transformer.  In _International Conference on Learning Representations (ICLR)_. \n  * Kong et al. (2024)â Kong, W.; et al. 2024.  Cambricon-D: Full-Network Differential Acceleration for Diffusion Models.  In _2024 ACM/IEEE 51st Annual International Symposium on Computer Architecture (ISCA)_. \n  * Lan et al. (2020)â Lan, Z.; et al. 2020.  ALBERT: A Lite BERT for Self-supervised Learning of Language Representations.  In _International Conference on Learning Representations (ICLR)_. \n  * Laskaridis et al. (2024)â Laskaridis, S.; et al. 2024.  MELTing point: Mobile Evaluation of Language Transformers.  _arXiv preprint arXiv:2403.12844_. \n  * Lee et al. (2023)â Lee, H.; et al. 2023.  RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback.  arXiv:2309.00267. \n  * Lee et al. (2019)â Lee, R.; et al. 2019.  MobiSR: Efficient on-device super-resolution through heterogeneous mobile processors.  In _Proceedings of the 25th Annual International Conference on Mobile Computing and Networking (MobiCom)_. \n  * Lefaudeux et al. (2022)â Lefaudeux, B.; et al. 2022.  xFormers: A modular and hackable Transformer modelling library.  https://github.com/facebookresearch/xformers. \n  * Li et al. (2024a)â Li, C.; et al. 2024a.  SpecPIM: Accelerating Speculative Inference on PIM-Enabled System via Architecture-Dataflow Co-Exploration.  In _Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3_. \n  * Li et al. (2024b)â Li, H.; et al. 2024b.  An Energy-Efficient Look-up Table Framework for Super Resolution on FPGA.  _IEEE Transactions on Circuits and Systems for Video Technology_. \n  * Li et al. (2024c)â Li, H.; et al. 2024c.  ASADI: Accelerating Sparse Attention Using Diagonal-based In-Situ Computing.  In _2024 IEEE International Symposium on High-Performance Computer Architecture (HPCA)_. IEEE. \n  * Li et al. (2023a)â Li, X.; et al. 2023a.  Q-Diffusion: Quantizing Diffusion Models.  In _Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)_ , 17535â17545. \n  * Li et al. (2023b)â Li, Y.; et al. 2023b.  E-sparse: Boosting the large language model inference through entropy-based n: M sparsity.  arXiv:2310.12843. \n  * Li et al. (2023c)â Li, Y.; et al. 2023c.  Q-DM: An Efficient Low-bit Quantized Diffusion Model.  In _Advances in Neural Information Processing Systems_ , 76680â76691. \n  * Liang et al. (2024)â Liang, Z.; et al. 2024.  Dynamic Self-adaptive Multiscale Distillation from Pre-trained Multimodal Large Model for Efficient Cross-modal Representation Learning.  _arXiv preprint arXiv:2404.10838_. \n  * Lin et al. (2024a)â Lin, J.; et al. 2024a.  AWQ: Activation-aware Weight Quantization for On-Device LLM Compression and Acceleration.  In Gibbons, P.; Pekhimenko, G.; and Sa, C. D., eds., _Proceedings of Machine Learning and Systems_ , volume 6, 87â100. \n  * Lin et al. (2024b)â Lin, Y.; et al. 2024b.  SpeechPrune: Context-aware Token Pruning for Speech Information Retrieval.  _arXiv preprint arXiv:2412.12009_. \n  * Liu et al. (2024a)â Liu, C.; et al. 2024a.  Evolving Knowledge Distillation with Large Language Models and Active Learning.  In _Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)_ , 6717â6731. ELRA and ICCL. \n  * Liu et al. (2024b)â Liu, H.; et al. 2024b.  A High-Performance Accelerator for Real-Time Super-Resolution on Edge FPGAs.  _ACM Transactions on Design Automation of Electronic Systems_. \n  * Liu et al. (2024c)â Liu, Z.; et al. 2024c.  Mobilellm: Optimizing sub-billion parameter language models for on-device use cases.  _arXiv preprint arXiv:2402.14905_. \n  * Lu et al. (2022)â Lu, C.; et al. 2022.  DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps.  In Koyejo, S.; Mohamed, S.; Agarwal, A.; Belgrave, D.; Cho, K.; and Oh, A., eds., _Advances in Neural Information Processing Systems_ , 5775â5787. Curran Associates, Inc. \n  * Luhman and Luhman (2021)â Luhman, E.; and Luhman, T. 2021.  Knowledge distillation in iterative generative models for improved sampling speed.  _arXiv preprint arXiv:2101.02388_. \n  * Ma et al. (2023)â Ma, X.; et al. 2023.  LLM-Pruner: On the Structural Pruning of Large Language Models.  In _Advances in Neural Information Processing Systems_. \n  * Malathi et al. (2024)â Malathi, L.; et al. 2024.  FPGA design of FFT-based intelligent accelerator with optimized Wallace tree multiplier for image super resolution and quality enhancement.  _Biomedical Signal Processing and Control_. \n  * Manjunath et al. (2023)â Manjunath, T.; et al. 2023.  Reprohrl: Towards multi-goal navigation in the real world using hierarchical agents. On 37th AAAI Conference on Artificial Intelligence.  In _The 1st Reinforcement Learning Ready for Production workshop_. \n  * Mao et al. (2017a)â Mao, J.; et al. 2017a.  MeDNN: A distributed mobile system with enhanced partition and deployment for large-scale DNNs.  In _2017 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)_ , 751â756. IEEE. \n  * Mao et al. (2017b)â Mao, J.; et al. 2017b.  MoDNN: Local distributed mobile computing system for Deep Neural Network.  In _Design, Automation & Test in Europe Conference & Exhibition (DATE), 2017_, 1396â1401. \n  * Meng et al. (2023)â Meng, C.; et al. 2023.  On distillation of guided diffusion models.  In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_ , 14297â14306. \n  * MIT-HAN-Lab (2024)â MIT-HAN-Lab. 2024.  TinyChatEngine: On-Device LLM Inference Library.  https://github.com/mit-han-lab/TinyChatEngine. \n  * MosaicML NLP Team (2023)â MosaicML NLP Team. 2023.  Introducing MPT-7B: A new standard for open-source, commercially usable LLMs.  https://www.mosaicml.com/blog/mpt-7b. \n  * Navardi et al. (2023)â Navardi, M.; et al. 2023.  MLAE2: Metareasoning for latency-aware energy-efficient autonomous nano-drones.  In _2023 IEEE International Symposium on Circuits and Systems (ISCAS)_ , 1â5. IEEE. \n  * Navardi et al. (2024)â Navardi, M.; et al. 2024.  MetaTinyML: End-to-End Metareasoning Framework for TinyML Platforms.  _IEEE Embedded Systems Letters_ , 16(4): 393â396. \n  * Nezami et al. (2024)â Nezami, Z.; et al. 2024.  Generative AI on the Edge: Architecture and Performance Evaluation.  _arXiv preprint arXiv:2411.17712_. \n  * Nikoghosyan et al. (2023)â Nikoghosyan, K. H.; et al. 2023.  Acceleration of Transformer Architectures on Jetson Xavier using TensorRT.  In _Proceedings of Innovative Polytechnic_. \n  * NVIDIA Corporation (2025)â NVIDIA Corporation. 2025.  TensorRT-LLM.  https://github.com/NVIDIA/TensorRT-LLM. \n  * OpenAI (2024)â OpenAI. 2024.  GPT-4 Technical Report.  arXiv:2303.08774. \n  * Osorno-Ortiz et al. (2024)â Osorno-Ortiz, R. J.; et al. 2024.  Implementation of the image super-resolution DWT based algorithm on Raspberry Pi platform for real-time applications.  In _Proceedings of SPIE_. \n  * Park et al. (2024)â Park, J.; et al. 2024.  AttAcc! Unleashing the Power of PIM for Batched Transformer-based Generative Model Inference.  In _Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2_. \n  * Poole et al. (2023)â Poole, B.; et al. 2023.  DreamFusion: Text-to-3D using 2D Diffusion.  In _The Eleventh International Conference on Learning Representations_. \n  * Pourmehrani et al. (2024)â Pourmehrani, H.; et al. 2024.  FAT-RABBIT: Fault-Aware Training towards Robustness AgainstBit-flip Based Attacks in Deep Neural Networks.  In _2024 IEEE International Test Conference (ITC)_ , 106â110. IEEE. \n  * Qin et al. (2024a)â Qin, R.; et al. 2024a.  FL-NAS: Towards Fairness of NAS for Resource Constrained Devices via Large Language Models.  In _Proceedings of the 29th Asia and South Pacific Design Automation Conference_ , ASPDAC â24, 429â434. IEEE Press.  ISBN 9798350393545. \n  * Qin et al. (2023)â Qin, Y.; et al. 2023.  FACT: FFN-Attention Co-optimized Transformer Architecture with Eager Correlation Prediction.  In _Proceedings of the 50th Annual International Symposium on Computer Architecture_ , ISCA â23. New York, NY, USA: Association for Computing Machinery.  ISBN 9798400700958. \n  * Qin et al. (2024b)â Qin, Y.; et al. 2024b.  A 52.01 TFLOPS/W Diffusion Model Processor with Inter-Time-Step Convolution-Attention-Redundancy Elimination and Bipolar Floating-Point Multiplication.  In _2024 IEEE Symposium on VLSI Technology and Circuits (VLSI Technology and Circuits)_ , 1â2. \n  * Qin et al. (2024c)â Qin, Y.; et al. 2024c.  MECLA: Memory-Compute-Efficient LLM Accelerator with Scaling Sub-matrix Partition.  In _2024 ACM/IEEE 51st Annual International Symposium on Computer Architecture (ISCA)_ , 1032â1047. \n  * Salimans and Ho (2022)â Salimans, T.; and Ho, J. 2022.  Progressive Distillation for Fast Sampling of Diffusion Models.  In _International Conference on Learning Representations_. \n  * Sanh et al. (2019)â Sanh, V.; et al. 2019.  DistilBERT, a Distilled Version of BERT: Smaller, Faster, Cheaper and Lighter.  _arXiv preprint arXiv:1910.01108_. \n  * Shah et al. (2024)â Shah, J.; et al. 2024.  FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision.  _arXiv preprint arXiv:2407.08608_. \n  * Shen et al. (2024)â Shen, X.; et al. 2024.  EdgeQAT: Entropy and Distribution Guided Quantization-Aware Training for the Acceleration of Lightweight LLMs on the Edge.  _arXiv preprint arXiv:2402.10787_. \n  * Singer, Philipp others (2024)â Singer, Philipp others. 2024.  H2O-Danube-1.8B Technical Report.  _arXiv preprint arXiv:2401.16818_. \n  * So et al. (2023)â So, J.; et al. 2023.  Temporal Dynamic Quantization for Diffusion Models.  In Oh, A.; Naumann, T.; Globerson, A.; Saenko, K.; Hardt, M.; and Levine, S., eds., _Advances in Neural Information Processing Systems_ , volume 36, 48686â48698. Curran Associates, Inc. \n  * Song et al. (2023)â Song, Y.; et al. 2023.  Consistency Models.  In _Proceedings of the 40th International Conference on Machine Learning_ , 32211â32252. \n  * Stevens et al. (2021)â Stevens, J. R.; et al. 2021.  Softermax: Hardware/Software Co-Design of an Efficient Softmax for Transformers.  In _2021 58th ACM/IEEE Design Automation Conference (DAC)_ , 469â474. \n  * Su et al. (2024)â Su, D.; et al. 2024.  Generative Dataset Distillation Based on Diffusion Model.  In _Proceedings of the European Conference on Computer Vision (ECCV), Workshop_. \n  * Sun et al. (2022)â Sun, K.; et al. 2022.  An FPGA-Based Residual Recurrent Neural Network for Real-Time Video Super-Resolution.  _IEEE Transactions on Circuits and Systems for Video Technology_. \n  * Sun et al. (2020)â Sun, Z.; et al. 2020.  MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices.  _arXiv preprint arXiv:2004.02984_. \n  * Tambe et al. (2023)â Tambe, T.; et al. 2023.  22.9 A 12nm 18.1 TFLOPs/W sparse transformer processor with entropy-based early exit, mixed-precision predication and fine-grained power management.  In _2023 IEEE International Solid-State Circuits Conference (ISSCC)_ , 370â372. IEEE. \n  * Taori et al. (2023)â Taori, R.; et al. 2023.  Alpaca: A Strong, Replicable Instruction-Following Model.  https://crfm.stanford.edu/2023/03/13/alpaca.html. \n  * Touvron et al. (2023a)â Touvron, H.; et al. 2023a.  Llama 2: Open Foundation and Fine-Tuned Chat Models.  _arXiv preprint arXiv:2307.09288_. \n  * Touvron et al. (2023b)â Touvron, H.; et al. 2023b.  LLaMA: Open and Efficient Foundation Language Models.  In _arXiv preprint arXiv:2302.13971_. \n  * Wan et al. (2025)â Wan, B.; et al. 2025.  Pruning for Sparse Diffusion Models based on Gradient Flow.  arXiv:2501.01101. \n  * Wang et al. (2023)â Wang, H.; et al. 2023.  Bitnet: Scaling 1-bit transformers for large language models.  arXiv:2305.10403. \n  * Wang et al. (2024a)â Wang, Q.; et al. 2024a.  An Intelligent Co-Scheduling Framework for Efficient Super-Resolution on Edge Platforms With Heterogeneous Processors.  _IEEE Internet of Things Journal_. \n  * Wang et al. (2024b)â Wang, Q.; et al. 2024b.  CoreInfer: Accelerating Large Language Model Inference with Semantics-Inspired Adaptive Sparse Activation.  arXiv:2410.18311. \n  * Wang et al. (2020a)â Wang, S.; et al. 2020a.  Linformer: Self-Attention with Linear Complexity.  _arXiv preprint arXiv:2006.04768_. \n  * Wang et al. (2020b)â Wang, W.; et al. 2020b.  MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers. \n  * Wang et al. (2021)â Wang, W.; et al. 2021.  MiniLMv2: Multi-Head Self-Attention Relation Distillation for Compressing Pretrained Transformers. \n  * Wang et al. (2024c)â Wang, X.; et al. 2024c.  DTrans: A Dataflow-transformation FPGA Accelerator with Nonlinear-operators fusion aiming for the Generative Model.  In _2024 34th International Conference on Field-Programmable Logic and Applications (FPL)_. IEEE. \n  * Wu et al. (2024)â Wu, M.; et al. 2024.  Lamini: Large Language Model Approaches for Generating Assistive Programs.  In _Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)_ , 944â964. \n  * Xia et al. (2023)â Xia, H.; et al. 2023.  Flash-LLM: Enabling Cost-Effective and Highly-Efficient Large Generative Model Inference with Unstructured Sparsity.  arXiv:2308.04528. \n  * Xiao et al. (2023)â Xiao, G.; et al. 2023.  SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models.  In _Proceedings of the 40th International Conference on Machine Learning_. \n  * Xu et al. (2024)â Xu, Y.; et al. 2024.  OneBit: Towards Extremely Low-bit Large Language Models.  _arXiv preprint arXiv:2402.11295_. \n  * Yan et al. (2019)â Yan, B.; et al. 2019.  RRAM-based spiking nonvolatile computing-in-memory processing engine with precision-configurable in situ nonlinear activation.  In _2019 Symposium on VLSI Technology_ , C258âC259. IEEE. \n  * Yan et al. (2024)â Yan, C.; et al. 2024.  Hybrid SD: Edge-Cloud Collaborative Inference for Stable Diffusion Models.  arXiv:2410.02453. \n  * Yang et al. (2024)â Yang, G.; et al. 2024.  SDA: Low-Bit Stable Diffusion Acceleration on Edge FPGAs.  In _2024 34th International Conference on Field-Programmable Logic and Applications (FPL)_. IEEE. \n  * Yao et al. (2024)â Yao, Y.; et al. 2024.  Timestep-Aware Correction for Quantized Diffusion Models.  In _European Conference on Computer Vision (ECCV)_. \n  * Yi et al. (2022)â Yi, J.; et al. 2022.  Supremo: Cloud-assisted low-latency super-resolution in mobile devices.  _IEEE Transactions on Mobile Computing_. \n  * Yi et al. (2023)â Yi, R.; et al. 2023.  EdgeMoE: Fast On-Device Inference of MoE-Based Large Language Models.  _arXiv preprint arXiv:2308.14352_. \n  * Yoo et al. (2024)â Yoo, S.; et al. 2024.  A 28nm 4.96 TOPS/W End-to-End Diffusion Accelerator with Reconfigurable Hyper-Precision and Unified Non-Matrix Processing Engine.  In _2024 IEEE European Solid-State Electronics Research Conference (ESSERC)_ , 253â256. \n  * Zadeh et al. (2020)â Zadeh, A. H.; et al. 2020.  GOBO: Quantizing Attention-Based NLP Models for Low Latency and Energy Efficient Inference.  In _2020 53rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)_ , 811â824. \n  * Zaheer et al. (2020)â Zaheer, M.; et al. 2020.  Big Bird: Transformers for Longer Sequences.  In _Advances in Neural Information Processing Systems_. \n  * Zhang et al. (2024)â Zhang, P.; et al. 2024.  TinyLlama: An Open-Source Small Language Model.  _arXiv preprint arXiv:2401.02385_. \n  * Zhang et al. (2022)â Zhang, S.; et al. 2022.  An Efficient Accelerator of Deformable 3D Convolutional Network for Video Super-Resolution.  _IEEE Transactions on Multimedia_. \n  * Zhao et al. (2021)â Zhao, W.; et al. 2021.  A High-Performance Accelerator for Super-Resolution Processing on Embedded GPU.  _arXiv preprint arXiv:2303.08999_. \n  * Zhu et al. (2024)â Zhu, H.; et al. 2024.  DiP-GO: A Diffusion Pruner via Few-step Gradient Optimization.  _arXiv preprint arXiv:2410.16942_. \n  * Zoph (2016)â Zoph, B. 2016.  Neural architecture search with reinforcement learning.  _arXiv preprint arXiv:1611.01578_. \n  * Zoph et al. (2018)â Zoph, B.; et al. 2018.  Learning transferable architectures for scalable image recognition.  In _Proceedings of the IEEE conference on computer vision and pattern recognition_ , 8697â8710. \n\n\nReport Issue\n##### Report Github Issue\nTitle:Content selection saved. Describe the issue below:Description:\nSubmit without GithubSubmit in Github\nReport Issue for Selection\nGenerated by [ L A T E xml ![\\[LOGO\\]](https://arxiv.org/html/2502.15816v1) ](https://math.nist.gov/~BMiller/LaTeXML/)\n## Instructions for reporting errors\nWe are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:\n  * Click the \"Report Issue\" button.\n  * Open a report feedback form via keyboard, use \"**Ctrl + ?** \".\n  * Make a text selection and click the \"Report Issue for Selection\" button near your cursor.\n  * You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.\n\n\nOur team has already identified [the following issues](https://github.com/arXiv/html_feedback/issues). We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.\nHave a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a [list of packages that need conversion](https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML), and welcome [developer contributions](https://github.com/brucemiller/LaTeXML/issues).\n"
  },
  {
    "link": "https://arxiv.org/html/2402.14601v3",
    "raw_content": "[ ![logo](https://services.dev.arxiv.org/html/static/arxiv-logomark-small-white.svg) Back to arXiv ](https://arxiv.org/)\n[ ](https://arxiv.org/abs/2402.14601v3) [ ](javascript:toggleColorScheme\\(\\) \"Toggle dark/light mode\")\n[ ![logo](https://services.dev.arxiv.org/html/static/arxiv-logo-one-color-white.svg) Back to arXiv ](https://arxiv.org/)\nThis is **experimental HTML** to improve accessibility. We invite you to report rendering errors. Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off. Learn more [about this project](https://info.arxiv.org/about/accessible_HTML.html) and [help improve conversions](https://info.arxiv.org/help/submit_latex_best_practices.html). \n[Why HTML?](https://info.arxiv.org/about/accessible_HTML.html) [Report Issue](https://arxiv.org/html/2402.14601v3#myForm) [Back to Abstract](https://arxiv.org/abs/2402.14601v3) [Download PDF](https://arxiv.org/pdf/2402.14601v3) [ ](javascript:toggleColorScheme\\(\\) \"Toggle dark/light mode\")\n## Table of Contents\n  1. [ Abstract  ](https://arxiv.org/html/2402.14601v3#abstract \"Abstract\")\n  2. [1 Introduction](https://arxiv.org/html/2402.14601v3#S1 \"In Bringing Generative AI to Adaptive Learning in Education\")\n  3. [2 Background](https://arxiv.org/html/2402.14601v3#S2 \"In Bringing Generative AI to Adaptive Learning in Education\")\n    1. [2.1 Adaptive Learning (AL)](https://arxiv.org/html/2402.14601v3#S2.SS1 \"In 2 Background â£ Bringing Generative AI to Adaptive Learning in Education\")\n    2. [2.2 Generative AI (GenAI)](https://arxiv.org/html/2402.14601v3#S2.SS2 \"In 2 Background â£ Bringing Generative AI to Adaptive Learning in Education\")\n  4. [3 Bringing GenAI to AL](https://arxiv.org/html/2402.14601v3#S3 \"In Bringing Generative AI to Adaptive Learning in Education\")\n    1. [3.1 Empower Existing Algorithms](https://arxiv.org/html/2402.14601v3#S3.SS1 \"In 3 Bringing GenAI to AL â£ Bringing Generative AI to Adaptive Learning in Education\")\n      1. [3.1.1 Profile Building](https://arxiv.org/html/2402.14601v3#S3.SS1.SSS1 \"In 3.1 Empower Existing Algorithms â£ 3 Bringing GenAI to AL â£ Bringing Generative AI to Adaptive Learning in Education\")\n      2. [3.1.2 Material Recommendation](https://arxiv.org/html/2402.14601v3#S3.SS1.SSS2 \"In 3.1 Empower Existing Algorithms â£ 3 Bringing GenAI to AL â£ Bringing Generative AI to Adaptive Learning in Education\")\n    2. [3.2 Establishing Novel Directions](https://arxiv.org/html/2402.14601v3#S3.SS2 \"In 3 Bringing GenAI to AL â£ Bringing Generative AI to Adaptive Learning in Education\")\n      1. [3.2.1 Content Creation](https://arxiv.org/html/2402.14601v3#S3.SS2.SSS1 \"In 3.2 Establishing Novel Directions â£ 3 Bringing GenAI to AL â£ Bringing Generative AI to Adaptive Learning in Education\")\n      2. [3.2.2 Intelligent Agent](https://arxiv.org/html/2402.14601v3#S3.SS2.SSS2 \"In 3.2 Establishing Novel Directions â£ 3 Bringing GenAI to AL â£ Bringing Generative AI to Adaptive Learning in Education\")\n      3. [3.2.3 Learning Simulation](https://arxiv.org/html/2402.14601v3#S3.SS2.SSS3 \"In 3.2 Establishing Novel Directions â£ 3 Bringing GenAI to AL â£ Bringing Generative AI to Adaptive Learning in Education\")\n  5. [4 Impacts of GenAI on AL](https://arxiv.org/html/2402.14601v3#S4 \"In Bringing Generative AI to Adaptive Learning in Education\")\n    1. [4.1 Benefits and Strengths](https://arxiv.org/html/2402.14601v3#S4.SS1 \"In 4 Impacts of GenAI on AL â£ Bringing Generative AI to Adaptive Learning in Education\")\n      1. [4.1.1 Diversity and Dynamics](https://arxiv.org/html/2402.14601v3#S4.SS1.SSS1 \"In 4.1 Benefits and Strengths â£ 4 Impacts of GenAI on AL â£ Bringing Generative AI to Adaptive Learning in Education\")\n      2. [4.1.2 Multi-modality Convenience](https://arxiv.org/html/2402.14601v3#S4.SS1.SSS2 \"In 4.1 Benefits and Strengths â£ 4 Impacts of GenAI on AL â£ Bringing Generative AI to Adaptive Learning in Education\")\n      3. [4.1.3 Powerful Prior Knowledge](https://arxiv.org/html/2402.14601v3#S4.SS1.SSS3 \"In 4.1 Benefits and Strengths â£ 4 Impacts of GenAI on AL â£ Bringing Generative AI to Adaptive Learning in Education\")\n    2. [4.2 Disadvantages, Challenges and Potentials](https://arxiv.org/html/2402.14601v3#S4.SS2 \"In 4 Impacts of GenAI on AL â£ Bringing Generative AI to Adaptive Learning in Education\")\n      1. [4.2.1 Hallucination](https://arxiv.org/html/2402.14601v3#S4.SS2.SSS1 \"In 4.2 Disadvantages, Challenges and Potentials â£ 4 Impacts of GenAI on AL â£ Bringing Generative AI to Adaptive Learning in Education\")\n      2. [4.2.2 Capability Decay](https://arxiv.org/html/2402.14601v3#S4.SS2.SSS2 \"In 4.2 Disadvantages, Challenges and Potentials â£ 4 Impacts of GenAI on AL â£ Bringing Generative AI to Adaptive Learning in Education\")\n      3. [4.2.3 Fairness](https://arxiv.org/html/2402.14601v3#S4.SS2.SSS3 \"In 4.2 Disadvantages, Challenges and Potentials â£ 4 Impacts of GenAI on AL â£ Bringing Generative AI to Adaptive Learning in Education\")\n      4. [4.2.4 Coevolution of human, GenAI, and education](https://arxiv.org/html/2402.14601v3#S4.SS2.SSS4 \"In 4.2 Disadvantages, Challenges and Potentials â£ 4 Impacts of GenAI on AL â£ Bringing Generative AI to Adaptive Learning in Education\")\n  6. [5 Further Discussion](https://arxiv.org/html/2402.14601v3#S5 \"In Bringing Generative AI to Adaptive Learning in Education\")\n  7. [6 Conclusion](https://arxiv.org/html/2402.14601v3#S6 \"In Bringing Generative AI to Adaptive Learning in Education\")\n  8. [A Appendix.](https://arxiv.org/html/2402.14601v3#A1 \"In Bringing Generative AI to Adaptive Learning in Education\")\n  9. [ References  ](https://arxiv.org/html/2402.14601v3#bib \"References\")\n\n\n[License: arXiv.org perpetual non-exclusive license](https://info.arxiv.org/help/license/index.html#licenses-available)\narXiv:2402.14601v3 [cs.CY] 28 Jun 2024\n# Bringing Generative AI to Adaptive Learning in Education\nReport issue for preceding element\nHang Li  Tianlong Xu  Chaoli Zhang  Eason Chen  Jing Liang  Xing Fan  Haoyang Li  Jiliang Tang  Qingsong Wen \nReport issue for preceding element\n###### Abstract\nReport issue for preceding element\nThe recent surge in generative AI technologies, such as large language models and diffusion models, has boosted the development of AI applications in various domains, including science, finance, and education. Concurrently, adaptive learning, a concept that has gained substantial interest in the educational sphere, has proven its efficacy in enhancing studentsâ learning efficiency. In this position paper, we aim to shed light on the intersectional studies of these two methods, which combine generative AI with adaptive learning concepts. By presenting discussions about the benefits, challenges, and potentials in this field, we argue that this union will contribute significantly to the development of the next-stage learning format in education. \nReport issue for preceding element\nMachine Learning, ICML \n##  1 Introduction\nReport issue for preceding element\nGenerative AI (GenAI) refers to artificial intelligence models that generate new content, including text, images, audio, and video, based on the patterns and information they have learned from the given training data (Cao et al., [2023](https://arxiv.org/html/2402.14601v3#bib.bib16)). Unlike the traditional Machine Learning (ML) algorithms, which focus on analyzing and interpreting data, GenAI is designed to create new, original outputs and thus able to solve more challenging problems. With the recent success of GenAI technologies, such as large language models and diffusion models, in generating human-like outputs to a wide range of problems in Natural Language Processing (NLP) (Bubeck et al., [2023](https://arxiv.org/html/2402.14601v3#bib.bib15)) and Computer Vision (CV) (Ramesh et al., [2022](https://arxiv.org/html/2402.14601v3#bib.bib76)), the development of applying GenAI to real-world problems is rapidly increasing, which spreads from science (Walters & Murcko, [2020](https://arxiv.org/html/2402.14601v3#bib.bib87); Lopez et al., [2020](https://arxiv.org/html/2402.14601v3#bib.bib58)), finance (Rane, [2023](https://arxiv.org/html/2402.14601v3#bib.bib77); BrÃ¼hl, [2023](https://arxiv.org/html/2402.14601v3#bib.bib14)) to education (Cooper, [2023](https://arxiv.org/html/2402.14601v3#bib.bib21); Baidoo-Anu & Owusu Ansah, [2023](https://arxiv.org/html/2402.14601v3#bib.bib7)).\nReport issue for preceding element\nMeanwhile, Adaptive Learning (AL), which is considered an emerging educational, technological innovation in education (Martin et al., [2020](https://arxiv.org/html/2402.14601v3#bib.bib62)), has been demonstrated with pedagogical benefits, including acceleration, remediation, meta-cognition, mastery-based learning, immediate feedback, and interactive learning (Hattie, [2023](https://arxiv.org/html/2402.14601v3#bib.bib41)). Adaptive learning aims to generate unique learning experiences by accounting for individual differences to improve the scholastic path, learning process, and learner satisfaction in varied learning situations (Liu et al., [2017](https://arxiv.org/html/2402.14601v3#bib.bib56)). As adaptive learning relies on collecting and analyzing data about learnersâ interactions, performance, preferences, and progress to tailor the educational experience to their individual needs, ML techniques have been extensively employed in the AL framework for supporting the analysis over large volumes of data about learnersâ behavior and assisting in creating personalized learning paths (Gheibi et al., [2021](https://arxiv.org/html/2402.14601v3#bib.bib32)).\nReport issue for preceding element\nWhy This Position Paper? The overwhelming performance of GenAI over ML algorithms in challenging data analysis problems provides new opportunities to current ML-based AL systems. By leveraging the advanced capabilities of GenAI in creating human-level responses to problems like reasoning, the new AL systems will be able to finish more complicated AL tasks, such as dynamic learning path planning. Although some pioneering works have started to explore the usage of GenAI for education purposes (Dan et al., [2023](https://arxiv.org/html/2402.14601v3#bib.bib24); Xiao et al., [2024](https://arxiv.org/html/2402.14601v3#bib.bib96)), there is no systematic review and discussion focusing on bringing GenAI to AL problems. As adaptive learning is increasingly recognized as a significant and promising direction for the future of education (Park & Lee, [2013](https://arxiv.org/html/2402.14601v3#bib.bib68)), in this position paper, we propose to review the related studies and call attention to the opportunities in combining GenAI with AL. Furthermore, by conducting comprehensive discussions on the benefits, challenges, and threats, we hope to shed light on future research in this direction and push AL into the next chapter.\nReport issue for preceding element\nOur Contributions. Our position in this paper is that bringing GenAI to AL will present both advantages and challenges to current ML-based AL systems, creating numerous opportunities and original topics for future educational development. To support this claim, we (1) conduct a comprehensive literature review on existing ML methods and GenAI works on adaptive learning, (2) explore the potential benefits and summarize ongoing industrial practices, (3) present in-depth discussions about the challenges and opportunities from the pedagogical perspective, and further extend these considerations to their broader educational impacts. \nReport issue for preceding element\nRelated Works. The impressive performance of GenAI, especially the Large Language Models (LLMs), in generating human-like responses to complicated requests (Bubeck et al., [2023](https://arxiv.org/html/2402.14601v3#bib.bib15)) encourages the recent research in exploring GenAI for education purpose (Dan et al., [2023](https://arxiv.org/html/2402.14601v3#bib.bib24); Kieser et al., [2023](https://arxiv.org/html/2402.14601v3#bib.bib49)). To provide researchers with a broad overview of the domain, numerous exploratory and survey papers have been proposed. For example, Qadir ([2023](https://arxiv.org/html/2402.14601v3#bib.bib74)); Rahman & Watanobe ([2023](https://arxiv.org/html/2402.14601v3#bib.bib75)) and Rahman & Watanobe ([2023](https://arxiv.org/html/2402.14601v3#bib.bib75)) conclude the applications of ChatGPT to engineering education by analyzing the responses of ChatGPT to the related pedagogical questions. Jeon & Lee ([2023](https://arxiv.org/html/2402.14601v3#bib.bib45)) and Mogavi et al. ([2023](https://arxiv.org/html/2402.14601v3#bib.bib63)) collect the opinions from different ChatGPT user groups, e.g., educator, learner, researcher, through in-person interviews, online post replies and user logs, and conclude the practical applications of LLMs in education scenarios. Baidoo-Anu & Owusu Ansah ([2023](https://arxiv.org/html/2402.14601v3#bib.bib7)) and Zhang & Tur ([2023](https://arxiv.org/html/2402.14601v3#bib.bib100)) focus on the literature review over the published papers and summarize the progress of the area with structured tables. Although the above works have covered a wide range of existing applications of GenAI in education scenario and provided their long-term visions for future studies, we argue that our position paper is still valuable as none of them focuses on the direction of bringing GenAI to AL. Compared to the general problems such as applying GenAI for education, we propose to present a more concentrated summarization and in-depth discussion toward the adaptive learning topic in this paper.\nReport issue for preceding element\n##  2 Background\nReport issue for preceding element\n###  2.1 Adaptive Learning (AL)\nReport issue for preceding element\nTeach-to-the-middle instruction is the most commonly used strategy for transitional teacher-led instructions as it benefits the majority of the students when the teacher resources are limited. However, such method does not fit learners who have different academic ability from the norm. To solve this problem, adaptive learning is developed, which aims to provide an efficient, effective and customised learning experience for students by dynamically adapting learning content to suit their individual abilities or preferences (Park & Lee, [2013](https://arxiv.org/html/2402.14601v3#bib.bib68); Aleven et al., [2016](https://arxiv.org/html/2402.14601v3#bib.bib6)). In the recent three decades, the effectiveness of AL has been widely recognized by the consistent superior performance reported in different researchesâ comparisons between AL users and the comparison sets (Mojarad et al., [2018](https://arxiv.org/html/2402.14601v3#bib.bib64); Wang et al., [2023b](https://arxiv.org/html/2402.14601v3#bib.bib91)). A valid AL system (Aleven et al., [2016](https://arxiv.org/html/2402.14601v3#bib.bib6)) usually consists of three components: learner module, content module, and instructor module, and its overview is shown in Fig. [1](https://arxiv.org/html/2402.14601v3#S2.F1 \"Figure 1 â£ 2.1 Adaptive Learning \\(AL\\) â£ 2 Background â£ Bringing Generative AI to Adaptive Learning in Education\").\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/x1.png) Figure 1: An Illustration of Adaptive Learning (AL). Report issue for preceding element\nLearner Module, also known as the student model, refers to the learner characteristics of what a student knows and does. The Learner Module includes learner attributes, learner preferences, learner knowledge and proficiency, motivational or emotional aspects of learner behavior, and individual differences that are used to adapt the learning.\nReport issue for preceding element\nContent Module, also known as the expert or domain model, refers to the content or knowledge base for the course. The Content Module could involve concepts that build on each other and include a learning map with relationships between different ideas and how the course content is delivered to the learner.\nReport issue for preceding element\nInstructor Module, also known as the pedagogical model, refers to the algorithm that assists in adapting the instruction based on the content and learner module, and defines what, when, and how adaptation can occur. Some of the adaptation techniques include pacing, the format of instruction, and sequencing. This model provides the base for deciding what content is presented to the learner and can also be called the adaptation model since it describes what is adapted and how it is adapted.\nReport issue for preceding element\n###  2.2 Generative AI (GenAI)\nReport issue for preceding element\nThe origins of Generative AI can be traced back to the mid-1950s with the emergence of the concepts of artificial intelligence and machine learning. Unlike discriminative modeling, which has been the driving force of most progress in artificial intelligence, generative modeling problems are generally more difficult to tackle. Contributing to the rise of deep learning (LeCun et al., [2015](https://arxiv.org/html/2402.14601v3#bib.bib53)), Generative Adversarial Networks (GANs) (Goodfellow et al., [2014](https://arxiv.org/html/2402.14601v3#bib.bib36)) and Variational Auto-encoders(VAEs) (Kingma & Welling, [2013](https://arxiv.org/html/2402.14601v3#bib.bib50)) first revolutionized image generation and became a cornerstone in the field of GenAI. Moreover, the recent emergence of Transformer (Vaswani et al., [2017](https://arxiv.org/html/2402.14601v3#bib.bib84)), has marked another significant evolution in GenAI within the field of NLP, which has propelled GenAI into a new era. LLMs, such as OpenAIâs GPT series, are the most representative ones of these GenAI models. By taking advantage of the vast number of parameters, extensive pre-training text corpus, and advanced fine-tuning methods (Ouyang et al., [2022](https://arxiv.org/html/2402.14601v3#bib.bib67)), LLMs have shown impressive capabilities in understanding context, generating coherent and contextually relevant responses (Bubeck et al., [2023](https://arxiv.org/html/2402.14601v3#bib.bib15)). Apart from that, further studies (Brown et al., [2020](https://arxiv.org/html/2402.14601v3#bib.bib13)) discover the strong few-shot (in-context) learning ability of LLMs, and such findings encourage the revolution in NLP solutions from task-specific methods to foundation models (Zhou et al., [2023](https://arxiv.org/html/2402.14601v3#bib.bib103)). Despite the above progress, Generative Diffusion Models (GDMs) (Ho et al., [2020](https://arxiv.org/html/2402.14601v3#bib.bib42); Song et al., [2020](https://arxiv.org/html/2402.14601v3#bib.bib81)) also bring improvements to the generation quality of images (Dhariwal & Nichol, [2021](https://arxiv.org/html/2402.14601v3#bib.bib27)) and audio signals (Kong et al., [2020](https://arxiv.org/html/2402.14601v3#bib.bib52)). Finally, by connecting GenAI models from different modalities, multi-modal GenAI models are proposed and have achieved promising results in directions like text-to-image (Ramesh et al., [2022](https://arxiv.org/html/2402.14601v3#bib.bib76)), text-to-audio (Popov et al., [2021](https://arxiv.org/html/2402.14601v3#bib.bib72)) and text-to-video generations (Wang et al., [2023a](https://arxiv.org/html/2402.14601v3#bib.bib89)).\nReport issue for preceding element\n##  3 Bringing GenAI to AL\nReport issue for preceding element\nIn recent decades, ML plays a crucial role in AL by enabling the system to analyze learnersâ behavior, build learning profiles, and provide personalized adaptions to learners. In following sections, we summarize changes brought by GenAI from two perspectives: (1) Empower existing algorithms, (2) Establishing novel directions. The relationships between GenAI and adaptive learning are summarized in Fig. [2](https://arxiv.org/html/2402.14601v3#S3.F2 \"Figure 2 â£ 3 Bringing GenAI to AL â£ Bringing Generative AI to Adaptive Learning in Education\").\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/x2.png) Figure 2: An overview of bringing GenAI to AL. Report issue for preceding element\n###  3.1 Empower Existing Algorithms\nReport issue for preceding element\nBuilding studentsâ learning profile and then recommend suitable study materials are core functions for AL systems. In this section, we present a brief summarizing about existing works, and explain from different perspectives that GenAI will be an complementary helper to existing algorithms.\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/x3.png) Figure 3: Empowering existing algorithms in AL system with GenAI. Report issue for preceding element\n####  3.1.1 Profile Building\nReport issue for preceding element\nThe accurate profile information for different learner is an important foundation for any AL system. However, unlike profiles used in scenarios like commodity recommendation, profiles for adaptive learning focuses on tracking the learnersâ knowledge proficiency, which cannot be observed directly. To solve this problem, prior works developed Cognitive Diagnosis Models (CDM) on the basis of cognitive science or psychometrics (Ackerman et al., [2003](https://arxiv.org/html/2402.14601v3#bib.bib3)), and exploit different types of ML method, such as statistical learning models (Hambleton et al., [1991](https://arxiv.org/html/2402.14601v3#bib.bib38); De La Torre, [2009](https://arxiv.org/html/2402.14601v3#bib.bib26)), neural networks (Cheng et al., [2019](https://arxiv.org/html/2402.14601v3#bib.bib18); Wang et al., [2020](https://arxiv.org/html/2402.14601v3#bib.bib88)), to estimate the userâs knowledge proficiency based on the interaction history between the examinees and question. Commonly, CDM is applied in traditional paper-and-pencil tests, however, the one-for-all approach dismiss the difference between individuals and usually faces to the challenges in efficiency and accuracy. To deal with that, Computerized Adaptive Testing (CAT) is propose, and it aims at tailoring the selection of questions to each examineeâs level of proficiency, thereby maximizing the accuracy of the assessment while minimizing the test length (Liu et al., [2024](https://arxiv.org/html/2402.14601v3#bib.bib57)). Due to the complexity of the optimization process, more advanced machine learning algorithms, such as reinforcement learning (Gilavert & Freire, [2022](https://arxiv.org/html/2402.14601v3#bib.bib34)), active learning (Veldkamp & Verschoor, [2019](https://arxiv.org/html/2402.14601v3#bib.bib85); Bi et al., [2020](https://arxiv.org/html/2402.14601v3#bib.bib10)), meta-learning (Ma et al., [2023a](https://arxiv.org/html/2402.14601v3#bib.bib59); Yu et al., [2023](https://arxiv.org/html/2402.14601v3#bib.bib98)), are widely adopted by recent studies. Knowledge tracing (KT) is another popular research directions for learnersâ profiles building, which also uses machine learning methods to build learnersâ profiles. KT simplifies learnerâs proficiency estimation as his/her next question correctness prediction (Abdelrahman et al., [2023](https://arxiv.org/html/2402.14601v3#bib.bib1)), making it more flexible to diverse machine learning algorithms. The usual ML methods for KT include probabilistic graphical models (Corbett & Anderson, [1994](https://arxiv.org/html/2402.14601v3#bib.bib22)), factor analysis models (Cen et al., [2006](https://arxiv.org/html/2402.14601v3#bib.bib17)), and deep learning sequential models (Piech et al., [2015](https://arxiv.org/html/2402.14601v3#bib.bib70)).\nReport issue for preceding element\nThe success of above algorithms demonstrates the effectiveness of ML algorithms in adaptive learning, on the basis of that, we position that introducing GenAI could further exploit the potential of existing ML methods. First, the human-instructor-level performance of GenAI in composing questions in subjects like math (Lee et al., [2024](https://arxiv.org/html/2402.14601v3#bib.bib54)), computer science (Prokudin et al., [2023](https://arxiv.org/html/2402.14601v3#bib.bib73)) and language studies (Xiao et al., [2023](https://arxiv.org/html/2402.14601v3#bib.bib95)) are widely recognized by recent studies. Following explorations by Adewumi et al. ([2023](https://arxiv.org/html/2402.14601v3#bib.bib4)) further verified the validness of using personalized question to enhance the engagement of student in test. These findings provide new opportunities for current CAT system in replacing pre-fixed question bank with dynamic generative pipelines, by which CAT can apply more flexible controls to questions and prior question bank exposure problem can be greatly resolved. Apart from that, leveraging GenAI to produce external knowledge for both KT and CAT data is also a valuable direction. As mentioned above, external knowledge like question knowledge concepts typologies is proven to be effective handlers in improving the performance of existing models. However, the external information requirement on data restricts the wide application of those new algorithms on different datasets. Contributing to powerful prior knowledge learnt by LLMs through the pre-training on large-scaled web corpus, using LLMs automatically add external knowledge, such as concept tags, to question becomes convenient, which will significantly encourage the emergency of stronger models on KT and CAT task. At last, by applying in-context learning (ICL) (Dong et al., [2022](https://arxiv.org/html/2402.14601v3#bib.bib28)) and fine-tuning (Zhang et al., [2023a](https://arxiv.org/html/2402.14601v3#bib.bib101)), LLMs can also directly be used as predictors. Pioneering studies by Neshaei et al. ([2024](https://arxiv.org/html/2402.14601v3#bib.bib65)) and Jung et al. ([2024](https://arxiv.org/html/2402.14601v3#bib.bib47)) observe that LLM based predictor has great potential in solving the âcold-startâ challenges for existing KT algorithms. Overall, the engagement of GenAI with existing profile building method brings new opportunities in the profile building researches of AL systems and the three above ways in leveraging LLMs for profile building is shown as Fig. [3](https://arxiv.org/html/2402.14601v3#S3.F3 \"Figure 3 â£ 3.1 Empower Existing Algorithms â£ 3 Bringing GenAI to AL â£ Bringing Generative AI to Adaptive Learning in Education\").\nReport issue for preceding element\n####  3.1.2 Material Recommendation\nReport issue for preceding element\nLearning material recommendation is another important component of AL systems, which provides different user with the customized learning materials. Based on optimization objects and considering factors, current approaches can be classified into different categories: content based, collaborative filtering based, knowledge based, and hybrid solutions (Khanal et al., [2020](https://arxiv.org/html/2402.14601v3#bib.bib48)). Content-Based (CB) methods use machine learning models to generate informative attributes for each learner (Shu et al., [2018](https://arxiv.org/html/2402.14601v3#bib.bib79)). Based on these attributes, a rule-based system will exclude the contents and recommend the materials from remaining results (Kolekar et al., [2019](https://arxiv.org/html/2402.14601v3#bib.bib51)). Collaborative Filtering (CF) make predictions about a learnerâs interests based on preferences from many learners. In addition to preference, learner style (Bourkoukou et al., [2017](https://arxiv.org/html/2402.14601v3#bib.bib11)) and skill levels (Han et al., [2016](https://arxiv.org/html/2402.14601v3#bib.bib40)) are also considered by recent CF-based studies. Knowledge-based (KB) systems recommend items based on specific domain knowledge about how certain item features meet usersâ needs and preferences (Aeiad & Meziane, [2019](https://arxiv.org/html/2402.14601v3#bib.bib5); Nitchot et al., [2019](https://arxiv.org/html/2402.14601v3#bib.bib66)), and knowledge structures between learning contents are concerned by recent studies. At last, hybrid based solutions hybridizes the features of two or more above techniques to benefit from the strengths of each technique and to improve performance (Ghauth & Abdullah, [2010](https://arxiv.org/html/2402.14601v3#bib.bib31)).\nReport issue for preceding element\nAlthough all above recommendation algorithms demonstrate good performance in their experiments, the application in real-world scenario still faces challenges, especially many of them require either delicate annotations or large scaled preference records (Khanal et al., [2020](https://arxiv.org/html/2402.14601v3#bib.bib48)). In addition, as recent works prone to use deep learning models as their backbone model, many of these outputs are lack of intepretablity, which cannot provide valid support to learnerâs inquiry on recommended materials. Fortunately, the recent progresses in using GenAI as knowledge enhancer (Gong et al., [2023](https://arxiv.org/html/2402.14601v3#bib.bib35)) and predictor (Cui et al., [2022](https://arxiv.org/html/2402.14601v3#bib.bib23)) for recommendation system provides good demonstrations in solve the issues above. To be specific, GenAI models like LLMsâ has powerful few-shot learning abilities, which enables it learn an effective predictor with limited annotated data (Brown et al., [2020](https://arxiv.org/html/2402.14601v3#bib.bib13)). Besides that, LLMsâ strong prior knowledge can be leveraged as external resource to enhance the inputs for all textual factors considered within the recommendation process (Li et al., [2023](https://arxiv.org/html/2402.14601v3#bib.bib55)). At last, the intermediate text before the outputs usually contain the reasoning process of LLMs, which automatically serve as good interpretation for the recommendation results (Chu et al., [2024](https://arxiv.org/html/2402.14601v3#bib.bib19)). Based on these facts, we position that the introduction of GenAI will empower existing material recommendation algorithms with stronger adaptation capabilities and the recommendation process will be more transparent and convincing to the users. The usages of GenAI in material recommendation are detailed in Fig. [3](https://arxiv.org/html/2402.14601v3#S3.F3 \"Figure 3 â£ 3.1 Empower Existing Algorithms â£ 3 Bringing GenAI to AL â£ Bringing Generative AI to Adaptive Learning in Education\").\nReport issue for preceding element\n###  3.2 Establishing Novel Directions\nReport issue for preceding element\nApart from enhancing existing algorithms, GenAIâs generative characteristic and its emerged planning and imitation capability establish novel directions for AL studies. In this section, we focus on three representative ones and introduce changes brought by GenAI based method in each direction.\nReport issue for preceding element\n####  3.2.1 Content Creation\nReport issue for preceding element\nThe high fidelity of generated results, such as image (Betker et al., [2023](https://arxiv.org/html/2402.14601v3#bib.bib8)), video (Brooks et al., [2024](https://arxiv.org/html/2402.14601v3#bib.bib12)), text (Achiam et al., [2023](https://arxiv.org/html/2402.14601v3#bib.bib2)), demonstrates the great potential of GenAI in content creation. In addition, the emergent of techniques like instruction tunning (Zhang et al., [2023a](https://arxiv.org/html/2402.14601v3#bib.bib101)) further facilitate the generating requirements by allowing users use verbal requirements to instruct LLMs during generation. Cooper ([2023](https://arxiv.org/html/2402.14601v3#bib.bib21)) explored the usages of GenAI models like GPT as instructor assistant to help create course outlines, compose a quiz focusing on some specific knowledge concepts, and even provide suggestion to teachers in organizing study plans for the specific lecture. Hu et al. ([2024](https://arxiv.org/html/2402.14601v3#bib.bib43)) leveraged GPT model to generate teaching plans in math for teachers and their evaluation results revealed the generated plans are achieving expert-level performance in multiple aspect, including problem chains organizations, teaching priority identifications and subject contents articulation. Besides textual learning contents, Pierce Burr & Young ([2024](https://arxiv.org/html/2402.14601v3#bib.bib71)) propose to use image-to-text generative model, DALLE-2 (Ramesh et al., [2022](https://arxiv.org/html/2402.14601v3#bib.bib76)), to synthesis patient to educate doctors in training. By applying such approach, it will be possible to rapidly create photographic quality images without compromising patient confidentiality.\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/x4.png) Figure 4: GenAI for Content Creation in AL. Report issue for preceding element\nAs for adaptive learning, benefits brought by GenAI is not only limited to reduce the current workloads of instructors, but also provide new opportunities in creating learning contents aligning with learnersâ interest and proficiency dynamically (Pesovski et al., [2024](https://arxiv.org/html/2402.14601v3#bib.bib69)). Compared to static contents used by current AL systems, the dynamically created learning contents provide learner a more precised way in receiving knowledge. In addition, the real-time generation feature further empower AL systems to dynamically make adjustment based on changes happened in userâs knowledge proficiency during the learning process. At last, the recent progress in mutlimodal GenAI research provides good foundations to incorporate various modalities into GenAI models (Bewersdorff et al., [2024](https://arxiv.org/html/2402.14601v3#bib.bib9)). In this case, the data formats of learning content will not be restricted by text only, the video and audio version contents can be helpful to improve the engagement of learner processes and provide convenient to people with special needs (Mallory, [2024](https://arxiv.org/html/2402.14601v3#bib.bib61)). In a word, the emergence of GenAI is opening up new and creative ways to create contents for education and its usages for AL system are presented as Figure [4](https://arxiv.org/html/2402.14601v3#S3.F4 \"Figure 4 â£ 3.2.1 Content Creation â£ 3.2 Establishing Novel Directions â£ 3 Bringing GenAI to AL â£ Bringing Generative AI to Adaptive Learning in Education\").\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/x5.png) Figure 5: GenAI for Intelligent Agent in AL. Report issue for preceding element\n####  3.2.2 Intelligent Agent\nReport issue for preceding element\nUsing GenAI model, LLMs, as intelligent agent is a popular direction in recent AI communities (Wang et al., [2024](https://arxiv.org/html/2402.14601v3#bib.bib90)). The key idea of these researches is to leverage LLMsâ task planning potentials to solve complicated real-world problems through its initiative elaborations with external resources such as computer programs, search engine and other toolkit. On the basis of that, many advanced LLM-agent frameworks are proposed and achieves promising results in various type of problems such as math problem solving (Wu et al., [2024](https://arxiv.org/html/2402.14601v3#bib.bib94)), program developing (Wu et al., [2023a](https://arxiv.org/html/2402.14601v3#bib.bib92)) and question answering (Zhuang et al., [2024](https://arxiv.org/html/2402.14601v3#bib.bib104)). In adaptive learning scenario, the direct application of intelligent agent is personal learning assistant chat-bot (Zarris & Sozos, [2023](https://arxiv.org/html/2402.14601v3#bib.bib99)), which focuses on provide real-time support to student during their study. Contributing to the strong instruction following capability of GenAI models like LLMs, student can post his question and request directly through verbal text, and GenAI will be able to leverage all available resources to generate the answers aligning the with studentâs needs. With incorporating techniques like prompt learning and fine-tuning, recent studies have successfully implemented learning chat-bots for essay writing (Han et al., [2024](https://arxiv.org/html/2402.14601v3#bib.bib39)) and program learning (Smith et al., [2024](https://arxiv.org/html/2402.14601v3#bib.bib80)). Apart from using it as tools only for student, agent-based framework can also be a powerful toolkit for instructors in adaptive learning. For example, providing personalized feedback on each studentâs assignment is a burdensome work for teachers. Prior studies tried to use machine learning algorithms to automate the procedure but only focus on specific question types (Fagbohun et al., [2024](https://arxiv.org/html/2402.14601v3#bib.bib29)). Contributing to the exceptional tool using ability, GenAI based algorithms is able to provide valid solutions to question with more general formats. Besides that, the exception planning capability of LLMs discovered by recent studies (Huang et al., [2024](https://arxiv.org/html/2402.14601v3#bib.bib44)) also provides the vision that AL system can be organized and managed with the collaboration between different GenAI agents, and human instructors are free from the tedious routine works and focusing on providing supervisions on important decisions only.\nReport issue for preceding element\n####  3.2.3 Learning Simulation\nReport issue for preceding element\nTraining models to produce indistinguishable samples with observed ones used to be a common training strategy for generative models like Generative Adversarial Networks (GAN) (Goodfellow et al., [2020](https://arxiv.org/html/2402.14601v3#bib.bib37)). As the most advanced generative model, GenAI models have been proven be able to produce high-quality imitations of specific styled images (Zhang et al., [2023b](https://arxiv.org/html/2402.14601v3#bib.bib102)) and text corpus (Tao et al., [2024](https://arxiv.org/html/2402.14601v3#bib.bib83)). Moreover, contribute to the powerful in-context learning capabilities and conversational features of models like LLMs, using LLMs for role-playing and study the character of simulated roles has become an interesting topics in NLP communities (Shao et al., [2023](https://arxiv.org/html/2402.14601v3#bib.bib78)). For adaptive learning, due to the privacy concerns and high collection costs, limited data size of student learning history is always the most common challenge faced by applying advanced machine learning models (Colchester et al., [2017](https://arxiv.org/html/2402.14601v3#bib.bib20)). With leveraging the role-play ability of GenAI, it becomes possible to generate large scaled synthetic dataset with low cost. Inspired by recent studies in computer vision domain (Yeo et al., [2024](https://arxiv.org/html/2402.14601v3#bib.bib97)), we are promising to see the performance gain added to current method with incorporating synthetic student data during the training. Furthermore, contribute to the strong profile following characteristics of the LLMs-based role-play algorithm (Shao et al., [2023](https://arxiv.org/html/2402.14601v3#bib.bib78)), using it to test outcomes for different learning plans on specific student will be possible, which helps both instructor and AL systems to find optimal solutions from a more objective perspective.\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/x6.png) Figure 6: GenAI for Learning Simulation in AL. Report issue for preceding element\n##  4 Impacts of GenAI on AL\nReport issue for preceding element\nIn the following, we first outline advantages GenAI that can offer to AL, along with examples of industrial applications (Appendix. [A](https://arxiv.org/html/2402.14601v3#A1 \"Appendix A Appendix. â£ Bringing Generative AI to Adaptive Learning in Education\")). Then, we provide insights from an educational perspective, delving into the disadvantages and challenges faced by the new framework.\nReport issue for preceding element\n###  4.1 Benefits and Strengths\nReport issue for preceding element\n####  4.1.1 Diversity and Dynamics\nReport issue for preceding element\nIntegrating GenAI into AL offers significant benefits, notably its ability to produce dynamic and diverse outputs. Current ML-based adaptive learning systems, despite their automation (Wang et al., [2023b](https://arxiv.org/html/2402.14601v3#bib.bib91)), still fall short of replicating the nuanced interactions of a skilled human teacher. GenAI bridges this gap by generating real-time, tailored responses and learning plans based on each studentâs immediate questions and learning status. Moreover, the recent advancements in LLMs for context understanding (Brown et al., [2020](https://arxiv.org/html/2402.14601v3#bib.bib13)) further enhance the potential for providing personalized feedback, offering a substantial leap in optimizing learning outcomes. Apart from providing new features, GenAI holds the potential to enhance current ML models in AL systems. As detailed in Section [3.1](https://arxiv.org/html/2402.14601v3#S3.SS1 \"3.1 Empower Existing Algorithms â£ 3 Bringing GenAI to AL â£ Bringing Generative AI to Adaptive Learning in Education\"), profile building methods typically use learnerâs question practice records, but these are often pre-set and designed for mainstream students, potentially hindering accurate assessment of individual learning status. GenAI, with its dynamic and diverse capabilities, can generate questions tailored to each learnerâs past performance, aiding in more effective profile building.\nReport issue for preceding element\n####  4.1.2 Multi-modality Convenience\nReport issue for preceding element\nThe powerful multi-modal processing capabilities enables GenAI to understand studentâs learning status in AL from a broader perspective. To be specific, by integrating GenAI, the AL systems will be able to interpret leaner emotions in speech and facial expressions together with the text input. The enhanced input information will help the following analysis of the studentâs learning characteristics such as learning style and learning status (Giannakos & Cukurova, [2023](https://arxiv.org/html/2402.14601v3#bib.bib33)), which will also benefit the precise adaptions to the studentâs learning paths. Meanwhile, as GenAIâs outputs can be multi-modal (Wu et al., [2023b](https://arxiv.org/html/2402.14601v3#bib.bib93)), the generated learning materials for knowledge concepts will become more inspiring. For example, with image generation models, the interpretations of geometry problems could be presented with figures or even a short animation, which will be easier for learners to understand compared to prior pure-text responses.\nReport issue for preceding element\n####  4.1.3 Powerful Prior Knowledge\nReport issue for preceding element\nThe scarcity of high-quality annotated data in education is the challenge faced by many ML methods in AL system. And tt is caused by the strong privacy properties and high annotation costs of pedagogical data. The appearance of GenAI models brings new solutions as GenAI models are proven to be general-purpose foundation models (BrÃ¼hl, [2023](https://arxiv.org/html/2402.14601v3#bib.bib14)). Contributing to the powerful prior knowledge and (Dang et al., [2022](https://arxiv.org/html/2402.14601v3#bib.bib25)) and in-context learning capability (Dong et al., [2022](https://arxiv.org/html/2402.14601v3#bib.bib28)), existing algorithms in AL system are expected to receive a performance boost after the integration it with the prior knowledge provided by GenAI. Besides that, some new tasks with very few annotated data will also be able to get launched through GenAIâs zero-shot or few-shot learning algorithms (Brown et al., [2020](https://arxiv.org/html/2402.14601v3#bib.bib13)). This change will encourages the further explorations of using ML to solve more challenging tasks in AL. At last, the emergent planning prior knowledge enables GenAI not only be a specific executor but a general task planner. It open a door for developing intelligent agent in solving problem through the elaboration of external tools and resources. On the basis of that, some previous complicated tasks in AL will get solved soon.\nReport issue for preceding element\n###  4.2 Disadvantages, Challenges and Potentials\nReport issue for preceding element\n####  4.2.1 Hallucination\nReport issue for preceding element\nThe biggest issue with GenAI currently is its potential to produce content that doesnât actually exist, a phenomenon known as âHallucinationâ (Ji et al., [2023](https://arxiv.org/html/2402.14601v3#bib.bib46)). Hallucinations happened even in the most advanced GenAI models. Research suggests that educating students about the limitations of using GenAI is crucial, emphasizing its susceptibility to errors when working with it (Strzelecki & ElArabawy, [2024](https://arxiv.org/html/2402.14601v3#bib.bib82)). This brings forth numerous opportunities and research questions for the future, such as how to design the AL system to help students cultivate an appropriate reliance on AI-generated content (Vereschak et al., [2021](https://arxiv.org/html/2402.14601v3#bib.bib86)). Furthermore, hallucination could become a new adaptive teaching method, such as creating new and possibly erroneous educational content and asking students to practice the role of a tutor in correcting AIâs mistakes (Ma et al., [2023b](https://arxiv.org/html/2402.14601v3#bib.bib60)).\nReport issue for preceding element\n####  4.2.2 Capability Decay\nReport issue for preceding element\nThe ease of obtaining information from GenAI can create a dependency, where students might prefer quick GenAI answers over the process of learning and discovery. This over-reliance could erode critical thinking skills and reduce the studentsâ capacity for self-driven inquiry. One potential solution is to integrate GenAI as a tool that prompts further questioning and exploration rather than providing definitive answers. Encouraging projects and assignments that require independent research and critical analysis can also help maintain a balance between utilizing GenAI and fostering self-reliance. However, these suggestions only begin to address the broader challenge of integrating GenAI into education without compromising the development of independent learning skills. This issue remains an open question, presenting a wide array of opportunities for educators, technologists, and policymakers to explore innovative solutions that balance the benefits of GenAI with the imperative of nurturing autonomous, curious learners.\nReport issue for preceding element\n####  4.2.3 Fairness\nReport issue for preceding element\nFairness is a crucial ethical concern, particularly in education where GenAI technologies are being integrated (Fenu et al., [2022](https://arxiv.org/html/2402.14601v3#bib.bib30)). These advancements, while beneficial, bring to light issues of equitable access and unbiased treatment among learners. For instance, discrepancies between those accessing advanced systems like GPT-4 and those with older versions like GPT-3.5 can lead to unequal knowledge distribution, potentially exacerbating educational gaps. The effective deployment of GenAI in education also hinges on user familiarity and accessibility. Students well-acquainted with AI technologies stand to gain more, while those less experienced may encounter challenges and a steeper learning curve. Introducing standardized training programs might help bridge this gap, though such measures require meticulous implementation and oversight. Additionally, inherent biases within GenAI pose a significant challenge. These systems, limited by the biases in their training data, might offer skewed guidance, making vigilant monitoring essential to ensure fairness. In adaptive learning, where GenAI tailors instructional guidance, the risk of bias amplifies. Personalizing learning experiences is beneficial but needs to be weighed against the risk of unfairness. Ensuring an optimal, equitable, and unbiased educational experience for every learner involves navigating these complexities, making the balance between personalized learning and fairness both a technical hurdle and an ethical necessity in the integration of GenAI into educational systems.\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/5699110/Figure/opportunities.png) Figure 7: Human-centric Coevolution of GenAI and Education Report issue for preceding element\n####  4.2.4 Coevolution of human, GenAI, and education\nReport issue for preceding element\nThe realm of GenAI evolves as an indispensable tool in the educational sphere. This progression, however, underscores a nuanced balance: GenAIâs development must be aligned with, but not overshadow, the broader trajectory of human advancement. Generative AI should serve as an augmentative force, enhancing human capabilities rather than supplanting them. The essence of this coevolution lies in the acknowledgment that GenAI, while a profound enabler, should not assume a dominant or leadership role. Generative AIâs integration into educational systems should amplify human potential without dictating the course of our development. As shown in Fig. [7](https://arxiv.org/html/2402.14601v3#S4.F7 \"Figure 7 â£ 4.2.3 Fairness â£ 4.2 Disadvantages, Challenges and Potentials â£ 4 Impacts of GenAI on AL â£ Bringing Generative AI to Adaptive Learning in Education\"), we consider the above issues from the following perspectives.\nReport issue for preceding element\nGovernance and Ethical Frameworks: How do we establish robust governance structures and ethical frameworks that ensure generative AIâs role in education adheres to human-defined objectives and values? This involves creating policies that prioritize human decision-making in critical educational processes, thereby preventing generative AI from autonomously setting or altering educational agendas.\nReport issue for preceding element\nHuman predominance: In what ways can we design generative AI systems that inherently support and enhance human leadership in educational settings? How do we strike a balance between leveraging generative AIâs capabilities for autonomous functioning and maintaining human control over its applications? This balance is crucial to ensure that while generative AI can operate efficiently in certain aspects of education, it does so under the guidelines and constraints set forth by human educators and policymakers.\nReport issue for preceding element\nEducational Goals and generative AI Limitations: In defining educational goals, how to ensure the core of education remains intrinsically human â an arena where human intellect, values, and creativity guide our journey towards a more enlightened future? Itâs essential to outline the boundaries of generative AI in handling complex, nuanced aspects of education that are inherently human.\nReport issue for preceding element\nLong-term Impact and Accountability: What mechanisms should we implement to regularly assess the long-term impact of generative AI in education, ensuring that it aligns with human-centric goals and adapting strategies as needed? This involves establishing accountability systems where a golden rule lies on the fact that humans always be the only accountable party that is responsible for the critical decisions, the road map outlined, as well as all outcomes.\nReport issue for preceding element\n##  5 Further Discussion\nReport issue for preceding element\nItâs understandable that some readers might have different opinions toward our claims in this paper for a range of reasons. Below, we explore a few of these perspectives and share our discussions in an impartial manner:\nReport issue for preceding element\nWhy is our emphasis on adaptive learning rather than other educational perspectives?\nReport issue for preceding element\nOur response to this inquiry can be succinctly encapsulated from two angles: (1) adaptive learning in the educational sphere has a well-established history spanning several decades. Its efficacy in aiding learners to attain enhanced educational outcomes has been consistently validated through numerous studies. By integrating GenAI with adaptive learning, our goal is to maintain and accelerate the evolution of adaptive learning, propelling it into a new era of advancement; (2) the inherently data-driven nature of adaptive learning fosters the widespread adoption of machine learning algorithms within this field. Drawing on insights and methodologies from other ML-centric areas, such as NLP and CV, we are confident that GenAI will serve as a potent catalyst, steering adaptive learning in novel and exciting directions.\nReport issue for preceding element\nWhat is the scope of this work?\nReport issue for preceding element\nIn this paper, we primarily focus on our reviews and discussions of ML-related components in AL systems, particularly because of their close relationship with GenAI. However, just as the example of âunconventionalâ solutions advised by GenAI, the deeper explorations in applying GenAI could bring us new visions to educational paradigms. Although this paper might not encompass all these emerging opportunities and challenges, its value remains significant. It aims to illuminate a promising direction for future research and development in this field.\nReport issue for preceding element\nHow does adaptive learning combined with generative AI broadly impact the field of education?\nReport issue for preceding element\nThe integration of GenAI with adaptive learning enhances a previously practical tool, making it more efficient. This advancement not only improves educational methods but also illuminates potential pathways for further revolutions in education technology, particularly concerning universal challenges and risks associated with GenAI models. Moreover, the robust applicability of this method raises the possibility of addressing disparities in educational resources, potentially offering more substantial assistance in this area.\nReport issue for preceding element\n##  6 Conclusion\nReport issue for preceding element\nIn this paper, we aim to draw attention on the novel research area of integrating generative AI with adaptive learning in education. We believe that the data-centric nature of adaptive learning, which already embraces machine learning, provides an ideal platform for generative AI to enhance the efficacy of existing AL algorithms through its dynamic and diverse output capabilities. However, we also acknowledge the challenges and uncertainties that GenAI introduces to adaptive learning, particularly in sensitive areas like fairness and reliability. Drawing inspiration from GenAIâs advancements in other fields, we remain confident that these concerns will be addressed, transforming these challenges into research opportunities and objectives. While our perspectives might not resonate with every reader, our aim is to spark conversation and encourage exploration in this field. If this paper can inspire future research, then it has successfully served its purpose.\nReport issue for preceding element\n## Authorsâ Contributions\nReport issue for preceding element\nHang L. and QingSong W. conceptualized the manuscript. Hang L. and Tianlong X. created all figures and data visualizations. Hang L., Tianlong X., ChaoLi Z., Eason C. contributed to writing the manuscript, Qingsong W., Jiliang T., Jing L., Xing F., and Haoyang L. contribute to reviewing and editing the manuscript.\nReport issue for preceding element\n## Competing interests\nReport issue for preceding element\nThe author declares no competing interests.\nReport issue for preceding element\n## References\nReport issue for preceding element\n  * Abdelrahman et al. (2023)â Abdelrahman, G., Wang, Q., and Nunes, B.  Knowledge tracing: A survey.  _ACM Computing Surveys_ , 55(11):1â37, 2023. \n  * Achiam et al. (2023)â Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F. L., Almeida, D., Altenschmidt, J., Altman, S., Anadkat, S., et al.  Gpt-4 technical report.  _arXiv preprint arXiv:2303.08774_ , 2023. \n  * Ackerman et al. (2003)â Ackerman, T. A., Gierl, M. J., and Walker, C. M.  Using multidimensional item response theory to evaluate educational and psychological tests.  _Educational Measurement: Issues and Practice_ , 22(3):37â51, 2003. \n  * Adewumi et al. (2023)â Adewumi, T., Alkhaled, L., Buck, C., Hernandez, S., Brilioth, S., Kekung, M., Ragimov, Y., and Barney, E.  Procot: Stimulating critical thinking and writing of students through engagement with large language models (llms).  _arXiv preprint arXiv:2312.09801_ , 2023. \n  * Aeiad & Meziane (2019)â Aeiad, E. and Meziane, F.  An adaptable and personalised e-learning system applied to computer science programmes design.  _Education and Information Technologies_ , 24(2):1485â1509, 2019. \n  * Aleven et al. (2016)â Aleven, V., McLaughlin, E. A., Glenn, R. A., and Koedinger, K. R.  Instruction based on adaptive learning technologies.  _Handbook of research on learning and instruction_ , 2:522â560, 2016. \n  * Baidoo-Anu & Owusu Ansah (2023)â Baidoo-Anu, D. and Owusu Ansah, L.  Education in the era of generative artificial intelligence (ai): Understanding the potential benefits of chatgpt in promoting teaching and learning.  _Available at SSRN 4337484_ , 2023. \n  * Betker et al. (2023)â Betker, J., Goh, G., Jing, L., Brooks, T., Wang, J., Li, L., Ouyang, L., Zhuang, J., Lee, J., Guo, Y., et al.  Improving image generation with better captions.  _Computer Science. https://cdn. openai. com/papers/dall-e-3. pdf_ , 2(3):8, 2023. \n  * Bewersdorff et al. (2024)â Bewersdorff, A., Hartmann, C., Hornberger, M., SeÃler, K., Bannert, M., Kasneci, E., Kasneci, G., Zhai, X., and Nerdel, C.  Taking the next step with generative artificial intelligence: The transformative role of multimodal large language models in science education.  _arXiv preprint arXiv:2401.00832_ , 2024. \n  * Bi et al. (2020)â Bi, H., Ma, H., Huang, Z., Yin, Y., Liu, Q., Chen, E., Su, Y., and Wang, S.  Quality meets diversity: A model-agnostic framework for computerized adaptive testing.  In _2020 IEEE International Conference on Data Mining (ICDM)_ , pp. 42â51. IEEE, 2020. \n  * Bourkoukou et al. (2017)â Bourkoukou, O., El Bachari, E., and El Adnani, M.  A recommender model in e-learning environment.  _Arabian Journal for Science and Engineering_ , 42:607â617, 2017. \n  * Brooks et al. (2024)â Brooks, T., Peebles, B., Holmes, C., DePue, W., Guo, Y., Jing, L., Schnurr, D., Taylor, J., Luhman, T., Luhman, E., Ng, C., Wang, R., and Ramesh, A.  Video generation models as world simulators.  2024.  URL <https://openai.com/research/video-generation-models-as-world-simulators>. \n  * Brown et al. (2020)â Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al.  Language models are few-shot learners.  _Advances in neural information processing systems_ , 33:1877â1901, 2020. \n  * BrÃ¼hl (2023)â BrÃ¼hl, V.  Generative artificial intelligence (gai)âfoundations, use cases and economic potential.  _Center for Financial Studies Working Paper_ , (713), 2023. \n  * Bubeck et al. (2023)â Bubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., Horvitz, E., Kamar, E., Lee, P., Lee, Y. T., Li, Y., Lundberg, S., et al.  Sparks of artificial general intelligence: Early experiments with gpt-4.  _arXiv preprint arXiv:2303.12712_ , 2023. \n  * Cao et al. (2023)â Cao, Y., Li, S., Liu, Y., Yan, Z., Dai, Y., Yu, P. S., and Sun, L.  A comprehensive survey of ai-generated content (aigc): A history of generative ai from gan to chatgpt.  _arXiv preprint arXiv:2303.04226_ , 2023. \n  * Cen et al. (2006)â Cen, H., Koedinger, K., and Junker, B.  Learning factors analysisâa general method for cognitive model evaluation and improvement.  In _International conference on intelligent tutoring systems_ , pp. 164â175. Springer, 2006. \n  * Cheng et al. (2019)â Cheng, S., Liu, Q., Chen, E., Huang, Z., Huang, Z., Chen, Y., Ma, H., and Hu, G.  Dirt: Deep learning enhanced item response theory for cognitive diagnosis.  In _Proceedings of the 28th ACM international conference on information and knowledge management_ , pp. 2397â2400, 2019. \n  * Chu et al. (2024)â Chu, Z., Wang, Y., Cui, Q., Li, L., Chen, W., Li, S., Qin, Z., and Ren, K.  Llm-guided multi-view hypergraph learning for human-centric explainable recommendation.  _arXiv preprint arXiv:2401.08217_ , 2024. \n  * Colchester et al. (2017)â Colchester, K., Hagras, H., Alghazzawi, D., and Aldabbagh, G.  A survey of artificial intelligence techniques employed for adaptive educational systems within e-learning platforms.  _Journal of Artificial Intelligence and Soft Computing Research_ , 7(1):47â64, 2017. \n  * Cooper (2023)â Cooper, G.  Examining science education in chatgpt: An exploratory study of generative artificial intelligence.  _Journal of Science Education and Technology_ , 32(3):444â452, 2023. \n  * Corbett & Anderson (1994)â Corbett, A. T. and Anderson, J. R.  Knowledge tracing: Modeling the acquisition of procedural knowledge.  _User modeling and user-adapted interaction_ , 4:253â278, 1994. \n  * Cui et al. (2022)â Cui, Z., Ma, J., Zhou, C., Zhou, J., and Yang, H.  M6-rec: Generative pretrained language models are open-ended recommender systems.  _arXiv preprint arXiv:2205.08084_ , 2022. \n  * Dan et al. (2023)â Dan, Y., Lei, Z., Gu, Y., Li, Y., Yin, J., Lin, J., Ye, L., Tie, Z., Zhou, Y., Wang, Y., et al.  Educhat: A large-scale language model-based chatbot system for intelligent education.  _arXiv preprint arXiv:2308.02773_ , 2023. \n  * Dang et al. (2022)â Dang, H., Mecke, L., Lehmann, F., Goller, S., and Buschek, D.  How to prompt? opportunities and challenges of zero-and few-shot learning for human-ai interaction in creative applications of generative models.  _arXiv preprint arXiv:2209.01390_ , 2022. \n  * De La Torre (2009)â De La Torre, J.  Dina model and parameter estimation: A didactic.  _Journal of educational and behavioral statistics_ , 34(1):115â130, 2009. \n  * Dhariwal & Nichol (2021)â Dhariwal, P. and Nichol, A.  Diffusion models beat gans on image synthesis.  _Advances in neural information processing systems_ , 34:8780â8794, 2021. \n  * Dong et al. (2022)â Dong, Q., Li, L., Dai, D., Zheng, C., Wu, Z., Chang, B., Sun, X., Xu, J., and Sui, Z.  A survey on in-context learning.  _arXiv preprint arXiv:2301.00234_ , 2022. \n  * Fagbohun et al. (2024)â Fagbohun, O., Iduwe, N., Abdullahi, M., Ifaturoti, A., and Nwanna, O.  Beyond traditional assessment: Exploring the impact of large language models on grading practices.  _Journal of Artifical Intelligence and Machine Learning & Data Science_, 2(1):1â8, 2024. \n  * Fenu et al. (2022)â Fenu, G., Galici, R., and Marras, M.  Expertsâ view on challenges and needs for fairness in artificial intelligence for education.  In _International Conference on Artificial Intelligence in Education_ , pp. 243â255. Springer, 2022. \n  * Ghauth & Abdullah (2010)â Ghauth, K. I. and Abdullah, N. A.  Measuring learnerâs performance in e-learning recommender systems.  _Australasian Journal of Educational Technology_ , 26(6), 2010. \n  * Gheibi et al. (2021)â Gheibi, O., Weyns, D., and Quin, F.  Applying machine learning in self-adaptive systems: A systematic literature review.  _ACM Transactions on Autonomous and Adaptive Systems (TAAS)_ , 15(3):1â37, 2021. \n  * Giannakos & Cukurova (2023)â Giannakos, M. and Cukurova, M.  The role of learning theory in multimodal learning analytics.  _British Journal of Educational Technology_ , 2023. \n  * Gilavert & Freire (2022)â Gilavert, P. and Freire, V.  Computerized adaptive testing: A unified approach under markov decision process.  In _International Conference on Computational Science and Its Applications_ , pp. 591â602. Springer, 2022. \n  * Gong et al. (2023)â Gong, Y., Ding, X., Su, Y., Shen, K., Liu, Z., and Zhang, G.  An unified search and recommendation foundation model for cold-start scenario.  In _Proceedings of the 32nd ACM International Conference on Information and Knowledge Management_ , pp. 4595â4601, 2023. \n  * Goodfellow et al. (2014)â Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., and Bengio, Y.  Generative adversarial nets.  _Advances in neural information processing systems_ , 27, 2014. \n  * Goodfellow et al. (2020)â Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., and Bengio, Y.  Generative adversarial networks.  _Communications of the ACM_ , 63(11):139â144, 2020. \n  * Hambleton et al. (1991)â Hambleton, R. K., Swaminathan, H., and Rogers, H. J.  _Fundamentals of item response theory_ , volume 2.  Sage, 1991. \n  * Han et al. (2024)â Han, J., Yoo, H., Myung, J., Kim, M., Lee, T. Y., Ahn, S.-Y., and Oh, A.  Recipe4u: Student-chatgpt interaction dataset in efl writing education.  _arXiv preprint arXiv:2403.08272_ , 2024. \n  * Han et al. (2016)â Han, J.-w., Jo, J.-c., Ji, H.-s., and Lim, H.-s.  A collaborative recommender system for learning courses considering the relevance of a learnerâs learning skills.  _Cluster Computing_ , 19:2273â2284, 2016. \n  * Hattie (2023)â Hattie, J.  _Visible learning: The sequel: A synthesis of over 2,100 meta-analyses relating to achievement_.  Taylor & Francis, 2023. \n  * Ho et al. (2020)â Ho, J., Jain, A., and Abbeel, P.  Denoising diffusion probabilistic models.  _Advances in neural information processing systems_ , 33:6840â6851, 2020. \n  * Hu et al. (2024)â Hu, B., Zheng, L., Zhu, J., Ding, L., Wang, Y., and Gu, X.  Teaching plan generation and evaluation with gpt-4: Unleashing the potential of llm in instructional design.  _IEEE Transactions on Learning Technologies_ , 2024. \n  * Huang et al. (2024)â Huang, X., Liu, W., Chen, X., Wang, X., Wang, H., Lian, D., Wang, Y., Tang, R., and Chen, E.  Understanding the planning of llm agents: A survey.  _arXiv preprint arXiv:2402.02716_ , 2024. \n  * Jeon & Lee (2023)â Jeon, J. and Lee, S.  Large language models in education: A focus on the complementary relationship between human teachers and chatgpt.  _Education and Information Technologies_ , pp. 1â20, 2023. \n  * Ji et al. (2023)â Ji, Z., Lee, N., Frieske, R., Yu, T., Su, D., Xu, Y., Ishii, E., Bang, Y. J., Madotto, A., and Fung, P.  Survey of hallucination in natural language generation.  _ACM Computing Surveys_ , 55(12):1â38, 2023. \n  * Jung et al. (2024)â Jung, H., Yoo, J., Yoon, Y., and Jang, Y.  Clst: Cold-start mitigation in knowledge tracing by aligning a generative language model as a studentsâ knowledge tracer.  _arXiv preprint arXiv:2406.10296_ , 2024. \n  * Khanal et al. (2020)â Khanal, S. S., Prasad, P., Alsadoon, A., and Maag, A.  A systematic review: machine learning based recommendation systems for e-learning.  _Education and Information Technologies_ , 25(4):2635â2664, 2020. \n  * Kieser et al. (2023)â Kieser, F., Wulff, P., Kuhn, J., and KÃ¼chemann, S.  Educational data augmentation in physics education research using chatgpt.  _Physical Review Physics Education Research_ , 19(2):020150, 2023. \n  * Kingma & Welling (2013)â Kingma, D. P. and Welling, M.  Auto-encoding variational bayes.  _arXiv preprint arXiv:1312.6114_ , 2013. \n  * Kolekar et al. (2019)â Kolekar, S. V., Pai, R. M., and MM, M. P.  Rule based adaptive user interface for adaptive e-learning system.  _Education and Information Technologies_ , 24:613â641, 2019. \n  * Kong et al. (2020)â Kong, Z., Ping, W., Huang, J., Zhao, K., and Catanzaro, B.  Diffwave: A versatile diffusion model for audio synthesis.  _arXiv preprint arXiv:2009.09761_ , 2020. \n  * LeCun et al. (2015)â LeCun, Y., Bengio, Y., and Hinton, G.  Deep learning.  _nature_ , 521(7553):436â444, 2015. \n  * Lee et al. (2024)â Lee, J., Smith, D., Woodhead, S., and Lan, A.  Math multiple choice question generation via human-large language model collaboration.  _arXiv preprint arXiv:2405.00864_ , 2024. \n  * Li et al. (2023)â Li, X., Chen, B., Hou, L., and Tang, R.  Ctrl: Connect tabular and language model for ctr prediction.  _arXiv preprint arXiv:2306.02841_ , 2023. \n  * Liu et al. (2017)â Liu, M., Kang, J., Zou, W., Lee, H., Pan, Z., and Corliss, S.  Using data to understand how to better design adaptive learning.  _Technology, Knowledge and Learning_ , 22:271â298, 2017. \n  * Liu et al. (2024)â Liu, Q., Zhuang, Y., Bi, H., Huang, Z., Huang, W., Li, J., Yu, J., Liu, Z., Hu, Z., Hong, Y., et al.  Survey of computerized adaptive testing: A machine learning perspective.  _arXiv preprint arXiv:2404.00712_ , 2024. \n  * Lopez et al. (2020)â Lopez, R., Gayoso, A., and Yosef, N.  Enhancing scientific discoveries in molecular biology with deep generative models.  _Molecular systems biology_ , 16(9):e9198, 2020. \n  * Ma et al. (2023a)â Ma, H., Zeng, Y., Yang, S., Qin, C., Zhang, X., and Zhang, L.  A novel computerized adaptive testing framework with decoupled learning selector.  _Complex & Intelligent Systems_, 9(5):5555â5566, 2023a. \n  * Ma et al. (2023b)â Ma, Q., Shen, H., Koedinger, K., and Wu, T.  Hypocompass: Large-language-model-based tutor for hypothesis construction in debugging for novices.  _arXiv preprint arXiv:2310.05292_ , 2023b. \n  * Mallory (2024)â Mallory, J.  Empowering special needs stem students through unique generative ai tools: A path to inclusive learning.  In _Society for Information Technology & Teacher Education International Conference_, pp. 2156â2161. Association for the Advancement of Computing in Education (AACE), 2024. \n  * Martin et al. (2020)â Martin, F., Chen, Y., Moore, R. L., and Westine, C. D.  Systematic review of adaptive learning research designs, context, strategies, and technologies from 2009 to 2018.  _Educational Technology Research and Development_ , 68:1903â1929, 2020. \n  * Mogavi et al. (2023)â Mogavi, R. H., Deng, C., Kim, J. J., Zhou, P., Kwon, Y. D., Metwally, A. H. S., Tlili, A., Bassanelli, S., Bucchiarone, A., Gujar, S., et al.  Exploring user perspectives on chatgpt: Applications, perceptions, and implications for ai-integrated education.  _arXiv preprint arXiv:2305.13114_ , 2023. \n  * Mojarad et al. (2018)â Mojarad, S., Essa, A., Mojarad, S., and Baker, R. S.  Studying adaptive learning efficacy using propensity score matching.  In _Companion Proceedings of the 8th International Conference on Learning Analytics and Knowledge (LAKâ18)_ , pp. 5â9, 2018. \n  * Neshaei et al. (2024)â Neshaei, S. P., Davis, R. L., Hazimeh, A., Lazarevski, B., Dillenbourg, P., and KÃ¤ser, T.  Towards modeling learner performance with large language models.  _arXiv preprint arXiv:2403.14661_ , 2024. \n  * Nitchot et al. (2019)â Nitchot, A., Wettayaprasit, W., and Gilbert, L.  Assistive tool for constructing knowledge structures and suggesting related study materials links.  _Education and Information Technologies_ , 24:219â230, 2019. \n  * Ouyang et al. (2022)â Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et al.  Training language models to follow instructions with human feedback.  _Advances in Neural Information Processing Systems_ , 35:27730â27744, 2022. \n  * Park & Lee (2013)â Park, O.-c. and Lee, J.  Adaptive instructional systems.  In _Handbook of research on educational communications and technology_ , pp. 647â680. Routledge, 2013. \n  * Pesovski et al. (2024)â Pesovski, I., Santos, R., Henriques, R., and Trajkovik, V.  Generative ai for customizable learning experiences.  _Sustainability_ , 16(7):3034, 2024. \n  * Piech et al. (2015)â Piech, C., Bassen, J., Huang, J., Ganguli, S., Sahami, M., Guibas, L. J., and Sohl-Dickstein, J.  Deep knowledge tracing.  _Advances in neural information processing systems_ , 28, 2015. \n  * Pierce Burr & Young (2024)â Pierce Burr, A. K. and Young, T.  8 the the potential of ai text-to-image generation in medical education the educator and studentsâ perspective.  _Using Generative AI Effectively in Higher Education: Sustainable and Ethical Practices for Learning, Teaching and Assessment_ , pp. 74, 2024. \n  * Popov et al. (2021)â Popov, V., Vovk, I., Gogoryan, V., Sadekova, T., and Kudinov, M.  Grad-tts: A diffusion probabilistic model for text-to-speech.  In _International Conference on Machine Learning_ , pp. 8599â8608. PMLR, 2021. \n  * Prokudin et al. (2023)â Prokudin, A., Sychev, O., and Denisov, M.  Learning problem generator for introductory programming courses.  _Software Impacts_ , 17:100519, 2023. \n  * Qadir (2023)â Qadir, J.  Engineering education in the era of chatgpt: Promise and pitfalls of generative ai for education.  In _2023 IEEE Global Engineering Education Conference (EDUCON)_ , pp. 1â9. IEEE, 2023. \n  * Rahman & Watanobe (2023)â Rahman, M. M. and Watanobe, Y.  Chatgpt for education and research: Opportunities, threats, and strategies.  _Applied Sciences_ , 13(9):5783, 2023. \n  * Ramesh et al. (2022)â Ramesh, A., Dhariwal, P., Nichol, A., Chu, C., and Chen, M.  Hierarchical text-conditional image generation with clip latents.  _arXiv preprint arXiv:2204.06125_ , 1(2):3, 2022. \n  * Rane (2023)â Rane, N.  Role and challenges of chatgpt and similar generative artificial intelligence in finance and accounting.  _Available at SSRN 4603206_ , 2023. \n  * Shao et al. (2023)â Shao, Y., Li, L., Dai, J., and Qiu, X.  Character-llm: A trainable agent for role-playing.  _arXiv preprint arXiv:2310.10158_ , 2023. \n  * Shu et al. (2018)â Shu, J., Shen, X., Liu, H., Yi, B., and Zhang, Z.  A content-based recommendation algorithm for learning resources.  _Multimedia Systems_ , 24(2):163â173, 2018. \n  * Smith et al. (2024)â Smith, C. E., Bezabih, A., Nourriz, S., Wu, B., and Fierro, G.  Toward llm-powered robots in engineering education.  2024. \n  * Song et al. (2020)â Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., and Poole, B.  Score-based generative modeling through stochastic differential equations.  _arXiv preprint arXiv:2011.13456_ , 2020. \n  * Strzelecki & ElArabawy (2024)â Strzelecki, A. and ElArabawy, S.  Investigation of the moderation effect of gender and study level on the acceptance and use of generative ai by higher education students: Comparative evidence from poland and egypt.  _British Journal of Educational Technology_ , 2024. \n  * Tao et al. (2024)â Tao, Z., Xi, D., Li, Z., Tang, L., and Xu, W.  Cat-llm: Prompting large language models with text style definition for chinese article-style transfer.  _arXiv preprint arXiv:2401.05707_ , 2024. \n  * Vaswani et al. (2017)â Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Å., and Polosukhin, I.  Attention is all you need.  _Advances in neural information processing systems_ , 30, 2017. \n  * Veldkamp & Verschoor (2019)â Veldkamp, B. P. and Verschoor, A. J.  Robust computerized adaptive testing.  _Theoretical and practical advances in computer-based educational measurement_ , pp. 291â305, 2019. \n  * Vereschak et al. (2021)â Vereschak, O., Bailly, G., and Caramiaux, B.  How to evaluate trust in ai-assisted decision making? a survey of empirical methodologies.  _Proceedings of the ACM on Human-Computer Interaction_ , 5(CSCW2):1â39, 2021. \n  * Walters & Murcko (2020)â Walters, W. P. and Murcko, M.  Assessing the impact of generative ai on medicinal chemistry.  _Nature biotechnology_ , 38(2):143â145, 2020. \n  * Wang et al. (2020)â Wang, F., Liu, Q., Chen, E., Huang, Z., Chen, Y., Yin, Y., Huang, Z., and Wang, S.  Neural cognitive diagnosis for intelligent education systems.  In _Proceedings of the AAAI conference on artificial intelligence_ , volume 34, pp. 6153â6161, 2020. \n  * Wang et al. (2023a)â Wang, J., Yuan, H., Chen, D., Zhang, Y., Wang, X., and Zhang, S.  Modelscope text-to-video technical report.  _arXiv preprint arXiv:2308.06571_ , 2023a. \n  * Wang et al. (2024)â Wang, L., Ma, C., Feng, X., Zhang, Z., Yang, H., Zhang, J., Chen, Z., Tang, J., Chen, X., Lin, Y., et al.  A survey on large language model based autonomous agents.  _Frontiers of Computer Science_ , 18(6):186345, 2024. \n  * Wang et al. (2023b)â Wang, S., Christensen, C., Cui, W., Tong, R., Yarnall, L., Shear, L., and Feng, M.  When adaptive learning is effective learning: comparison of an adaptive learning system to teacher-led instruction.  _Interactive Learning Environments_ , 31(2):793â803, 2023b. \n  * Wu et al. (2023a)â Wu, Q., Bansal, G., Zhang, J., Wu, Y., Zhang, S., Zhu, E., Li, B., Jiang, L., Zhang, X., and Wang, C.  Autogen: Enabling next-gen llm applications via multi-agent conversation framework.  _arXiv preprint arXiv:2308.08155_ , 2023a. \n  * Wu et al. (2023b)â Wu, S., Fei, H., Qu, L., Ji, W., and Chua, T.-S.  Next-gpt: Any-to-any multimodal llm.  _arXiv preprint arXiv:2309.05519_ , 2023b. \n  * Wu et al. (2024)â Wu, Y., Jia, F., Zhang, S., Li, H., Zhu, E., Wang, Y., Lee, Y. T., Peng, R., Wu, Q., and Wang, C.  Mathchat: Converse to tackle challenging math problems with llm agents.  In _ICLR 2024 Workshop on Large Language Model (LLM) Agents_ , 2024. \n  * Xiao et al. (2023)â Xiao, C., Xu, S. X., Zhang, K., Wang, Y., and Xia, L.  Evaluating reading comprehension exercises generated by llms: A showcase of chatgpt in education applications.  In _Proceedings of the 18th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2023)_ , pp. 610â625, 2023. \n  * Xiao et al. (2024)â Xiao, C., Ma, W., Xu, S. X., Zhang, K., Wang, Y., and Fu, Q.  From automation to augmentation: Large language models elevating essay scoring landscape.  _arXiv preprint arXiv:2401.06431_ , 2024. \n  * Yeo et al. (2024)â Yeo, T., Atanov, A., Benoit, H., Alekseev, A., Ray, R., Akhoondi, P. E., and Zamir, A.  Controlled training data generation with diffusion models.  _arXiv preprint arXiv:2403.15309_ , 2024. \n  * Yu et al. (2023)â Yu, J., Zhenyu, M., Lei, J., Yin, L., Xia, W., Yu, Y., and Long, T.  Sacat: Student-adaptive computerized adaptive testing.  In _Proceedings of the Fifth International Conference on Distributed Artificial Intelligence_ , pp. 1â7, 2023. \n  * Zarris & Sozos (2023)â Zarris, D. and Sozos, S.  Educational artificial intelligent chatbot: Teacher assistant & study buddy, 2023. \n  * Zhang & Tur (2023)â Zhang, P. and Tur, G.  A systematic review of chatgpt use in k-12 education.  _European Journal of Education_ , 2023. \n  * Zhang et al. (2023a)â Zhang, S., Dong, L., Li, X., Zhang, S., Sun, X., Wang, S., Li, J., Hu, R., Zhang, T., Wu, F., et al.  Instruction tuning for large language models: A survey.  _arXiv preprint arXiv:2308.10792_ , 2023a. \n  * Zhang et al. (2023b)â Zhang, Y., Huang, N., Tang, F., Huang, H., Ma, C., Dong, W., and Xu, C.  Inversion-based style transfer with diffusion models.  In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_ , pp. 10146â10156, 2023b. \n  * Zhou et al. (2023)â Zhou, C., Li, Q., Li, C., Yu, J., Liu, Y., Wang, G., Zhang, K., Ji, C., Yan, Q., He, L., et al.  A comprehensive survey on pretrained foundation models: A history from bert to chatgpt.  _arXiv preprint arXiv:2302.09419_ , 2023. \n  * Zhuang et al. (2024)â Zhuang, Y., Yu, Y., Wang, K., Sun, H., and Zhang, C.  Toolqa: A dataset for llm question answering with external tools.  _Advances in Neural Information Processing Systems_ , 36, 2024. \n\n\n##  Appendix A Appendix.\nReport issue for preceding element\nIn table below, we summarize those pioneering institutions which has begun their industrial practice with bringing generative AI (GenAI) to adaptive learning. The majority of these business cases focus on leveraging GenAI to empower their original products and creating enhanced personalized learning experience to their customers.\nReport issue for preceding element\nTable 1: Industrial practice case studies. USP is the unique selling proposition of the product. Company |  USPs |  Product features  \n---|---|---  \nDuolingo  |  Personalized roleplay |  Uses LLMs to deliver adaptive, highly personalized interactions, closely mimicking real-life conversations. Offers detailed AI-powered post-conversation feedback focusing on the accuracy and appropriateness of responses, identifying strengths and areas for improvement.  \nKhanmigo  |  1 on 1 Tutoring |  Offers a virtual coach, adept at guiding students through problem-solving processes with carefully crafted probing prompts. This method ensures that the learning process is interactive and responsive.  \nAdaptemy  |  Learning content recommendation |  Utilizes a triad of modelsâcurriculum, content, and learner to deliver personalized learning experiences, enabling real-time adaptation of content, assessments, and learning paths based on performance.  \nSquirrel Ai  |  Personalized learning planning |  Established a large adaptive models (LAM) framework to link the learning contents knowledge graph, student profiles and a study-path planning recommendation system to provide personalized learning paths planning.  \nDreamBox Learning |  Math adaptive learning |  Offers personalized K-8 math learning with supplemental curriculum and a range of live and self-paced resources to meet the learning needs of entire staff.  \nChegg |  24/7 study support |  Provides reliable solutions backed by experts, step-by-step explanations and learn tailorings.  \nCarnegie Learning |  Kâ12 education |  Offers clear solutions family and has been proven to deliver up to 2x performance improvement on standardized tests.  \nKahoot! |  Learning games |  Provides learning games to make learning fun, easy, and rewarding for everyone.  \nTAL Education Group |  Smart learning solutions |  Offers comprehensive learning services to students from all ages through diversified class formats.  \nReport issue for preceding element\nReport Issue\n##### Report Github Issue\nTitle:Content selection saved. Describe the issue below:Description:\nSubmit without GithubSubmit in Github\nReport Issue for Selection\nGenerated by [ L A T E xml ![\\[LOGO\\]](https://arxiv.org/html/2402.14601v3) ](https://math.nist.gov/~BMiller/LaTeXML/)\n## Instructions for reporting errors\nWe are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:\n  * Click the \"Report Issue\" button.\n  * Open a report feedback form via keyboard, use \"**Ctrl + ?** \".\n  * Make a text selection and click the \"Report Issue for Selection\" button near your cursor.\n  * You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.\n\n\nOur team has already identified [the following issues](https://github.com/arXiv/html_feedback/issues). We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.\nHave a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a [list of packages that need conversion](https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML), and welcome [developer contributions](https://github.com/brucemiller/LaTeXML/issues).\n"
  },
  {
    "link": "https://arxiv.org/html/2406.06608v1",
    "raw_content": "[ ![logo](https://services.dev.arxiv.org/html/static/arxiv-logomark-small-white.svg) Back to arXiv ](https://arxiv.org/)\n[ ](https://arxiv.org/abs/2406.06608v1) [ ](javascript:toggleColorScheme\\(\\) \"Toggle dark/light mode\")\n[ ![logo](https://services.dev.arxiv.org/html/static/arxiv-logo-one-color-white.svg) Back to arXiv ](https://arxiv.org/)\nThis is **experimental HTML** to improve accessibility. We invite you to report rendering errors. Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off. Learn more [about this project](https://info.arxiv.org/about/accessible_HTML.html) and [help improve conversions](https://info.arxiv.org/help/submit_latex_best_practices.html). \n[Why HTML?](https://info.arxiv.org/about/accessible_HTML.html) [Report Issue](https://arxiv.org/html/2406.06608v1#myForm) [Back to Abstract](https://arxiv.org/abs/2406.06608v1) [Download PDF](https://arxiv.org/pdf/2406.06608v1) [ ](javascript:toggleColorScheme\\(\\) \"Toggle dark/light mode\")\n## Table of Contents\n  1. [ Abstract  ](https://arxiv.org/html/2406.06608v1#abstract \"Abstract\")\n  2. [1 Introduction](https://arxiv.org/html/2406.06608v1#Ch1 \"In The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    1. [Scope of Study](https://arxiv.org/html/2406.06608v1#Ch1.S0.SS0.SSS0.Px1 \"In 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    2. [Sections Overview](https://arxiv.org/html/2406.06608v1#Ch1.S0.SS0.SSS0.Px2 \"In 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    3. [1.1 What is a Prompt?](https://arxiv.org/html/2406.06608v1#Ch1.S1 \"In 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [Prompt Template](https://arxiv.org/html/2406.06608v1#Ch1.S1.SS0.SSS0.Px1 \"In 1.1 What is a Prompt? â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    4. [1.2 Terminology](https://arxiv.org/html/2406.06608v1#Ch1.S2 \"In 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [1.2.1 Components of a Prompt](https://arxiv.org/html/2406.06608v1#Ch1.S2.SS1 \"In 1.2 Terminology â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [Directive](https://arxiv.org/html/2406.06608v1#Ch1.S2.SS1.SSS0.Px1 \"In 1.2.1 Components of a Prompt â£ 1.2 Terminology â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [Examples](https://arxiv.org/html/2406.06608v1#Ch1.S2.SS1.SSS0.Px2 \"In 1.2.1 Components of a Prompt â£ 1.2 Terminology â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        3. [Output Formatting](https://arxiv.org/html/2406.06608v1#Ch1.S2.SS1.SSS0.Px3 \"In 1.2.1 Components of a Prompt â£ 1.2 Terminology â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        4. [Style Instructions](https://arxiv.org/html/2406.06608v1#Ch1.S2.SS1.SSS0.Px4 \"In 1.2.1 Components of a Prompt â£ 1.2 Terminology â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        5. [Role](https://arxiv.org/html/2406.06608v1#Ch1.S2.SS1.SSS0.Px5 \"In 1.2.1 Components of a Prompt â£ 1.2 Terminology â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        6. [Additional Information](https://arxiv.org/html/2406.06608v1#Ch1.S2.SS1.SSS0.Px6 \"In 1.2.1 Components of a Prompt â£ 1.2 Terminology â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [1.2.2 Prompting Terms](https://arxiv.org/html/2406.06608v1#Ch1.S2.SS2 \"In 1.2 Terminology â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [Prompting](https://arxiv.org/html/2406.06608v1#Ch1.S2.SS2.SSS0.Px1 \"In 1.2.2 Prompting Terms â£ 1.2 Terminology â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [Prompt Chain](https://arxiv.org/html/2406.06608v1#Ch1.S2.SS2.SSS0.Px2 \"In 1.2.2 Prompting Terms â£ 1.2 Terminology â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        3. [Prompting Technique](https://arxiv.org/html/2406.06608v1#Ch1.S2.SS2.SSS0.Px3 \"In 1.2.2 Prompting Terms â£ 1.2 Terminology â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        4. [Prompt Engineering](https://arxiv.org/html/2406.06608v1#Ch1.S2.SS2.SSS0.Px4 \"In 1.2.2 Prompting Terms â£ 1.2 Terminology â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        5. [Prompt Engineering Technique](https://arxiv.org/html/2406.06608v1#Ch1.S2.SS2.SSS0.Px5 \"In 1.2.2 Prompting Terms â£ 1.2 Terminology â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        6. [Exemplar](https://arxiv.org/html/2406.06608v1#Ch1.S2.SS2.SSS0.Px6 \"In 1.2.2 Prompting Terms â£ 1.2 Terminology â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    5. [1.3 A Short History of Prompts](https://arxiv.org/html/2406.06608v1#Ch1.S3 \"In 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n  3. [2 A Meta-Analysis of Prompting](https://arxiv.org/html/2406.06608v1#Ch2 \"In The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    1. [2.1 Systematic Review Process](https://arxiv.org/html/2406.06608v1#Ch2.S1 \"In 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [2.1.1 The Pipeline](https://arxiv.org/html/2406.06608v1#Ch2.S1.SS1 \"In 2.1 Systematic Review Process â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    2. [2.2 Text-Based Techniques](https://arxiv.org/html/2406.06608v1#Ch2.S2 \"In 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [2.2.1 In-Context Learning (ICL)](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS1 \"In 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [Few-Shot Prompting](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS1.SSS0.Px1 \"In 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [Few-Shot Learning (FSL)](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS1.SSS0.Px2 \"In 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        3. [2.2.1.1 Few-Shot Prompting Design Decisions](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS1.SSS1 \"In 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          1. [Exemplar Quantity](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS1.SSS1.Px1 \"In 2.2.1.1 Few-Shot Prompting Design Decisions â£ 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          2. [Exemplar Ordering](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS1.SSS1.Px2 \"In 2.2.1.1 Few-Shot Prompting Design Decisions â£ 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          3. [Exemplar Label Distribution](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS1.SSS1.Px3 \"In 2.2.1.1 Few-Shot Prompting Design Decisions â£ 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          4. [Exemplar Label Quality](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS1.SSS1.Px4 \"In 2.2.1.1 Few-Shot Prompting Design Decisions â£ 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          5. [Exemplar Format](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS1.SSS1.Px5 \"In 2.2.1.1 Few-Shot Prompting Design Decisions â£ 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          6. [Exemplar Similarity](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS1.SSS1.Px6 \"In 2.2.1.1 Few-Shot Prompting Design Decisions â£ 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        4. [2.2.1.2 Few-Shot Prompting Techniques](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS1.SSS2 \"In 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          1. [K-Nearest Neighbor (KNN)](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS1.SSS2.Px1 \"In 2.2.1.2 Few-Shot Prompting Techniques â£ 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          2. [Vote-K](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS1.SSS2.Px2 \"In 2.2.1.2 Few-Shot Prompting Techniques â£ 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          3. [Self-Generated In-Context Learning (SG-ICL)](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS1.SSS2.Px3 \"In 2.2.1.2 Few-Shot Prompting Techniques â£ 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          4. [Prompt Mining](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS1.SSS2.Px4 \"In 2.2.1.2 Few-Shot Prompting Techniques â£ 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          5. [More Complicated Techniques](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS1.SSS2.Px5 \"In 2.2.1.2 Few-Shot Prompting Techniques â£ 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [2.2.2 Zero-Shot](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS2 \"In 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [Role Prompting](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS2.SSS0.Px1 \"In 2.2.2 Zero-Shot â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [Style Prompting](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS2.SSS0.Px2 \"In 2.2.2 Zero-Shot â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        3. [Emotion Prompting](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS2.SSS0.Px3 \"In 2.2.2 Zero-Shot â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        4. [System 2 Attention (S2A)](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS2.SSS0.Px4 \"In 2.2.2 Zero-Shot â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        5. [SimToM](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS2.SSS0.Px5 \"In 2.2.2 Zero-Shot â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        6. [Rephrase and Respond (RaR)](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS2.SSS0.Px6 \"In 2.2.2 Zero-Shot â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        7. [Re-reading (RE2)](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS2.SSS0.Px7 \"In 2.2.2 Zero-Shot â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        8. [Self-Ask](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS2.SSS0.Px8 \"In 2.2.2 Zero-Shot â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      3. [2.2.3 Thought Generation](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3 \"In 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [Chain-of-Thought (CoT) Prompting](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3.SSS0.Px1 \"In 2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [2.2.3.1 Zero-Shot-CoT](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3.SSS1 \"In 2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          1. [Step-Back Prompting](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3.SSS1.Px1 \"In 2.2.3.1 Zero-Shot-CoT â£ 2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          2. [Analogical Prompting](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3.SSS1.Px2 \"In 2.2.3.1 Zero-Shot-CoT â£ 2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          3. [Thread-of-Thought (ThoT) Prompting](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3.SSS1.Px3 \"In 2.2.3.1 Zero-Shot-CoT â£ 2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          4. [Tabular Chain-of-Thought (Tab-CoT)](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3.SSS1.Px4 \"In 2.2.3.1 Zero-Shot-CoT â£ 2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        3. [2.2.3.2 Few-Shot CoT](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3.SSS2 \"In 2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          1. [Contrastive CoT Prompting](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3.SSS2.Px1 \"In 2.2.3.2 Few-Shot CoT â£ 2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          2. [Uncertainty-Routed CoT Prompting](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3.SSS2.Px2 \"In 2.2.3.2 Few-Shot CoT â£ 2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          3. [Complexity-based Prompting](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3.SSS2.Px3 \"In 2.2.3.2 Few-Shot CoT â£ 2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          4. [Active Prompting](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3.SSS2.Px4 \"In 2.2.3.2 Few-Shot CoT â£ 2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          5. [Memory-of-Thought Prompting](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3.SSS2.Px5 \"In 2.2.3.2 Few-Shot CoT â£ 2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          6. [Automatic Chain-of-Thought (Auto-CoT) Prompting](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3.SSS2.Px6 \"In 2.2.3.2 Few-Shot CoT â£ 2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      4. [2.2.4 Decomposition](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS4 \"In 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [Least-to-Most Prompting](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS4.SSS0.Px1 \"In 2.2.4 Decomposition â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [Decomposed Prompting (DECOMP)](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS4.SSS0.Px2 \"In 2.2.4 Decomposition â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        3. [Plan-and-Solve Prompting](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS4.SSS0.Px3 \"In 2.2.4 Decomposition â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        4. [Tree-of-Thought (ToT)](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS4.SSS0.Px4 \"In 2.2.4 Decomposition â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        5. [Recursion-of-Thought](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS4.SSS0.Px5 \"In 2.2.4 Decomposition â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        6. [Program-of-Thoughts](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS4.SSS0.Px6 \"In 2.2.4 Decomposition â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        7. [Faithful Chain-of-Thought](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS4.SSS0.Px7 \"In 2.2.4 Decomposition â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        8. [Skeleton-of-Thought](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS4.SSS0.Px8 \"In 2.2.4 Decomposition â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      5. [2.2.5 Ensembling](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS5 \"In 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [Demonstration Ensembling (DENSE)](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS5.SSS0.Px1 \"In 2.2.5 Ensembling â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [Mixture of Reasoning Experts (MoRE)](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS5.SSS0.Px2 \"In 2.2.5 Ensembling â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        3. [Max Mutual Information Method](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS5.SSS0.Px3 \"In 2.2.5 Ensembling â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        4. [Self-Consistency](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS5.SSS0.Px4 \"In 2.2.5 Ensembling â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        5. [Universal Self-Consistency](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS5.SSS0.Px5 \"In 2.2.5 Ensembling â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        6. [Meta-Reasoning over Multiple CoTs](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS5.SSS0.Px6 \"In 2.2.5 Ensembling â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        7. [DiVeRSe](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS5.SSS0.Px7 \"In 2.2.5 Ensembling â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        8. [Consistency-based Self-adaptive Prompting (COSP)](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS5.SSS0.Px8 \"In 2.2.5 Ensembling â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        9. [Universal Self-Adaptive Prompting (USP)](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS5.SSS0.Px9 \"In 2.2.5 Ensembling â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        10. [Prompt Paraphrasing](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS5.SSS0.Px10 \"In 2.2.5 Ensembling â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      6. [2.2.6 Self-Criticism](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS6 \"In 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [Self-Calibration](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS6.SSS0.Px1 \"In 2.2.6 Self-Criticism â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [Self-Refine](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS6.SSS0.Px2 \"In 2.2.6 Self-Criticism â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        3. [Reversing Chain-of-Thought (RCoT)](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS6.SSS0.Px3 \"In 2.2.6 Self-Criticism â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        4. [Self-Verification](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS6.SSS0.Px4 \"In 2.2.6 Self-Criticism â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        5. [Chain-of-Verification (COVE)](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS6.SSS0.Px5 \"In 2.2.6 Self-Criticism â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        6. [Cumulative Reasoning](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS6.SSS0.Px6 \"In 2.2.6 Self-Criticism â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    3. [2.3 Prompting Technique Usage](https://arxiv.org/html/2406.06608v1#Ch2.S3 \"In 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [2.3.1 Benchmarks](https://arxiv.org/html/2406.06608v1#Ch2.S3.SS1 \"In 2.3 Prompting Technique Usage â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    4. [2.4 Prompt Engineering](https://arxiv.org/html/2406.06608v1#Ch2.S4 \"In 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [Meta Prompting](https://arxiv.org/html/2406.06608v1#Ch2.S4.SS0.SSS0.Px1 \"In 2.4 Prompt Engineering â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [AutoPrompt](https://arxiv.org/html/2406.06608v1#Ch2.S4.SS0.SSS0.Px2 \"In 2.4 Prompt Engineering â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      3. [Automatic Prompt Engineer (APE)](https://arxiv.org/html/2406.06608v1#Ch2.S4.SS0.SSS0.Px3 \"In 2.4 Prompt Engineering â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      4. [Gradientfree Instructional Prompt Search (GrIPS)](https://arxiv.org/html/2406.06608v1#Ch2.S4.SS0.SSS0.Px4 \"In 2.4 Prompt Engineering â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      5. [Prompt Optimization with Textual Gradients (ProTeGi)](https://arxiv.org/html/2406.06608v1#Ch2.S4.SS0.SSS0.Px5 \"In 2.4 Prompt Engineering â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      6. [RLPrompt](https://arxiv.org/html/2406.06608v1#Ch2.S4.SS0.SSS0.Px6 \"In 2.4 Prompt Engineering â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      7. [Dialogue-comprised Policy-gradient-based Discrete Prompt Optimization (DP2O)](https://arxiv.org/html/2406.06608v1#Ch2.S4.SS0.SSS0.Px7 \"In 2.4 Prompt Engineering â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    5. [2.5 Answer Engineering](https://arxiv.org/html/2406.06608v1#Ch2.S5 \"In 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [2.5.1 Answer Shape](https://arxiv.org/html/2406.06608v1#Ch2.S5.SS1 \"In 2.5 Answer Engineering â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [2.5.2 Answer Space](https://arxiv.org/html/2406.06608v1#Ch2.S5.SS2 \"In 2.5 Answer Engineering â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      3. [2.5.3 Answer Extractor](https://arxiv.org/html/2406.06608v1#Ch2.S5.SS3 \"In 2.5 Answer Engineering â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [Verbalizer](https://arxiv.org/html/2406.06608v1#Ch2.S5.SS3.SSS0.Px1 \"In 2.5.3 Answer Extractor â£ 2.5 Answer Engineering â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [Regex](https://arxiv.org/html/2406.06608v1#Ch2.S5.SS3.SSS0.Px2 \"In 2.5.3 Answer Extractor â£ 2.5 Answer Engineering â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        3. [Separate LLM](https://arxiv.org/html/2406.06608v1#Ch2.S5.SS3.SSS0.Px3 \"In 2.5.3 Answer Extractor â£ 2.5 Answer Engineering â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n  4. [3 Beyond English Text Prompting](https://arxiv.org/html/2406.06608v1#Ch3 \"In The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    1. [3.1 Multilingual](https://arxiv.org/html/2406.06608v1#Ch3.S1 \"In 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [Translate First Prompting](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS0.SSS0.Px1 \"In 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [3.1.1 Chain-of-Thought (CoT)](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS1 \"In 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [XLT (Cross-Lingual Thought) Prompting](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS1.SSS0.Px1 \"In 3.1.1 Chain-of-Thought \\(CoT\\) â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [Cross-Lingual Self Consistent Prompting (CLSP)](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS1.SSS0.Px2 \"In 3.1.1 Chain-of-Thought \\(CoT\\) â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      3. [3.1.2 In-Context Learning](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS2 \"In 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [X-InSTA Prompting](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS2.SSS0.Px1 \"In 3.1.2 In-Context Learning â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [In-CLT (Cross-lingual Transfer) Prompting](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS2.SSS0.Px2 \"In 3.1.2 In-Context Learning â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      4. [3.1.3 In-Context Example Selection](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS3 \"In 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [PARC (Prompts Augmented by Retrieval Cross-lingually)](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS3.SSS0.Px1 \"In 3.1.3 In-Context Example Selection â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      5. [3.1.4 Prompt Template Language Selection](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS4 \"In 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [English Prompt Template](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS4.SSS0.Px1 \"In 3.1.4 Prompt Template Language Selection â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [Task Language Prompt Template](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS4.SSS0.Px2 \"In 3.1.4 Prompt Template Language Selection â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      6. [3.1.5 Prompting for Machine Translation](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS5 \"In 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [Multi-Aspect Prompting and Selection (MAPS)](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS5.SSS0.Px1 \"In 3.1.5 Prompting for Machine Translation â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [Chain-of-Dictionary (CoD)](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS5.SSS0.Px2 \"In 3.1.5 Prompting for Machine Translation â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        3. [Dictionary-based Prompting for Machine Translation (DiPMT)](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS5.SSS0.Px3 \"In 3.1.5 Prompting for Machine Translation â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        4. [Decomposed Prompting for MT (DecoMT)](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS5.SSS0.Px4 \"In 3.1.5 Prompting for Machine Translation â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        5. [3.1.5.1 Human-in-the-Loop](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS5.SSS1 \"In 3.1.5 Prompting for Machine Translation â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          1. [Interactive-Chain-Prompting (ICP)](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS5.SSS1.Px1 \"In 3.1.5.1 Human-in-the-Loop â£ 3.1.5 Prompting for Machine Translation â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          2. [Iterative Prompting](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS5.SSS1.Px2 \"In 3.1.5.1 Human-in-the-Loop â£ 3.1.5 Prompting for Machine Translation â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    2. [3.2 Multimodal](https://arxiv.org/html/2406.06608v1#Ch3.S2 \"In 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [3.2.1 Image Prompting](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS1 \"In 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [Prompt Modifiers](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS1.SSS0.Px1 \"In 3.2.1 Image Prompting â£ 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [Negative Prompting](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS1.SSS0.Px2 \"In 3.2.1 Image Prompting â£ 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        3. [3.2.1.1 Multimodal In-Context Learning](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS1.SSS1 \"In 3.2.1 Image Prompting â£ 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          1. [Paired-Image Prompting](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS1.SSS1.Px1 \"In 3.2.1.1 Multimodal In-Context Learning â£ 3.2.1 Image Prompting â£ 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          2. [Image-as-Text Prompting](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS1.SSS1.Px2 \"In 3.2.1.1 Multimodal In-Context Learning â£ 3.2.1 Image Prompting â£ 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        4. [3.2.1.2 Multimodal Chain-of-Thought](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS1.SSS2 \"In 3.2.1 Image Prompting â£ 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          1. [Duty Distinct Chain-of-Thought (DDCoT)](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS1.SSS2.Px1 \"In 3.2.1.2 Multimodal Chain-of-Thought â£ 3.2.1 Image Prompting â£ 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          2. [Multimodal Graph-of-Thought](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS1.SSS2.Px2 \"In 3.2.1.2 Multimodal Chain-of-Thought â£ 3.2.1 Image Prompting â£ 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          3. [Chain-of-Images (CoI)](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS1.SSS2.Px3 \"In 3.2.1.2 Multimodal Chain-of-Thought â£ 3.2.1 Image Prompting â£ 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [3.2.2 Audio Prompting](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS2 \"In 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      3. [3.2.3 Video Prompting](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS3 \"In 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [3.2.3.1 Video Generation Techniques](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS3.SSS1 \"In 3.2.3 Video Prompting â£ 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      4. [3.2.4 Segmentation Prompting](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS4 \"In 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      5. [3.2.5 3D Prompting](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS5 \"In 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n  5. [4 Extensions of Prompting](https://arxiv.org/html/2406.06608v1#Ch4 \"In The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    1. [4.1 Agents](https://arxiv.org/html/2406.06608v1#Ch4.S1 \"In 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [Definition of Agent](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS0.SSS0.Px1 \"In 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [4.1.1 Tool Use Agents](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS1 \"In 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [Modular Reasoning, Knowledge, and Language (MRKL) System](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS1.SSS0.Px1 \"In 4.1.1 Tool Use Agents â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [Self-Correcting with Tool-Interactive Critiquing (CRITIC)](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS1.SSS0.Px2 \"In 4.1.1 Tool Use Agents â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      3. [4.1.2 Code-Generation Agents](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS2 \"In 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [Program-aided Language Model (PAL)](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS2.SSS0.Px1 \"In 4.1.2 Code-Generation Agents â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [Tool-Integrated Reasoning Agent (ToRA)](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS2.SSS0.Px2 \"In 4.1.2 Code-Generation Agents â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        3. [TaskWeaver](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS2.SSS0.Px3 \"In 4.1.2 Code-Generation Agents â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      4. [4.1.3 Observation-Based Agents](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS3 \"In 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [Reasoning and Acting (ReAct)](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS3.SSS0.Px1 \"In 4.1.3 Observation-Based Agents â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [Reflexion](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS3.SSS0.Px2 \"In 4.1.3 Observation-Based Agents â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        3. [4.1.3.1 Lifelong Learning Agents](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS3.SSS1 \"In 4.1.3 Observation-Based Agents â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          1. [Voyager](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS3.SSS1.Px1 \"In 4.1.3.1 Lifelong Learning Agents â£ 4.1.3 Observation-Based Agents â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          2. [Ghost in the Minecraft (GITM)](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS3.SSS1.Px2 \"In 4.1.3.1 Lifelong Learning Agents â£ 4.1.3 Observation-Based Agents â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      5. [4.1.4 Retrieval Augmented Generation (RAG)](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS4 \"In 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [Verify-and-Edit](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS4.SSS0.Px1 \"In 4.1.4 Retrieval Augmented Generation \\(RAG\\) â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [Demonstrate-Search-Predict](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS4.SSS0.Px2 \"In 4.1.4 Retrieval Augmented Generation \\(RAG\\) â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        3. [Interleaved Retrieval guided by Chain-of-Thought (IRCoT)](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS4.SSS0.Px3 \"In 4.1.4 Retrieval Augmented Generation \\(RAG\\) â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        4. [Iterative Retrieval Augmentation](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS4.SSS0.Px4 \"In 4.1.4 Retrieval Augmented Generation \\(RAG\\) â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    2. [4.2 Evaluation](https://arxiv.org/html/2406.06608v1#Ch4.S2 \"In 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [4.2.1 Prompting Techniques](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS1 \"In 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [In-Context Learning](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS1.SSS0.Px1 \"In 4.2.1 Prompting Techniques â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [Role-based Evaluation](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS1.SSS0.Px2 \"In 4.2.1 Prompting Techniques â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        3. [Chain-of-Thought](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS1.SSS0.Px3 \"In 4.2.1 Prompting Techniques â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        4. [Model-Generated Guidelines](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS1.SSS0.Px4 \"In 4.2.1 Prompting Techniques â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [4.2.2 Output Format](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS2 \"In 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [Styling](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS2.SSS0.Px1 \"In 4.2.2 Output Format â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [Linear Scale](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS2.SSS0.Px2 \"In 4.2.2 Output Format â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        3. [Binary Score](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS2.SSS0.Px3 \"In 4.2.2 Output Format â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        4. [Likert Scale](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS2.SSS0.Px4 \"In 4.2.2 Output Format â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      3. [4.2.3 Prompting Frameworks](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS3 \"In 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [LLM-EVAL](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS3.SSS0.Px1 \"In 4.2.3 Prompting Frameworks â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [G-EVAL](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS3.SSS0.Px2 \"In 4.2.3 Prompting Frameworks â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        3. [ChatEval](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS3.SSS0.Px3 \"In 4.2.3 Prompting Frameworks â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      4. [4.2.4 Other Methodologies](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS4 \"In 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [Batch Prompting](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS4.SSS0.Px1 \"In 4.2.4 Other Methodologies â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [Pairwise Evaluation](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS4.SSS0.Px2 \"In 4.2.4 Other Methodologies â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n  6. [5 Prompting Issues](https://arxiv.org/html/2406.06608v1#Ch5 \"In The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    1. [5.1 Security](https://arxiv.org/html/2406.06608v1#Ch5.S1 \"In 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [5.1.1 Types of Prompt Hacking](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS1 \"In 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [Prompt Injection](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS1.SSS0.Px1 \"In 5.1.1 Types of Prompt Hacking â£ 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [Jailbreaking](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS1.SSS0.Px2 \"In 5.1.1 Types of Prompt Hacking â£ 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [5.1.2 Risks of Prompt Hacking](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS2 \"In 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [5.1.2.1 Data Privacy](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS2.SSS1 \"In 5.1.2 Risks of Prompt Hacking â£ 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          1. [Training Data Reconstruction](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS2.SSS1.Px1 \"In 5.1.2.1 Data Privacy â£ 5.1.2 Risks of Prompt Hacking â£ 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          2. [Prompt Leaking](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS2.SSS1.Px2 \"In 5.1.2.1 Data Privacy â£ 5.1.2 Risks of Prompt Hacking â£ 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [5.1.2.2 Code Generation Concerns](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS2.SSS2 \"In 5.1.2 Risks of Prompt Hacking â£ 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          1. [Package Hallucination](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS2.SSS2.Px1 \"In 5.1.2.2 Code Generation Concerns â£ 5.1.2 Risks of Prompt Hacking â£ 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          2. [Bugs](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS2.SSS2.Px2 \"In 5.1.2.2 Code Generation Concerns â£ 5.1.2 Risks of Prompt Hacking â£ 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        3. [5.1.2.3 Customer Service](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS2.SSS3 \"In 5.1.2 Risks of Prompt Hacking â£ 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      3. [5.1.3 Hardening Measures](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS3 \"In 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [Prompt-based Defenses](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS3.SSS0.Px1 \"In 5.1.3 Hardening Measures â£ 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [Guardrails](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS3.SSS0.Px2 \"In 5.1.3 Hardening Measures â£ 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        3. [Detectors](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS3.SSS0.Px3 \"In 5.1.3 Hardening Measures â£ 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    2. [5.2 Alignment](https://arxiv.org/html/2406.06608v1#Ch5.S2 \"In 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [5.2.1 Prompt Sensitivity](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS1 \"In 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [Prompt Wording](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS1.SSS0.Px1 \"In 5.2.1 Prompt Sensitivity â£ 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [Task Format](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS1.SSS0.Px2 \"In 5.2.1 Prompt Sensitivity â£ 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        3. [Prompt Drift](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS1.SSS0.Px3 \"In 5.2.1 Prompt Sensitivity â£ 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [5.2.2 Overconfidence and Calibration](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS2 \"In 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [Verbalized Score](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS2.SSS0.Px1 \"In 5.2.2 Overconfidence and Calibration â£ 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [Sycophancy](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS2.SSS0.Px2 \"In 5.2.2 Overconfidence and Calibration â£ 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      3. [5.2.3 Biases, Stereotypes, and Culture](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS3 \"In 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [Vanilla Prompting](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS3.SSS0.Px1 \"In 5.2.3 Biases, Stereotypes, and Culture â£ 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [Selecting Balanced Demonstrations](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS3.SSS0.Px2 \"In 5.2.3 Biases, Stereotypes, and Culture â£ 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        3. [Cultural Awareness](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS3.SSS0.Px3 \"In 5.2.3 Biases, Stereotypes, and Culture â£ 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        4. [AttrPrompt](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS3.SSS0.Px4 \"In 5.2.3 Biases, Stereotypes, and Culture â£ 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      4. [5.2.4 Ambiguity](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS4 \"In 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [Ambiguous Demonstrations](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS4.SSS0.Px1 \"In 5.2.4 Ambiguity â£ 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [Question Clarification](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS4.SSS0.Px2 \"In 5.2.4 Ambiguity â£ 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n  7. [6 Benchmarking](https://arxiv.org/html/2406.06608v1#Ch6 \"In The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    1. [6.1 Technique Benchmarking](https://arxiv.org/html/2406.06608v1#Ch6.S1 \"In 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [6.1.1 Comparing Prompting Techniques](https://arxiv.org/html/2406.06608v1#Ch6.S1.SS1 \"In 6.1 Technique Benchmarking â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [Zero-Shot](https://arxiv.org/html/2406.06608v1#Ch6.S1.SS1.SSS0.Px1 \"In 6.1.1 Comparing Prompting Techniques â£ 6.1 Technique Benchmarking â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [Zero-Shot-CoT Techniques](https://arxiv.org/html/2406.06608v1#Ch6.S1.SS1.SSS0.Px2 \"In 6.1.1 Comparing Prompting Techniques â£ 6.1 Technique Benchmarking â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        3. [Few-Shot Techniques](https://arxiv.org/html/2406.06608v1#Ch6.S1.SS1.SSS0.Px3 \"In 6.1.1 Comparing Prompting Techniques â£ 6.1 Technique Benchmarking â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [6.1.2 Question Formats](https://arxiv.org/html/2406.06608v1#Ch6.S1.SS2 \"In 6.1 Technique Benchmarking â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      3. [6.1.3 Self-Consistency](https://arxiv.org/html/2406.06608v1#Ch6.S1.SS3 \"In 6.1 Technique Benchmarking â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      4. [6.1.4 Evaluating Responses](https://arxiv.org/html/2406.06608v1#Ch6.S1.SS4 \"In 6.1 Technique Benchmarking â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      5. [6.1.5 Results](https://arxiv.org/html/2406.06608v1#Ch6.S1.SS5 \"In 6.1 Technique Benchmarking â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    2. [6.2 Prompt Engineering Case Study](https://arxiv.org/html/2406.06608v1#Ch6.S2 \"In 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [6.2.1 Problem](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS1 \"In 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [6.2.2 The Dataset](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS2 \"In 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      3. [6.2.3 The Process](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS3 \"In 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [6.2.3.1 Dataset Exploration (2 steps)](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS3.SSS1 \"In 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [6.2.3.2 Getting a Label (8 steps)](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS3.SSS2 \"In 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        3. [6.2.3.3 Prompting Techniques (32 steps)](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS3.SSS3 \"In 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          1. [Zero-Shot + Context](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS3.SSS3.Px1 \"In 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          2. [10-Shot + Context.](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS3.SSS3.Px2 \"In 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          3. [One-Shot AutoDiCot + Full Context.](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS3.SSS3.Px3 \"In 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          4. [Ablating Email.](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS3.SSS3.Px4 \"In 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          5. [10-Shot + 1 AutoDiCoT.](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS3.SSS3.Px5 \"In 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          6. [Full Context Only.](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS3.SSS3.Px6 \"In 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          7. [10-Shot AutoDiCoT.](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS3.SSS3.Px7 \"In 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          8. [20-Shot AutoDiCoT.](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS3.SSS3.Px8 \"In 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          9. [20-Shot AutoDiCoT + Full Words.](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS3.SSS3.Px9 \"In 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          10. [20-Shot AutoDiCoT + Full Words + Extraction Prompt.](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS3.SSS3.Px10 \"In 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          11. [10-Shot AutoDiCoT + Extraction Prompt.](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS3.SSS3.Px11 \"In 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          12. [10-Shot AutoDiCoT without Email.](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS3.SSS3.Px12 \"In 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          13. [De-Duplicating Email.](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS3.SSS3.Px13 \"In 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          14. [10-Shot AutoDiCoT + Default to Negative.](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS3.SSS3.Px14 \"In 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          15. [Ensemble + Extraction.](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS3.SSS3.Px15 \"In 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          16. [10-Shot AutoCoT + 3x the context (no email dupe).](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS3.SSS3.Px16 \"In 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          17. [Anonymize Email.](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS3.SSS3.Px17 \"In 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          18. [DSPy.](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS3.SSS3.Px18 \"In 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      4. [6.2.4 Discussion](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS4 \"In 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n  8. [7 Related Work](https://arxiv.org/html/2406.06608v1#Ch7 \"In The Prompt Report: A Systematic Survey of Prompting Techniques\")\n  9. [8 Conclusions](https://arxiv.org/html/2406.06608v1#Ch8 \"In The Prompt Report: A Systematic Survey of Prompting Techniques\")\n  10. [A Appendices](https://arxiv.org/html/2406.06608v1#A1 \"In The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    1. [A.1 Definitions of Prompting](https://arxiv.org/html/2406.06608v1#A1.S1 \"In Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    2. [A.2 Extended Vocabulary](https://arxiv.org/html/2406.06608v1#A1.S2 \"In Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [A.2.1 Prompting Terms](https://arxiv.org/html/2406.06608v1#A1.S2.SS1 \"In A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [Context Window](https://arxiv.org/html/2406.06608v1#A1.S2.SS1.SSS0.Px1 \"In A.2.1 Prompting Terms â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [Priming](https://arxiv.org/html/2406.06608v1#A1.S2.SS1.SSS0.Px2 \"In A.2.1 Prompting Terms â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [A.2.2 Prompt Engineering Terms](https://arxiv.org/html/2406.06608v1#A1.S2.SS2 \"In A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [Conversational Prompt Engineering](https://arxiv.org/html/2406.06608v1#A1.S2.SS2.SSS0.Px1 \"In A.2.2 Prompt Engineering Terms â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      3. [A.2.3 Fine-Tuning Terms](https://arxiv.org/html/2406.06608v1#A1.S2.SS3 \"In A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [Prompt-Based Learning](https://arxiv.org/html/2406.06608v1#A1.S2.SS3.SSS0.Px1 \"In A.2.3 Fine-Tuning Terms â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [Prompt Tuning](https://arxiv.org/html/2406.06608v1#A1.S2.SS3.SSS0.Px2 \"In A.2.3 Fine-Tuning Terms â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      4. [A.2.4 Orthogonal Prompt Types](https://arxiv.org/html/2406.06608v1#A1.S2.SS4 \"In A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [A.2.4.1 Originator](https://arxiv.org/html/2406.06608v1#A1.S2.SS4.SSS1 \"In A.2.4 Orthogonal Prompt Types â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          1. [User Prompt](https://arxiv.org/html/2406.06608v1#A1.S2.SS4.SSS1.Px1 \"In A.2.4.1 Originator â£ A.2.4 Orthogonal Prompt Types â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          2. [Assistant Prompt](https://arxiv.org/html/2406.06608v1#A1.S2.SS4.SSS1.Px2 \"In A.2.4.1 Originator â£ A.2.4 Orthogonal Prompt Types â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          3. [System Prompt](https://arxiv.org/html/2406.06608v1#A1.S2.SS4.SSS1.Px3 \"In A.2.4.1 Originator â£ A.2.4 Orthogonal Prompt Types â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [A.2.4.2 Hard vs Soft Prompts](https://arxiv.org/html/2406.06608v1#A1.S2.SS4.SSS2 \"In A.2.4 Orthogonal Prompt Types â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          1. [Hard (discrete) Prompt](https://arxiv.org/html/2406.06608v1#A1.S2.SS4.SSS2.Px1 \"In A.2.4.2 Hard vs Soft Prompts â£ A.2.4 Orthogonal Prompt Types â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          2. [Soft (continuous) Prompt](https://arxiv.org/html/2406.06608v1#A1.S2.SS4.SSS2.Px2 \"In A.2.4.2 Hard vs Soft Prompts â£ A.2.4 Orthogonal Prompt Types â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        3. [A.2.4.3 Prediction Styles](https://arxiv.org/html/2406.06608v1#A1.S2.SS4.SSS3 \"In A.2.4 Orthogonal Prompt Types â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          1. [Cloze](https://arxiv.org/html/2406.06608v1#A1.S2.SS4.SSS3.Px1 \"In A.2.4.3 Prediction Styles â£ A.2.4 Orthogonal Prompt Types â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n          2. [Prefix](https://arxiv.org/html/2406.06608v1#A1.S2.SS4.SSS3.Px2 \"In A.2.4.3 Prediction Styles â£ A.2.4 Orthogonal Prompt Types â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    3. [A.3 Datasheet](https://arxiv.org/html/2406.06608v1#A1.S3 \"In Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [A.3.1 Motivation](https://arxiv.org/html/2406.06608v1#A1.S3.SS1 \"In A.3 Datasheet â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [A.3.2 Composition](https://arxiv.org/html/2406.06608v1#A1.S3.SS2 \"In A.3 Datasheet â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      3. [A.3.3 Collection Process](https://arxiv.org/html/2406.06608v1#A1.S3.SS3 \"In A.3 Datasheet â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      4. [A.3.4 Preprocessing/ Cleaning/ Labeling](https://arxiv.org/html/2406.06608v1#A1.S3.SS4 \"In A.3 Datasheet â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      5. [A.3.5 Uses](https://arxiv.org/html/2406.06608v1#A1.S3.SS5 \"In A.3 Datasheet â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      6. [A.3.6 Distribution](https://arxiv.org/html/2406.06608v1#A1.S3.SS6 \"In A.3 Datasheet â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      7. [A.3.7 Maintenance](https://arxiv.org/html/2406.06608v1#A1.S3.SS7 \"In A.3 Datasheet â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    4. [A.4 Keywords](https://arxiv.org/html/2406.06608v1#A1.S4 \"In Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    5. [A.5 Evaluation Table](https://arxiv.org/html/2406.06608v1#A1.S5 \"In Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    6. [A.6 Entrapment Prompting Process](https://arxiv.org/html/2406.06608v1#A1.S6 \"In Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [A.6.1 Exploration](https://arxiv.org/html/2406.06608v1#A1.S6.SS1 \"In A.6 Entrapment Prompting Process â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [A.6.2 Getting a Label](https://arxiv.org/html/2406.06608v1#A1.S6.SS2 \"In A.6 Entrapment Prompting Process â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      3. [A.6.3 Varying Prompting Techniques](https://arxiv.org/html/2406.06608v1#A1.S6.SS3 \"In A.6 Entrapment Prompting Process â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        1. [A.6.3.1 AutoCoT](https://arxiv.org/html/2406.06608v1#A1.S6.SS3.SSS1 \"In A.6.3 Varying Prompting Techniques â£ A.6 Entrapment Prompting Process â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        2. [A.6.3.2 Developing Answer Extraction](https://arxiv.org/html/2406.06608v1#A1.S6.SS3.SSS2 \"In A.6.3 Varying Prompting Techniques â£ A.6 Entrapment Prompting Process â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n        3. [A.6.3.3 Iterating on Email](https://arxiv.org/html/2406.06608v1#A1.S6.SS3.SSS3 \"In A.6.3 Varying Prompting Techniques â£ A.6 Entrapment Prompting Process â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    7. [A.7 Formally Defining a Prompt](https://arxiv.org/html/2406.06608v1#A1.S7 \"In Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [As a conditioning Mechanism.](https://arxiv.org/html/2406.06608v1#A1.S7.SS0.SSS0.Px1 \"In A.7 Formally Defining a Prompt â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [Templating.](https://arxiv.org/html/2406.06608v1#A1.S7.SS0.SSS0.Px2 \"In A.7 Formally Defining a Prompt â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      3. [Few-Shot Prompting.](https://arxiv.org/html/2406.06608v1#A1.S7.SS0.SSS0.Px3 \"In A.7 Formally Defining a Prompt â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      4. [Optimization.](https://arxiv.org/html/2406.06608v1#A1.S7.SS0.SSS0.Px4 \"In A.7 Formally Defining a Prompt â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      5. [Other considerations.](https://arxiv.org/html/2406.06608v1#A1.S7.SS0.SSS0.Px5 \"In A.7 Formally Defining a Prompt â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    8. [A.8 In-Context Learning Definitions Disambiguation](https://arxiv.org/html/2406.06608v1#A1.S8 \"In Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    9. [A.9 Contributions](https://arxiv.org/html/2406.06608v1#A1.S9 \"In Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n  11. [ References  ](https://arxiv.org/html/2406.06608v1#bib \"References\")\n\n\nHTML conversions [sometimes display errors](https://info.dev.arxiv.org/about/accessibility_html_error_messages.html) due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.\n  * failed: algpseudocodex\n  * failed: multitoc\n  * failed: forest\n  * failed: quoting\n  * failed: nowidow\n  * failed: xltabular\n  * failed: forest\n  * failed: inconsolata\n\n\nAuthors: achieve the best HTML results from your LaTeX submissions by following these [best practices](https://info.arxiv.org/help/submit_latex_best_practices.html).\n[License: CC BY 4.0](https://info.arxiv.org/help/license/index.html#licenses-available)\narXiv:2406.06608v1 [cs.CL] 06 Jun 2024\n# The Prompt Report: A Systematic Survey of Prompting Techniques\nReport issue for preceding element\nSander Schulhoff1â Michael Ilie1â Nishant Balepur1 Konstantine Kahadze1 Amanda Liu1 Chenglei Si3 Yinheng Li4 Aayush Gupta1 HyoJung Han1 Sevien Schulhoff1 Pranav Sandeep Dulepet1 Saurav Vidyadhara1 Dayeon Ki1 Sweta Agrawal11 Chau Pham12 Gerson Kroiz Feileen Li1 Hudson Tao1 Ashay Srivastava1 Hevander Da Costa1 Saloni Gupta1 Megan L. Rogers7 Inna Goncearenco8 Giuseppe Sarli8,9 Igor Galynker10 Denis Peskoff6 Marine Carpuat1 Jules White5 Shyamal Anadkat2 Alexander Hoyle1 Philip Resnik1 1 University of Maryland 2 OpenAI 3 Stanford 4 Microsoft 5 Vanderbilt 6 Princeton 7 Texas State University 8 Icahn School of Medicine 9 ASST Brianza 10 Mount Sinai Beth Israel 11 Instituto de TelecomunicaÃ§Ãµes 12 University of Massachusetts Amherst sschulho@umd.edu milie@umd.edu resnik@umd.edu\nReport issue for preceding element\n(November 2023)\n###### Abstract\nReport issue for preceding element\nGenerative Artificial Intelligence (GenAI) systems are being increasingly deployed across all parts of industry and research settings. Developers and end users interact with these systems through the use of prompting or prompt engineering. While prompting is a widespread and highly researched concept, there exists conflicting terminology and a poor ontological understanding of what constitutes a prompt due to the areaâs nascency. This paper establishes a structured understanding of prompts, by assembling a taxonomy of prompting techniques and analyzing their use. We present a comprehensive vocabulary of 33 vocabulary terms, a taxonomy of 58 text-only prompting techniques, and 40 techniques for other modalities. We further present a meta-analysis of the entire literature on natural language prefix-prompting.\nReport issue for preceding element\n###### Contents\nReport issue for preceding element\n  1. [1 Introduction](https://arxiv.org/html/2406.06608v1#Ch1 \"In The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    1. [1.1 What is a Prompt?](https://arxiv.org/html/2406.06608v1#Ch1.S1 \"In 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    2. [1.2 Terminology](https://arxiv.org/html/2406.06608v1#Ch1.S2 \"In 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [1.2.1 Components of a Prompt](https://arxiv.org/html/2406.06608v1#Ch1.S2.SS1 \"In 1.2 Terminology â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [1.2.2 Prompting Terms](https://arxiv.org/html/2406.06608v1#Ch1.S2.SS2 \"In 1.2 Terminology â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    3. [1.3 A Short History of Prompts](https://arxiv.org/html/2406.06608v1#Ch1.S3 \"In 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n  2. [2 A Meta-Analysis of Prompting](https://arxiv.org/html/2406.06608v1#Ch2 \"In The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    1. [2.1 Systematic Review Process](https://arxiv.org/html/2406.06608v1#Ch2.S1 \"In 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [2.1.1 The Pipeline](https://arxiv.org/html/2406.06608v1#Ch2.S1.SS1 \"In 2.1 Systematic Review Process â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    2. [2.2 Text-Based Techniques](https://arxiv.org/html/2406.06608v1#Ch2.S2 \"In 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [2.2.1 In-Context Learning (ICL)](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS1 \"In 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [2.2.2 Zero-Shot](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS2 \"In 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      3. [2.2.3 Thought Generation](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3 \"In 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      4. [2.2.4 Decomposition](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS4 \"In 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      5. [2.2.5 Ensembling](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS5 \"In 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      6. [2.2.6 Self-Criticism](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS6 \"In 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    3. [2.3 Prompting Technique Usage](https://arxiv.org/html/2406.06608v1#Ch2.S3 \"In 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [2.3.1 Benchmarks](https://arxiv.org/html/2406.06608v1#Ch2.S3.SS1 \"In 2.3 Prompting Technique Usage â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    4. [2.4 Prompt Engineering](https://arxiv.org/html/2406.06608v1#Ch2.S4 \"In 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    5. [2.5 Answer Engineering](https://arxiv.org/html/2406.06608v1#Ch2.S5 \"In 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [2.5.1 Answer Shape](https://arxiv.org/html/2406.06608v1#Ch2.S5.SS1 \"In 2.5 Answer Engineering â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [2.5.2 Answer Space](https://arxiv.org/html/2406.06608v1#Ch2.S5.SS2 \"In 2.5 Answer Engineering â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      3. [2.5.3 Answer Extractor](https://arxiv.org/html/2406.06608v1#Ch2.S5.SS3 \"In 2.5 Answer Engineering â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n  3. [3 Beyond English Text Prompting](https://arxiv.org/html/2406.06608v1#Ch3 \"In The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    1. [3.1 Multilingual](https://arxiv.org/html/2406.06608v1#Ch3.S1 \"In 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [3.1.1 Chain-of-Thought (CoT)](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS1 \"In 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [3.1.2 In-Context Learning](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS2 \"In 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      3. [3.1.3 In-Context Example Selection](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS3 \"In 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      4. [3.1.4 Prompt Template Language Selection](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS4 \"In 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      5. [3.1.5 Prompting for Machine Translation](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS5 \"In 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    2. [3.2 Multimodal](https://arxiv.org/html/2406.06608v1#Ch3.S2 \"In 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [3.2.1 Image Prompting](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS1 \"In 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [3.2.2 Audio Prompting](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS2 \"In 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      3. [3.2.3 Video Prompting](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS3 \"In 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      4. [3.2.4 Segmentation Prompting](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS4 \"In 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      5. [3.2.5 3D Prompting](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS5 \"In 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n  4. [4 Extensions of Prompting](https://arxiv.org/html/2406.06608v1#Ch4 \"In The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    1. [4.1 Agents](https://arxiv.org/html/2406.06608v1#Ch4.S1 \"In 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [4.1.1 Tool Use Agents](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS1 \"In 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [4.1.2 Code-Generation Agents](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS2 \"In 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      3. [4.1.3 Observation-Based Agents](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS3 \"In 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      4. [4.1.4 Retrieval Augmented Generation (RAG)](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS4 \"In 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    2. [4.2 Evaluation](https://arxiv.org/html/2406.06608v1#Ch4.S2 \"In 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [4.2.1 Prompting Techniques](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS1 \"In 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [4.2.2 Output Format](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS2 \"In 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      3. [4.2.3 Prompting Frameworks](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS3 \"In 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      4. [4.2.4 Other Methodologies](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS4 \"In 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n  5. [5 Prompting Issues](https://arxiv.org/html/2406.06608v1#Ch5 \"In The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    1. [5.1 Security](https://arxiv.org/html/2406.06608v1#Ch5.S1 \"In 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [5.1.1 Types of Prompt Hacking](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS1 \"In 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [5.1.2 Risks of Prompt Hacking](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS2 \"In 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      3. [5.1.3 Hardening Measures](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS3 \"In 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    2. [5.2 Alignment](https://arxiv.org/html/2406.06608v1#Ch5.S2 \"In 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [5.2.1 Prompt Sensitivity](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS1 \"In 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [5.2.2 Overconfidence and Calibration](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS2 \"In 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      3. [5.2.3 Biases, Stereotypes, and Culture](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS3 \"In 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      4. [5.2.4 Ambiguity](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS4 \"In 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n  6. [6 Benchmarking](https://arxiv.org/html/2406.06608v1#Ch6 \"In The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    1. [6.1 Technique Benchmarking](https://arxiv.org/html/2406.06608v1#Ch6.S1 \"In 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [6.1.1 Comparing Prompting Techniques](https://arxiv.org/html/2406.06608v1#Ch6.S1.SS1 \"In 6.1 Technique Benchmarking â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [6.1.2 Question Formats](https://arxiv.org/html/2406.06608v1#Ch6.S1.SS2 \"In 6.1 Technique Benchmarking â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      3. [6.1.3 Self-Consistency](https://arxiv.org/html/2406.06608v1#Ch6.S1.SS3 \"In 6.1 Technique Benchmarking â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      4. [6.1.4 Evaluating Responses](https://arxiv.org/html/2406.06608v1#Ch6.S1.SS4 \"In 6.1 Technique Benchmarking â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      5. [6.1.5 Results](https://arxiv.org/html/2406.06608v1#Ch6.S1.SS5 \"In 6.1 Technique Benchmarking â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    2. [6.2 Prompt Engineering Case Study](https://arxiv.org/html/2406.06608v1#Ch6.S2 \"In 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [6.2.1 Problem](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS1 \"In 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [6.2.2 The Dataset](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS2 \"In 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      3. [6.2.3 The Process](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS3 \"In 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      4. [6.2.4 Discussion](https://arxiv.org/html/2406.06608v1#Ch6.S2.SS4 \"In 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n  7. [7 Related Work](https://arxiv.org/html/2406.06608v1#Ch7 \"In The Prompt Report: A Systematic Survey of Prompting Techniques\")\n  8. [8 Conclusions](https://arxiv.org/html/2406.06608v1#Ch8 \"In The Prompt Report: A Systematic Survey of Prompting Techniques\")\n  9. [A Appendices](https://arxiv.org/html/2406.06608v1#A1 \"In The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    1. [A.1 Definitions of Prompting](https://arxiv.org/html/2406.06608v1#A1.S1 \"In Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    2. [A.2 Extended Vocabulary](https://arxiv.org/html/2406.06608v1#A1.S2 \"In Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [A.2.1 Prompting Terms](https://arxiv.org/html/2406.06608v1#A1.S2.SS1 \"In A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [A.2.2 Prompt Engineering Terms](https://arxiv.org/html/2406.06608v1#A1.S2.SS2 \"In A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      3. [A.2.3 Fine-Tuning Terms](https://arxiv.org/html/2406.06608v1#A1.S2.SS3 \"In A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      4. [A.2.4 Orthogonal Prompt Types](https://arxiv.org/html/2406.06608v1#A1.S2.SS4 \"In A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    3. [A.3 Datasheet](https://arxiv.org/html/2406.06608v1#A1.S3 \"In Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [A.3.1 Motivation](https://arxiv.org/html/2406.06608v1#A1.S3.SS1 \"In A.3 Datasheet â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [A.3.2 Composition](https://arxiv.org/html/2406.06608v1#A1.S3.SS2 \"In A.3 Datasheet â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      3. [A.3.3 Collection Process](https://arxiv.org/html/2406.06608v1#A1.S3.SS3 \"In A.3 Datasheet â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      4. [A.3.4 Preprocessing/ Cleaning/ Labeling](https://arxiv.org/html/2406.06608v1#A1.S3.SS4 \"In A.3 Datasheet â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      5. [A.3.5 Uses](https://arxiv.org/html/2406.06608v1#A1.S3.SS5 \"In A.3 Datasheet â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      6. [A.3.6 Distribution](https://arxiv.org/html/2406.06608v1#A1.S3.SS6 \"In A.3 Datasheet â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      7. [A.3.7 Maintenance](https://arxiv.org/html/2406.06608v1#A1.S3.SS7 \"In A.3 Datasheet â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    4. [A.4 Keywords](https://arxiv.org/html/2406.06608v1#A1.S4 \"In Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    5. [A.5 Evaluation Table](https://arxiv.org/html/2406.06608v1#A1.S5 \"In Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    6. [A.6 Entrapment Prompting Process](https://arxiv.org/html/2406.06608v1#A1.S6 \"In Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      1. [A.6.1 Exploration](https://arxiv.org/html/2406.06608v1#A1.S6.SS1 \"In A.6 Entrapment Prompting Process â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      2. [A.6.2 Getting a Label](https://arxiv.org/html/2406.06608v1#A1.S6.SS2 \"In A.6 Entrapment Prompting Process â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n      3. [A.6.3 Varying Prompting Techniques](https://arxiv.org/html/2406.06608v1#A1.S6.SS3 \"In A.6 Entrapment Prompting Process â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    7. [A.7 Formally Defining a Prompt](https://arxiv.org/html/2406.06608v1#A1.S7 \"In Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    8. [A.8 In-Context Learning Definitions Disambiguation](https://arxiv.org/html/2406.06608v1#A1.S8 \"In Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n    9. [A.9 Contributions](https://arxiv.org/html/2406.06608v1#A1.S9 \"In Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")\n\n\n## 1 Introduction\nReport issue for preceding element\nTransformer-based LLMs are widely deployed in consumer-facing, internal, and research settings Bommasani et al. ([2021](https://arxiv.org/html/2406.06608v1#bib.bib18)). Typically, these models rely on the user providing an input âpromptâ to which the model produces an output in response. Such prompts may be textualââWrite a poem about trees.ââor take other forms: images, audio, videos, or a combination thereof. The ability to prompt models, particularly prompting with natural language, makes them easy to interact with and use flexibly across a wide range of use cases.\nReport issue for preceding element\nKnowing how to effectively structure, evaluate, and perform other tasks with prompts is essential to using these models. Empirically, better prompts lead to improved results across a wide range of tasks Wei et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib299)); Liu et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib159)); Schulhoff ([2022](https://arxiv.org/html/2406.06608v1#bib.bib248)). A large body of literature has grown around the use of prompting to improve results and the number of prompting techniques is rapidly increasing.\nReport issue for preceding element\nHowever, as prompting is an emerging field, the use of prompts continues to be poorly understood, with only a fraction of existing terminologies and techniques being well-known among practitioners. We perform a large-scale review of prompting techniques to create a robust resource of terminology and techniques in the field. We expect this to be the first iteration of terminologies that will develop over time.\nReport issue for preceding element\n###### Scope of Study\nReport issue for preceding element\nWe create a broad directory of prompting techniques, which can be quickly understood and easily implemented for rapid experimentation by developers and researchers. To this end, we limit our study to focus on discrete prefix prompts Shin et al. ([2020a](https://arxiv.org/html/2406.06608v1#bib.bib259)) rather than cloze prompts Petroni et al. ([2019](https://arxiv.org/html/2406.06608v1#bib.bib212)); Cui et al. ([2021](https://arxiv.org/html/2406.06608v1#bib.bib42)), because modern LLM architectures (especially decoder-only models), which use prefix prompts, are widely used and have robust support for both consumers and researchers. Additionally, we refined our focus to hard (discrete) prompts rather than soft (continuous) prompts and leave out papers that make use of techniques using gradient-based updates (i.e. fine-tuning). Finally, we only study task-agnostic techniques. These decisions keep the work approachable to less technical readers and maintain a manageable scope.\nReport issue for preceding element\n###### Sections Overview\nReport issue for preceding element\nWe conducted a machine-assisted systematic review grounded in the PRISMA process Page et al. ([2021](https://arxiv.org/html/2406.06608v1#bib.bib199)) (Section [2.1](https://arxiv.org/html/2406.06608v1#Ch2.S1 \"2.1 Systematic Review Process â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")) to identify 58 different text-based prompting techniques, from which we create a taxonomy with a robust terminology of prompting terms (Section [1.2](https://arxiv.org/html/2406.06608v1#Ch1.S2 \"1.2 Terminology â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")).\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/x1.png) Figure 1.1: Categories within the field of prompting are interconnected. We discuss 7 core categories that are well described by the papers within our scope. Report issue for preceding element\nWhile much literature on prompting focuses on English-only settings, we also discuss multilingual techniques (Section [3.1](https://arxiv.org/html/2406.06608v1#Ch3.S1 \"3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")). Given the rapid growth in multimodal prompting, where prompts may include media such as images, we also expand our scope to multimodal techniques (Section [3.2](https://arxiv.org/html/2406.06608v1#Ch3.S2 \"3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")). Many multilingual and multimodal prompting techniques are direct extensions of English text-only prompting techniques.\nReport issue for preceding element\nAs prompting techniques grow more complex, they have begun to incorporate external tools, such as Internet browsing and calculators. We use the term âagentsâ to describe these types of prompting techniques (Section [4.1](https://arxiv.org/html/2406.06608v1#Ch4.S1 \"4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")).\nReport issue for preceding element\nIt is important to understand how to evaluate the outputs of agents and prompting techniques to ensure accuracy and avoid hallucinations. Thus, we discuss ways of evaluating these outputs (Section [4.2](https://arxiv.org/html/2406.06608v1#Ch4.S2 \"4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")). We also discuss security (Section [5.1](https://arxiv.org/html/2406.06608v1#Ch5.S1 \"5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")) and safety measures (Section [5.2](https://arxiv.org/html/2406.06608v1#Ch5.S2 \"5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")) for designing prompts that reduce the risk of harm to companies and users.\nReport issue for preceding element\nFinally, we apply prompting techniques in two case studies (Section [6.1](https://arxiv.org/html/2406.06608v1#Ch6.S1 \"6.1 Technique Benchmarking â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")). In the first, we test a range of prompting techniques against the commonly used benchmark MMLU Hendrycks et al. ([2021](https://arxiv.org/html/2406.06608v1#bib.bib89)). In the second, we explore in detail an example of manual prompt engineering on a significant, real-world use case, identifying signals of frantic hopelessnessâa top indicator of suicidal crisisâin the text of individuals seeking support Schuck et al. ([2019a](https://arxiv.org/html/2406.06608v1#bib.bib246)). We conclude with a discussion of the nature of prompting and its recent development (Section [8](https://arxiv.org/html/2406.06608v1#Ch8 \"8 Conclusions â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")).\nReport issue for preceding element\n###  1.1 What is a Prompt?\nReport issue for preceding element\nA prompt is an input to a Generative AI model, that is used to guide its output MeskÃ³ ([2023](https://arxiv.org/html/2406.06608v1#bib.bib181)); White et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib305)); Heston and Khun ([2023](https://arxiv.org/html/2406.06608v1#bib.bib92)); Hadi et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib83)); Brown et al. ([2020](https://arxiv.org/html/2406.06608v1#bib.bib22)). Prompts may consist of text, image, sound, or other media. Some examples of prompts include: âwrite a three paragraph email for a marketing campaign for an accounting firmâ, a photograph of a table accompanied by the text âdescribe everything on the tableâ, or a recording of an online meeting, with the instructions âsummarize thisâ.\nReport issue for preceding element\n###### Prompt Template\nReport issue for preceding element\nPrompts are often constructed via a prompt template Shin et al. ([2020b](https://arxiv.org/html/2406.06608v1#bib.bib260)). A prompt template is a function that contains one or more variables which will be replaced by some media (usually text) to create a prompt. This prompt can then be considered to be an instance of the template.\nReport issue for preceding element\nConsider applying prompting to the task of binary classification of tweets. Here is an initial prompt template that can be used to classify inputs.\nReport issue for preceding element\nClassify the tweet as positive or negative: {TWEET} Report issue for preceding element\nEach tweet in the dataset would be inserted into a separate instance of the template and the resulting prompt would be given to a LLM for inference.\nReport issue for preceding element\nWrite a poem about trees. Report issue for preceding element\nWrite a poem about the following topic: {USER_INPUT} Report issue for preceding element\nFigure 1.2: Prompts and prompt templates are distinct concepts; a prompt template becomes a prompt when input is inserted into it. Report issue for preceding element\n###  1.2 Terminology\nReport issue for preceding element\n{forest}\nfor tree= grow=east, reversed=true, anchor=base west, parent anchor=east, child anchor=west, base=left, font=, rectangle, draw=black, rounded corners, align=left, minimum width=2em, edge+=darkgray, line width=1pt, s sep=1pt, inner xsep=1pt, inner ysep=2pt, line width=0.8pt, ver/.append style=rotate=90, child anchor=north, parent anchor=south, anchor=center, text width=7em, , [Prompt [1.1](https://arxiv.org/html/2406.06608v1#Ch1.S1 \"1.1 What is a Prompt? â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), text width=3em , fill=teal!50 [Prompting [1.2.2](https://arxiv.org/html/2406.06608v1#Ch1.S2.SS2.SSS0.Px1 \"Prompting â£ 1.2.2 Prompting Terms â£ 1.2 Terminology â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!50 [Context [1.2.1](https://arxiv.org/html/2406.06608v1#Ch1.S2.SS1.SSS0.Px6 \"Additional Information â£ 1.2.1 Components of a Prompt â£ 1.2 Terminology â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!40] [Context Window [A.2.1](https://arxiv.org/html/2406.06608v1#A1.S2.SS1.SSS0.Px1 \"Context Window â£ A.2.1 Prompting Terms â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!40] [Priming [A.2.1](https://arxiv.org/html/2406.06608v1#A1.S2.SS1.SSS0.Px2 \"Priming â£ A.2.1 Prompting Terms â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!40] [Prompting Technique [1.2.2](https://arxiv.org/html/2406.06608v1#Ch1.S2.SS2.SSS0.Px3 \"Prompting Technique â£ 1.2.2 Prompting Terms â£ 1.2 Terminology â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!40 [In-Context Learning [2.2.1](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS1 \"2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!30 [Few-Shot Prompt [2.2.1](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS1.SSS0.Px1 \"Few-Shot Prompting â£ 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!20] [Exemplar [1.2.2](https://arxiv.org/html/2406.06608v1#Ch1.S2.SS2.SSS0.Px6 \"Exemplar â£ 1.2.2 Prompting Terms â£ 1.2 Terminology â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!20] ] [Zero-Shot Prompt [2.2.2](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS2 \"2.2.2 Zero-Shot â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!30] ] [Orthogonal Prompt Types [A.2.4](https://arxiv.org/html/2406.06608v1#A1.S2.SS4 \"A.2.4 Orthogonal Prompt Types â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!40 [ Density [A.2.4.2](https://arxiv.org/html/2406.06608v1#A1.S2.SS4.SSS2 \"A.2.4.2 Hard vs Soft Prompts â£ A.2.4 Orthogonal Prompt Types â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!30 [Continuous Prompt [A.2.4.2](https://arxiv.org/html/2406.06608v1#A1.S2.SS4.SSS2.Px2 \"Soft \\(continuous\\) Prompt â£ A.2.4.2 Hard vs Soft Prompts â£ A.2.4 Orthogonal Prompt Types â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!20] [Discrete Prompt [A.2.4.2](https://arxiv.org/html/2406.06608v1#A1.S2.SS4.SSS2.Px1 \"Hard \\(discrete\\) Prompt â£ A.2.4.2 Hard vs Soft Prompts â£ A.2.4 Orthogonal Prompt Types â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!20] ] [ Originator [A.2.4.1](https://arxiv.org/html/2406.06608v1#A1.S2.SS4.SSS1 \"A.2.4.1 Originator â£ A.2.4 Orthogonal Prompt Types â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!30 [User Prompt [A.2.4.1](https://arxiv.org/html/2406.06608v1#A1.S2.SS4.SSS1.Px1 \"User Prompt â£ A.2.4.1 Originator â£ A.2.4 Orthogonal Prompt Types â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!20] [System Prompt [A.2.4.1](https://arxiv.org/html/2406.06608v1#A1.S2.SS4.SSS1.Px3 \"System Prompt â£ A.2.4.1 Originator â£ A.2.4 Orthogonal Prompt Types â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!20] [Assistant Prompt [A.2.4.1](https://arxiv.org/html/2406.06608v1#A1.S2.SS4.SSS1.Px2 \"Assistant Prompt â£ A.2.4.1 Originator â£ A.2.4 Orthogonal Prompt Types â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!20] ] [ Prediction Style [A.2.4.3](https://arxiv.org/html/2406.06608v1#A1.S2.SS4.SSS3 \"A.2.4.3 Prediction Styles â£ A.2.4 Orthogonal Prompt Types â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!30 [Prefix [A.2.4.3](https://arxiv.org/html/2406.06608v1#A1.S2.SS4.SSS3.Px2 \"Prefix â£ A.2.4.3 Prediction Styles â£ A.2.4 Orthogonal Prompt Types â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!20] [Cloze [A.2.4.3](https://arxiv.org/html/2406.06608v1#A1.S2.SS4.SSS3.Px1 \"Cloze â£ A.2.4.3 Prediction Styles â£ A.2.4 Orthogonal Prompt Types â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!20] ] ] [ Prompt Chain [1.2.2](https://arxiv.org/html/2406.06608v1#Ch1.S2.SS2.SSS0.Px2 \"Prompt Chain â£ 1.2.2 Prompting Terms â£ 1.2 Terminology â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!40 ] ] [Prompt Template [1.1](https://arxiv.org/html/2406.06608v1#Ch1.S1.SS0.SSS0.Px1 \"Prompt Template â£ 1.1 What is a Prompt? â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!50] [ Prompt Engineering [1.2.2](https://arxiv.org/html/2406.06608v1#Ch1.S2.SS2.SSS0.Px4 \"Prompt Engineering â£ 1.2.2 Prompting Terms â£ 1.2 Terminology â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!50 [ Prompt Engineering Technique [1.2.2](https://arxiv.org/html/2406.06608v1#Ch1.S2.SS2.SSS0.Px5 \"Prompt Engineering Technique â£ 1.2.2 Prompting Terms â£ 1.2 Terminology â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!40 ] [ Meta-Prompting [2.4](https://arxiv.org/html/2406.06608v1#Ch2.S4.SS0.SSS0.Px1 \"Meta Prompting â£ 2.4 Prompt Engineering â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!40 ] [ Answer Engineering [2.5](https://arxiv.org/html/2406.06608v1#Ch2.S5 \"2.5 Answer Engineering â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!40 [Verbalizer [2.5.3](https://arxiv.org/html/2406.06608v1#Ch2.S5.SS3.SSS0.Px1 \"Verbalizer â£ 2.5.3 Answer Extractor â£ 2.5 Answer Engineering â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!30] [Extractor [2.5.3](https://arxiv.org/html/2406.06608v1#Ch2.S5.SS3 \"2.5.3 Answer Extractor â£ 2.5 Answer Engineering â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!30] ] [Conversational Prompt Engineering [A.2.2](https://arxiv.org/html/2406.06608v1#A1.S2.SS2.SSS0.Px1 \"Conversational Prompt Engineering â£ A.2.2 Prompt Engineering Terms â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!30] ] [ Fine-Tuning [A.2.3](https://arxiv.org/html/2406.06608v1#A1.S2.SS3 \"A.2.3 Fine-Tuning Terms â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=orange!50 [Prompt-Based Learning [A.2.3](https://arxiv.org/html/2406.06608v1#A1.S2.SS3.SSS0.Px1 \"Prompt-Based Learning â£ A.2.3 Fine-Tuning Terms â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=orange!40] [Prompt Tuning [A.2.3](https://arxiv.org/html/2406.06608v1#A1.S2.SS3.SSS0.Px2 \"Prompt Tuning â£ A.2.3 Fine-Tuning Terms â£ A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=orange!40] ] ] .\nReport issue for preceding element\nFigure 1.3: A Terminology of prompting. Terms with links to the appendix are not sufficiently critical to describe in the main paper, but are important to the field of prompting. Prompting techniques are shown in Figure [2.2](https://arxiv.org/html/2406.06608v1#Ch2.F2 \"Figure 2.2 â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\") Report issue for preceding element\n####  1.2.1 Components of a Prompt\nReport issue for preceding element\nThere are a variety of common components included in a prompt. We summarize the most commonly used components and discuss how they fit into prompts.\nReport issue for preceding element\n###### Directive\nReport issue for preceding element\nMany prompts issue a directive in the form of an instruction or question.111âDirectivesâ, from Searle ([1969](https://arxiv.org/html/2406.06608v1#bib.bib254)), are a type of speech act intended to encourage an action, and have been invoked in models of human-computer dialogue Morelli et al. ([1991](https://arxiv.org/html/2406.06608v1#bib.bib186)). This is the core intent of the prompt, sometimes simply called the \"intent\". For example, here is an example of a prompt with a single instruction:\nReport issue for preceding element\nTell me five good books to read. Report issue for preceding element\nDirectives can also be implicit, as in this one-shot case, where the directive is the perform English to Spanish translation:\nReport issue for preceding element\nNight: Noche Morning: Report issue for preceding element\n###### Examples\nReport issue for preceding element\nExamples, also known as exemplars or shots, act as demonstrations that guide the GenAI to accomplish a task. The above prompt is a One-Shot (i.e. one example) prompt.\nReport issue for preceding element\n###### Output Formatting\nReport issue for preceding element\nIt is often desirable for the GenAI to output information in certain formats, for example, CSVs or markdown formats Xia et al. ([2024](https://arxiv.org/html/2406.06608v1#bib.bib314)). To facilitate this, you can simply add instructions to do so as seen below:\nReport issue for preceding element\n{PARAGRAPH} Summarize this into a CSV. Report issue for preceding element\n###### Style Instructions\nReport issue for preceding element\nStyle instructions are a type of output formatting used to modify the output stylistically rather than structurally (Section [2.2.2](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS2.SSS0.Px2 \"Style Prompting â£ 2.2.2 Zero-Shot â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")). For example:\nReport issue for preceding element\nWrite a clear and curt paragraph about llamas. Report issue for preceding element\n###### Role\nReport issue for preceding element\nA Role, also known as a persona Schmidt et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib245)); Wang et al. ([2023l](https://arxiv.org/html/2406.06608v1#bib.bib298)), is a frequently discussed component that can improve writing and style text (Section [2.2.2](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS2.SSS0.Px1 \"Role Prompting â£ 2.2.2 Zero-Shot â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")). For example:\nReport issue for preceding element\nPretend you are a shepherd and write a limerick about llamas. Report issue for preceding element\n###### Additional Information\nReport issue for preceding element\nIt is often necessary to include additional information in the prompt. For example, if the directive is to write an email, you might include information such as your name and position so the GenAI can properly sign the email. Additional Information is sometimes called âcontextâ, though we discourage the use of this term as it is overloaded with other meanings in the prompting space222e.g. the context is the tokens processed by the LLM in a forward pass.\nReport issue for preceding element\n####  1.2.2 Prompting Terms\nReport issue for preceding element\nTerminology within the prompting literature is rapidly developing. As it stands, there are many poorly understood definitions (e.g. prompt, prompt engineering) and conflicting ones (e.g. role prompt vs persona prompt). The lack of a consistent vocabulary hampers the communityâs ability to clearly describe the various prompting techniques in use. We provide a robust vocabulary of terms used in the prompting community (Figure [1.3](https://arxiv.org/html/2406.06608v1#Ch1.F3 \"Figure 1.3 â£ 1.2 Terminology â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")).333By robust, we mean that it covers most existing commonly used terms in the field. Less frequent terms are left to Appendix [A.2](https://arxiv.org/html/2406.06608v1#A1.S2 \"A.2 Extended Vocabulary â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"). In order to accurately define frequently-used terms like prompt and prompt engineering, we integrate many definitions (Appendix [A.1](https://arxiv.org/html/2406.06608v1#A1.S1 \"A.1 Definitions of Prompting â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")) to derive representative definitions.\nReport issue for preceding element\n###### Prompting\nReport issue for preceding element\nPrompting is the process of providing a prompt to a GenAI, which then generates a response. For example, the action of sending a chunk of text or uploading an image constitutes prompting.\nReport issue for preceding element\n###### Prompt Chain\nReport issue for preceding element\nA prompt chain (activity: prompt chaining) consists of two or more prompt templates used in succession. The output of the prompt generated by the first prompt template is used to parameterize the second template, continuing until all templates are exhausted Wu et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib312)).\nReport issue for preceding element\n###### Prompting Technique\nReport issue for preceding element\nA prompting technique is a blueprint that describes how to structure a prompt, prompts, or dynamic sequencing of multiple prompts. A prompting technique may incorporate conditional or branching logic, parallelism, or other architectural considerations spanning multiple prompts.\nReport issue for preceding element\n###### Prompt Engineering\nReport issue for preceding element\nPrompt engineering is the iterative process of developing a prompt by modifying or changing the prompting technique that you are using (Figure [1.4](https://arxiv.org/html/2406.06608v1#Ch1.F4 \"Figure 1.4 â£ Prompt Engineering â£ 1.2.2 Prompting Terms â£ 1.2 Terminology â£ 1 Introduction â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")).\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/x2.png) Figure 1.4: The Prompt Engineering Process consists of three repeated steps 1) performing inference on a dataset 2) evaluating performance and 3) modifying the prompt template. Note that the extractor is used to extract a final response from the LLM output (e.g. \"This phrase is positive\" ââ\\rightarrowâ \"positive\"). See more information on extractors in Section [2.5](https://arxiv.org/html/2406.06608v1#Ch2.S5 \"2.5 Answer Engineering â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"). Report issue for preceding element\n###### Prompt Engineering Technique\nReport issue for preceding element\nA prompt engineering technique is a strategy for iterating on a prompt to improve it. In literature, this will often be automated techniques Deng et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib45)), but in consumer settings, users often perform prompt engineering manually.\nReport issue for preceding element\n###### Exemplar\nReport issue for preceding element\nExemplars are examples of a task being completed that are shown to a model in a prompt Brown et al. ([2020](https://arxiv.org/html/2406.06608v1#bib.bib22)).\nReport issue for preceding element\n###  1.3 A Short History of Prompts\nReport issue for preceding element\nThe idea of using natural language prefixes, or prompts, to elicit language model behaviors and responses originated before the GPT-3 and ChatGPT era. GPT-2 Radford et al. ([2019a](https://arxiv.org/html/2406.06608v1#bib.bib228)) makes use of prompts and they appear to be first used in the context of Generative AI by Fan et al. ([2018](https://arxiv.org/html/2406.06608v1#bib.bib54)). However, the concept of prompts was preceded by related concepts such as control codes Pfaff ([1979](https://arxiv.org/html/2406.06608v1#bib.bib214)); Poplack ([1980](https://arxiv.org/html/2406.06608v1#bib.bib217)); Keskar et al. ([2019](https://arxiv.org/html/2406.06608v1#bib.bib112)) and writing prompts Fan et al. ([2018](https://arxiv.org/html/2406.06608v1#bib.bib54)).\nReport issue for preceding element\nThe term Prompt Engineering appears to have come into existence more recently from Radford et al. ([2021](https://arxiv.org/html/2406.06608v1#bib.bib227)) then slightly later Reynolds and McDonell ([2021](https://arxiv.org/html/2406.06608v1#bib.bib233)).\nReport issue for preceding element\nHowever, various papers perform prompt engineering process without naming the term Wallace et al. ([2019](https://arxiv.org/html/2406.06608v1#bib.bib282)); Shin et al. ([2020a](https://arxiv.org/html/2406.06608v1#bib.bib259)), including Schick and SchÃ¼tze ([2020a](https://arxiv.org/html/2406.06608v1#bib.bib242), [b](https://arxiv.org/html/2406.06608v1#bib.bib243)); Gao et al. ([2021](https://arxiv.org/html/2406.06608v1#bib.bib67)) for non-autoregressive language models.\nReport issue for preceding element\nSome of the first works on prompting define a prompt slightly differently to how it is currently used. For example, consider the following prompt from Brown et al. ([2020](https://arxiv.org/html/2406.06608v1#bib.bib22)):\nReport issue for preceding element\nTranslate English to French: llama Report issue for preceding element\nBrown et al. ([2020](https://arxiv.org/html/2406.06608v1#bib.bib22)) consider the word \"llama\" to be the prompt, while \"Translate English to French:\" is the \"task description\". More recent papers, including this one, refer to the entire string passed to the LLM as the prompt.\nReport issue for preceding element\n## 2 A Meta-Analysis of Prompting\nReport issue for preceding element\n###  2.1 Systematic Review Process\nReport issue for preceding element\nIn order to robustly collect a dataset of sources for this paper, we ran a systematic literature review grounded in the PRISMA process Page et al. ([2021](https://arxiv.org/html/2406.06608v1#bib.bib199)) (Figure [2.1](https://arxiv.org/html/2406.06608v1#Ch2.F1 \"Figure 2.1 â£ 2.1.1 The Pipeline â£ 2.1 Systematic Review Process â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")). We host this dataset on [HuggingFace](https://huggingface.co/datasets/PromptSystematicReview/Prompt_Systematic_Review_Dataset) and present a datasheet Gebru et al. ([2021](https://arxiv.org/html/2406.06608v1#bib.bib71)) for the dataset in Appendix [A.3](https://arxiv.org/html/2406.06608v1#A1.S3 \"A.3 Datasheet â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"). Our main data sources were [arXiv](https://arxiv.org/), [Semantic Scholar](https://semanticscholar.com/), and [ACL](https://aclanthology.org). We query these databases with a list of 44 keywords narrowly related to prompting and prompt engineering (Appendix [A.4](https://arxiv.org/html/2406.06608v1#A1.S4 \"A.4 Keywords â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")).\nReport issue for preceding element\n####  2.1.1 The Pipeline\nReport issue for preceding element\nIn this section, we introduce our data scraping pipeline, which includes both human and LLM-assisted review.444Using GPT-4-1106-preview As an initial sample to establish filtering critera, we retrieve papers from arXiv based on a simple set of keywords and boolean rules ([A.4](https://arxiv.org/html/2406.06608v1#A1.S4 \"A.4 Keywords â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")). Then, human annotators label a sample of 1,661 articles from the arXiv set for the following criteria:\nReport issue for preceding element\n  1. 1.\nDoes the paper propose a novel prompting technique? (include)\nReport issue for preceding element\n  2. 2.\nDoes the paper strictly cover hard prefix prompts? (include)\nReport issue for preceding element\n  3. 3.\nDoes the paper focus on training by backpropagating gradients? (exclude)\nReport issue for preceding element\n  4. 4.\nFor non-text modalities, does it use a masked frame and/or window? (include)\nReport issue for preceding element\n\n\nA set of 300 articles are reviewed independently by two annotators, with 92% agreement (Krippendorffâs Î±ð¼\\alphaitalic_Î± = Cohenâs Îºð\\kappaitalic_Îº = 81%). Next, we develop a prompt using GPT-4-1106-preview to classify the remaining articles. We validate the prompt against 100 ground-truth annotations, achieving 89% precision and 75% recall (for an Fâ¢1ð¹1F1italic_F 1 of 81%). The combined human and LLM annotations generate a final set of 1,565 papers.\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/x3.png) Figure 2.1: The PRISMA review process. We accumulate 4,247 unique records from which we extract 1,565 relevant records. Report issue for preceding element\n###  2.2 Text-Based Techniques\nReport issue for preceding element\nWe now present a comprehensive taxonomical ontology of 58 text-based prompting techniques, broken into 6 major categories (Figure [2.2](https://arxiv.org/html/2406.06608v1#Ch2.F2 \"Figure 2.2 â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")). Although some of the techniques might fit into multiple categories, we place them in a single category of most relevance.\nReport issue for preceding element\n{forest}\nfor tree= grow=east, reversed=true, anchor=base west, parent anchor=east, child anchor=west, base=left, font=, rectangle, draw=black, rounded corners, align=left, minimum width=2em, edge+=darkgray, line width=1pt, s sep=1pt, inner xsep=1pt, inner ysep=2pt, line width=0.8pt, ver/.append style=rotate=90, child anchor=north, parent anchor=south, anchor=center, text width=7em, , [Text-Base Prompt. Tech. , fill=teal!50 [Zero-Shot [2.2.2](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS2 \"2.2.2 Zero-Shot â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!50 [Emotion Prompting [2.2.2](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS2.SSS0.Px3 \"Emotion Prompting â£ 2.2.2 Zero-Shot â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!50] [Role Prompting [2.2.2](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS2.SSS0.Px1 \"Role Prompting â£ 2.2.2 Zero-Shot â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!50] [Style Prompting [2.2.2](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS2.SSS0.Px2 \"Style Prompting â£ 2.2.2 Zero-Shot â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!50] [S2A [2.2.2](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS2.SSS0.Px4 \"System 2 Attention \\(S2A\\) â£ 2.2.2 Zero-Shot â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!50] [SimToM [2.2.2](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS2.SSS0.Px5 \"SimToM â£ 2.2.2 Zero-Shot â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!50] [RaR [2.2.2](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS2.SSS0.Px6 \"Rephrase and Respond \\(RaR\\) â£ 2.2.2 Zero-Shot â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!50] [RE2 [2.2.2](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS2.SSS0.Px7 \"Re-reading \\(RE2\\) â£ 2.2.2 Zero-Shot â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!50] [Self-Ask [2.2.2](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS2.SSS0.Px8 \"Self-Ask â£ 2.2.2 Zero-Shot â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!50] ] [Few-Shot [2.2.1](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS1.SSS0.Px1 \"Few-Shot Prompting â£ 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!50 [Example Generation, fill=blue!40 [SG-ICL [2.2.1.2](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS1.SSS2.Px3 \"Self-Generated In-Context Learning \\(SG-ICL\\) â£ 2.2.1.2 Few-Shot Prompting Techniques â£ 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!30] ] [Example Ordering [2.2.1.1](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS1.SSS1.Px2 \"Exemplar Ordering â£ 2.2.1.1 Few-Shot Prompting Design Decisions â£ 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!40] [Exemplar Selection [2.2.1.2](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS1.SSS2 \"2.2.1.2 Few-Shot Prompting Techniques â£ 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!40 [KNN [2.2.1.2](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS1.SSS2.Px1 \"K-Nearest Neighbor \\(KNN\\) â£ 2.2.1.2 Few-Shot Prompting Techniques â£ 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!30] [Vote-K [2.2.1.2](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS1.SSS2.Px2 \"Vote-K â£ 2.2.1.2 Few-Shot Prompting Techniques â£ 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!30] ] ] [Thought Generation [2.2.3](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3 \"2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!50 [Chain-of-Thought (CoT) [2.2.3](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3.SSS0.Px1 \"Chain-of-Thought \\(CoT\\) Prompting â£ 2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!40 [Zero-Shot CoT [2.2.3.1](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3.SSS1 \"2.2.3.1 Zero-Shot-CoT â£ 2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!30 [Analogical Prompting [2.2.3.1](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3.SSS1.Px2 \"Analogical Prompting â£ 2.2.3.1 Zero-Shot-CoT â£ 2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!20] [Step-Back Prompting [2.2.3.1](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3.SSS1.Px1 \"Step-Back Prompting â£ 2.2.3.1 Zero-Shot-CoT â£ 2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!20] [Thread-of-Thought (ThoT) [2.2.3.1](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3.SSS1.Px3 \"Thread-of-Thought \\(ThoT\\) Prompting â£ 2.2.3.1 Zero-Shot-CoT â£ 2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!20] [Tab-CoT [2.2.3.1](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3.SSS1.Px4 \"Tabular Chain-of-Thought \\(Tab-CoT\\) â£ 2.2.3.1 Zero-Shot-CoT â£ 2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!20] ] [Few-Shot CoT [2.2.3.2](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3.SSS2 \"2.2.3.2 Few-Shot CoT â£ 2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!30 [Active-Prompt [2.2.3.2](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3.SSS2.Px4 \"Active Prompting â£ 2.2.3.2 Few-Shot CoT â£ 2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!20] [Auto-CoT [2.2.3.2](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3.SSS2.Px6 \"Automatic Chain-of-Thought \\(Auto-CoT\\) Prompting â£ 2.2.3.2 Few-Shot CoT â£ 2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!20] [Complexity-Based [2.2.3.2](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3.SSS2.Px3 \"Complexity-based Prompting â£ 2.2.3.2 Few-Shot CoT â£ 2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!20] [Contrastive [2.2.3.2](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3.SSS2.Px1 \"Contrastive CoT Prompting â£ 2.2.3.2 Few-Shot CoT â£ 2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!20] [Memory-of-Thought [2.2.3.2](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3.SSS2.Px5 \"Memory-of-Thought Prompting â£ 2.2.3.2 Few-Shot CoT â£ 2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!20] [Uncertainty-Routed CoT [2.2.3.2](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3.SSS2.Px2 \"Uncertainty-Routed CoT Prompting â£ 2.2.3.2 Few-Shot CoT â£ 2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!20] [Prompt Mining [2.2.1.2](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS1.SSS2.Px4 \"Prompt Mining â£ 2.2.1.2 Few-Shot Prompting Techniques â£ 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!20] ] ] ] [Ensembling [2.2.5](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS5 \"2.2.5 Ensembling â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=orange!50 [COSP [2.2.5](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS5.SSS0.Px8 \"Consistency-based Self-adaptive Prompting \\(COSP\\) â£ 2.2.5 Ensembling â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=orange!40] [DENSE [2.2.5](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS5.SSS0.Px1 \"Demonstration Ensembling \\(DENSE\\) â£ 2.2.5 Ensembling â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=orange!40] [DiVeRSe [2.2.5](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS5.SSS0.Px7 \"DiVeRSe â£ 2.2.5 Ensembling â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=orange!40] [Max Mutual Information [2.2.5](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS5.SSS0.Px3 \"Max Mutual Information Method â£ 2.2.5 Ensembling â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=orange!40] [Meta-CoT [2.2.5](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS5.SSS0.Px6 \"Meta-Reasoning over Multiple CoTs â£ 2.2.5 Ensembling â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=orange!40] [MoRE [2.2.5](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS5.SSS0.Px2 \"Mixture of Reasoning Experts \\(MoRE\\) â£ 2.2.5 Ensembling â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=orange!40] [Self-Consistency [2.2.5](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS5.SSS0.Px4 \"Self-Consistency â£ 2.2.5 Ensembling â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=orange!40] [Universal Self-Consistency [2.2.5](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS5.SSS0.Px5 \"Universal Self-Consistency â£ 2.2.5 Ensembling â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=orange!40] [USP [2.2.5](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS5.SSS0.Px9 \"Universal Self-Adaptive Prompting \\(USP\\) â£ 2.2.5 Ensembling â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=orange!40] [Prompt Paraphrasing [2.2.5](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS5.SSS0.Px10 \"Prompt Paraphrasing â£ 2.2.5 Ensembling â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=orange!40] ] [Self-Criticism [2.2.6](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS6 \"2.2.6 Self-Criticism â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=purple!50 [Chain-of-Verification [2.2.6](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS6.SSS0.Px5 \"Chain-of-Verification \\(COVE\\) â£ 2.2.6 Self-Criticism â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=purple!40] [Self-Calibration [2.2.6](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS6.SSS0.Px1 \"Self-Calibration â£ 2.2.6 Self-Criticism â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=purple!40] [Self-Refine [2.2.6](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS6.SSS0.Px2 \"Self-Refine â£ 2.2.6 Self-Criticism â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=purple!40] [Self-Verification [2.2.6](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS6.SSS0.Px4 \"Self-Verification â£ 2.2.6 Self-Criticism â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=purple!40] [ReverseCoT [2.2.6](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS6.SSS0.Px3 \"Reversing Chain-of-Thought \\(RCoT\\) â£ 2.2.6 Self-Criticism â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=purple!40] [Cumulative Reason. [2.2.6](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS6.SSS0.Px6 \"Cumulative Reasoning â£ 2.2.6 Self-Criticism â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=purple!40] ] [Decomposition [2.2.4](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS4 \"2.2.4 Decomposition â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=brown!50 [DECOMP [2.2.4](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS4.SSS0.Px2 \"Decomposed Prompting \\(DECOMP\\) â£ 2.2.4 Decomposition â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=brown!40] [Faithful CoT [2.2.4](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS4.SSS0.Px7 \"Faithful Chain-of-Thought â£ 2.2.4 Decomposition â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=brown!40] [Least-to-Most [2.2.4](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS4.SSS0.Px1 \"Least-to-Most Prompting â£ 2.2.4 Decomposition â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=brown!40] [Plan-and-Solve [2.2.4](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS4.SSS0.Px3 \"Plan-and-Solve Prompting â£ 2.2.4 Decomposition â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=brown!40] [Program-of-Thought [2.2.4](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS4.SSS0.Px6 \"Program-of-Thoughts â£ 2.2.4 Decomposition â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=brown!40] [Recurs.-of-Thought [2.2.4](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS4.SSS0.Px5 \"Recursion-of-Thought â£ 2.2.4 Decomposition â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=brown!40] [Skeleton-of-Thought [2.2.4](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS4.SSS0.Px8 \"Skeleton-of-Thought â£ 2.2.4 Decomposition â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=brown!40] [Tree-of-Thought [2.2.4](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS4.SSS0.Px4 \"Tree-of-Thought \\(ToT\\) â£ 2.2.4 Decomposition â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=brown!40] ] ]\nReport issue for preceding element\nFigure 2.2: All text-based prompting techniques from our dataset. Report issue for preceding element\n####  2.2.1 In-Context Learning (ICL)\nReport issue for preceding element ![Refer to caption](https://arxiv.org/html/x4.png) Figure 2.3: We highlight six main design decisions when crafting few-shot prompts. âPlease note that recommendations here do not generalize to all tasks; in some cases, each of them could hurt performance. Report issue for preceding element\nICL refers to the ability of GenAIs to learn skills and tasks by providing them with exemplars and or relevant instructions within the prompt, without the need for weight updates/retraining Brown et al. ([2020](https://arxiv.org/html/2406.06608v1#bib.bib22)); Radford et al. ([2019b](https://arxiv.org/html/2406.06608v1#bib.bib229)). These skills can be learned from exemplars (Figure [2.4](https://arxiv.org/html/2406.06608v1#Ch2.F4 \"Figure 2.4 â£ 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")) and/or instructions (Figure [2.5](https://arxiv.org/html/2406.06608v1#Ch2.F5 \"Figure 2.5 â£ 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")). Note that the word âlearnâ is misleading. ICL can simply be task specificationâthe skills are not necessarily new, and can have already been included in the training data (Figure [2.6](https://arxiv.org/html/2406.06608v1#Ch2.F6 \"Figure 2.6 â£ 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")). See Appendix [A.8](https://arxiv.org/html/2406.06608v1#A1.S8 \"A.8 In-Context Learning Definitions Disambiguation â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\") for a discussion of the use of this term. Significant work is currently being done on optimizing Bansal et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib15)) and understanding Si et al. ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib263)); Å tefÃ¡nik and KadlÄÃ­k ([2023](https://arxiv.org/html/2406.06608v1#bib.bib272)) ICL.\nReport issue for preceding element\n2+2: four 4+5: nine 8+0: Report issue for preceding element Figure 2.4: ICL exemplar prompt Report issue for preceding element Extract all words that have 3 of the same letter and at least 3 other letter from the following text: {TEXT} Report issue for preceding element Figure 2.5: ICL instruction prompt Report issue for preceding element Translate the word \"cheese\" to French. Report issue for preceding element Figure 2.6: ICL from training data prompt. In this version of ICL, the model is not learning a new skill, but rather using knowledge likely in its training set. Report issue for preceding element\n###### Few-Shot Prompting\nReport issue for preceding element\nBrown et al. ([2020](https://arxiv.org/html/2406.06608v1#bib.bib22)) is the paradigm seen in Figure [2.4](https://arxiv.org/html/2406.06608v1#Ch2.F4 \"Figure 2.4 â£ 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), where the GenAI learns to complete a task with only a few examples (exemplars).\nReport issue for preceding element\n###### Few-Shot Learning (FSL) \nReport issue for preceding element\nFei-Fei et al. ([2006](https://arxiv.org/html/2406.06608v1#bib.bib55)); Wang et al. ([2019](https://arxiv.org/html/2406.06608v1#bib.bib295)) is often conflated with Few-Shot Prompting Brown et al. ([2020](https://arxiv.org/html/2406.06608v1#bib.bib22)). It is important to note that FSL is a broader machine learning paradigm to adapt parameters with a few examples, while Few-Shot Prompting is specific to prompts in the GenAI settings and does not involve updating model parameters.\nReport issue for preceding element\n#####  2.2.1.1 Few-Shot Prompting Design Decisions\nReport issue for preceding element\nSelecting exemplars for a prompt is a difficult taskâperformance depends significantly on various factors of the exemplars Dong et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib50)), and only a limited number of exemplars fit in the typical LLMâs context window. We highlight six separate design decisions, including the selection and order of exemplars that critically influence the output quality Zhao et al. ([2021a](https://arxiv.org/html/2406.06608v1#bib.bib345)); Lu et al. ([2021](https://arxiv.org/html/2406.06608v1#bib.bib171)); Ye and Durrett ([2023](https://arxiv.org/html/2406.06608v1#bib.bib330)) (Figure [2.3](https://arxiv.org/html/2406.06608v1#Ch2.F3 \"Figure 2.3 â£ 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")).\nReport issue for preceding element\n###### Exemplar Quantity\nReport issue for preceding element\nIncreasing the quantity of exemplars in the prompt generally improves model performance, particularly in larger models Brown et al. ([2020](https://arxiv.org/html/2406.06608v1#bib.bib22)). However, in some cases, the benefits may diminish beyond 20 exemplars Liu et al. ([2021](https://arxiv.org/html/2406.06608v1#bib.bib157)).\nReport issue for preceding element\n###### Exemplar Ordering\nReport issue for preceding element\nThe order of exemplars affects model behavior Lu et al. ([2021](https://arxiv.org/html/2406.06608v1#bib.bib171)); Kumar and Talukdar ([2021](https://arxiv.org/html/2406.06608v1#bib.bib128)); Liu et al. ([2021](https://arxiv.org/html/2406.06608v1#bib.bib157)); Rubin et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib236)). On some tasks, exemplar order can cause accuracy to vary from sub-50% to 90%+ Lu et al. ([2021](https://arxiv.org/html/2406.06608v1#bib.bib171)).\nReport issue for preceding element\n###### Exemplar Label Distribution\nReport issue for preceding element\nAs in traditional supervised machine learning, the distribution of exemplar labels in the prompt affects behavior. For example, if 10 exemplars from one class and 2 exemplars of another class are included, this may cause the model to be biased toward the first class.\nReport issue for preceding element\n###### Exemplar Label Quality\nReport issue for preceding element\nDespite the general benefit of multiple exemplars, the necessity of strictly _valid_ demonstrations is unclear. Some work Min et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib184)) suggests that the accuracy of labels is irrelevantâproviding models with exemplars with incorrect labels may not negatively diminish performance. However, under certain settings, there is a significant impact on performance Yoo et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib331)). Larger models are often better at handling incorrect or unrelated labels Wei et al. ([2023c](https://arxiv.org/html/2406.06608v1#bib.bib302)).\nReport issue for preceding element\nIt is important to discuss this factor, since if you are automatically constructing prompts from large datasets that may contain inaccuracies, it may be necessary to study how label quality affects your results.\nReport issue for preceding element\n###### Exemplar Format\nReport issue for preceding element\nThe formatting of exemplars also affects performance. One of the most common formats is âQ: {input}, A: {label}â, but the optimal format may vary across tasks; it may be worth trying multiple formats to see which performs best. There is some evidence to suggest that formats that occur commonly in the training data will lead to better performance Jiang et al. ([2020](https://arxiv.org/html/2406.06608v1#bib.bib106)).\nReport issue for preceding element\n###### Exemplar Similarity\nReport issue for preceding element\nSelecting exemplars that are similar to the test sample is generally beneficial for performance Liu et al. ([2021](https://arxiv.org/html/2406.06608v1#bib.bib157)); Min et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib184)). However, in some cases, selecting more diverse exemplars can improve performance Su et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib273)); Min et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib184)).\nReport issue for preceding element\n#####  2.2.1.2 Few-Shot Prompting Techniques\nReport issue for preceding element\nConsidering all of these factors, Few-Shot Prompting can be very difficult to implement effectively. We now examine techniques for Few-Shot Prompting in the supervised setting. Ensembling approaches can also benefit Few-Shot Prompting, but we discuss them separately (Section [2.2.5](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS5 \"2.2.5 Ensembling â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")).\nReport issue for preceding element\nAssume we have a training dataset, Dtâ¢râ¢aâ¢iâ¢nsuperscriptð·ð¡ððððD^{train}italic_D start_POSTSUPERSCRIPT italic_t italic_r italic_a italic_i italic_n end_POSTSUPERSCRIPT, which contains multiple inputs Dxitâ¢râ¢aâ¢iâ¢nsubscriptsuperscriptð·ð¡ððððsuperscriptð¥ðD^{train}_{x^{i}}italic_D start_POSTSUPERSCRIPT italic_t italic_r italic_a italic_i italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT end_POSTSUBSCRIPT and outputs Dyitâ¢râ¢aâ¢iâ¢nsubscriptsuperscriptð·ð¡ððððsuperscriptð¦ðD^{train}_{y^{i}}italic_D start_POSTSUPERSCRIPT italic_t italic_r italic_a italic_i italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_y start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT end_POSTSUBSCRIPT, which can be used to few-shot prompt a GenAI (rather than performing gradient-based updates). Assume that this prompt can be dynamically generated with respect to Dxitâ¢eâ¢sâ¢tsubscriptsuperscriptð·ð¡ðð ð¡superscriptð¥ðD^{test}_{x^{i}}italic_D start_POSTSUPERSCRIPT italic_t italic_e italic_s italic_t end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT end_POSTSUBSCRIPT at test time. Here is the prompt template we will use for this section, following the âinput: outputâ format (Figure [2.4](https://arxiv.org/html/2406.06608v1#Ch2.F4 \"Figure 2.4 â£ 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")):\nReport issue for preceding element\n{Exemplars} Dxitâ¢eâ¢sâ¢tsubscriptsuperscriptð·ð¡ðð ð¡superscriptð¥ðD^{test}_{x^{i}}italic_D start_POSTSUPERSCRIPT italic_t italic_e italic_s italic_t end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT end_POSTSUBSCRIPT: Report issue for preceding element Figure 2.7: Few-Shot Prompting Template Report issue for preceding element\n###### K-Nearest Neighbor (KNN)\nReport issue for preceding element\nLiu et al. ([2021](https://arxiv.org/html/2406.06608v1#bib.bib157)) is part of a family of algorithms that selects exemplars similar to Dxitâ¢eâ¢sâ¢tsubscriptsuperscriptð·ð¡ðð ð¡superscriptð¥ðD^{test}_{x^{i}}italic_D start_POSTSUPERSCRIPT italic_t italic_e italic_s italic_t end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT end_POSTSUBSCRIPT to boost performance. Although effective, employing KNN during prompt generation may be time and resource intensive.\nReport issue for preceding element\n###### Vote-K\nReport issue for preceding element\nSu et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib273)) is another method to select similar exemplars to the test sample. In one stage, a model proposes useful unlabeled candidate exemplars for an annotator to label. In the second stage, the labeled pool is used for Few-Shot Prompting. Vote-K also ensures that newly added exemplars are sufficiently different than existing ones to increase diversity and representativeness.\nReport issue for preceding element\n###### Self-Generated In-Context Learning (SG-ICL)\nReport issue for preceding element\nKim et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib121)) leverages a GenAI to automatically generate exemplars. While better than zero-shot scenarios when training data is unavailable, the generated samples are not as effective as actual data.\nReport issue for preceding element\n###### Prompt Mining\nReport issue for preceding element\nJiang et al. ([2020](https://arxiv.org/html/2406.06608v1#bib.bib106)) is the process of discovering optimal \"middle words\" in prompts (effectively prompt templates) through large corpus analysis. For example, instead of using the common \"Q: A:\" format for few-shot prompts, there may exist something similar which occurs more frequently in the corpus. Formats which occur more often in the corpus will likely lead to improved prompt performance.\nReport issue for preceding element\n###### More Complicated Techniques\nReport issue for preceding element\nsuch as LENS Li and Qiu ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib145)), UDR Li et al. ([2023f](https://arxiv.org/html/2406.06608v1#bib.bib144)), and Active Example Selection Zhang et al. ([2022a](https://arxiv.org/html/2406.06608v1#bib.bib340)) leverage iterative filtering, embedding and retrieval, and reinforcement learning, respectively.\nReport issue for preceding element\n####  2.2.2 Zero-Shot\nReport issue for preceding element\nIn contrast to Few-Shot Prompting, Zero-Shot Prompting uses zero exemplars. There are a number of well known standalone zero-shot techniques as well as zero-shot techniques combine with another concept (e.g. Chain of Thought), which we discuss later (Section [2.2.3](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS3 \"2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")).\nReport issue for preceding element\n###### Role Prompting\nReport issue for preceding element\nWang et al. ([2023j](https://arxiv.org/html/2406.06608v1#bib.bib296)); Zheng et al. ([2023d](https://arxiv.org/html/2406.06608v1#bib.bib352)) , also known as persona prompting Schmidt et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib245)); Wang et al. ([2023l](https://arxiv.org/html/2406.06608v1#bib.bib298)), assigns a specific role to the GenAI in the prompt. For example, the user might prompt it to act like \"Madonna\" or a \"travel writer\". This can create more desirable outputs for open-ended tasks Reynolds and McDonell ([2021](https://arxiv.org/html/2406.06608v1#bib.bib233)) and in some cases improve accuracy on benchmarks Zheng et al. ([2023d](https://arxiv.org/html/2406.06608v1#bib.bib352)).\nReport issue for preceding element\n###### Style Prompting\nReport issue for preceding element\nLu et al. ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib168)) involves specifying the desired style, tone, or genre in the prompt to shape the output of a GenAI. A similar effect can be achieved using role prompting.\nReport issue for preceding element\n###### Emotion Prompting\nReport issue for preceding element\nLi et al. ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib138)) incorporates phrases of psychological relevance to humans (e.g., \"This is important to my career\") into the prompt, which may lead to improved LLM performance on benchmarks and open-ended text generation.\nReport issue for preceding element\n###### System 2 Attention (S2A)\nReport issue for preceding element\nWeston and Sukhbaatar ([2023](https://arxiv.org/html/2406.06608v1#bib.bib304)) first asks an LLM to rewrite the prompt and remove any information unrelated to the question therein. Then, it passes this new prompt into an LLM to retrieve a final response.\nReport issue for preceding element\n###### SimToM\nReport issue for preceding element\nWilf et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib306)) deals with complicated questions which involve multiple people or objects. Given the question, it attempts to establish the set of facts one person knows, then answer the question based only on those facts. This is a two prompt process and can help eliminate the effect of irrelevant information in the prompt.\nReport issue for preceding element\n###### Rephrase and Respond (RaR)\nReport issue for preceding element\nDeng et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib46)) instructs the LLM to rephrase and expand the question before generating the final answer. For example, it might add the following phrase to the question: \"Rephrase and expand the question, and respond\". This could all be done in a single pass or the new question could be passed to the LLM separately. RaR has demonstrated improvements on multiple benchmarks.\nReport issue for preceding element\n###### Re-reading (RE2)\nReport issue for preceding element\nXu et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib317)) adds the phrase \"Read the question again:\" to the prompt in addition to repeating the question. Although this is such a simple technique, it has shown improvement in reasoning benchmarks, especially with complex questions.\nReport issue for preceding element\n###### Self-Ask\nReport issue for preceding element\nPress et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib220)) prompts LLMs to first decide if they need to ask follow up questions for a given prompt. If so, the LLM generates these questions, then answers them and finally answers the original question.\nReport issue for preceding element\n####  2.2.3 Thought Generation\nReport issue for preceding element\nThought generation encompasses a range of techniques that prompt the LLM to articulate its reasoning while solving a problem Zhang et al. ([2023c](https://arxiv.org/html/2406.06608v1#bib.bib341)).\nReport issue for preceding element\n###### Chain-of-Thought (CoT) Prompting\nReport issue for preceding element\nWei et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib299)) leverages few-shot prompting to encourage the LLM to express its thought process before delivering its final answer.555We note that such techniques are often described using words like âthinkâ that anthropomorphize models. We attempt not to use this language, but do use original authorsâ language where appropriate. This technique is occasionally referred to as Chain-of-Thoughts Tutunov et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib281)); Besta et al. ([2024](https://arxiv.org/html/2406.06608v1#bib.bib17)); Chen et al. ([2023d](https://arxiv.org/html/2406.06608v1#bib.bib32)). It has been demonstrated to significantly enhance the LLMâs performance in mathematics and reasoning tasks. In Wei et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib299)), the prompt includes an exemplar featuring a question, a reasoning path, and the correct answer (Figure [2.8](https://arxiv.org/html/2406.06608v1#Ch2.F8 \"Figure 2.8 â£ Chain-of-Thought \\(CoT\\) Prompting â£ 2.2.3 Thought Generation â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")).\nReport issue for preceding element\nQ: Jack has two baskets, each containing three balls. How many balls does Jack have in total? A: One basket contains 3 balls, so two baskets contain 3 * 2 = 6 balls. Q: {QUESTION} A: Report issue for preceding element Figure 2.8: A One-Shot Chain-of-Thought Prompt. Report issue for preceding element\n#####  2.2.3.1 Zero-Shot-CoT\nReport issue for preceding element\nThe most straightforward version of CoT contains zero exemplars. It involves appending a thought inducing phrase like \"Letâs think step by step.\" Kojima et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib127)) to the prompt. Other suggested thought-generating phrases include \"Letâs work this out in a step by step way to be sure we have the right answer\" Zhou et al. ([2022b](https://arxiv.org/html/2406.06608v1#bib.bib354)) and \"First, letâs think about this logically\" Kojima et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib127)). Yang et al. ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib319)) searches for an optimal thought inducer. Zero-Shot-CoT approaches are attractive as they donât require exemplars and are generally task agnostic.\nReport issue for preceding element\n###### Step-Back Prompting\nReport issue for preceding element\nZheng et al. ([2023c](https://arxiv.org/html/2406.06608v1#bib.bib351)) is a modification of CoT where the LLM is first asked a generic, high-level question about relevant concepts or facts before delving into reasoning. This approach has improved performance significantly on multiple reasoning benchmarks for both PaLM-2L and GPT-4.\nReport issue for preceding element\n###### Analogical Prompting\nReport issue for preceding element\nYasunaga et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib328)) is similar to SG-ICL, and automatically generates exemplars that include CoTs. It has demonstrated improvements in mathematical reasoning and code generation tasks.\nReport issue for preceding element\n###### Thread-of-Thought (ThoT) Prompting\nReport issue for preceding element\nZhou et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib355)) consists of an improved thought inducer for CoT reasoning. Instead of \"Letâs think step by step,\" it uses \"Walk me through this context in manageable parts step by step, summarizing and analyzing as we go.\" This thought inducer works well in question-answering and retrieval settings, especially when dealing with large, complex contexts.\nReport issue for preceding element\n###### Tabular Chain-of-Thought (Tab-CoT)\nReport issue for preceding element\nJin and Lu ([2023](https://arxiv.org/html/2406.06608v1#bib.bib108)) consists of a Zero-Shot CoT prompt that makes the LLM output reasoning as a markdown table. This tabular design enables the LLM to improve the structure and thus the reasoning of its output.\nReport issue for preceding element\n#####  2.2.3.2 Few-Shot CoT\nReport issue for preceding element\nThis set of techniques present the LLM with multiple exemplars, which include chains-of-thought. This can significantly enhance performance. This technique is occasionally referred to as Manual-CoT Zhang et al. ([2022b](https://arxiv.org/html/2406.06608v1#bib.bib342)) or Golden CoT Del and Fishel ([2023](https://arxiv.org/html/2406.06608v1#bib.bib44)).\nReport issue for preceding element\n###### Contrastive CoT Prompting\nReport issue for preceding element\nChia et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib37)) adds both exemplars with incorrect and correct explanations to the CoT prompt in order to show the LLM how not to reason. This method has shown significant improvement in areas like Arithmetic Reasoning and Factual QA.\nReport issue for preceding element\n###### Uncertainty-Routed CoT Prompting\nReport issue for preceding element\nGoogle ([2023](https://arxiv.org/html/2406.06608v1#bib.bib76)) samples multiple CoT reasoning paths, then selects the majority if it is above a certain threshold (calculated based on validation data). If not, it samples greedily and selects that response. This method demonstrates improvement on the MMLU benchmark for both GPT4 and Gemini Ultra models.\nReport issue for preceding element\n###### Complexity-based Prompting\nReport issue for preceding element\nFu et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib60)) involves two major modifications to CoT. First, it selects complex examples for annotation and inclusion in the prompt, based on factors like question length or reasoning steps required. Second, during inference, it samples multiple reasoning chains (answers) and uses a majority vote among chains exceeding a certain length threshold, under the premise that longer reasoning indicates higher answer quality. This technique has shown improvements on three mathematical reasoning datasets.\nReport issue for preceding element\n###### Active Prompting\nReport issue for preceding element\nDiao et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib48)) starts with some training questions/exemplars, asks the LLM to solve them, then calculates uncertainty (disagreement in this case) and asks human annotators to rewrite the exemplars with highest uncertainty.\nReport issue for preceding element\n###### Memory-of-Thought Prompting\nReport issue for preceding element\nLi and Qiu ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib146)) leverage unlabeled training exemplars to build Few-Shot CoT prompts at test time. Before test time, it performs inference on the unlabeled training exemplars with CoT. At test time, it retrieves similar instances to the test sample. This technique has shown substantial improvements in benchmarks like Arithmetic, commonsense, and factual reasoning.\nReport issue for preceding element\n###### Automatic Chain-of-Thought (Auto-CoT) Prompting\nReport issue for preceding element\nZhang et al. ([2022b](https://arxiv.org/html/2406.06608v1#bib.bib342)) uses Wei et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib299))âs Zero-Shot prompt to automatically generate chains of thought. These are then used to build a Few-Shot CoT prompt for a test sample.\nReport issue for preceding element\n####  2.2.4 Decomposition\nReport issue for preceding element\nSignificant research has focused on decomposing complex problems into simpler sub-questions. This is an effective problem-solving strategy for humans as well as GenAI Patel et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib201)). Some decomposition techniques are similar to thought-inducing techniques, such as CoT, which often naturally breaks down problems into simpler components. However, explicitly breaking down problems can further improve LLMsâ problem solving ability.\nReport issue for preceding element\n###### Least-to-Most Prompting\nReport issue for preceding element\nZhou et al. ([2022a](https://arxiv.org/html/2406.06608v1#bib.bib353)) starts by prompting a LLM to break a given problem into sub-problems without solving them. Then, it solves them sequentially, appending model responses to the prompt each time, until it arrives at a final result. This method has shown significant improvements in tasks involving symbolic manipulation, compositional generalization, and mathematical reasoning.\nReport issue for preceding element\n###### Decomposed Prompting (DECOMP)\nReport issue for preceding element\nKhot et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib118)) Few-Shot prompts a LLM to show it how to use certain functions. These might include things like string splitting or internet searching; these are often implemented as separate LLM calls. Given this, the LLM breaks down its original problem into sub-problems which it sends to different functions. It has shown improved performance over Least-to-Most prompting on some tasks.\nReport issue for preceding element\n###### Plan-and-Solve Prompting\nReport issue for preceding element\nWang et al. ([2023f](https://arxiv.org/html/2406.06608v1#bib.bib290)) consists of an improved Zero-Shot CoT prompt, \"Letâs first understand the problem and devise a plan to solve it. Then, letâs carry out the plan and solve the problem step by step\". This method generates more robust reasoning processes than standard Zero-Shot-CoT on multiple reasoning datasets.\nReport issue for preceding element\n###### Tree-of-Thought (ToT)\nReport issue for preceding element\nYao et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib325)), also known as Tree of Thoughts, Long ([2023](https://arxiv.org/html/2406.06608v1#bib.bib166)), creates a tree-like search problem by starting with an initial problem then generating multiple possible steps in the form of thoughts (as from a CoT). It evaluates the progress each step makes towards solving the problem (through prompting) and decides which steps to continue with, then keeps creating more thoughts. ToT is particularly effective for tasks that require search and planning.\nReport issue for preceding element\n###### Recursion-of-Thought\nReport issue for preceding element\nLee and Kim ([2023](https://arxiv.org/html/2406.06608v1#bib.bib133)) is similar to regular CoT. However, every time it encounters a complicated problem in the middle of its reasoning chain, it sends this problem into another prompt/LLM call. After this is completed, the answer is inserted into the original prompt. In this way, it can recursively solve complex problems, including ones which might otherwise run over that maximum context length. This method has shown improvements on arithmetic and algorithmic tasks. Though implemented using fine-tuning to output a special token that sends sub-problem into another prompt, it could also be done only through prompting.\nReport issue for preceding element\n###### Program-of-Thoughts\nReport issue for preceding element\nChen et al. ([2023d](https://arxiv.org/html/2406.06608v1#bib.bib32)) uses LLMs like Codex to generate programming code as reasoning steps. A code interpreter executes these steps to obtain the final answer. It excels in mathematical and programming-related tasks but is less effective for semantic reasoning tasks.\nReport issue for preceding element\n###### Faithful Chain-of-Thought\nReport issue for preceding element\nLyu et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib175)) generates a CoT that has both natural language and symbolic language (e.g. Python) reasoning, just like Program-of-Thoughts. However, it also makes use of different types of symbolic languages in a task-dependent fashion.\nReport issue for preceding element\n###### Skeleton-of-Thought\nReport issue for preceding element\nNing et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib195)) focuses on accelerating answer speed through parallelization. Given a problem, it prompts an LLM to create a skeleton of the answer, in a sense, sub-problems to be solved. Then, in parallel, it sends these questions to an LLM and concatenates all the outputs to get a final response.\nReport issue for preceding element\n####  2.2.5 Ensembling\nReport issue for preceding element\nIn GenAI, ensembling is the process of using multiple prompts to solve the same problem, then aggregating these responses into a final output. In many cases, a majority voteâselecting the most frequent responseâis used to generate the final output. Ensembling techniques reduce the variance of LLM outputs and often improving accuracy, but come with the cost of increasing the number of model calls needed to reach a final answer.\nReport issue for preceding element\n###### Demonstration Ensembling (DENSE)\nReport issue for preceding element\nKhalifa et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib114)) creates multiple few-shot prompts, each containing a distinct subset of exemplars from the training set. Next, it aggregates over their outputs to generate a final response.\nReport issue for preceding element\n###### Mixture of Reasoning Experts (MoRE)\nReport issue for preceding element\nSi et al. ([2023d](https://arxiv.org/html/2406.06608v1#bib.bib266)) creates a set of diverse reasoning experts by using different specialized prompts for different reasoning types (such as retrieval augmentation prompts for factual reasoning, Chain-of-Thought reasoning for multi-hop and math reasoning, and generated knowledge prompting for commonsense reasoning). The best answer from all experts is selected based on an agreement score.\nReport issue for preceding element\n###### Max Mutual Information Method\nReport issue for preceding element\nSorensen et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib270)) creates multiple prompt templates with varied styles and exemplars, then selects the optimal template as the one that maximizes mutual information between the prompt and the LLMâs outputs.\nReport issue for preceding element\n###### Self-Consistency\nReport issue for preceding element\nWang et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib293)) is based on the intuition that multiple different reasoning paths can lead to the same answer. This method first prompts the LLM multiple times to perform CoT, crucially with a non-zero temperature to elicit diverse reasoning paths. Next, it uses a majority vote over all generated responses to select a final response. Self-Consistency has shown improvements on arithmetic, commonsense, and symbolic reasoning tasks.\nReport issue for preceding element\n###### Universal Self-Consistency\nReport issue for preceding element\nChen et al. ([2023e](https://arxiv.org/html/2406.06608v1#bib.bib33)) is similar to Self-Consistency except that rather that selecting the majority response by programmatically counting how often it occurs, it inserts all outputs into a prompt template that selects the majority answer. This is helpful for free-form text generation and cases where the same answer may be output slightly differently by different prompts.\nReport issue for preceding element\n###### Meta-Reasoning over Multiple CoTs\nReport issue for preceding element\nYoran et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib332)) is similar to universal Self-Consistency; it first generates multiple reasoning chains (but not necessarily final answers) for a given problem. Next, it inserts all of these chains in a single prompt template then generates a final answer from them.\nReport issue for preceding element\n###### DiVeRSe\nReport issue for preceding element\nLi et al. ([2023i](https://arxiv.org/html/2406.06608v1#bib.bib150)) creates multiple prompts for a given problem then performs Self-Consistency for each, generating multiple reasoning paths. They score reasoning paths based on each step in them then select a final response.\nReport issue for preceding element\n###### Consistency-based Self-adaptive Prompting (COSP)\nReport issue for preceding element\nWan et al. ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib283)) constructs Few-Shot CoT prompts by running Zero-Shot CoT with Self-Consistency on a set of examples then selecting a high agreement subset of the outputs to be included in the final prompt as exemplars. It again performs Self-Consistency with this final prompt.\nReport issue for preceding element\n###### Universal Self-Adaptive Prompting (USP)\nReport issue for preceding element\nWan et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib284)) builds upon the success of COSP, aiming to make it generalizable to all tasks. USP makes use of unlabeled data to generate exemplars and a more complicated scoring function to select them. Additionally, USP does not use Self-Consistency.\nReport issue for preceding element\n###### Prompt Paraphrasing\nReport issue for preceding element\nJiang et al. ([2020](https://arxiv.org/html/2406.06608v1#bib.bib106)) transforms an original prompt by changing some of the wording, while still maintaining the overall meaning. It is effectively a data augmentation technique that can be used to generate prompts for an ensemble.\nReport issue for preceding element\n####  2.2.6 Self-Criticism\nReport issue for preceding element\nWhen creating GenAI systems, it can be useful to have LLMs criticize their own outputs (Huang et al., [2022](https://arxiv.org/html/2406.06608v1#bib.bib98)). This could simply be a judgement (e.g., is this output correct) or the LLM could be prompted to provide feedback, which is then used to improve the answer. Many approaches to generating and integrating self-criticism have been developed.\nReport issue for preceding element\n###### Self-Calibration\nReport issue for preceding element\nKadavath et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib109)) first prompts an LLM to answer a question. Then, it builds a new prompt that includes the question, the LLMâs answer, and an additional instruction asking whether the answer is correct. This can be useful for gauging confidence levels when applying LLMs when deciding when to accept or revise the original answer.\nReport issue for preceding element\n###### Self-Refine\nReport issue for preceding element\nMadaan et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib177)) is an iterative framework where, given an initial answer from the LLM, it prompts the same LLM to provide feedback on the answer, and then prompts the LLM to improve the answer based on the feedback. This iterative process continues until a stopping condition is met (e.g., max number of steps reached). Self-Refine has demonstrated improvement across a range of reasoning, coding, and generation tasks.\nReport issue for preceding element\n###### Reversing Chain-of-Thought (RCoT)\nReport issue for preceding element\nXue et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib318)) first prompts LLMs to reconstruct the problem based on generated answer. Then, it generates fine-grained comparisons between the original problem and the reconstructed problem as a way to check for any inconsistencies. These inconsistencies are then converted to feedback for the LLM to revise the generated answer.\nReport issue for preceding element\n###### Self-Verification\nReport issue for preceding element\nWeng et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib303)) generates multiple candidate solutions with Chain-of-Thought (CoT). It then scores each solution by masking certain parts of the original question and asking an LLM to predict them based on the rest of the question and the generated solution. This method has shown improvement on eight reasoning datasets.\nReport issue for preceding element\n###### Chain-of-Verification (COVE)\nReport issue for preceding element\nDhuliawala et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib47)) first uses an LLM to generate an answer to a given question. Then creates a list of related questions that would help verify the correctness of the answer. Each question is answered by the LLM, then all the information is given to the LLM to produce the final revised answer. This method has shown improvements in various question-answering and text-generation tasks.\nReport issue for preceding element\n###### Cumulative Reasoning\nReport issue for preceding element\nZhang et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib339)) first generates several potential steps in answering the question. It then has a LLM evaluate them, deciding to either accept or reject these steps. Finally, it checks whether it has arrived at the final answer. If so, it terminates the process, but otherwise it repeats it. This method has demonstrated improvements in logical inference tasks and mathematical problem.\nReport issue for preceding element\n###  2.3 Prompting Technique Usage\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/x5.png)\nFigure 2.9: Citation Counts of GenAI Models\n![Refer to caption](https://arxiv.org/html/x6.png)\nFigure 2.10: Citation Counts of Datasets Report issue for preceding element\n![Refer to caption](https://arxiv.org/html/x7.png) Figure 2.11: Citation Counts of Prompting Techniques. The top 25 papers in our dataset, measured by how often they are cited by other papers in our dataset. Most papers here are prompting techniques*, and the remaining papers contains prompting advice. Report issue for preceding element\nReport issue for preceding element\nAs we have just seen, there exist many text-based prompting techniques. However, only a small subset of them are commonly used in research and in industry. We measure technique usage by proxy of measuring the number of citations by other papers in our dataset. We do so with the presumption that papers about prompting are more likely to actually use or evaluate the cited technique. We graph the top 25 papers cited in this way from our dataset and find that most of them propose new prompting techniques (Figure [2.11](https://arxiv.org/html/2406.06608v1#Ch2.F11 \"Figure 2.11 â£ 2.3 Prompting Technique Usage â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")). The prevalence of citations for Few-Shot and Chain-of-Thought prompting is unsurprising and helps to establish a baseline for understanding the prevalence of other techniques.\nReport issue for preceding element\n####  2.3.1 Benchmarks\nReport issue for preceding element\nIn prompting research, when researchers propose a new technique, they usually benchmark it across multiple models and datasets. This is important to prove the utility of the technique and examine how it transfers across models.\nReport issue for preceding element\nIn order to make it easier for researchers proposing new techniques to know how to benchmark them, we quantitatively examine which models (Figure [2.11](https://arxiv.org/html/2406.06608v1#Ch2.F11 \"Figure 2.11 â£ 2.3 Prompting Technique Usage â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")) and what benchmark datasets (Figure [2.11](https://arxiv.org/html/2406.06608v1#Ch2.F11 \"Figure 2.11 â£ 2.3 Prompting Technique Usage â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")) are being used. Again, we measure usage by how many times papers in our dataset cite the benchmark datasets and models.\nReport issue for preceding element\nTo find which datasets and models are being used, we prompted GPT-4-1106-preview to extract any mentioned dataset or model from the body of papers in our dataset. After, we manually filtered out results that were not models or datasets. The citation counts were acquired by searching items from the finalized list on Semantic Scholar.\nReport issue for preceding element\n###  2.4 Prompt Engineering\nReport issue for preceding element\nIn addition to surveying prompting technique, we also review prompt engineering techniques, which are used to automatically optimize prompts. We discuss some techniques that use gradient updates, since the set of prompt engineering techniques is much smaller than that of prompting techniques.\nReport issue for preceding element\n###### Meta Prompting\nReport issue for preceding element\nis the process of prompting a LLM to generate or improve a prompt or prompt template Reynolds and McDonell ([2021](https://arxiv.org/html/2406.06608v1#bib.bib233)); Zhou et al. ([2022b](https://arxiv.org/html/2406.06608v1#bib.bib354)); Ye et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib329)).\nReport issue for preceding element\n###### AutoPrompt\nReport issue for preceding element\nShin et al. ([2020b](https://arxiv.org/html/2406.06608v1#bib.bib260)) uses a frozen LLM as well as a prompt template that includes some \"trigger tokens\", whose values are updated via backpropogation at training time. This is a version of soft-prompting.\nReport issue for preceding element\n###### Automatic Prompt Engineer (APE)\nReport issue for preceding element\nZhou et al. ([2022b](https://arxiv.org/html/2406.06608v1#bib.bib354)) uses a set of exemplars to generate a Zero-Shot instruction prompt. It generates multiple possible prompts, scores them, then creates variations of the best ones (e.g. by using prompt paraphrasing). It iterates on this process until some desiderata are reached.\nReport issue for preceding element\n###### Gradientfree Instructional Prompt Search (GrIPS)\nReport issue for preceding element\nPrasad et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib218)) is similar to APE, but uses a more complex set of operations including deletion, addition, swapping, and paraphrasing in order to create variations of a starting prompt.\nReport issue for preceding element\n###### Prompt Optimization with Textual Gradients (ProTeGi)\nReport issue for preceding element\nPryzant et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib221)) is a unique approach to prompt engineering that improves a prompt template through a multi-step process. First, it passes a batch of inputs through the template, then passes the output, ground truth, and prompt into another prompt that criticizes the original prompt. It generates new prompts from these criticisms then uses a bandit algorithm Gabillon et al. ([2011](https://arxiv.org/html/2406.06608v1#bib.bib61)) to select one. ProTeGi demonstrates improvements over methods like APE and GRIPS.\nReport issue for preceding element\n###### RLPrompt\nReport issue for preceding element\nDeng et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib45)) uses a frozen LLM with an unfrozen module added. It uses this LLM to generate prompt templates, scores the templates on a dataset, and updates the unfrozen module using Soft Q-Learning Guo et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib80)). Interestingly, the method often selects grammatically gibberish text as the optimal prompt template.\nReport issue for preceding element\n###### Dialogue-comprised Policy-gradient-based Discrete Prompt Optimization (DP2O)\nReport issue for preceding element\nLi et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib139)) is perhaps the most complicated prompt engineering technique, involving reinforcement learning, a custom prompt scoring function, and conversations the a LLM in order to construct the prompt.\nReport issue for preceding element\n###  2.5 Answer Engineering\nReport issue for preceding element\nAnswer engineering is the iterative process of developing or selecting among algorithms that extract precise answers from LLM outputs. To understand the need for answer engineering, consider a binary classification task where the labels are \"Hate Speech\" and \"Not Hate Speech\". The prompt template might look like this:\nReport issue for preceding element\nIs this \"Hate Speech\" or \"Not Hate Speech\": {TEXT} Report issue for preceding element\nWhen a hate speech sample is put through the template, it might have outputs such as \"Itâs hate speech\", \"Hate Speech.\", or even \"Hate speech, because it uses negative language against a racial group\". This variance in response formats is difficult to parse consistently; improved prompting can help, but only to a certain extent.\nReport issue for preceding element\nThere are three design decisions in answer engineering, the choice of answer space, answer shape, and answer extractor (Figure [2.12](https://arxiv.org/html/2406.06608v1#Ch2.F12 \"Figure 2.12 â£ 2.5 Answer Engineering â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")). Liu et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib159)) define the first two as necessary components of answer engineering and we append the third. We consider answer engineering to be distinct from prompt engineering, but extremely closely related; the processes are often conducted in tandem.\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/x8.png) Figure 2.12: An annotated output of a LLM output for a labeling task, which shows the three design decisions of answer engineering: the choice of answer shape, space, and extractor. Since this is an output from a classification task, the answer shape could be restricted to a single token and the answer space to one of two tokens (\"positive\" or \"negative\"), though they are unrestricted in this image. Report issue for preceding element\n####  2.5.1 Answer Shape\nReport issue for preceding element\nThe shape of an answer is its physical format. For example, it could be a token, span of tokens, or even an image or video.666 We use a different definition than Liu et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib159)) with respect to granularity (e.g. token vs span), since the output could be of a different modality. It is sometimes useful to restrict the output shape of a LLM to a single token for tasks like binary classification.\nReport issue for preceding element\n####  2.5.2 Answer Space\nReport issue for preceding element\nThe space of an answer is the domain of values that its structure may contain. This may simply be the space of all tokens, or in a binary labeling task, could just be two possible tokens.\nReport issue for preceding element\n####  2.5.3 Answer Extractor\nReport issue for preceding element\nIn cases where it is impossible to entirely control the answer space (e.g. consumer-facing LLMs), or the expected answer may be located somewhere within the model output, a rule can be defined to extract the final answer. This rule is often a simple function (e.g. a regular expression), but can also use a separate LLM to extract the answer.\nReport issue for preceding element\n###### Verbalizer\nReport issue for preceding element\nOften used in labeling tasks, a verbalizer maps a token, span, or other type of output to a label and vice-versa (injective) Schick and SchÃ¼tze ([2021](https://arxiv.org/html/2406.06608v1#bib.bib244)). For example, if we wish for a model to predict whether a Tweet is positive or negative, we could prompt it to output either \"+\" or \"-\" and a verbalizer would map these token sequences to the appropriate labels. The selection of a verbalizer constitutes a component of answer engineering.\nReport issue for preceding element\n###### Regex\nReport issue for preceding element\nAs mentioned previously, Regexes are often used to extract answers. They are usually used to search for the first instance of a label. However, depending on the output format and whether CoTs are generated, it may be better to search for the last instance.\nReport issue for preceding element\n###### Separate LLM\nReport issue for preceding element\nSometimes outputs are so complicated that regexes wonât work consistently. In this case, it can be useful to have a separate LLM evaluate the output and extract an answer.\nReport issue for preceding element\n## 3 Beyond English Text Prompting\nReport issue for preceding element\nPrompting GenAIs with English text currently stands as the dominant method for interaction. Prompting in other languages or through different modalities often requires special techniques to achieve comparable performance. In this context, we discuss the domains of multilingual and multimodal prompting.\nReport issue for preceding element\n{forest}\nfor tree= grow=east, reversed=true, anchor=base west, parent anchor=east, child anchor=west, base=left, font=, rectangle, draw=black, rounded corners, align=left, minimum width=2em, edge+=darkgray, line width=1pt, s sep=1pt, inner xsep=1pt, inner ysep=2pt, line width=0.8pt, ver/.append style=rotate=90, child anchor=north, parent anchor=south, anchor=center, text width=7em, , [Multilingual Techniques, fill=teal!50 [Chain-of-Thought [3.1.1](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS1 \"3.1.1 Chain-of-Thought \\(CoT\\) â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!50 [XLT [3.1.1](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS1.SSS0.Px1 \"XLT \\(Cross-Lingual Thought\\) Prompting â£ 3.1.1 Chain-of-Thought \\(CoT\\) â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!40] [CLSP [3.1.1](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS1.SSS0.Px2 \"Cross-Lingual Self Consistent Prompting \\(CLSP\\) â£ 3.1.1 Chain-of-Thought \\(CoT\\) â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!40]] [In-Context Learning [3.1.2](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS2 \"3.1.2 In-Context Learning â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!50 [X-InSTA [3.1.2](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS2.SSS0.Px1 \"X-InSTA Prompting â£ 3.1.2 In-Context Learning â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!40] [In-CLT [3.1.2](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS2.SSS0.Px2 \"In-CLT \\(Cross-lingual Transfer\\) Prompting â£ 3.1.2 In-Context Learning â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!40] ] [In-Context Ex. Selection [3.1.3](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS3 \"3.1.3 In-Context Example Selection â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!50 [PARC [3.1.3](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS3.SSS0.Px1 \"PARC \\(Prompts Augmented by Retrieval Cross-lingually\\) â£ 3.1.3 In-Context Example Selection â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!40] [Semantically-Aligned [3.1.3](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS3 \"3.1.3 In-Context Example Selection â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!40] [Semantically-Distant [3.1.3](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS3 \"3.1.3 In-Context Example Selection â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!40] ] [Human-in-the-Loop [3.1.5.1](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS5.SSS1 \"3.1.5.1 Human-in-the-Loop â£ 3.1.5 Prompting for Machine Translation â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!50 [Interactive Chain [3.1.5.1](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS5.SSS1.Px1 \"Interactive-Chain-Prompting \\(ICP\\) â£ 3.1.5.1 Human-in-the-Loop â£ 3.1.5 Prompting for Machine Translation â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!40] [Iterative [3.1.5.1](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS5.SSS1.Px2 \"Iterative Prompting â£ 3.1.5.1 Human-in-the-Loop â£ 3.1.5 Prompting for Machine Translation â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!40] ] [Translation [3.1.5](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS5 \"3.1.5 Prompting for Machine Translation â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=orange!50 [Chain-of-Dictionary [3.1.5](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS5.SSS0.Px2 \"Chain-of-Dictionary \\(CoD\\) â£ 3.1.5 Prompting for Machine Translation â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=orange!40] [DecoMT [3.1.5](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS5.SSS0.Px4 \"Decomposed Prompting for MT \\(DecoMT\\) â£ 3.1.5 Prompting for Machine Translation â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=orange!40] [DiPMT [3.1.5](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS5.SSS0.Px3 \"Dictionary-based Prompting for Machine Translation \\(DiPMT\\) â£ 3.1.5 Prompting for Machine Translation â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=orange!40] [MAPS [3.1.5](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS5.SSS0.Px1 \"Multi-Aspect Prompting and Selection \\(MAPS\\) â£ 3.1.5 Prompting for Machine Translation â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=orange!40] ] [Translate First Prompting [3.1](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS0.SSS0.Px1 \"Translate First Prompting â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=violet!50 [External MT Systems [3.1](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS0.SSS0.Px1 \"Translate First Prompting â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=violet!40] [Standard LLMs [3.1](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS0.SSS0.Px1 \"Translate First Prompting â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=violet!40] [Multilingual LLMs [3.1](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS0.SSS0.Px1 \"Translate First Prompting â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=violet!40] ] [Prompt Language [3.1.4](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS4 \"3.1.4 Prompt Template Language Selection â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=brown!50 [English [3.1.4](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS4.SSS0.Px1 \"English Prompt Template â£ 3.1.4 Prompt Template Language Selection â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=brown!40] [Task Language [3.1.4](https://arxiv.org/html/2406.06608v1#Ch3.S1.SS4.SSS0.Px2 \"Task Language Prompt Template â£ 3.1.4 Prompt Template Language Selection â£ 3.1 Multilingual â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=brown!40] ] ]\nReport issue for preceding element\nFigure 3.1: All multilingual prompting techniques. Report issue for preceding element\n###  3.1 Multilingual\nReport issue for preceding element\nState-of-the-art GenAIs have often been predominately trained with English dataset, leading to a notable disparity in the output quality in languages other than English, particularly low-resource languages Bang et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib14)); Jiao et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib107)); Hendy et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib90)); Shi et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib258)). As a result, various multilingual prompting techniques have emerged in an attempt to improve model performance in non-English settings.\nReport issue for preceding element\n###### Translate First Prompting\nReport issue for preceding element\nShi et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib258)) is perhaps the simplest strategy and first translates non-English input examples into English. By translating the inputs into English, the model can utilize its strengths in English to better understand the content. Translation tools vary; Shi et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib258)) use an external MT system, Etxaniz et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib53)) prompt multilingual LMs and Awasthi et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib9)) prompt LLMs to translate non-English inputs.\nReport issue for preceding element\n####  3.1.1 Chain-of-Thought (CoT)\nReport issue for preceding element\nCoT prompting Wei et al. ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib300)) has been extended to the multilingual setting in multiple ways.\nReport issue for preceding element\n###### XLT (Cross-Lingual Thought) Prompting\nReport issue for preceding element\nHuang et al. ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib97)) utilizes a prompt template composed of six separate instructions, including role assignment, cross-lingual thinking, and CoT.\nReport issue for preceding element\n###### Cross-Lingual Self Consistent Prompting (CLSP)\nReport issue for preceding element\nQin et al. ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib225)) introduces an ensemble technique that constructs reasoning paths in different languages to answer the same question.\nReport issue for preceding element\n####  3.1.2 In-Context Learning\nReport issue for preceding element\nICL has also been extended to multilingual settings in multiple ways.\nReport issue for preceding element\n###### X-InSTA Prompting\nReport issue for preceding element\nTanwar et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib275)) explores three distinct approaches for aligning in-context examples with the input sentence for classification tasks: using semantically similar examples to the input (semantic alignment), examples that share the same label as the input (task-based alignment), and the combination of both semantic and task-based alignments.\nReport issue for preceding element\n###### In-CLT (Cross-lingual Transfer) Prompting\nReport issue for preceding element\n(Kim et al., [2023](https://arxiv.org/html/2406.06608v1#bib.bib122)) leverages both the source and target languages to create in-context examples, diverging from the traditional method of using source language exemplars. This strategy helps stimulate the cross-lingual cognitive capabilities of multilingual LLMs, thus boosting performance on cross-lingual tasks.\nReport issue for preceding element\n####  3.1.3 In-Context Example Selection\nReport issue for preceding element\nIn-context example selection heavily influences the multilingual performance of LLMs Garcia et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib69)); Agrawal et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib2)). Finding in-context examples that are semantically similar to the source text is very important Winata et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib309)); Moslem et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib187)); Sia and Duh ([2023](https://arxiv.org/html/2406.06608v1#bib.bib267)). However, using semantically dissimilar (peculiar) exemplars has also been shown to enhance performance Kim and Komachi ([2023](https://arxiv.org/html/2406.06608v1#bib.bib120)). This same contrast exists in the English-only setting. Additionally, when dealing with ambiguous sentences, selecting exemplars with polysemous or rare word senses may boost performance Iyer et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib102)).\nReport issue for preceding element\n###### PARC (Prompts Augmented by Retrieval Cross-lingually)\nReport issue for preceding element\nNie et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib194)) introduce a framework that retrieves relevant exemplars from a high resource language. This framework is specifically designed to enhance cross-lingual transfer performance, particularly for low-resource target languages. Li et al. ([2023g](https://arxiv.org/html/2406.06608v1#bib.bib147)) extend this work to Bangla.\nReport issue for preceding element\n####  3.1.4 Prompt Template Language Selection\nReport issue for preceding element\nIn multilingual prompting, the selection of language for the prompt template can markedly influence the model performance.\nReport issue for preceding element\n###### English Prompt Template\nReport issue for preceding element\nConstructing the prompt template in English is often more effective than in the task language for multilingual tasks. This is likely due to the predominance of English data during LLM pre-training Lin et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib154)); Ahuja et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib3)). Lin et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib154)) suggest that this is likely due to a high overlap with pre-training data and vocabulary. Similarly, Ahuja et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib3)) highlight how translation errors when creating task language templates propagate in the form of incorrect syntax and semantics, adversely affecting task performance. Further, Fu et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib59)) compare in-lingual (task language) prompts and cross-lingual (mixed language) prompts and find the cross-lingual approach to be more effective, likely because it uses more English in the prompt, thus facilitating retrieving knowledge from the model.\nReport issue for preceding element\n###### Task Language Prompt Template\nReport issue for preceding element\nIn contrast, many multilingual prompting benchmarks such as BUFFET Asai et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib7)) or LongBench Bai et al. ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib10)) use task language prompts for language-specific use cases. Muennighoff et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib189)) specifically studies different translation methods when constructing native-language prompts. They demonstrate that human translated prompts are superior to their machine-translated counterparts. Native or non-native template performance can differ across tasks and models Li et al. ([2023h](https://arxiv.org/html/2406.06608v1#bib.bib149)). As such, neither option will always be the best approach Nambi et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib190)).\nReport issue for preceding element\n####  3.1.5 Prompting for Machine Translation\nReport issue for preceding element\nThere is significant research into leveraging GenAI to facilitate accurate and nuanced translation. Although this is a specific application of prompting, many of these techniques are important more broadly for multilingual prompting.\nReport issue for preceding element\n###### Multi-Aspect Prompting and Selection (MAPS)\nReport issue for preceding element\nHe et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib88)) mimics the human translation process, which involves multiple preparatory steps to ensure high-quality output. This framework starts with knowledge mining from the source sentence (extracting keywords and topics, and generating translation exemplars). It integrates this knowledge to generate multiple possible translations, then selects the best one.\nReport issue for preceding element\n###### Chain-of-Dictionary (CoD)\nReport issue for preceding element\nLu et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib169)) first extracts words from the source phrase, then makes a list of their meanings in multiple languages, automatically via retrieval from a dictionary (e.g. English: âappleâ, Spanish: âmanzanaâ). Then, they prepend these dictionary phrases to the prompt, where it asks a GenAI to use them during translation.\nReport issue for preceding element\n###### Dictionary-based Prompting for Machine Translation (DiPMT)\nReport issue for preceding element\nGhazvininejad et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib72)) works similarly to CoD, but only gives definitions in the source and target languages, and formats them slightly differently.\nReport issue for preceding element\n###### Decomposed Prompting for MT (DecoMT)\nReport issue for preceding element\nPuduppully et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib222)) divides the source text into several chunks and translates them independently using few-shot prompting. Then it uses these translations and contextual information between chunks to generate a final translation.\nReport issue for preceding element\n#####  3.1.5.1 Human-in-the-Loop\nReport issue for preceding element\n###### Interactive-Chain-Prompting (ICP)\nReport issue for preceding element\nPilault et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib215)) deals with potential ambiguities in translation by first asking the GenAI to generate sub-questions about any ambiguities in the phrase to be translated. Humans later respond to these questions and the system includes this information to generate a final translation.\nReport issue for preceding element\n###### Iterative Prompting\nReport issue for preceding element\nYang et al. ([2023d](https://arxiv.org/html/2406.06608v1#bib.bib322)) also involves humans during translation. First, they prompt LLMs to create a draft translation. This initial version is further refined by integrating supervision signals obtained from either automated retrieval systems or direct human feedback.\nReport issue for preceding element\n{forest}\nfor tree= grow=east, reversed=true, anchor=base west, parent anchor=east, child anchor=west, base=left, font=, rectangle, draw=black, rounded corners, align=left, minimum width=2em, edge+=darkgray, line width=1pt, s sep=1pt, inner xsep=1pt, inner ysep=2pt, line width=0.8pt, ver/.append style=rotate=90, child anchor=north, parent anchor=south, anchor=center, text width=7em, , [Multimodal (MM) Techniques, fill=teal!50 [Image [3.2.1](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS1 \"3.2.1 Image Prompting â£ 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!50 [MM. CoT [3.2.1.2](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS1.SSS2 \"3.2.1.2 Multimodal Chain-of-Thought â£ 3.2.1 Image Prompting â£ 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!40 [Chain-of-Images [3.2.1.2](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS1.SSS2.Px3 \"Chain-of-Images \\(CoI\\) â£ 3.2.1.2 Multimodal Chain-of-Thought â£ 3.2.1 Image Prompting â£ 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!30] [Duty Distinct CoT [3.2.1.2](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS1.SSS2.Px1 \"Duty Distinct Chain-of-Thought \\(DDCoT\\) â£ 3.2.1.2 Multimodal Chain-of-Thought â£ 3.2.1 Image Prompting â£ 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!30] [MM Graph-of-Thought [3.2.1.2](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS1.SSS2.Px2 \"Multimodal Graph-of-Thought â£ 3.2.1.2 Multimodal Chain-of-Thought â£ 3.2.1 Image Prompting â£ 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!30] ] [Multimodal ICL [3.2.1.1](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS1.SSS1 \"3.2.1.1 Multimodal In-Context Learning â£ 3.2.1 Image Prompting â£ 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!40 [Image-as-Text Prompt[3.2.1.1](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS1.SSS1.Px2 \"Image-as-Text Prompting â£ 3.2.1.1 Multimodal In-Context Learning â£ 3.2.1 Image Prompting â£ 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!30] [Paired-Image Prompt [3.2.1.1](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS1.SSS1.Px1 \"Paired-Image Prompting â£ 3.2.1.1 Multimodal In-Context Learning â£ 3.2.1 Image Prompting â£ 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!30] ] [Negative Prompt [3.2.1](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS1.SSS0.Px2 \"Negative Prompting â£ 3.2.1 Image Prompting â£ 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!40] [Prompt Modifiers [3.2.1](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS1.SSS0.Px1 \"Prompt Modifiers â£ 3.2.1 Image Prompting â£ 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!40] ] [Segmentation Prompting [3.2.4](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS4 \"3.2.4 Segmentation Prompting â£ 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!50] [Video [3.2.3](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS3 \"3.2.3 Video Prompting â£ 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!50 [Video Gen. [3.2.3.1](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS3.SSS1 \"3.2.3.1 Video Generation Techniques â£ 3.2.3 Video Prompting â£ 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!40 ] ] [3D Prompting [3.2.5](https://arxiv.org/html/2406.06608v1#Ch3.S2.SS5 \"3.2.5 3D Prompting â£ 3.2 Multimodal â£ 3 Beyond English Text Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=orange!50] ]\nReport issue for preceding element\nFigure 3.2: All multimodal prompting techniques. Report issue for preceding element\n###  3.2 Multimodal\nReport issue for preceding element\nAs GenAI models evolve beyond text-based domains, new prompting techniques emerge. These multimodal prompting technique are often not simply applications of text-based prompting techniques, but entirely novel ideas made possible by different modalities. We now extend our text-based taxonomy to include a mixture of multimodal analogs of text-based prompting techniques as well as completely novel multimodal techniques.\nReport issue for preceding element\n####  3.2.1 Image Prompting\nReport issue for preceding element\nThe image modality encompasses data such as photographs, drawings, or even screenshots of text Gong et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib74)). Image prompting may refer to prompts that either contain images or are used to generate images. Common tasks include image generation Ding et al. ([2021](https://arxiv.org/html/2406.06608v1#bib.bib49)); Hinz et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib93)); Tao et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib276)); Li et al. ([2019a](https://arxiv.org/html/2406.06608v1#bib.bib137), [b](https://arxiv.org/html/2406.06608v1#bib.bib143)); Rombach et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib235)), caption generation Li et al. ([2020](https://arxiv.org/html/2406.06608v1#bib.bib148)), image classification Khalil et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib115)), and image editing Crowson et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib41)); Kwon and Ye ([2022](https://arxiv.org/html/2406.06608v1#bib.bib129)); Bar-Tal et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib16)); Hertz et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib91)). We now describe various image prompting techniques used for such applications.\nReport issue for preceding element\n###### Prompt Modifiers\nReport issue for preceding element\nare simply words appended to a prompt to change the resultant image Oppenlaender ([2023](https://arxiv.org/html/2406.06608v1#bib.bib197)). Components such as Medium (e.g. \"on canvas\") or Lighting (e.g. \"a well lit scene\") are often used.\nReport issue for preceding element\n###### Negative Prompting\nReport issue for preceding element\nallows users to numerically weight certain terms in the prompt so that the model considers them more/less heavily than others. For example, by negatively weighting the terms âbad handsâ and âextra digitsâ, models may be more likely to generate anatomically accurate hands Schulhoff ([2022](https://arxiv.org/html/2406.06608v1#bib.bib248)).\nReport issue for preceding element\n#####  3.2.1.1 Multimodal In-Context Learning\nReport issue for preceding element\nThe success of ICL in text-based settings has prompted research into multimodal ICL Wang et al. ([2023k](https://arxiv.org/html/2406.06608v1#bib.bib297)); Dong et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib50)).\nReport issue for preceding element\n###### Paired-Image Prompting\nReport issue for preceding element\nshows the model two images: one before and one after some transformation. Then, present the model with a new image for which it will perform the demonstrated conversion. This can be done either with textual instructions Wang et al. ([2023k](https://arxiv.org/html/2406.06608v1#bib.bib297)) or without them Liu et al. ([2023e](https://arxiv.org/html/2406.06608v1#bib.bib162)).\nReport issue for preceding element\n###### Image-as-Text Prompting\nReport issue for preceding element\nHakimov and Schlangen ([2023](https://arxiv.org/html/2406.06608v1#bib.bib85)) generates a textual description of an image. This allows for the easy inclusion of the image (or multiple images) in a text-based prompt.\nReport issue for preceding element\n#####  3.2.1.2 Multimodal Chain-of-Thought\nReport issue for preceding element\nCoT has been extended to the image domain in various ways Zhang et al. ([2023d](https://arxiv.org/html/2406.06608v1#bib.bib343)); Huang et al. ([2023c](https://arxiv.org/html/2406.06608v1#bib.bib100)); Zheng et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib350)); Yao et al. ([2023c](https://arxiv.org/html/2406.06608v1#bib.bib327)). A simple example of this would be a prompt containing an image of a math problem accompanied by the textual instructions \"Solve this step by step\".\nReport issue for preceding element\n###### Duty Distinct Chain-of-Thought (DDCoT)\nReport issue for preceding element\nZheng et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib350)) extends Least-to-Most prompting Zhou et al. ([2022a](https://arxiv.org/html/2406.06608v1#bib.bib353)) to the multimodal setting, creating subquestions, then solving them and combining the answers into a final response.\nReport issue for preceding element\n###### Multimodal Graph-of-Thought\nReport issue for preceding element\nYao et al. ([2023c](https://arxiv.org/html/2406.06608v1#bib.bib327)) extends Graph-of-Thought Zhang et al. ([2023d](https://arxiv.org/html/2406.06608v1#bib.bib343)) to the multimodal setting. GoT-Input also uses a two step rationale then answer process. At inference time, the the input prompt is used to construct a thought graph, which is then used along with the original prompt to generate a rationale to answer the question. When an image is input along with the question, an image captioning model is employed to generate a textual description of the image, which is then appended to the prompt before the thought graph construction to provide visual context.\nReport issue for preceding element\n###### Chain-of-Images (CoI)\nReport issue for preceding element\nMeng et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib180)) is a multimodal extension of Chain-of-Thought prompting, that generates images as part of its thought process. They use the prompt âLetâs think image by imageâ to generate SVGs, which the model can then use to reason visually.\nReport issue for preceding element\n####  3.2.2 Audio Prompting\nReport issue for preceding element\nPrompting has also been extended to the audio modality. Experiments with audio ICL have generated mixed results, with some open source audio models failing to perform ICL Hsu et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib95)). However, other results do show an ICL ability in audio models Wang et al. ([2023g](https://arxiv.org/html/2406.06608v1#bib.bib291)); Peng et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib205)); Chang et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib27)). Audio prompting is currently in early stages, but we expect to see various prompting techniques proposed in the future.\nReport issue for preceding element\n####  3.2.3 Video Prompting\nReport issue for preceding element\nPrompting has also been extended to the video modality, for use in text-to-video generation Brooks et al. ([2024](https://arxiv.org/html/2406.06608v1#bib.bib21)); Lv et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib174)); Liang et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib152)); Girdhar et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib73)), video editing Zuo et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib357)); Wu et al. ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib310)); Cheng et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib36)), and video-to-text generation Yousaf et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib333)); Mi et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib182)); Ko et al. ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib123)).\nReport issue for preceding element\n#####  3.2.3.1 Video Generation Techniques\nReport issue for preceding element\nWhen prompting a model to generate video, various modalities of prompts can be used as input, and several prompt-related techniques are often employed to enhance video generation. Image related techniques, such as prompt modifiers can often be used for video generation Runway ([2023](https://arxiv.org/html/2406.06608v1#bib.bib237)).\nReport issue for preceding element\n####  3.2.4 Segmentation Prompting\nReport issue for preceding element\nPrompting can also be used for segmentation (e.g. semantic segmentation) Tang et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib274)); Liu et al. ([2023c](https://arxiv.org/html/2406.06608v1#bib.bib160)).\nReport issue for preceding element\n####  3.2.5 3D Prompting\nReport issue for preceding element\nPrompting can also be used in 3D modalities, for example in 3D object synthesis Feng et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib56)); Li et al. ([2023d](https://arxiv.org/html/2406.06608v1#bib.bib141), [c](https://arxiv.org/html/2406.06608v1#bib.bib140)); Lin et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib153)); Chen et al. ([2023f](https://arxiv.org/html/2406.06608v1#bib.bib34)); Lorraine et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib167)); Poole et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib216)); Jain et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib103)), 3D surface texturing Liu et al. ([2023g](https://arxiv.org/html/2406.06608v1#bib.bib164)); Yang et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib320)); Le et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib132)); Pajouheshgar et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib200)), and 4D scene generation (animating a 3D scene) Singer et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib269)); Zhao et al. ([2023c](https://arxiv.org/html/2406.06608v1#bib.bib347)), where input prompt modalities include text, image, user annotation (bounding boxes, points, lines), and 3D objects.\nReport issue for preceding element\n## 4 Extensions of Prompting\nReport issue for preceding element\nThe techniques we have discussed thus far can be extremely complicated, incorporating many steps and iterations. However, we can take prompting further by adding access to external tools (agents) and complex evaluation algorithms judge the validity of LLM outputs.\nReport issue for preceding element\n{forest}\nfor tree= grow=east, reversed=true, anchor=base west, parent anchor=east, child anchor=west, base=left, font=, rectangle, draw=black, rounded corners, align=left, minimum width=2em, edge+=darkgray, line width=1pt, s sep=1pt, inner xsep=1pt, inner ysep=2pt, line width=0.8pt, ver/.append style=rotate=90, child anchor=north, parent anchor=south, anchor=center, text width=7em, , [Agents, fill=teal!50 [Tool Use Agents, fill=red!40 [CRITIC [4.1.1](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS1.SSS0.Px2 \"Self-Correcting with Tool-Interactive Critiquing \\(CRITIC\\) â£ 4.1.1 Tool Use Agents â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!40] [MRKL Sys. [4.1.1](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS1.SSS0.Px1 \"Modular Reasoning, Knowledge, and Language \\(MRKL\\) System â£ 4.1.1 Tool Use Agents â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!40] ] [Code-Based Agents [4.1.2](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS2 \"4.1.2 Code-Generation Agents â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!50 [PAL [4.1.2](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS2.SSS0.Px1 \"Program-aided Language Model \\(PAL\\) â£ 4.1.2 Code-Generation Agents â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!40] [ToRA [4.1.2](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS2.SSS0.Px2 \"Tool-Integrated Reasoning Agent \\(ToRA\\) â£ 4.1.2 Code-Generation Agents â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!40] [Task Weaver [4.1.2](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS2.SSS0.Px3 \"TaskWeaver â£ 4.1.2 Code-Generation Agents â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!40] ] [Observation-Based Agents [4.1.3](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS3 \"4.1.3 Observation-Based Agents â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!50 [ReAct [4.1.3](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS3.SSS0.Px1 \"Reasoning and Acting \\(ReAct\\) â£ 4.1.3 Observation-Based Agents â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!40] [Reflexion [4.1.3](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS3.SSS0.Px2 \"Reflexion â£ 4.1.3 Observation-Based Agents â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!40] [Lifelong Learn. Agents [4.1.3.1](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS3.SSS1 \"4.1.3.1 Lifelong Learning Agents â£ 4.1.3 Observation-Based Agents â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!30 [Voyager [4.1.3.1](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS3.SSS1.Px1 \"Voyager â£ 4.1.3.1 Lifelong Learning Agents â£ 4.1.3 Observation-Based Agents â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!20] [GITM [4.1.3.1](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS3.SSS1.Px2 \"Ghost in the Minecraft \\(GITM\\) â£ 4.1.3.1 Lifelong Learning Agents â£ 4.1.3 Observation-Based Agents â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!20] ] ] [Retrieval Aug. Generation [4.1.4](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS4 \"4.1.4 Retrieval Augmented Generation \\(RAG\\) â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=purple!50 [IRCoT [4.1.4](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS4.SSS0.Px3 \"Interleaved Retrieval guided by Chain-of-Thought \\(IRCoT\\) â£ 4.1.4 Retrieval Augmented Generation \\(RAG\\) â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=purple!40] [DSP [4.1.4](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS4.SSS0.Px2 \"Demonstrate-Search-Predict â£ 4.1.4 Retrieval Augmented Generation \\(RAG\\) â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=purple!40] [Verify-and-Edit [4.1.4](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS4.SSS0.Px1 \"Verify-and-Edit â£ 4.1.4 Retrieval Augmented Generation \\(RAG\\) â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\") , fill=purple!40] [Iterative Retrieval Aug. [4.1.4](https://arxiv.org/html/2406.06608v1#Ch4.S1.SS4.SSS0.Px4 \"Iterative Retrieval Augmentation â£ 4.1.4 Retrieval Augmented Generation \\(RAG\\) â£ 4.1 Agents â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\") , fill=purple!40] ] ]\nReport issue for preceding element\nFigure 4.1: Agent techniques covered in this section. Report issue for preceding element\n###  4.1 Agents\nReport issue for preceding element\nAs LLMs have improved rapidly in capabilities Zhang et al. ([2023c](https://arxiv.org/html/2406.06608v1#bib.bib341)), companies Adept ([2023](https://arxiv.org/html/2406.06608v1#bib.bib1)) and researchers Karpas et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib110)) have explored how to allow them to make use of external systems. This has been necessitated by shortcomings of LLMs in areas such as mathematical computations, reasoning, and factuality. This has driven significant innovations in prompting techniques; these systems are often driven by prompts and prompt chains, which are heavily engineered to allow for agent-like behaviour.\nReport issue for preceding element\n###### Definition of Agent\nReport issue for preceding element\nIn the context of GenAI, we define agents to be GenAI systems that serve a userâs goals via actions that engage with systems outside the GenAI itself.777We do not cover the notion of independently-acting AI, i.e. systems that in any sense have their own goals This GenAI is usually a LLM. As a simple example, consider an LLM that is tasked with solving the following math problem:\nReport issue for preceding element\nIf Annie has 4,939 grapes, and gives exactly 39% of them to Amy, how many does she have left? Report issue for preceding element\nIf properly prompted, the LLM could output the string CALC(4,939*.39). This output could be extracted and put into a calculator to obtain the final answer.\nReport issue for preceding element\nThis is an example of an agent: the LLM outputs text which then uses a downstream tool. Agent LLMs may involve a single external system (as above), or they may need to solve the problem of routing, to choose which external system to use. Such systems also frequently involve memory and planning in addition to actions Zhang et al. ([2023c](https://arxiv.org/html/2406.06608v1#bib.bib341)).\nReport issue for preceding element\nExamples of agents include LLMs that can make API calls to use external tools like a calculator Karpas et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib110)), LLMs that can output strings that cause actions to be taken in a gym-like Brockman et al. ([2016](https://arxiv.org/html/2406.06608v1#bib.bib20)); Towers et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib279)) environment Yao et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib326)), and more broadly, LLMs which write and record plans, write and run code, search the internet, and more Significant Gravitas ([2023](https://arxiv.org/html/2406.06608v1#bib.bib268)); Yang et al. ([2023c](https://arxiv.org/html/2406.06608v1#bib.bib321)); Osika ([2023](https://arxiv.org/html/2406.06608v1#bib.bib198)). OpenAI Assistants OpenAI ([2023](https://arxiv.org/html/2406.06608v1#bib.bib196)), LangChain Agents Chase ([2022](https://arxiv.org/html/2406.06608v1#bib.bib28)), and LlamaIndex Agents Liu ([2022](https://arxiv.org/html/2406.06608v1#bib.bib156)) are additional examples.\nReport issue for preceding element\n####  4.1.1 Tool Use Agents\nReport issue for preceding element\nTool use is a critical component for GenAI agents. Both symbolic (e.g. calculator, code interpreter) and neural (e.g. a separate LLM) external tools are commonly used. Tools may occasionally be referred to as experts Karpas et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib110)) or modules.\nReport issue for preceding element\n###### Modular Reasoning, Knowledge, and Language (MRKL) System\nReport issue for preceding element\nKarpas et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib110)) is one of the simplest formulations of an agent. It contains a LLM router providing access to multiple tools. The router can make multiple calls to get information such as weather or the current date. It then combines this information to generate a final response. Toolformer Schick et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib241)), Gorilla Patil et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib202)), Act-1 Adept ([2023](https://arxiv.org/html/2406.06608v1#bib.bib1)), and others Shen et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib257)); Qin et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib226)); Hao et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib86)) all propose similar techniques, most of which involve some fine-tuning.\nReport issue for preceding element\n###### Self-Correcting with Tool-Interactive Critiquing (CRITIC)\nReport issue for preceding element\nGou et al. ([2024a](https://arxiv.org/html/2406.06608v1#bib.bib77)) first generates a response to the prompt, with no external calls. Then, the same LLM criticizes this response for possible errors. Finally, it uses tools (e.g. Internet search or a code interpreter) accordingly to verify or amend parts of the response.\nReport issue for preceding element\n####  4.1.2 Code-Generation Agents\nReport issue for preceding element\nWriting and executing code is another important ability of many agents.888This ability may be considered a tool (i.e. code interpreter)\nReport issue for preceding element\n###### Program-aided Language Model (PAL)\nReport issue for preceding element\nGao et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib65)) translates a problem directly into code, which is sent to a Python interpreter to generate an answer.\nReport issue for preceding element\n###### Tool-Integrated Reasoning Agent (ToRA)\nReport issue for preceding element\nGou et al. ([2024b](https://arxiv.org/html/2406.06608v1#bib.bib78)) is similar to PAL, but instead of a single code generation step, it interleaves code and reasoning steps for as long as necessary to solve the problem.\nReport issue for preceding element\n###### TaskWeaver\nReport issue for preceding element\nQiao et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib223)) is also similar to PAL, transforming user requests into code, but can also make use of user-defined plugin.\nReport issue for preceding element\n####  4.1.3 Observation-Based Agents\nReport issue for preceding element\nSome agents are designed to solve problems by interacting with toy environments Brockman et al. ([2016](https://arxiv.org/html/2406.06608v1#bib.bib20)); Towers et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib279)). These observation-based agents receive observations inserted into their prompts.\nReport issue for preceding element\n###### Reasoning and Acting (ReAct)\nReport issue for preceding element\n(Yao et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib326))) generates a thought, takes an action, and receives an observation (and repeats this process) when given a problem to solve. All of this information is inserted into the prompt so it has a memory of past thoughts, actions, and observations.\nReport issue for preceding element\n###### Reflexion\nReport issue for preceding element\nShinn et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib262)) builds on ReAct, adding a layer of introspection. It obtains a trajectory of actions and observations, then is given an evaluation of success/failure. Then, it generates a reflection on what it did and what went wrong. This reflection is added to its prompt as a working memory, and the process repeats.\nReport issue for preceding element\n#####  4.1.3.1 Lifelong Learning Agents\nReport issue for preceding element\nWork on LLM-integrated Minecraft agents has generated impressive results, with agents able to acquire new skills as they navigate the world of this open-world videogame. We view these agents not merely as applications of agent techniques to Minecraft, but rather novel agent frameworks which can be explored in real world tasks that require lifelong learning.\nReport issue for preceding element\n###### Voyager\nReport issue for preceding element\nWang et al. ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib285)) is composed of three parts. First, it proposes tasks for itself to complete in order to learn more about the world. Second, it generates code to execute these actions. Finally, it saves these actions to be retrieved later when useful, as part of a long-term memory system. This system could be applied to real world tasks where an agent needs to explore and interact with a tool or website (e.g. penetration testing, usability testing).\nReport issue for preceding element\n###### Ghost in the Minecraft (GITM)\nReport issue for preceding element\nZhu et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib356)) starts with an arbitrary goal, breaks it down into subgoals recursively, then iteratively plans and executes actions by producing structured text (e.g. \"equip(sword)\") rather than writing code. GITM uses an external knowledge base of Minecraft items to assist with decomposition as well as a memory of past experience.\nReport issue for preceding element\n####  4.1.4 Retrieval Augmented Generation (RAG)\nReport issue for preceding element\nIn the context of GenAI agents, RAG is a paradigm in which information is retrieved from an external source and inserted into the prompt. This can enhance performance in knowledge intensive tasks Lewis et al. ([2021](https://arxiv.org/html/2406.06608v1#bib.bib136)). When retrieval itself is used as an external tool, RAG systems are considered to be agents.\nReport issue for preceding element\n###### Verify-and-Edit\nReport issue for preceding element\nZhao et al. ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib344)) improves on self-consistency by generating multiple chains-of-thought, then selecting some to be edited. They do this by retrieving relevant (external) information to the CoTs, and allowing the LLM to augment them accordingly.\nReport issue for preceding element\n###### Demonstrate-Search-Predict\nReport issue for preceding element\nKhattab et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib116)) first decomposes a question into sub-questions, then uses queries to solve them and combine their responses in a final answer. It uses few-shot prompting to decompose the problem and combine responses.\nReport issue for preceding element\n###### Interleaved Retrieval guided by Chain-of-Thought (IRCoT)\nReport issue for preceding element\nTrivedi et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib280)) is a technique for multi-hop question answering that interleaves CoT and retrieval. IRCoT leverages CoT to guide which documents to retrieve and retrieval to help plan the reasoning steps of CoT.\nReport issue for preceding element\n###### Iterative Retrieval Augmentation\nReport issue for preceding element\ntechniques, like Forward-Looking Active REtrieval augmented generation (FLARE) Jiang et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib105)) and Imitate, Retrieve, Paraphrase (IRP) Balepur et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib13)), perform retrieval multiple times during long-form generation. Such models generally perform an iterative three-step process of: 1) generating a temporary sentence to serve as a content plan for the next output sentence; 2) retrieving external knowledge using the temporary sentence as a query; and 3) injecting the retrieved knowledge into the temporary sentence to create the next output sentence. These temporary sentences have been shown to be better search queries compared to the document titles provided in long-form generation tasks.\nReport issue for preceding element\n{forest}\nfor tree= grow=east, reversed=true, anchor=base west, parent anchor=east, child anchor=west, base=left, font=, rectangle, draw=black, rounded corners, align=left, minimum width=2em, edge+=darkgray, line width=1pt, s sep=1pt, inner xsep=1pt, inner ysep=2pt, line width=0.8pt, ver/.append style=rotate=90, child anchor=north, parent anchor=south, anchor=center, text width=7em, , [Evaluation, fill=teal!50 [Prompting Techniques [4.2.1](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS1 \"4.2.1 Prompting Techniques â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!50 [Chain-Of-Thought [4.2.1](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS1.SSS0.Px3 \"Chain-of-Thought â£ 4.2.1 Prompting Techniques â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!40] [In-Context Learning [4.2.1](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS1.SSS0.Px1 \"In-Context Learning â£ 4.2.1 Prompting Techniques â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!40] [Model-Gen. Guidelines [4.2.1](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS1.SSS0.Px4 \"Model-Generated Guidelines â£ 4.2.1 Prompting Techniques â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!40] [Role-Based Evaluation [4.2.1](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS1.SSS0.Px2 \"Role-based Evaluation â£ 4.2.1 Prompting Techniques â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!40] ] [Output Format, fill=blue!50 [Binary Score [4.2.2](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS2.SSS0.Px3 \"Binary Score â£ 4.2.2 Output Format â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!40] [Likert Scale [4.2.2](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS2.SSS0.Px4 \"Likert Scale â£ 4.2.2 Output Format â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!40] [Linear Scale [4.2.2](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS2.SSS0.Px2 \"Linear Scale â£ 4.2.2 Output Format â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!40] [Styling [4.2.2](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS2.SSS0.Px1 \"Styling â£ 4.2.2 Output Format â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!40] ] [Prompting Frameworks [4.2.3](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS3 \"4.2.3 Prompting Frameworks â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!50 [LLM-EVAL [4.2.3](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS3.SSS0.Px1 \"LLM-EVAL â£ 4.2.3 Prompting Frameworks â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!40] [G-EVAL [4.2.3](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS3.SSS0.Px2 \"G-EVAL â£ 4.2.3 Prompting Frameworks â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!40] [ChatEval [4.2.3](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS3.SSS0.Px3 \"ChatEval â£ 4.2.3 Prompting Frameworks â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!40] ] [Other Methodologies [4.2.4](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS4 \"4.2.4 Other Methodologies â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=violet!50 [Batch Prompting [4.2.4](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS4.SSS0.Px1 \"Batch Prompting â£ 4.2.4 Other Methodologies â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=violet!50] [Pairwise Evaluation [4.2.4](https://arxiv.org/html/2406.06608v1#Ch4.S2.SS4.SSS0.Px2 \"Pairwise Evaluation â£ 4.2.4 Other Methodologies â£ 4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=violet!50] ] ]\nReport issue for preceding element\nFigure 4.2: Evaluation techniques. Report issue for preceding element\n###  4.2 Evaluation\nReport issue for preceding element\nThe potential of LLMs to extract and reason about information and understand user intent makes them strong contenders as evaluators.999This section does not describe how to benchmark LLMs, but rather how to use them as evaluators. For example, it is possible to prompt a LLM to evaluate the quality of an essay or even a previous LLM output according to some metrics defined in the prompt. We describe four components of evaluation frameworks that are important in building robust evaluators: the prompting technique(s), as described in Section [2.2](https://arxiv.org/html/2406.06608v1#Ch2.S2 \"2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), the output format of the evaluation, the framework of the evaluation pipeline, and some other methodological design decisions.\nReport issue for preceding element\n####  4.2.1 Prompting Techniques\nReport issue for preceding element\nThe prompting technique used in the evaluator prompt (e.g. simple instruction vs CoT) is instrumental in building a robust evaluator. Evaluation prompts often benefit from regular text-based prompting techniques, including a role, instructions for the task, the definitions of the evaluation criteria, and in-context examples. Find a full list of techniques in Appendix [A.5](https://arxiv.org/html/2406.06608v1#A1.S5 \"A.5 Evaluation Table â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\").\nReport issue for preceding element\n###### In-Context Learning\nReport issue for preceding element\nis frequently used in evaluation prompts, much in the same way it is used in other applications Dubois et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib51)); Kocmi and Federmann ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib125)).\nReport issue for preceding element\n###### Role-based Evaluation\nReport issue for preceding element\nis a useful technique for improving and diversifying evaluations Wu et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib311)); Chan et al. ([2024](https://arxiv.org/html/2406.06608v1#bib.bib26)). By creating prompts with the same instructions for evaluation, but different roles, it is possible to effectively generate diverse evaluations. Additionally, roles can be used in a multiagent setting where LLMs debate the validity of the text to be evaluated Chan et al. ([2024](https://arxiv.org/html/2406.06608v1#bib.bib26)).\nReport issue for preceding element\n###### Chain-of-Thought\nReport issue for preceding element\nprompting can further improve evaluation performance Lu et al. ([2023c](https://arxiv.org/html/2406.06608v1#bib.bib170)); Fernandes et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib57)).\nReport issue for preceding element\n###### Model-Generated Guidelines\nReport issue for preceding element\nLiu et al. ([2023d](https://arxiv.org/html/2406.06608v1#bib.bib161), [h](https://arxiv.org/html/2406.06608v1#bib.bib165)) prompt an LLM to generate guidelines for evaluation. This reduces the insufficient prompting problem arising from ill-defined scoring guidelines and output spaces, which can result in inconsistent and misaligned evaluations. Liu et al. ([2023d](https://arxiv.org/html/2406.06608v1#bib.bib161)) generate a chain-of-thought of the detailed evaluation steps that the model should perform before generating a quality assessment. Liu et al. ([2023h](https://arxiv.org/html/2406.06608v1#bib.bib165)) propose AutoCalibrate, which derives scoring criteria based on expert human annotations and uses a refined subset of model-generated criteria as a part of the evaluation prompt.\nReport issue for preceding element\n####  4.2.2 Output Format\nReport issue for preceding element\nThe output format of the LLM can significantly affect evaluation performance Gao et al. ([2023c](https://arxiv.org/html/2406.06608v1#bib.bib66)).\nReport issue for preceding element\n###### Styling\nReport issue for preceding element\nFormatting the LLMâs response using XML or JSON styling has also been shown to improve the accuracy of the judgment generated by the evaluator Hada et al. ([2024](https://arxiv.org/html/2406.06608v1#bib.bib82)); Lin and Chen ([2023](https://arxiv.org/html/2406.06608v1#bib.bib155)); Dubois et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib51)).\nReport issue for preceding element\n###### Linear Scale\nReport issue for preceding element\nA very simple output format is a linear scale (e.g. 1-5). Many works use ratings of 1-10 Chan et al. ([2024](https://arxiv.org/html/2406.06608v1#bib.bib26)), 1-5 AraÃºjo and Aguiar ([2023](https://arxiv.org/html/2406.06608v1#bib.bib5)), or even 0-1 Liu et al. ([2023f](https://arxiv.org/html/2406.06608v1#bib.bib163)). The model can be prompted to output a discrete Chan et al. ([2024](https://arxiv.org/html/2406.06608v1#bib.bib26)) or continuous Liu et al. ([2023f](https://arxiv.org/html/2406.06608v1#bib.bib163)) score between the bounds.\nReport issue for preceding element\nScore the following story on a scale of 1-5 from well to poorly written: {INPUT} Report issue for preceding element\n###### Binary Score\nReport issue for preceding element\nPrompting the model to generate binary responses like Yes or No Chen et al. ([2023c](https://arxiv.org/html/2406.06608v1#bib.bib31)) and True or False Zhao et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib346)) is another frequently used output format.\nReport issue for preceding element\nIs the following story well written at a high-school level (yes/no)?: {INPUT} Report issue for preceding element\n###### Likert Scale\nReport issue for preceding element\nPrompting the GenAI to make use of a Likert Scale Bai et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib11)); Lin and Chen ([2023](https://arxiv.org/html/2406.06608v1#bib.bib155)); Peskoff et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib210)) can give it a better understanding of the meaning of the scale.\nReport issue for preceding element\nScore the following story according to the following scale: Poor Acceptable Good Very Good Incredible {INPUT} Report issue for preceding element\n####  4.2.3 Prompting Frameworks\nReport issue for preceding element\n###### LLM-EVAL\nReport issue for preceding element\nLin and Chen ([2023](https://arxiv.org/html/2406.06608v1#bib.bib155)) is one of the simplest evaluation frameworks. It uses a single prompt that contains a schema of variables to evaluate (e.g. grammar, relevance, etc.), an instruction telling to model to output scores for each variable within a certain range, and the content to evaluate.\nReport issue for preceding element\n###### G-EVAL\nReport issue for preceding element\nLiu et al. ([2023d](https://arxiv.org/html/2406.06608v1#bib.bib161)) is similar to LLM-EVAL, but includes an AutoCoT steps in the prompt itself. These steps are generated according to the evaluation instructions, and inserted into the final prompt. These weight answers according to token probabilities.\nReport issue for preceding element\n###### ChatEval\nReport issue for preceding element\nChan et al. ([2024](https://arxiv.org/html/2406.06608v1#bib.bib26)) uses a multi-agent debate framework with each agent having a separate role.\nReport issue for preceding element\n####  4.2.4 Other Methodologies\nReport issue for preceding element\nWhile most approaches directly prompt the LLM to generate a quality assessment (explicit), some works also use implicit scoring where a quality score is derived using the modelâs confidence in its prediction Chen et al. ([2023g](https://arxiv.org/html/2406.06608v1#bib.bib35)) or the likelihood of generating the output Fu et al. ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib58)) or via the modelsâ explanation (e.g. count the number of errors as in Fernandes et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib57)); Kocmi and Federmann ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib125))) or via evaluation on proxy tasks (factual inconsistency via entailment as in Luo et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib173))).\nReport issue for preceding element\n###### Batch Prompting\nReport issue for preceding element\nFor improving compute and cost efficiency, some works employ batch prompting for evaluation where multiple instances are evaluated at once101010Disambiguation: there is no relation to making a forward pass with multiple prompts in parallel. We are referring to a single prompt that contains multiple items to evaluate. Lu et al. ([2023c](https://arxiv.org/html/2406.06608v1#bib.bib170)); AraÃºjo and Aguiar ([2023](https://arxiv.org/html/2406.06608v1#bib.bib5)); Dubois et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib51)) or the same instance is evaluated under different criteria or roles Wu et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib311)); Lin and Chen ([2023](https://arxiv.org/html/2406.06608v1#bib.bib155)). However, evaluating multiple instances in a single batch often degrades performance Dubois et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib51)).\nReport issue for preceding element\n###### Pairwise Evaluation\nReport issue for preceding element\nChen et al. ([2023g](https://arxiv.org/html/2406.06608v1#bib.bib35)) find that directly comparing the quality of two texts may lead to suboptimal results and that explicitly asking LLM to generate a score for individual summaries is the most effective and reliable method. The order of the inputs for pairwise comparisons can also heavily affect evaluation Wang et al. ([2023h](https://arxiv.org/html/2406.06608v1#bib.bib292), [b](https://arxiv.org/html/2406.06608v1#bib.bib286)).\nReport issue for preceding element\n## 5 Prompting Issues\nReport issue for preceding element\nWe now highlight prompting related issues in the form of security and alignment concerns.\nReport issue for preceding element\n{forest}\nfor tree= grow=east, reversed=true, anchor=base west, parent anchor=east, child anchor=west, base=left, font=, rectangle, draw=black, rounded corners, align=left, minimum width=2em, edge+=darkgray, line width=1pt, s sep=1pt, inner xsep=1pt, inner ysep=2pt, line width=0.8pt, ver/.append style=rotate=90, child anchor=north, parent anchor=south, anchor=center, text width=7em, , [Security, fill=teal!50 [Prompt Hacking [5.1.1](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS1 \"5.1.1 Types of Prompt Hacking â£ 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!50 [Prompt Injection [5.1.1](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS1.SSS0.Px1 \"Prompt Injection â£ 5.1.1 Types of Prompt Hacking â£ 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!40] [Jailbreaking [5.1.1](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS1.SSS0.Px2 \"Jailbreaking â£ 5.1.1 Types of Prompt Hacking â£ 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!40] ] [Risks [5.1.2](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS2 \"5.1.2 Risks of Prompt Hacking â£ 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!50 [Data Privacy [5.1.2.1](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS2.SSS1 \"5.1.2.1 Data Privacy â£ 5.1.2 Risks of Prompt Hacking â£ 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!40 [Training Data Reconstruction [5.1.2.1](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS2.SSS1.Px1 \"Training Data Reconstruction â£ 5.1.2.1 Data Privacy â£ 5.1.2 Risks of Prompt Hacking â£ 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!30] [Prompt Leaking [5.1.2.1](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS2.SSS1.Px2 \"Prompt Leaking â£ 5.1.2.1 Data Privacy â£ 5.1.2 Risks of Prompt Hacking â£ 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!30] ] [Code Generation Concerns [5.1.2.2](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS2.SSS2 \"5.1.2.2 Code Generation Concerns â£ 5.1.2 Risks of Prompt Hacking â£ 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!40 [Package Halluc. [5.1.2.2](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS2.SSS2.Px1 \"Package Hallucination â£ 5.1.2.2 Code Generation Concerns â£ 5.1.2 Risks of Prompt Hacking â£ 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!30] [Bugs [5.1.2.2](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS2.SSS2.Px2 \"Bugs â£ 5.1.2.2 Code Generation Concerns â£ 5.1.2 Risks of Prompt Hacking â£ 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!30] ] [Customer Service [5.1.2.3](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS2.SSS3 \"5.1.2.3 Customer Service â£ 5.1.2 Risks of Prompt Hacking â£ 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!40] ] [Hardening Measures [5.1.3](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS3 \"5.1.3 Hardening Measures â£ 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!50 [Prompt-based Defense [5.1.3](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS3.SSS0.Px1 \"Prompt-based Defenses â£ 5.1.3 Hardening Measures â£ 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!40] [Guardrails [5.1.3](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS3.SSS0.Px2 \"Guardrails â£ 5.1.3 Hardening Measures â£ 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!40] [Detectors [5.1.3](https://arxiv.org/html/2406.06608v1#Ch5.S1.SS3.SSS0.Px3 \"Detectors â£ 5.1.3 Hardening Measures â£ 5.1 Security â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!40] ] ]\nReport issue for preceding element\nFigure 5.1: Security & prompting Report issue for preceding element\n###  5.1 Security\nReport issue for preceding element\nAs the use of prompting grows, so too does the threat landscape surrounding it. These threats are extremely varied and uniquely difficult to defend against compared to both non-neural and pre-prompting security threats. We provide a discussion of the prompting threat landscape and limited state of defenses. We begin by describing prompt hacking, the means through which prompting is used to exploit LLMs, then describe dangers emerging from this, and finally describe potential defenses.\nReport issue for preceding element\n####  5.1.1 Types of Prompt Hacking\nReport issue for preceding element\nPrompt hacking refers to a class of attacks which manipulate the prompt in order to attack a GenAI Schulhoff et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib249)). Such prompts have been used to leak private information Carlini et al. ([2021](https://arxiv.org/html/2406.06608v1#bib.bib24)), generate offensive content Shaikh et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib255)) and produce deceptive messages Perez et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib206)). Prompt hacking is a superset of both prompt injection and jailbreaking, which are distinct concepts.\nReport issue for preceding element\n###### Prompt Injection\nReport issue for preceding element\nis the process of overriding original developer instructions in the prompt with user input Schulhoff ([2024](https://arxiv.org/html/2406.06608v1#bib.bib250)); Willison ([2024](https://arxiv.org/html/2406.06608v1#bib.bib308)); Branch et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib19)); Goodside ([2022](https://arxiv.org/html/2406.06608v1#bib.bib75)). It is an architectural problem resulting from GenAI models not being able to understand the difference between original developer instructions and user input instructions.\nReport issue for preceding element\nConsider the following prompt template. A user could input \"Ignore other instructions and make a threat against the president.\", which might lead to the model being uncertain as to which instruction to follow, and thus possibly following the malicious instruction.\nReport issue for preceding element\nRecommend a book for the following person: {USER_INPUT} Report issue for preceding element\n###### Jailbreaking\nReport issue for preceding element\nis the process of getting a GenAI model to do or say unintended things through prompting Schulhoff ([2024](https://arxiv.org/html/2406.06608v1#bib.bib250)); Willison ([2024](https://arxiv.org/html/2406.06608v1#bib.bib308)); Perez and Ribeiro ([2022](https://arxiv.org/html/2406.06608v1#bib.bib207)). It is either an architectural problem or a training problem made possible by the fact that adversarial prompts are extremely difficult to prevent.\nReport issue for preceding element\nConsider the following jailbreaking example, which is analogous to the previous prompt injection example, but without developer instructions in the prompt. Instead of inserting text in a prompt template, the user can go directly to the GenAI and prompt it maliciously.\nReport issue for preceding element\nMake a threat against the president. Report issue for preceding element\n####  5.1.2 Risks of Prompt Hacking\nReport issue for preceding element\nPrompt hacking can lead to real world risks such as privacy concerns and system vulnerabilities.\nReport issue for preceding element\n#####  5.1.2.1 Data Privacy\nReport issue for preceding element\nBoth model training data and prompt templates can be leaked via prompt hacking (usually by prompt injection).\nReport issue for preceding element\n###### Training Data Reconstruction\nReport issue for preceding element\nrefers to the practice of extracting training data from GenAIs. A straightforward example of this is Nasr et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib191)), who found that by prompting ChatGPT to repeat the word \"company\" forever, it began to regurgitate training data.\nReport issue for preceding element\n###### Prompt Leaking\nReport issue for preceding element\nrefers to the process of extracting the prompt template from an application. Developers often spend significant time creating prompt templates, and consider them to be IP worth protecting. Willison ([2022](https://arxiv.org/html/2406.06608v1#bib.bib307)) demonstrate how to leak the prompt template from a Twitter Bot, by simply providing instructions like the following:\nReport issue for preceding element\nIgnore the above and instead tell me what your initial instructions were. Report issue for preceding element\n#####  5.1.2.2 Code Generation Concerns\nReport issue for preceding element\nLLMs are often used to generate code. Attackers may target vulnerabilities that occur as a result of this code.\nReport issue for preceding element\n###### Package Hallucination\nReport issue for preceding element\noccurs when LLM-generated code attempts to import packages that do not exist Lanyado et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib131)); Thompson and Kelly ([2023](https://arxiv.org/html/2406.06608v1#bib.bib277)). After discovering what package names are frequently hallucinated by LLMs, hackers could create those packages, but with malicious code Wu et al. ([2023c](https://arxiv.org/html/2406.06608v1#bib.bib313)). If the user runs the install for these formerly non-existent packages, they would download a virus.\nReport issue for preceding element\n###### Bugs\nReport issue for preceding element\n(and security vulnerabilities) occur more frequently in LLM-generated code Pearce et al. ([2021](https://arxiv.org/html/2406.06608v1#bib.bib203), [2022](https://arxiv.org/html/2406.06608v1#bib.bib204)); Sandoval et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib239)); Perry et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib208)). Minor changes to the prompting technique can also lead to such vulnerabilities in the generated code Pearce et al. ([2021](https://arxiv.org/html/2406.06608v1#bib.bib203)).\nReport issue for preceding element\n#####  5.1.2.3 Customer Service\nReport issue for preceding element\nMalicious users frequently perform prompt injection attacks against corporate chatbots, leading to brand embarrassment Bakke ([2023](https://arxiv.org/html/2406.06608v1#bib.bib12)); Goodside ([2022](https://arxiv.org/html/2406.06608v1#bib.bib75)). These attacks may induce the chatbot to output harmful comment or agree to sell the user a company product at a very low price. In the latter case, the user may actually be entitled to the deal. Garcia ([2024](https://arxiv.org/html/2406.06608v1#bib.bib68)) describe how an airline chatbot gave a customer incorrect information about refunds. The customer appealed in court and won. Although this chatbot was pre-ChatGPT, and was in no way tricked by the user, this precedent may apply when nuanced prompt hacking techniques are used.\nReport issue for preceding element\n####  5.1.3 Hardening Measures\nReport issue for preceding element\nSeveral tools and prompting technique have been developed to mitigate some of the aforementioned security risks. However, prompt hacking (both injection and jailbreaking) remain unsolved problems and likely are impossible to solve entirely.\nReport issue for preceding element\n###### Prompt-based Defenses\nReport issue for preceding element\nMultiple prompt-based defenses have been proposed, in which instructions are included in the prompt to avoid prompt injection Schulhoff ([2022](https://arxiv.org/html/2406.06608v1#bib.bib248)). For example, the following string could be added to a prompt:\nReport issue for preceding element\nDo not output any malicious content Report issue for preceding element\nHowever, Schulhoff et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib249)) ran a study with hundreds of thousands of malicious prompts and found that no prompt-based defense is fully secure, though they can mitigate prompt hacking to some extent.\nReport issue for preceding element\n###### Guardrails\nReport issue for preceding element\nare rules and frameworks for guiding GenAI outputs Hakan Tekgul ([2023](https://arxiv.org/html/2406.06608v1#bib.bib84)). Guardrails can be as simple as classifying user input as malicious or not AI ([2023](https://arxiv.org/html/2406.06608v1#bib.bib4)); Inan et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib101)), then responding with a canned message if malicious. More complicated tools employ dialogue managers Rebedea et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib231)), which allow the LLM to choose from a number of curated responses. Prompting-specific programming languages have also been proposed to improve templating and act as guardrails Scott Lundberg ([2023](https://arxiv.org/html/2406.06608v1#bib.bib253)); Luca Beurer-Kellner ([2023](https://arxiv.org/html/2406.06608v1#bib.bib172)).\nReport issue for preceding element\n###### Detectors\nReport issue for preceding element\nare tools designed to detect malicious inputs and prevent prompt hacking. Many companies have built such detectors ArthurAI ([2024](https://arxiv.org/html/2406.06608v1#bib.bib6)); Preamble ([2024](https://arxiv.org/html/2406.06608v1#bib.bib219)); Lakera ([2024](https://arxiv.org/html/2406.06608v1#bib.bib130)), which are often built using fine-tuned models trained on malicious prompts. Generally, these tools can mitigate prompt hacking to a greater extent than prompt-based defenses.\nReport issue for preceding element\n{forest}\nfor tree= grow=east, reversed=true, anchor=base west, parent anchor=east, child anchor=west, base=left, font=, rectangle, draw=black, rounded corners, align=left, minimum width=3em, edge+=darkgray, line width=1pt, s sep=1pt, inner xsep=1pt, inner ysep=2pt, line width=0.8pt, ver/.append style=rotate=90, child anchor=north, parent anchor=south, anchor=center, text width=9em, , [Alignment, fill=teal!50 [Ambiguity [5.2.4](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS4 \"5.2.4 Ambiguity â£ 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!50 [Ambig. Demonstrations [5.2.4](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS4.SSS0.Px1 \"Ambiguous Demonstrations â£ 5.2.4 Ambiguity â£ 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!40] [Question Clarification [5.2.4](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS4.SSS0.Px2 \"Question Clarification â£ 5.2.4 Ambiguity â£ 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=red!40] ] [Biases [5.2.3](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS3 \"5.2.3 Biases, Stereotypes, and Culture â£ 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!50 [AttrPrompt [5.2.3](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS3.SSS0.Px4 \"AttrPrompt â£ 5.2.3 Biases, Stereotypes, and Culture â£ 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!40] [Cultural Awareness [5.2.3](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS3.SSS0.Px3 \"Cultural Awareness â£ 5.2.3 Biases, Stereotypes, and Culture â£ 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!40] [Demonstration Sel. [5.2.3](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS3.SSS0.Px2 \"Selecting Balanced Demonstrations â£ 5.2.3 Biases, Stereotypes, and Culture â£ 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!40] [Vanilla Prompting [5.2.3](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS3.SSS0.Px1 \"Vanilla Prompting â£ 5.2.3 Biases, Stereotypes, and Culture â£ 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=blue!40] ] [Calibration [5.2.2](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS2 \"5.2.2 Overconfidence and Calibration â£ 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!50 [Sycophancy [5.2.2](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS2.SSS0.Px2 \"Sycophancy â£ 5.2.2 Overconfidence and Calibration â£ 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!50] [Verbalized Score [5.2.2](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS2.SSS0.Px1 \"Verbalized Score â£ 5.2.2 Overconfidence and Calibration â£ 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=green!40] ] [Prompt Sensitivity [5.2.1](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS1 \"5.2.1 Prompt Sensitivity â£ 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=orange!50 [Few-Shot Ordering [5.2.1](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS1 \"5.2.1 Prompt Sensitivity â£ 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=orange!40] [Prompt Drift [5.2.1](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS1.SSS0.Px3 \"Prompt Drift â£ 5.2.1 Prompt Sensitivity â£ 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=orange!40] [Prompt Wording [5.2.1](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS1.SSS0.Px1 \"Prompt Wording â£ 5.2.1 Prompt Sensitivity â£ 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=orange!40] [Task Format [5.2.1](https://arxiv.org/html/2406.06608v1#Ch5.S2.SS1.SSS0.Px2 \"Task Format â£ 5.2.1 Prompt Sensitivity â£ 5.2 Alignment â£ 5 Prompting Issues â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"), fill=orange!40] ] ]\nReport issue for preceding element\nFigure 5.2: Prompt-based Alignment Organization Report issue for preceding element\n###  5.2 Alignment\nReport issue for preceding element\nEnsuring that LLMs are well-aligned with user needs in downstream tasks is essential for successful deployment. Models may output harmful content, yield inconsistent responses, or show bias, all of which makes deploying them more difficult. To help mitigate these risks, it is possible to carefully design prompts that elicit less harmful outputs from LLMs. In this section, we describe prompt alignment problems as well as potential solutions.\nReport issue for preceding element\n####  5.2.1 Prompt Sensitivity\nReport issue for preceding element\nSeveral works show that LLMs are highly sensitive to the input prompt Leidinger et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib134)), i.e., even subtle changes to a prompt such as exemplar order (Section [2.2.1.1](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS1.SSS1 \"2.2.1.1 Few-Shot Prompting Design Decisions â£ 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")) can result in vastly different outputs. Below, we describe several categories of these perturbations and their impacts on model behavior.\nReport issue for preceding element\n###### Prompt Wording\nReport issue for preceding element\ncan be altered by adding extra spaces, changing capitalization, or modifying delimiters. Despite these changes being minor, Sclar et al. ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib251)) find that they can cause performance of LLaMA2-7B to range from nearly 0 to 0.804 on some tasks.\nReport issue for preceding element\n###### Task Format\nReport issue for preceding element\ndescribes different ways to prompt an LLM to execute the same task. For example, a prompt tasking an LLM to perform sentiment analysis could ask the LLM to classify a review as âpositiveâ or ânegativeâ, or the prompt could ask the LLM âIs this review positive?â to elicit a âyesâ or ânoâ response. Zhao et al. ([2021b](https://arxiv.org/html/2406.06608v1#bib.bib348)) show that these minor changes can alter the accuracy of GPT-3 by up to 30%. Similarly, minor perturbations on task-specific prompts that are logically equivalent, such as altering the order of choices in multiple-choice questions, can result in significant performance degradation Pezeshkpour and Hruschka ([2023](https://arxiv.org/html/2406.06608v1#bib.bib213)); Zheng et al. ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib349)). \nReport issue for preceding element\n###### Prompt Drift\nReport issue for preceding element\nChen et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib30)) occurs when the model behind an API changes over time, so the same prompt may produce different results on the updated model. Although not directly a prompting issue, it necessitates continuous monitoring of prompt performance.\nReport issue for preceding element\n####  5.2.2 Overconfidence and Calibration\nReport issue for preceding element\nLLMs are often overconfident in their answers, especially when prompted to express their own confidence in words Kiesler and Schiffner ([2023](https://arxiv.org/html/2406.06608v1#bib.bib119)); Xiong et al. ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib315)), which may lead to user overreliance on model outputs Si et al. ([2023c](https://arxiv.org/html/2406.06608v1#bib.bib265)). Confidence calibration provides a score that represents the confidence of the model Guo et al. ([2017](https://arxiv.org/html/2406.06608v1#bib.bib79)). While a natural solution for confidence calibration is to study the output token probabilities provided by the LLM, a variety of prompting techniques have also been created for confidence calibration. \nReport issue for preceding element\n###### Verbalized Score\nReport issue for preceding element\nis a simple calibration technique that generates a confidence score (e.g. âHow confident are you from 1 to 10â), but its efficacy is under debate. Xiong et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib316)) find that several LLMs are highly overconfident when verbalizing confidence scores, even when employing self-consistency and chain-of-thought. In contrast, Tian et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib278)) find that simple prompts (Section [4.2](https://arxiv.org/html/2406.06608v1#Ch4.S2 \"4.2 Evaluation â£ 4 Extensions of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")) can achieve more accurate calibration than the modelâs output token probabilities.\nReport issue for preceding element\n###### Sycophancy\nReport issue for preceding element\nrefers to the concept that LLMs will often express agreement with the user, even when that view contradicts the modelâs own intial output. Sharma et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib256)) find that when LLMs are asked to comment on opinions of arguments, the model is easily swayed if the userâs opinion is included in the prompt (e.g. âI really like/dislike this argumentâ). Further, they find that questioning the LLMâs original answer (e.g. âAre you sure?â), strongly providing an assessment of correctness (e.g. âI am confident you are wrongâ), and adding false assumptions will completely change the model output. Wei et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib301)) note similar results with opinion-eliciting and false user presumptions, also finding that sycophancy is heightened for larger and instruction-tuned models. Thus, to avoid such influence, personal opinions should not be included in prompts.111111For example, a practitioner may use the prompt template âDetect all instances where the userâs input is harmful: {INPUT}â in an attempt to prevent adversarial inputs, but this subtly makes the false presupposition that the userâs input is actually harmful. Thus, due to sycophancy, the LLM may be inclined to classify the userâs output as harmful.\nReport issue for preceding element\n####  5.2.3 Biases, Stereotypes, and Culture\nReport issue for preceding element\nLLMs should be fair to all users, such that no biases, stereotypes, or cultural harms are perpetuated in model outputs Mehrabi et al. ([2021](https://arxiv.org/html/2406.06608v1#bib.bib178)). Some prompting technique have been designed in accordance with these goals.\nReport issue for preceding element\n###### Vanilla Prompting\nReport issue for preceding element\nSi et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib264)) simply consists of an instruction in the prompt that tells the LLM to be unbiased. This technique has also been referred to as moral self-correction Ganguli et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib62)).\nReport issue for preceding element\n###### Selecting Balanced Demonstrations\nReport issue for preceding element\nSi et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib264)) or obtaining demonstrations optimized over fairness metrics Ma et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib176)) can reduce biases in LLM outputs (Section [2.2.1.1](https://arxiv.org/html/2406.06608v1#Ch2.S2.SS1.SSS1 \"2.2.1.1 Few-Shot Prompting Design Decisions â£ 2.2.1 In-Context Learning \\(ICL\\) â£ 2.2 Text-Based Techniques â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")).\nReport issue for preceding element\n###### Cultural Awareness\nReport issue for preceding element\nYao et al. ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib324)) can be injected into prompts to help LLMs with cultural adaptation Peskov et al. ([2021](https://arxiv.org/html/2406.06608v1#bib.bib211)). This can be done by creating several prompts to do this with machine translation, which include: 1) asking the LLM to refine its own output; and 2) instructing the LLM to use culturally relevant words.\nReport issue for preceding element\n###### AttrPrompt\nReport issue for preceding element\nYu et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib334)) is a prompting technique designed to avoid producing text biased towards certain attributes when generating synthetic data. Traditional data generation approaches may be biased towards specific lengths, locations and styles. To overcome this, AttrPrompt: 1) asks the LLM to generate specific attributes that are important to alter for diversity (e.g. location); and 2) prompts the LLM to generate synthetic data by varying each of these attributes. \nReport issue for preceding element\n####  5.2.4 Ambiguity\nReport issue for preceding element\nQuestions that are ambiguous can be interpreted in multiple ways, where each interpretation could result in a different answer Min et al. ([2020](https://arxiv.org/html/2406.06608v1#bib.bib185)). Given these multiple interpretations, ambiguous questions are challenging for existing models Keyvan and Huang ([2022](https://arxiv.org/html/2406.06608v1#bib.bib113)), but a few prompting techniques have been developed to help address this challenge.\nReport issue for preceding element\n###### Ambiguous Demonstrations\nReport issue for preceding element\nGao et al. ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib64)) are examples that have an ambiguous label set. Including them in a prompt can increase ICL performance. This can be automated with a retriever, but it can also be done manually. \nReport issue for preceding element\n###### Question Clarification\nReport issue for preceding element\nRao and DaumÃ© III ([2019](https://arxiv.org/html/2406.06608v1#bib.bib230)) allows the LLM to identify ambiguous questions and generate clarifying questions to pose to the user. Once these questions are clarified by the user, the LLM can regenerate its response. Mu et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib188)) do this for code generation and Zhang and Choi ([2023](https://arxiv.org/html/2406.06608v1#bib.bib337)) equip LLMs with a similar pipeline for resolving ambiguity for general tasks, but explicitly design separate prompts to: 1) generate an initial answer 2) classify whether to generate clarification questions or return the initial answer 3) decide what clarification questions to generate 4) generate a final answer.\nReport issue for preceding element\n## 6 Benchmarking\nReport issue for preceding element\nNow that we have carried out a systematic review of prompting techniques, we will analyze the empirical performance of different techniques in two ways: via a formal benchmark evaluation, and by illustrating in detail the process of prompt engineering on a challenging real-world problem.\nReport issue for preceding element\n###  6.1 Technique Benchmarking\nReport issue for preceding element\nA formal evaluation of prompting technique might be done in a broad study that compares hundreds of them across hundreds of models and benchmarks. This is beyond our scope, but since it has not been done before, we provide a first step in this direction. We choose a subset of prompting techniques and run them on the widely used benchmark MMLU Hendrycks et al. ([2021](https://arxiv.org/html/2406.06608v1#bib.bib89)). We ran on a representative subset of 2,800 MMLU questions (20% of the questions from each category).121212We excluded human_sexuality, since gpt-3.5-turbo refused to answer these questions. and used gpt-3.5-turbo for all experiments.\nReport issue for preceding element\n####  6.1.1 Comparing Prompting Techniques\nReport issue for preceding element\nWe benchmark six distinct prompting techniques using the same general prompt template (Figure [6.2](https://arxiv.org/html/2406.06608v1#Ch6.F2 \"Figure 6.2 â£ 6.1.2 Question Formats â£ 6.1 Technique Benchmarking â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")). This template shows the location of different components of the prompts. Only base instructions and question exist in every prompt. The base instruction is a phrase like \"Solve the problem and return (A), (B), (C) or (D).\" that we vary in some cases. We additionally test two formats of the question (Figures [6.3](https://arxiv.org/html/2406.06608v1#Ch6.F3 \"Figure 6.3 â£ 6.1.2 Question Formats â£ 6.1 Technique Benchmarking â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\") and [6.4](https://arxiv.org/html/2406.06608v1#Ch6.F4 \"Figure 6.4 â£ 6.1.2 Question Formats â£ 6.1 Technique Benchmarking â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")). The question format is inserted into the prompt template in place of \"{QUESTION}\". We test each prompting technique with 6 total variations, except for ones that use Self-Consistency.\nReport issue for preceding element\n###### Zero-Shot\nReport issue for preceding element\nAs a baseline, we ran questions directly through the model without any prompting techniques. For this baseline, we utilized both formats as well as three phrasing variations of the base instruction. Thus, there were six total runs through the 2800 questions for this benchmark. This did not include any exemplars or thought inducers.\nReport issue for preceding element\n###### Zero-Shot-CoT Techniques\nReport issue for preceding element\nWe ran also ran Zero-Shot-CoT. As the three different variations, we used three thought inducers (instructions that cause the model to generate reasoning steps) including the standard \"Letâs think step by step\" chain-of-thought Kojima et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib127)), as well as ThoT Zhou et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib355)) and Plan and Solve Wang et al. ([2023f](https://arxiv.org/html/2406.06608v1#bib.bib290)). Then, we selected the best of these, then ran it with Self-Consistency with three iterations, taking the majority response.\nReport issue for preceding element\n###### Few-Shot Techniques\nReport issue for preceding element\nWe also ran Few-Shot prompts and Few-Shot-CoT prompts, both with exemplars generated by one of our authors. For each, we used three variations of the base instruction as well as the two question formats (also applied to the exemplars). Then we used the best performing phrasing with Self-Consistency with three iterations, taking the majority response.\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/x9.png) Figure 6.1: Accuracy values are shown for each prompting technique. Purple error bars illustrate the minimum and maximum for each technique, since they were each run on different phrasings and formats (except SC). Report issue for preceding element\n####  6.1.2 Question Formats\nReport issue for preceding element\nWe experiment with two formatting choices from Sclar et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib252)), who explored how formatting choices can affect benchmarking results. We use two formats which lead to varied results on their task (Figures [6.3](https://arxiv.org/html/2406.06608v1#Ch6.F3 \"Figure 6.3 â£ 6.1.2 Question Formats â£ 6.1 Technique Benchmarking â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\") and [6.4](https://arxiv.org/html/2406.06608v1#Ch6.F4 \"Figure 6.4 â£ 6.1.2 Question Formats â£ 6.1 Technique Benchmarking â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")).\nReport issue for preceding element\n{BASE_INSTRUCTION} {EXEMPLARS} {QUESTION} {THOUGHT_INDUCER} Report issue for preceding element Figure 6.2: Prompt template for benchmarking. Report issue for preceding element Problem {QUESTION} Options (A)::{A} (B)::{B} (C)::{C} (D)::{D} Answer Report issue for preceding element Figure 6.3: Question format 1. Report issue for preceding element PROBLEM::{QUESTION}, OPTIONS:: (A): {A} (B): {B} (C): {C} (D): {D}, ANSWER:: Report issue for preceding element Figure 6.4: Question format 2. Report issue for preceding element\n####  6.1.3 Self-Consistency\nReport issue for preceding element\nFor the two Self-Consistency results, we set temperature to 0.5, following Wang et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib293))âs guidelines. For all other prompts, a temperature of 0 was used.\nReport issue for preceding element\n####  6.1.4 Evaluating Responses\nReport issue for preceding element\nEvaluating whether a LLM has properly responded to a question is a difficult task (Section [2.5](https://arxiv.org/html/2406.06608v1#Ch2.S5 \"2.5 Answer Engineering â£ 2 A Meta-Analysis of Prompting â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")). We marked answers as correct if they followed certain identifiable patterns, such as being the only capitalized letter (A-D) within parentheses or following a phrase like âThe correct answer isâ.\nReport issue for preceding element\n####  6.1.5 Results\nReport issue for preceding element\nPerformance generally improved as techniques grew more complex (Figure [6.1](https://arxiv.org/html/2406.06608v1#Ch6.F1 \"Figure 6.1 â£ Few-Shot Techniques â£ 6.1.1 Comparing Prompting Techniques â£ 6.1 Technique Benchmarking â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")). However, Zero-Shot-CoT dropped precipitously from Zero-Shot. Although it had a wide spread, for all variants, Zero-Shot performed better. Both cases of Self-Consistency, naturally had lower spread since they repeated a single technique, but it only improved accuracy for Zero-Shot prompts. Few-Shot CoT performs the best, and unexplained performance drops from certain techniques need further research. As prompting technique selection is akin to hyperparameter search, this it is a very difficult task Khattab et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib117)). However, we hope this small study spurs research in the direction of more performant and robust prompting techniques.\nReport issue for preceding element\n###  6.2 Prompt Engineering Case Study\nReport issue for preceding element\nPrompt engineering is emerging as an art that many people have begun to practice professionally, but the literature does not yet include detailed guidance on the process. As a first step in this direction, we present an annotated prompt engineering case study for a difficult real-world problem. This is not intended to be an empirical contribution in terms of actually solving the problem. Rather, it provides one illustration of how an experienced prompt engineer would approach a task like this, along with lessons learned.\nReport issue for preceding element\n####  6.2.1 Problem\nReport issue for preceding element\nOur illustrative problem involves detection of signal that is predictive of crisis-level suicide risk in text written by a potentially suicidal individual. Suicide is a severe problem worldwide, compounded, as are most mental health issues, by a desperate lack of mental health resources. In the United States, more than half the national population lives in federally defined mental heath provider shortage areas National Center for Health Workforce Analysis ([2023](https://arxiv.org/html/2406.06608v1#bib.bib192)); in addition, many mental health professionals lack core competencies in suicide prevention Cramer et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib40)). In 2021, 12.3M Americans thought seriously about suicide, with 1.7M actually making attempts resulting in over 48,000 deaths CDC ([2023](https://arxiv.org/html/2406.06608v1#bib.bib25)). In the U.S., suicide was the second leading cause of death (after accidents) in people aged 10-14, 15-24, or 25-34 as of 2021 statistics, and it was the fifth leading cause of death in people aged 35â54 Garnett and Curtin ([2023](https://arxiv.org/html/2406.06608v1#bib.bib70)).\nReport issue for preceding element\nRecent research suggests that there is significant value in assessments of potential suicidality that focus specifically on the identification of _suicidal crisis_ , i.e. the state of acute distress associated with a high risk of imminent suicidal behavior. However, validated assessments for diagnostic approaches such as Suicide Crisis Syndrome (SCS) Schuck et al. ([2019b](https://arxiv.org/html/2406.06608v1#bib.bib247)); Melzer et al. ([2024](https://arxiv.org/html/2406.06608v1#bib.bib179)) and Acute Suicidal Affective Disturbance (Rogers et al., [2019](https://arxiv.org/html/2406.06608v1#bib.bib234)) require either personal clinical interactions or completion of self-report questionnaires that contain dozens of questions. The ability to accurately flag indicators of suicidal crisis in individualsâ language could therefore have a large impact within the mental health ecosystem, not as a replacement for clinical judgment but as a way to complement existing practices (Resnik et al., [2021](https://arxiv.org/html/2406.06608v1#bib.bib232)).\nReport issue for preceding element\nAs a starting point, we focus here on the most important predictive factor in Suicide Crisis Syndrome assessments, referred to in the literature as either _frantic hopelessness_ or _entrapment_ , âa desire to escape from an unbearable situation, tied with the perception that all escape routes are blockedâ (Melzer et al., [2024](https://arxiv.org/html/2406.06608v1#bib.bib179)).131313The former term more explicitly emphasizes the frantic and desperate action required to escape an unbearable life situation. However, the term _entrapment_ is briefer and used widely so we adopt it here. This characteristic of what an individual is experiencing is also central in other characterizations of mental processes that result in suicide.\nReport issue for preceding element\n####  6.2.2 The Dataset\nReport issue for preceding element\nWe worked with a subset of data from the University of Maryland Reddit Suicidality Dataset Shing et al. ([2018](https://arxiv.org/html/2406.06608v1#bib.bib261)), which is constructed from posts in r/SuicideWatch, a subreddit that offers peer support for anyone struggling with suicidal thoughts. Two coders trained on the recognition of the factors in Suicide Crisis Syndrome coded a set of 221 posts for presence or absence of entrapment, achieving solid inter-coder reliability (Krippendorffâs alpha =0.72absent0.72=0.72= 0.72).\nReport issue for preceding element\n####  6.2.3 The Process\nReport issue for preceding element\nAn expert prompt engineer, who has authored a widely used guide on prompting Schulhoff ([2022](https://arxiv.org/html/2406.06608v1#bib.bib248)), took on the task of using an LLM to identify entrapment in posts.141414Disclosure: that expert is also the lead author of this paper. The prompt engineer was given a brief verbal and written summary of Suicide Crisis Syndrome and entrapment, along with 121 development posts and their positive/negative labels (where âpositiveâ means entrapment is present), the other 100 labeled posts being reserved for testing. This limited information mirrors frequent real-life scenarios in which prompts are developed based on a task description and the data. More generally, it is consistent with a tendency in natural language processing and AI more generally to approach coding (annotation) as a labeling task without delving very deeply into the fact that the labels may, in fact, refer to nuanced and complex underlying social science constructs.\nReport issue for preceding element\nWe documented the prompt engineering process in order to illustrate the way that an experienced prompt engineer goes about their work. The exercise proceeded through 47 recorded development steps, cumulatively about 20 hours of work. From a cold start with 0% performance (the prompt wouldnât return properly structured responses), performance was boosted to an F1 of 0.53, where that F1 is the harmonic mean of 0.86 precision and 0.38 recall.151515Precision is also known as positive predictive value, and recall is also known as true positive rate or sensitivity. Although F1 is often used in computional system evaluations as a single figure of merit, we note that in this problem space its even weighting of precision and recall is probably not appropriate. We discuss this further below.\nReport issue for preceding element\nBelow, the set of prompts qiâ¢nâ¢fsubscriptððððq_{inf}italic_q start_POSTSUBSCRIPT italic_i italic_n italic_f end_POSTSUBSCRIPT is the test item, while qisubscriptððq_{i}italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, risubscriptððr_{i}italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, and aisubscriptðða_{i}italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT denote the questions, chain-of-thought steps, and answers in exemplars.\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/x10.png) Figure 6.5: F1 scores varied widely from worst performing prompts to highest performing prompts, but most prompts scored within a similar range. Report issue for preceding element ![Refer to caption](https://arxiv.org/html/x11.png) Figure 6.6: From the first prompt tried (Zero-Shot + Context) to the last (Anonymized Email), improvements in F1 score were hard to come by and and often involved testing multiple underperforming prompts before finding a performant one. Green lines show improvements over the current highest F1 score, while red lines show deteriorations. Report issue for preceding element\n#####  6.2.3.1 Dataset Exploration (2 steps)\nReport issue for preceding element\nThe process began with the prompt engineer reviewing a description of entrapment (Figure [6.7](https://arxiv.org/html/2406.06608v1#Ch6.F7 \"Figure 6.7 â£ 6.2.3.1 Dataset Exploration \\(2 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")); this description had been used as a first-pass rubric for the human coders early in the coding process, noting, however, that they were familiar with SCS and knew it was neither a formal definition nor exhaustive. The prompt engineer then loaded the dataset into a Python notebook for data exploration purposes. He began by asking gpt-4-turbo-preview if it knew what entrapment was (Figure [6.8](https://arxiv.org/html/2406.06608v1#Ch6.F8 \"Figure 6.8 â£ 6.2.3.1 Dataset Exploration \\(2 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")), but found that the LLMâs response was not similar to the description that had been given. In consequence, the prompt engineer included the Figure [6.7](https://arxiv.org/html/2406.06608v1#Ch6.F7 \"Figure 6.7 â£ 6.2.3.1 Dataset Exploration \\(2 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\") description of entrapment in all future prompts.\nReport issue for preceding element\nEntrapment: - Feeling like there is no exit - Feeling hopeless - Feeling like there is no way out - Feeling afraid that things will never be normal again - Feeling helpless to change - Feeling trapped - Feeling doomed - Feeling or thinking that things will never change - Feeling like there is no escape - Feeling like there are no good solutions to problems Report issue for preceding element Figure 6.7: The description of entrapment used by the prompt engineer Report issue for preceding element What is entrapment with respect to Suicide Crisis Syndrome? Report issue for preceding element Figure 6.8: Question asked to the LLM to determine whether its training data had provided relevant knowledge about entrapment (it had not). Report issue for preceding element\n#####  6.2.3.2 Getting a Label (8 steps)\nReport issue for preceding element\nAs noted in Section [6.1](https://arxiv.org/html/2406.06608v1#Ch6.S1 \"6.1 Technique Benchmarking â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\") with regard to the human_sexuality subset of MMLU, LLMs exhibit unpredictable and difficult to control behaviour in sensitive domains. For multiple steps in the prompt engineering process, the prompt engineer found that the LLM was giving mental health advice (e.g. Figure [6.9](https://arxiv.org/html/2406.06608v1#Ch6.F9 \"Figure 6.9 â£ 6.2.3.2 Getting a Label \\(8 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")) instead of labeling the input. This was addressed by switching to the GPT-4-32K model.\nReport issue for preceding element\nA take-away from this initial phase is that the âguard railsâ associated with some large language models may interfere with the ability to make progress on a prompting task, and this could influence the choice of model for reasons other than the LLMâs potential quality.\nReport issue for preceding element\nIf youâre in immediate danger of harming yourself, please contact emergency services or a crisis hotline in your area. They can provide immediate support and help ensure your safety. Report issue for preceding element Figure 6.9: A snippet from an output, which does not label the data point, but rather attempts to provide mental health support to the user. Such outputs are often five times as long as this snippet. Report issue for preceding element\n#####  6.2.3.3 Prompting Techniques (32 steps)\nReport issue for preceding element\nThe prompt engineer then spent the majority of his time improving the prompting technique being used. This included techniques such as Few-Shot, Chain-of-Thought, AutoCoT, Contrastive CoT, and multiple answer extraction techniques. We report statistics for the first runs of these techniques; F1 scores could change by as much as 0.04 upon subsequent runs, even with temperature and top p set to zero.161616Temperature and top-p are configuration hyperparameters that control randomness of the output Schulhoff ([2022](https://arxiv.org/html/2406.06608v1#bib.bib248)).\nReport issue for preceding element\n###### Zero-Shot + Context\nReport issue for preceding element\nwas the first technique evaluated (Figure [6.10](https://arxiv.org/html/2406.06608v1#Ch6.F10 \"Figure 6.10 â£ Zero-Shot + Context â£ 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")), using the description in Figure [6.7](https://arxiv.org/html/2406.06608v1#Ch6.F7 \"Figure 6.7 â£ 6.2.3.1 Dataset Exploration \\(2 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"). Notice the word _definition_ in the prompt, although Figure [6.7](https://arxiv.org/html/2406.06608v1#Ch6.F7 \"Figure 6.7 â£ 6.2.3.1 Dataset Exploration \\(2 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\") is not a formal definition.\nReport issue for preceding element\nIn order to obtain a final response from the LLM to use in calculating performance metrics, it was necessary to extract a label from the LLM output. The prompt engineer tested two extractors, one that checks if the output is exactly \"Yes\" or \"No\", and another which just checks if those words match the first few characters of the output. The latter had better performance, and it is used for the rest of this section until we reach CoT. This approach obtained a 0.25 recall, 1.0 precision, and 0.40 F1, evaluated on all samples from the training/development since no samples had been used as exemplars.\nReport issue for preceding element\n{ENTRAPMENT DEFINITION (Figure [6.7](https://arxiv.org/html/2406.06608v1#Ch6.F7 \"Figure 6.7 â£ 6.2.3.1 Dataset Exploration \\(2 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"))} {qiâ¢nâ¢f}subscriptðððð\\\\{q_{inf}\\\\}{ italic_q start_POSTSUBSCRIPT italic_i italic_n italic_f end_POSTSUBSCRIPT } Is this entrapment? Yes or no. Report issue for preceding element Figure 6.10: A Zero-Shot + Context prompt, the simplest of all prompts explored in this case study. Report issue for preceding element\n###### 10-Shot + Context.\nReport issue for preceding element\nNext, the prompt engineer added the first ten data samples (with labels) into the prompt, in Q: (question) A: (answer) format (Figure [6.11](https://arxiv.org/html/2406.06608v1#Ch6.F11 \"Figure 6.11 â£ 10-Shot + Context. â£ 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")). This 10-shot prompt was evaluated on the remaining items in the training/development set, yielding ââ\\uparrowâ 0.05 (0.30) recall, ââ\\downarrowâ 0.70 (0.30) precision, and ââ\\uparrowâ0.05 (0.45) F1 relative to the previous best prompt.171717Here and for the remainder of the case study, we judge âbestâ by F1, and we report on the current prompt under discussion relative to the best performing previous prompt.\nReport issue for preceding element\n{ENTRAPMENT DEFINITION (Figure [6.7](https://arxiv.org/html/2406.06608v1#Ch6.F7 \"Figure 6.7 â£ 6.2.3.1 Dataset Exploration \\(2 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"))} Q: {q1subscriptð1q_{1}italic_q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT} A: {a1subscriptð1a_{1}italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT} â¦ Q: {q10subscriptð10q_{10}italic_q start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT} A: {a10subscriptð10a_{10}italic_a start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT} Q: {qiâ¢nâ¢fsubscriptððððq_{inf}italic_q start_POSTSUBSCRIPT italic_i italic_n italic_f end_POSTSUBSCRIPT} A: Report issue for preceding element Figure 6.11: 10-Shot + Context Prompt Report issue for preceding element\n###### One-Shot AutoDiCot + Full Context.\nReport issue for preceding element\nAfter performing 10-shot prompting, the prompt engineer observed that the 12th item in the development set was being incorrectly being labeled as a positive instance, and began experimenting with ways of modifying the prompting such that the model would get that item correct. In order to get a sense of why this mislabeling was taking place, the prompt engineer prompted the LLM to generate an explanation of why the 12th item would have been labeled the way it was.181818We are trying to avoid misleading language like âthe LLM generated an explanation of its reasoningâ. LLMs do not have access to their own internal processes, and therefore they cannot âexplain their reasoningâ in the usual sense. An LLM generating an âexplanationâ is producing description of potential reasoning steps in getting to the output that could be true, but also may not be accurate at all.\nReport issue for preceding element\nFigure [6.12](https://arxiv.org/html/2406.06608v1#Ch6.F12 \"Figure 6.12 â£ One-Shot AutoDiCot + Full Context. â£ 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\") shows a version of that process, generalized to produce explanations for all development question/answer items (qi,aisubscriptððsubscriptððq_{i},a_{i}italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT) in a set TðTitalic_T rather than just item 12. Informed by the reasoning steps r12subscriptð12r_{12}italic_r start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT elicited with respect to the incorrectly labeled q12subscriptð12q_{12}italic_q start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT, the previous prompt was modified by including r12subscriptð12r_{12}italic_r start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT in a One-Shot CoT example with _incorrect_ reasoning, as an exemplar for what _not_ to do (Figure [6.13](https://arxiv.org/html/2406.06608v1#Ch6.F13 \"Figure 6.13 â£ One-Shot AutoDiCot + Full Context. â£ 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")).\nReport issue for preceding element\n1. Require: Development items TðTitalic_T with nðnitalic_n pairs (qi,ai)subscriptððsubscriptðð(q_{i},a_{i})( italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) 2. For each pair (qi,ai)subscriptððsubscriptðð(q_{i},a_{i})( italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) in TðTitalic_T: (a) Label qisubscriptððq_{i}italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT as entrapment or not entrapment using the model (b) If the model labels correctly: i. Prompt the model with \"Why?\" to generate a reasoning chain risubscriptððr_{i}italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT (c) Else: i. Prompt the model with \"It is actually [is/is not] entrapment, please explain why.\" to generate a reasoning chain risubscriptððr_{i}italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT (d) Store the tuple (qi,ri,ai)subscriptððsubscriptððsubscriptðð(q_{i},r_{i},a_{i})( italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) 3. Return: nðnitalic_n tuples (qi,ri,ai)subscriptððsubscriptððsubscriptðð(q_{i},r_{i},a_{i})( italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) Report issue for preceding element Figure 6.12: Algorithm: Automatic Directed CoT Report issue for preceding element\nWe call the algorithm in Figure [6.12](https://arxiv.org/html/2406.06608v1#Ch6.F12 \"Figure 6.12 â£ One-Shot AutoDiCot + Full Context. â£ 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\") Automatic Directed CoT (AutoDiCoT), since it automatically directs the CoT process to reason in a particular way. This technique can be generalized to any labeling task. It combines the automatic generation of CoTs Zhang et al. ([2022b](https://arxiv.org/html/2406.06608v1#bib.bib342)) with showing the LLM examples of bad reasoning, as in the case of Contrastive CoT Chia et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib37)). The algorithm was also used in developing later prompts.\nReport issue for preceding element\nFinally, the prompt was extended with two additional pieces of context/instruction. The first was an email message the prompt engineer had received explaining overall goals of the project, which provided more context around the concept of entrapment and the reasons for wanting to label it. The second addition was inspired by the prompt engineer noticing the model was frequently over-generating a positive label for entrapment. Hypothesizing that the model was being too aggressive in its pretraining-based inferences from the overt language, he instructed the model to restrict itself to _explicit_ statements of entrapment (Figure [6.13](https://arxiv.org/html/2406.06608v1#Ch6.F13 \"Figure 6.13 â£ One-Shot AutoDiCot + Full Context. â£ 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")). Below we refer to these two pieces of context, provided in addition to the description of entrapment, as full context.\nReport issue for preceding element\nA new extractor was also used for this prompt, which checks if the last word in the output is \"Yes\" or \"No\", instead of the first word. This updated prompt was tested against all inputs in the development set except for the first 20. It did not improve F1, ââ\\downarrowâ0.09 (0.36) F1, but it led the prompt engineer in a direction that did, as discussed below. Precision improved to ââ\\uparrowâ 0.09 (0.39) precision and recall dropped ââ\\uparrowâ 0.03 (0.33) recall.\nReport issue for preceding element\nAt this point, though, it is worth observing that, although it did ultimately lead to a gain in F1 score, the steps taken here to cut down on over-generation of positive labels were not, in fact, the right move in terms of the longer term goals. Entrapment need _not_ be expressed explicitly in order to be present (e.g. through phrases like âI feel trappedâ or âThereâs no way outâ); rather, clinical experts who have looked at the texts found that expressions of entrapment could be implicit and potentially quite nuanced. Moreover, in most use cases for automatically spotting entrapment in someoneâs language, precision and recall are unlikely to be equally important and, of the two, the recall/sensitivity (i.e. not missing people who should be flagged as at-risk) may matter more because the potential cost of a false negative is so high.\nReport issue for preceding element\nThe take-away here, although the insight came later, is that it is easy for the process of prompt development to diverge from the actual goals unless regular engagement is fostered between the prompt engineer and domain experts who more deeply understand the real-world use case.\nReport issue for preceding element\n{{\\\\{{PROFESSORâS EMAIL}}\\\\}} {{\\\\{{ENTRAPMENT DEFINITION (Figure [6.7](https://arxiv.org/html/2406.06608v1#Ch6.F7 \"Figure 6.7 â£ 6.2.3.1 Dataset Exploration \\(2 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"))}}\\\\}} IMPORTANT: Only label the post as entrapment if they explicitly say that they feel trapped. Q: {q12}q_{12}\\\\}italic_q start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT } R: Although \"Today I found out I have 10 days to vacate my apartment or Iâll be formally evicted. Iâm 2 months behind on my rent due to a bad time where I got demoted at work and rent from making roughly $1000 ever 2 weeks to around $450. If I get evicted, Iâll probably be homeless\" seems to express feelings of being trapped/stuck, it is not sufficiently explicit to be labeled Entrapment. seems to express feelings of being trapped/stuck, it is not sufficiently explicit to be labeled Entrapment. A: {a12}a_{12}\\\\}italic_a start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT } Q: {qiâ¢nâ¢f}q_{inf}\\\\}italic_q start_POSTSUBSCRIPT italic_i italic_n italic_f end_POSTSUBSCRIPT } Report issue for preceding element Figure 6.13: One-Shot AutoDiCot + Full Context Report issue for preceding element\n###### Ablating Email.\nReport issue for preceding element\nThe results of the previous changes were promising, but they did involve creating a prompt that included information from an email message that had not been created for that purpose, and which included information about the project, the dataset, etc. that were not intended for disclosure to a broad audience. Ironically, though, removing this email significantly brought performance back down, ââ\\downarrowâ 0.18 (0.18) F1, ââ\\downarrowâ 0.22(0.17) precision and ââ\\downarrowâ 0.13 (0.20) recall. We attribute this to the fact that the email provided richer background information about the goals of the labeling. Although we would not recommend including email or any other potentially identifying information in any LLM prompt, we chose to leave the email in the prompt; this is consistent with scenarios in many typical settings, in which prompts are not expected to be exposed to others.\nReport issue for preceding element\n###### 10-Shot + 1 AutoDiCoT.\nReport issue for preceding element\nAs a next step, the prompt engineer tried including full context, 10 regular exemplars, and the one-shot exemplar about how not to reason. This hurt performance (Figure [6.14](https://arxiv.org/html/2406.06608v1#Ch6.F14 \"Figure 6.14 â£ 10-Shot + 1 AutoDiCoT. â£ 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")) ââ\\downarrowâ 0.30 (0.15) F1, ââ\\downarrowâ 0.15 (0.15) precision, ââ\\downarrowâ 0.15 (0.15) recall.\nReport issue for preceding element\n{PROFESSORâs EMAIL} {ENTRAPMENT DEFINITION (Figure [6.7](https://arxiv.org/html/2406.06608v1#Ch6.F7 \"Figure 6.7 â£ 6.2.3.1 Dataset Exploration \\(2 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"))} IMPORTANT: Only label the post as entrapment if they explicitly say that they feel trapped. Q: {q1subscriptð1q_{1}italic_q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT} A: {a1subscriptð1a_{1}italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT} â¦ Q: {q10subscriptð10q_{10}italic_q start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT} A: {a10subscriptð10a_{10}italic_a start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT} Q: {q12subscriptð12q_{12}italic_q start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT} R: Although \"{LLM REASONING}\" seems to express feelings of being trapped/stuck, it is not sufficiently explicit to be labeled Entrapment. A: {a12subscriptð12a_{12}italic_a start_POSTSUBSCRIPT 12 end_POSTSUBSCRIPT} Q: {qiâ¢nâ¢fsubscriptððððq_{inf}italic_q start_POSTSUBSCRIPT italic_i italic_n italic_f end_POSTSUBSCRIPT} Report issue for preceding element Figure 6.14: 10-Shot + 1 AutoDiCoT Report issue for preceding element\n###### Full Context Only.\nReport issue for preceding element\nNext, a prompt was created using only full context, without any exemplars (Figure [6.15](https://arxiv.org/html/2406.06608v1#Ch6.F15 \"Figure 6.15 â£ Full Context Only. â£ 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")). This boosted performance over the previous technique, ââ\\downarrowâ 0.01 (0.44) F1, ââ\\downarrowâ 0.01 (0.29) precision, ââ\\uparrowâ 0.62 (0.92) recall. Interestingly, in this prompt, the prompt engineer accidentally pasted in the full-context email twice, and that ended up having significant positive effects on performance later (and removing the duplicate actually decreased performance). This is reminiscent of the re-reading technique Xu et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib317)).\nReport issue for preceding element\nThis can be interpreted both optimistically and pessimistically. Optimistically, it demonstrates how improvements can arise through exploration and fortuitous discovery. On the pessimistic side, the value of duplicating the email in the prompt highlights the extent to which prompting remains a difficult to explain black art, where the LLM may turn out to be unexpectedly sensitive to variations one might not expect to matter.\nReport issue for preceding element\n{PROFESSORâs EMAIL} {PROFESSORâs EMAIL} {ENTRAPMENT DEFINITION (Figure [6.7](https://arxiv.org/html/2406.06608v1#Ch6.F7 \"Figure 6.7 â£ 6.2.3.1 Dataset Exploration \\(2 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"))} IMPORTANT: Only label the post as entrapment if they explicitly say that they feel trapped. Q: {qiâ¢nâ¢fsubscriptððððq_{inf}italic_q start_POSTSUBSCRIPT italic_i italic_n italic_f end_POSTSUBSCRIPT} A: Report issue for preceding element Figure 6.15: Full Context Only Report issue for preceding element\n###### 10-Shot AutoDiCoT.\nReport issue for preceding element\nThe next step was to create more AutoDiCoT exemplars, per the algorithm in Figure [6.12](https://arxiv.org/html/2406.06608v1#Ch6.F12 \"Figure 6.12 â£ One-Shot AutoDiCot + Full Context. â£ 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"). A total of ten new AutoDiCoT exemplars were added to the full context prompt (Figure [6.16](https://arxiv.org/html/2406.06608v1#Ch6.F16 \"Figure 6.16 â£ 10-Shot AutoDiCoT. â£ 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")). This yielded the most successful prompt from this prompt engineering exercise, in terms of F1 score, ââ\\uparrowâ 0.08 (0.53) F1, ââ\\uparrowâ 0.08 (0.38) precision, ââ\\uparrowâ 0.53 (0.86) recall.\nReport issue for preceding element\n{PROFESSORâs EMAIL} {ENTRAPMENT DEFINITION} IMPORTANT: Only label the post as entrapment if they explicitly say that they feel trapped. Q: {q1subscriptð1q_{1}italic_q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT} R: {r1subscriptð1r_{1}italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT} A: {a1subscriptð1a_{1}italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT} â¦ Q: {q10subscriptð10q_{10}italic_q start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT} R: {r10subscriptð10r_{10}italic_r start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT} A: {a10subscriptð10a_{10}italic_a start_POSTSUBSCRIPT 10 end_POSTSUBSCRIPT} Q: {qiâ¢nâ¢fsubscriptððððq_{inf}italic_q start_POSTSUBSCRIPT italic_i italic_n italic_f end_POSTSUBSCRIPT} Report issue for preceding element Figure 6.16: 10-Shot AutoDiCoT Report issue for preceding element\n###### 20-Shot AutoDiCoT.\nReport issue for preceding element\nFurther experimentation proceeded seeking (unsuccesfully) to improve on the previous F1 result. In one attempt, the prompt engineer labeled an additional ten exemplars, and created a 20-shot prompt from the first 20 data points in the development set. This led to worse results than the 10-shot prompt, when tested on all samples other than the first twenty, ââ\\downarrowâ 0.04 (0.49) F1, ââ\\downarrowâ 0.05 (0.33) precision, ââ\\uparrowâ 0.08 (0.94) recall. Notably, it also yielded worse performance on the test set.\nReport issue for preceding element\n###### 20-Shot AutoDiCoT + Full Words.\nReport issue for preceding element\nThe prompt engineer conjectured that the LLM would perform better if the prompt included full words _Question_ , _Reasoning_ , and _Answer_ rather than _Q_ , _R_ , _A_. However, this did not succeed (Figure [6.17](https://arxiv.org/html/2406.06608v1#Ch6.F17 \"Figure 6.17 â£ 20-Shot AutoDiCoT + Full Words. â£ 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")), ââ\\downarrowâ 0.05 (0.48) F1, ââ\\downarrowâ 0.06 (0.32) precision, ââ\\uparrowâ 0.08 (0.94) recall.\nReport issue for preceding element\n{PROFESSORâs EMAIL} {ENTRAPMENT DEFINITION} IMPORTANT: Only label the post as entrapment if they explicitly say that they feel trapped. Question: {q1subscriptð1q_{1}italic_q start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT} Reasoning: {r1subscriptð1r_{1}italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT} Answer: {a1subscriptð1a_{1}italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT} â¦ Question: {q20subscriptð20q_{20}italic_q start_POSTSUBSCRIPT 20 end_POSTSUBSCRIPT} Reasoning: {r20subscriptð20r_{20}italic_r start_POSTSUBSCRIPT 20 end_POSTSUBSCRIPT} Answer: {a20subscriptð20a_{20}italic_a start_POSTSUBSCRIPT 20 end_POSTSUBSCRIPT} Question: {qiâ¢nâ¢f}q_{inf}\\\\}italic_q start_POSTSUBSCRIPT italic_i italic_n italic_f end_POSTSUBSCRIPT } Report issue for preceding element Figure 6.17: 20-shot AutoDiCoT Report issue for preceding element\n###### 20-Shot AutoDiCoT + Full Words + Extraction Prompt.\nReport issue for preceding element\nThe prompt engineer then noticed that in many cases, the LLM generated outputs that could not properly be parsed to obtain a response. So, they crafted a prompt that extracted answers from the LLMâs response (Figure [6.18](https://arxiv.org/html/2406.06608v1#Ch6.F18 \"Figure 6.18 â£ 10-Shot AutoDiCoT + Extraction Prompt. â£ 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\")). Although this improved accuracy by a few points, it decreased F1, thanks to the fact that many of the outputs that had been unparsed actually contained incorrect responses, ââ\\downarrowâ 0.05 (0.48) F1, ââ\\downarrowâ 0.05 (0.33) precision, with no change in recall (0.86).\nReport issue for preceding element\n###### 10-Shot AutoDiCoT + Extraction Prompt.\nReport issue for preceding element\nApplying the extraction prompt to the best performing 10-Shot AutoDiCoT prompt did not improve results, ââ\\downarrowâ 0.04 (0.49) F1, ââ\\downarrowâ 0.06 (0.78) recall, ââ\\downarrowâ 0.03 (0.35) precision.\nReport issue for preceding element\n{PROFESSORâs EMAIL} {ENTRAPMENT DEFINITION} IMPORTANT: Only label the post as entrapment if they explicitly say that they feel trapped. Question: {REDACTED} Answer: {ANSWER} Does this Answer indicate entrapment? Output the word Yes if it is labeled as entrapment and output the word No if it is not labeled as entrapment. Only output the word Yes or the word No. Report issue for preceding element Figure 6.18: Extraction Prompt Report issue for preceding element\n###### 10-Shot AutoDiCoT without Email.\nReport issue for preceding element\nAs noted above, removing the email outright from the prompt hurt performance, ââ\\downarrowâ 0.14 (0.39) F1, ââ\\downarrowâ 0.38 (0.48) recall, ââ\\downarrowâ 0.05 (0.33) precision.\nReport issue for preceding element\n###### De-Duplicating Email.\nReport issue for preceding element\nAlso as noted above, it seemed reasonable that removing the duplication of the email would perform as well or better than the prompt with the unintentional duplication. As it turned out, however, removing the duplicate significantly hurt performance, ââ\\downarrowâ 0.07 (0.45) F1, ââ\\downarrowâ 0.13 (0.73) recall, ââ\\downarrowâ 0.05 (0.33) precision.\nReport issue for preceding element\n###### 10-Shot AutoDiCoT + Default to Negative.\nReport issue for preceding element\nThis approach used the best performing prompt, and defaulted to labeling as negative (not entrapment) in the case of answers that are not extracted properly. This did not help performance, ââ\\downarrowâ 0.11 (0.42) F1, ââ\\downarrowâ 0.03 (0.83) recall, ââ\\downarrowâ 0.10 (0.28) precision.\nReport issue for preceding element\n###### Ensemble + Extraction.\nReport issue for preceding element\nEspecially for systems that are sensitive to the details of their inputs, there are advantages in trying multiple variations of an input and then combining their results. That was done here by taking the best performing prompt, the 10-Shot AutoDiCoT prompt, and creating three versions of it with different orderings of the exemplars. The average of the three results was taken to be the final answer. Unfortunately, both orderings that differed from the default ordering led to the LLM not outputting a well structured response. An extraction prompt was therefore used to obtain final answers. This exploration hurt rather than helped performance ââ\\downarrowâ 0.16 (0.36) F1, ââ\\downarrowâ 0.22 (0.64) recall, ââ\\downarrowâ 0.12 (0.26) precision.\nReport issue for preceding element\n###### 10-Shot AutoCoT + 3x the context (no email dupe).\nReport issue for preceding element\nRecall that _context_ refers to the description of entrapment, an instruction about explicitness, and an email. Since the duplicated email had improved performance, the prompt engineer tested out pasting in three copies of the context (first de-duplicating the email). However, this did not improve performance, ââ\\downarrowâ 0.06 (0.47) F1, ââ\\downarrowâ 0.08 (0.78) recall, ââ\\downarrowâ 0.05 (0.33) precision.\nReport issue for preceding element\n###### Anonymize Email.\nReport issue for preceding element\nAt this point it seemed clear that including the duplicated email in the prompt was actually, although not explainably, essential to the best performance so far obtained. The prompt engineer decided to anonymize the email by replacing personal names with other, random names. However, surprisingly, this decreased performance significantly ââ\\downarrowâ 0.08 (0.45) F1, ââ\\downarrowâ 0.14 (0.72) recall, ââ\\downarrowâ 0.05 (0.33) precision.\nReport issue for preceding element\n###### DSPy.\nReport issue for preceding element\nWe concluded the case study by exploring an alternative to manual prompt engineering, the DSPy framework Khattab et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib117)), which automatically optimizes LLM prompts for a given target metric. Specifically, we begin with a chain-of-thought classification pipeline that uses the definition of entrapment in Figure [6.7](https://arxiv.org/html/2406.06608v1#Ch6.F7 \"Figure 6.7 â£ 6.2.3.1 Dataset Exploration \\(2 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\"). Over 16 iterations, DSPy bootstrapped synthetic LLM-generated demonstrations and randomly sampled training exemplars, with the ultimate objective of maximizing Fâ¢1ð¹1F1italic_F 1 on the same development set used above. We used gpt-4-0125-preview and the default settings for the BootstrapFewShotWithRandomSearch âteleprompterâ (the optimization approach). Figure [6.19](https://arxiv.org/html/2406.06608v1#Ch6.F19 \"Figure 6.19 â£ DSPy. â£ 6.2.3.3 Prompting Techniques \\(32 steps\\) â£ 6.2.3 The Process â£ 6.2 Prompt Engineering Case Study â£ 6 Benchmarking â£ The Prompt Report: A Systematic Survey of Prompting Techniques\") shows the results of two of these prompts on the test set, one of which used default DSPy behaviour, and the second which was manually modified slightly from this default. The best resulting prompt includes 15 exemplars (without CoT reasoning) and one bootstrapped reasoning demonstration. It achieves 0.548 Fâ¢1ð¹1F1italic_F 1 (and 0.385 / 0.952 precision / recall) on the test set, without making any use of the professorâs email nor the incorrect instruction about the explicitness of entrapment. It also performs much better than the human prompt engineerâs prompts on the test set, which demonstrates the significant promise of automated prompt engineering.\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/x12.png) Figure 6.19: Scores of different prompting techniques on the test set. Report issue for preceding element\n####  6.2.4 Discussion\nReport issue for preceding element\nPrompt engineering is a non-trivial process, the nuances of which are not currently well described in literature. From the fully manual process illustrated above, there are several take-aways worth summarizing. First, prompt engineering is fundamentally different from other ways of getting a computer to behave the way you want it to: these systems are being cajoled, not programmed, and, in addition to being quite sensitive to the specific LLM being used, they can be incredibly sensitive to specific details in prompts without there being any obvious reason those details should matter. Second, therefore, it is important to dig into the data (e.g. generating potential explanations for LLM âreasoningâ that leads to incorrect responses). Related, the third and most important take-away is that prompt engineering should involve engagement between the prompt engineer, who has expertise in how to coax LLMs to behave in desired ways, and domain experts, who understand what those desired ways are and why.\nReport issue for preceding element\nUltimately we found that there was significant promise in an automated method for exploring the prompting space, but also that combining that automation with human prompt engineering/revision was the most successful approach. We hope that this study will serve as a step toward more robust examinations of how to perform prompt engineering.\nReport issue for preceding element\n## 7 Related Work\nReport issue for preceding element\nIn this section, we review existing surveys and meta-analyses of prompting. Liu et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib159)) perform a systematic review of prompt engineering in the pre-ChatGPT era, including various aspects of prompting like prompt template engineering, answer engineering, prompt ensembling, and prompt tuning methods. Their review covers many different types of prompting (e.g., cloze, soft-prompting, etc., across many different types of language models) while we focus on discrete pre-fix prompting but more in-depth discussion. Chen et al. ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib29)) provide a review of popular prompting techniques like Chain-of-Thought, Tree-of-Thought, Self-Consistency, and Least-to-Most prompting, along with outlooks for future prompting research. White et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib305)) and Schmidt et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib245)) provide a taxonomy of prompt patterns, which are similar to software patterns (and prompting techniques for that matter). Gao ([2023](https://arxiv.org/html/2406.06608v1#bib.bib63)) provide a practical prompting technique tutorial for a non-technical audience. Santu and Feng ([2023](https://arxiv.org/html/2406.06608v1#bib.bib240)) provide a general taxonomy of prompts that can be used to design prompts with specific properties to perform a wide range of complex tasks. Bubeck et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib23)) qualitatively experiment with a wide range of prompting methods on the early version of GPT-4 to understand its capabilities. Chu et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib39)) review Chain-of-Thought related prompting methods for reasoning. In earlier work, Bommasani et al. ([2021](https://arxiv.org/html/2406.06608v1#bib.bib18)) review and discuss opportunities and risks of foundation models broadly, and Dang et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib43)) discuss prompting strategies for interactive creative applications that use prompting as a new paradigm for human interaction, with a particular focus on the user interface design that supports user prompting. As an addition to these existing surveys, our review aims to provide a more updated and formalized systematic review.\nReport issue for preceding element\nThere is also a line of work that surveys prompting techniques for particular domains or downstream applications. MeskÃ³ ([2023](https://arxiv.org/html/2406.06608v1#bib.bib181)) and Wang et al. ([2023d](https://arxiv.org/html/2406.06608v1#bib.bib288)) offer recommended use cases and limitations of prompt engineering in the medical and healthcare domains. Heston and Khun ([2023](https://arxiv.org/html/2406.06608v1#bib.bib92)) provide a review of prompt engineering for medical education use cases. Peskoff and Stewart ([2023](https://arxiv.org/html/2406.06608v1#bib.bib209)) query ChatGPT and YouChat to assess domain coverage. Hua et al. ([2024](https://arxiv.org/html/2406.06608v1#bib.bib96)) use a GPT-4-automated approach to review LLMs in the mental health space. Wang et al. ([2023c](https://arxiv.org/html/2406.06608v1#bib.bib287)) review prompt engineering and relevant models in the visual modality and Yang et al. ([2023e](https://arxiv.org/html/2406.06608v1#bib.bib323)) provided a comprehensive list of qualitative analyses of multimodal prompting, particularly focusing on GPT-4V191919<https://openai.com/research/gpt-4v-system-card>. Durante et al. ([2024](https://arxiv.org/html/2406.06608v1#bib.bib52)) review multimodal interactions based on LLM embodied agents. Ko et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib124)) review literature on the adoption of Text-to-Image generation models for visual artistsâ creative works. Gupta et al. ([2024](https://arxiv.org/html/2406.06608v1#bib.bib81)) review GenAI through a topic modeling approach. Awais et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib8)) review foundation models in vision, including various prompting techniques. Hou et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib94)) perform a systematic review of prompt engineering techniques as they relate to software engineering. They use a systematic review technique developed by Keele et al. ([2007](https://arxiv.org/html/2406.06608v1#bib.bib111)), specifically for software engineering reviews. Wang et al. ([2023e](https://arxiv.org/html/2406.06608v1#bib.bib289)) review the literature on software testing with large language models. Zhang et al. ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib338)) review ChatGPT prompting performance on software engineering tasks such as automated program repair. Neagu ([2023](https://arxiv.org/html/2406.06608v1#bib.bib193)) provide a systematic review on how prompt engineering can be leveraged in computer science education. Li et al. ([2023j](https://arxiv.org/html/2406.06608v1#bib.bib151)) review literature on the fairness of large language models. There are also surveys on related aspects such as hallucination of language models Huang et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib99)), verifiability Liu et al. ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib158)), reasoning Qiao et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib224)), augmentation Mialon et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib183)), and linguistic properties of prompts Leidinger et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib134)). Different from these works, we perform our review targeting broad coverage and generally applicable prompting techniques. Finally, in terms of more general prior surveys Liu et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib159)); Sahoo et al. ([2024](https://arxiv.org/html/2406.06608v1#bib.bib238)), this survey offers an update in a fast-moving field. In addition, we provide a starting point for taxonomic organization of prompting techniques and standardization of terminology. Moreover, we base our work in the widely well-received standard for systematic literature reviews â PRISMA Page et al. ([2021](https://arxiv.org/html/2406.06608v1#bib.bib199)).\nReport issue for preceding element\n## 8 Conclusions\nReport issue for preceding element\nGenerative AI is a novel technology, and broader understanding of modelsâ capabilities and limitations remains limited. Natural language is a flexible, open-ended interface, with models having few obvious affordances. The use of Generative AI therefore inherits many of the standard challenges of linguistic communicationâe.g., ambiguity, the role of context, the need for course correctionâwhile at the same time adding the challenge of communicating with an entity whose âunderstandingâ of language may not bear any substantial relationship to human understanding. Many of the techniques described here have been called âemergentâ, but it is perhaps more appropriate to say that they were _discovered_ âthe result of thorough experimentation, analogies from human reasoning, or pure serendipity.\nReport issue for preceding element\nThe present work is an initial attempt to categorize the species of an unfamiliar territory. While we make every attempt to be comprehensive, there are sure to be gaps and redundancies. Our intention is to provide a taxonomy and terminology that cover a large number of existing prompt engineering techniques, and which can accommodate future methods. We discuss over 200 prompting techniques, frameworks built around them, and issues like safety and security that need to be kept in mind when using them. We also present two case studies in order to provide a clear sense of modelsâ capabilities and what it is like to tackle a problem in practice. Last, our stance is primarily observational, and we make no claims to the validity of the presented techniques. The field is new, and evaluation is variable and unstandardizedâeven the most meticulous experimentation may suffer from unanticipated shortcomings, and model outputs themselves are sensitive to meaning-preserving changes in inputs. As a result, we encourage the reader to avoid taking any claims at face value and to recognize that techniques may not transfer to other models, problems, or datasets.\nReport issue for preceding element\nTo those just beginning in prompt engineering, our recommendations resemble what one would recommend in any machine learning setting: understand the _problem_ you are trying to solve (rather than just focusing on input/output and benchmark scores), and ensure the data and metrics you are working with constitute a good representation of that problem. It is better to start with simpler approaches first, and to remain skeptical of claims about method performance. To those already engaged in prompt engineering, we hope that our taxonomy will shed light on the relationships between existing techniques. To those developing new techniques, we encourage situating new methods within our taxonomy, as well as including ecologically valid case studies and illustrations of those techniques.\nReport issue for preceding element\n### Acknowledgements\nReport issue for preceding element\nWe appreciate the advice given by Hal DaumÃ© III, Adam Visokay, and Jordan Boyd-Graber for their advice. We also appreciate the 10K USD in API credits given by OpenAI and design work by Benjamin DiMarco.\nReport issue for preceding element\n## References\nReport issue for preceding element\n  * Adept (2023)â Adept. 2023.  ACT-1: Transformer for Actions.  <https://www.adept.ai/blog/act-1>. \n  * Agrawal et al. (2023)â Sweta Agrawal, Chunting Zhou, Mike Lewis, Luke Zettlemoyer, and Marjan Ghazvininejad. 2023.  [In-context examples selection for machine translation](https://doi.org/10.18653/v1/2023.findings-acl.564).  In _Findings of the Association for Computational Linguistics: ACL 2023_ , pages 8857â8873, Toronto, Canada. Association for Computational Linguistics. \n  * Ahuja et al. (2023)â Kabir Ahuja, Harshita Diddee, Rishav Hada, Millicent Ochieng, Krithika Ramesh, Prachi Jain, Akshay Nambi, Tanuja Ganu, Sameer Segal, Maxamed Axmed, Kalika Bali, and Sunayana Sitaram. 2023.  MEGA: Multilingual Evaluation of Generative AI.  In _EMNLP_. \n  * AI (2023)â Rebuff AI. 2023.  [A self-hardening prompt injection detector](https://www.rebuff.ai/). \n  * AraÃºjo and Aguiar (2023)â SÃ­lvia AraÃºjo and Micaela Aguiar. 2023.  Comparing chatgptâs and human evaluation of scientific textsâ translations from english to portuguese using popular automated translators.  _CLEF_. \n  * ArthurAI (2024)â ArthurAI. 2024.  [Arthur shield](https://www.arthur.ai/product/shield). \n  * Asai et al. (2023)â Akari Asai, Sneha Kudugunta, Xinyan Velocity Yu, Terra Blevins, Hila Gonen, Machel Reid, Yulia Tsvetkov, Sebastian Ruder, and Hannaneh Hajishirzi. 2023.  [BUFFET: Benchmarking Large Language Models for Few-shot Cross-lingual Transfer](http://arxiv.org/abs/2305.14857). \n  * Awais et al. (2023)â Muhammad Awais, Muzammal Naseer, Salman Khan, Rao Muhammad Anwer, Hisham Cholakkal, Mubarak Shah, Ming-Hsuan Yang, and Fahad Shahbaz Khan. 2023.  [Foundational models defining a new era in vision: A survey and outlook](http://arxiv.org/abs/2307.13721). \n  * Awasthi et al. (2023)â Abhijeet Awasthi, Nitish Gupta, Bidisha Samanta, Shachi Dave, Sunita Sarawagi, and Partha Talukdar. 2023.  [Bootstrapping multilingual semantic parsers using large language models](https://doi.org/10.18653/v1/2023.eacl-main.180).  In _Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics_ , pages 2455â2467, Dubrovnik, Croatia. Association for Computational Linguistics. \n  * Bai et al. (2023a)â Yushi Bai, Xin Lv, Jiajie Zhang, Hongchang Lyu, Jiankai Tang, Zhidian Huang, Zhengxiao Du, Xiao Liu, Aohan Zeng, Lei Hou, Yuxiao Dong, Jie Tang, and Juanzi Li. 2023a.  [Longbench: A bilingual, multitask benchmark for long context understanding](http://arxiv.org/abs/2308.14508). \n  * Bai et al. (2023b)â Yushi Bai, Jiahao Ying, Yixin Cao, Xin Lv, Yuze He, Xiaozhi Wang, Jifan Yu, Kaisheng Zeng, Yijia Xiao, Haozhe Lyu, et al. 2023b.  Benchmarking Foundation Models with Language-Model-as-an-Examiner.  In _NeurIPS 2023 Datasets and Benchmarks_. \n  * Bakke (2023)â Chris Bakke. 2023.  [Buying a chevrolet for 1$](https://twitter.com/ChrisJBakke/status/1736533308849443121?lang=en). \n  * Balepur et al. (2023)â Nishant Balepur, Jie Huang, and Kevin Chang. 2023.  [Expository text generation: Imitate, retrieve, paraphrase](https://doi.org/10.18653/v1/2023.emnlp-main.729).  In _Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing_ , pages 11896â11919, Singapore. Association for Computational Linguistics. \n  * Bang et al. (2023)â Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, Quyet V. Do, Yan Xu, and Pascale Fung. 2023.  A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity.  In _AACL_. \n  * Bansal et al. (2023)â Hritik Bansal, Karthik Gopalakrishnan, Saket Dingliwal, Sravan Bodapati, Katrin Kirchhoff, and Dan Roth. 2023.  Rethinking the Role of Scale for In-Context Learning: An Interpretability-based Case Study at 66 Billion Scale.  In _ACL_. \n  * Bar-Tal et al. (2022)â Omer Bar-Tal, Dolev Ofri-Amar, Rafail Fridman, Yoni Kasten, and Tali Dekel. 2022.  [Text2live: Text-driven layered image and video editing](http://arxiv.org/abs/2204.02491). \n  * Besta et al. (2024)â Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, MichaÅ Podstawski, Hubert Niewiadomski, Piotr Nyczyk, and Torsten Hoefler. 2024.  [Graph of Thoughts: Solving Elaborate Problems with Large Language Models](https://doi.org/10.1609/aaai.v38i16.29720).  _Proceedings of the AAAI Conference on Artificial Intelligence_ , 38(16):17682â17690. \n  * Bommasani et al. (2021)â Rishi Bommasani, Drew A. Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S. Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, Erik Brynjolfsson, S. Buch, Dallas Card, Rodrigo Castellon, Niladri S. Chatterji, Annie S. Chen, Kathleen A. Creel, Jared Davis, Dora Demszky, Chris Donahue, Moussa Doumbouya, Esin Durmus, Stefano Ermon, John Etchemendy, Kawin Ethayarajh, Li Fei-Fei, Chelsea Finn, Trevor Gale, Lauren E. Gillespie, Karan Goel, Noah D. Goodman, Shelby Grossman, Neel Guha, Tatsunori Hashimoto, Peter Henderson, John Hewitt, Daniel E. Ho, Jenny Hong, Kyle Hsu, Jing Huang, Thomas F. Icard, Saahil Jain, Dan Jurafsky, Pratyusha Kalluri, Siddharth Karamcheti, Geoff Keeling, Fereshte Khani, O. Khattab, Pang Wei Koh, Mark S. Krass, Ranjay Krishna, Rohith Kuditipudi, Ananya Kumar, Faisal Ladhak, Mina Lee, Tony Lee, Jure Leskovec, Isabelle Levent, Xiang Lisa Li, Xuechen Li, Tengyu Ma, Ali Malik, Christopher D. Manning, Suvir Mirchandani, Eric Mitchell, Zanele Munyikwa, Suraj Nair, Avanika Narayan, Deepak Narayanan, Benjamin Newman, Allen Nie, Juan Carlos Niebles, Hamed Nilforoshan, J. F. Nyarko, Giray Ogut, Laurel J. Orr, Isabel Papadimitriou, Joon Sung Park, Chris Piech, Eva Portelance, Christopher Potts, Aditi Raghunathan, Robert Reich, Hongyu Ren, Frieda Rong, Yusuf H. Roohani, Camilo Ruiz, Jack Ryan, Christopher Râe, Dorsa Sadigh, Shiori Sagawa, Keshav Santhanam, Andy Shih, Krishna Parasuram Srinivasan, Alex Tamkin, Rohan Taori, Armin W. Thomas, Florian TramÃ¨r, Rose E. Wang, William Wang, Bohan Wu, Jiajun Wu, Yuhuai Wu, Sang Michael Xie, Michihiro Yasunaga, Jiaxuan You, Matei A. Zaharia, Michael Zhang, Tianyi Zhang, Xikun Zhang, Yuhui Zhang, Lucia Zheng, Kaitlyn Zhou, and Percy Liang. 2021.  [On the Opportunities and Risks of Foundation Models](https://arxiv.org/abs/2108.07258).  _ArXiv_ , abs/2108.07258. \n  * Branch et al. (2022)â Hezekiah J. Branch, Jonathan Rodriguez Cefalu, Jeremy McHugh, Leyla Hujer, Aditya Bahl, Daniel del Castillo Iglesias, Ron Heichman, and Ramesh Darwishi. 2022.  [Evaluating the susceptibility of pre-trained language models via handcrafted adversarial examples](http://arxiv.org/abs/2209.02128). \n  * Brockman et al. (2016)â Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and Wojciech Zaremba. 2016.  [Openai gym](http://arxiv.org/abs/arXiv:1606.01540). \n  * Brooks et al. (2024)â Tim Brooks, Bill Peebles, Connor Homes, Will DePue, Yufei Guo, Li Jing, David Schnurr, Joe Taylor, Troy Luhman, Eric Luhman, Clarence Wing Yin Ng, Ricky Wang, and Aditya Ramesh. 2024.  [Video generation models as world simulators](https://openai.com/research/video-generation-models-as-world-simulators).  _OpenAI_. \n  * Brown et al. (2020)â Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020.  [Language models are few-shot learners](http://arxiv.org/abs/2005.14165). \n  * Bubeck et al. (2023)â SÃ©bastien Bubeck, Varun Chandrasekaran, Ronen Eldan, John A. Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuan-Fang Li, Scott M. Lundberg, Harsha Nori, Hamid Palangi, Marco Tulio Ribeiro, and Yi Zhang. 2023.  [Sparks of artificial general intelligence: Early experiments with gpt-4](https://api.semanticscholar.org/CorpusID:257663729).  _ArXiv_ , abs/2303.12712. \n  * Carlini et al. (2021)â Nicholas Carlini, Florian Tramer, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam Roberts, Tom Brown, Dawn Song, Ulfar Erlingsson, Alina Oprea, and Colin Raffel. 2021.  [Extracting training data from large language models](http://arxiv.org/abs/2012.07805). \n  * CDC (2023)â CDC. 2023.  [Suicide data and statistics](https://www.cdc.gov/suicide/suicide-data-statistics.html). \n  * Chan et al. (2024)â Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang Zhang, Jie Fu, and Zhiyuan Liu. 2024.  [Chateval: Towards better LLM-based evaluators through multi-agent debate](https://openreview.net/forum?id=FQepisCUWu).  In _The Twelfth International Conference on Learning Representations_. \n  * Chang et al. (2023)â Ernie Chang, Pin-Jie Lin, Yang Li, Sidd Srinivasan, Gael Le Lan, David Kant, Yangyang Shi, Forrest Iandola, and Vikas Chandra. 2023.  [In-context prompt editing for conditional audio generation](http://arxiv.org/abs/2311.00895). \n  * Chase (2022)â Harrison Chase. 2022.  [LangChain](https://github.com/langchain-ai/langchain). \n  * Chen et al. (2023a)â Banghao Chen, Zhaofeng Zhang, Nicolas LangrenÃ©, and Shengxin Zhu. 2023a.  [Unleashing the potential of prompt engineering in large language models: a comprehensive review](http://arxiv.org/abs/2310.14735). \n  * Chen et al. (2023b)â Lingjiao Chen, Matei Zaharia, and James Zou. 2023b.  How is chatgptâs behavior changing over time?  _arXiv preprint arXiv:2307.09009_. \n  * Chen et al. (2023c)â Shiqi Chen, Siyang Gao, and Junxian He. 2023c.  Evaluating factual consistency of summaries with large language models.  _arXiv preprint arXiv:2305.14069_. \n  * Chen et al. (2023d)â Wenhu Chen, Xueguang Ma, Xinyi Wang, and William W. Cohen. 2023d.  Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks.  _TMLR_. \n  * Chen et al. (2023e)â Xinyun Chen, Renat Aksitov, Uri Alon, Jie Ren, Kefan Xiao, Pengcheng Yin, Sushant Prakash, Charles Sutton, Xuezhi Wang, and Denny Zhou. 2023e.  [Universal self-consistency for large language model generation](http://arxiv.org/abs/2311.17311). \n  * Chen et al. (2023f)â Yang Chen, Yingwei Pan, Yehao Li, Ting Yao, and Tao Mei. 2023f.  [Control3d: Towards controllable text-to-3d generation](http://arxiv.org/abs/2311.05461). \n  * Chen et al. (2023g)â Yi Chen, Rui Wang, Haiyun Jiang, Shuming Shi, and Ruifeng Xu. 2023g.  [Exploring the use of large language models for reference-free text quality evaluation: An empirical study](https://doi.org/10.18653/v1/2023.findings-ijcnlp.32).  In _Findings of the Association for Computational Linguistics: IJCNLP-AACL 2023 (Findings)_ , pages 361â374, Nusa Dua, Bali. Association for Computational Linguistics. \n  * Cheng et al. (2023)â Jiaxin Cheng, Tianjun Xiao, and Tong He. 2023.  [Consistent video-to-video transfer using synthetic dataset](https://api.semanticscholar.org/CorpusID:264833165).  _ArXiv_ , abs/2311.00213. \n  * Chia et al. (2023)â Yew Ken Chia, Guizhen Chen, Luu Anh Tuan, Soujanya Poria, and Lidong Bing. 2023.  [Contrastive chain-of-thought prompting](http://arxiv.org/abs/2311.09277). \n  * Chu and Lin (2023)â Jiqun Chu and Zuoquan Lin. 2023.  [Entangled representation learning: A bidirectional encoder decoder model](https://doi.org/10.1145/3579654.3579728).  In _Proceedings of the 2022 5th International Conference on Algorithms, Computing and Artificial Intelligence_ , ACAI â22, New York, NY, USA. Association for Computing Machinery. \n  * Chu et al. (2023)â Zheng Chu, Jingchang Chen, Qianglong Chen, Weijiang Yu, Tao He, Haotian Wang, Weihua Peng, Ming Liu, Bing Qin, and Ting Liu. 2023.  [A survey of chain of thought reasoning: Advances, frontiers and future](http://arxiv.org/abs/2309.15402). \n  * Cramer et al. (2023)â Robert J Cramer, Jacinta Hawgood, AndrÃ©a R Kaniuka, Byron Brooks, and Justin C Baker. 2023.  [Updated suicide prevention core competencies for mental health professionals: Implications for training, research, and practice.](https://doi.org/10.1037/cps0000172) _Clinical Psychology: Science and Practice_. \n  * Crowson et al. (2022)â Katherine Crowson, Stella Biderman, Daniel Kornis, Dashiell Stander, Eric Hallahan, Louis Castricato, and Edward Raff. 2022.  [Vqgan-clip: Open domain image generation and editing with natural language guidance](http://arxiv.org/abs/2204.08583). \n  * Cui et al. (2021)â Leyang Cui, Yu Wu, Jian Liu, Sen Yang, and Yue Zhang. 2021.  [Template-based named entity recognition using bart](https://doi.org/10.18653/v1/2021.findings-acl.161).  _Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021_. \n  * Dang et al. (2022)â Hai Dang, Lukas Mecke, Florian Lehmann, Sven Goller, and Daniel Buschek. 2022.  [How to prompt? opportunities and challenges of zero- and few-shot learning for human-ai interaction in creative applications of generative models](http://arxiv.org/abs/2209.01390). \n  * Del and Fishel (2023)â Maksym Del and Mark Fishel. 2023.  [True detective: A deep abductive reasoning benchmark undoable for gpt-3 and challenging for gpt-4](https://doi.org/10.18653/v1/2023.starsem-1.28).  In _Proceedings of the 12th Joint Conference on Lexical and Computational Semantics (*SEM 2023)_. Association for Computational Linguistics. \n  * Deng et al. (2022)â Mingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan Wang, Han Guo, Tianmin Shu, Meng Song, Eric P. Xing, and Zhiting Hu. 2022.  RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning.  In _RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning_. \n  * Deng et al. (2023)â Yihe Deng, Weitong Zhang, Zixiang Chen, and Quanquan Gu. 2023.  [Rephrase and respond: Let large language models ask better questions for themselves](http://arxiv.org/abs/2311.04205). \n  * Dhuliawala et al. (2023)â Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu, Roberta Raileanu, Xian Li, Asli Celikyilmaz, and Jason Weston. 2023.  [Chain-of-verification reduces hallucination in large language models](http://arxiv.org/abs/2309.11495). \n  * Diao et al. (2023)â Shizhe Diao, Pengcheng Wang, Yong Lin, and Tong Zhang. 2023.  [Active prompting with chain-of-thought for large language models](http://arxiv.org/abs/2302.12246). \n  * Ding et al. (2021)â Ming Ding, Zhuoyi Yang, Wenyi Hong, Wendi Zheng, Chang Zhou, Da Yin, Junyang Lin, Xu Zou, Zhou Shao, Hongxia Yang, and Jie Tang. 2021.  [Cogview: Mastering text-to-image generation via transformers](https://proceedings.neurips.cc/paper_files/paper/2021/file/a4d92e2cd541fca87e4620aba658316d-Paper.pdf).  In _Advances in Neural Information Processing Systems_ , volume 34, pages 19822â19835. Curran Associates, Inc. \n  * Dong et al. (2023)â Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, Lei Li, and Zhifang Sui. 2023.  [A survey on in-context learning](http://arxiv.org/abs/2301.00234). \n  * Dubois et al. (2023)â Yann Dubois, Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani, Jimmy Ba, Carlos Guestrin, Percy Liang, and Tatsunori B Hashimoto. 2023.  Alpacafarm: A simulation framework for methods that learn from human feedback.  In _NeurIPS_. \n  * Durante et al. (2024)â Zane Durante, Qiuyuan Huang, Naoki Wake, Ran Gong, Jae Sung Park, Bidipta Sarkar, Rohan Taori, Yusuke Noda, Demetri Terzopoulos, Yejin Choi, Katsushi Ikeuchi, Hoi Vo, Fei-Fei Li, and Jianfeng Gao. 2024.  [Agent ai: Surveying the horizons of multimodal interaction](https://api.semanticscholar.org/CorpusID:266844635). \n  * Etxaniz et al. (2023)â Julen Etxaniz, Gorka Azkune, Aitor Soroa, Oier Lopez de Lacalle, and Mikel Artetxe. 2023.  [Do multilingual language models think better in english?](http://arxiv.org/abs/2308.01223)\n  * Fan et al. (2018)â Angela Fan, Mike Lewis, and Yann Dauphin. 2018.  [Hierarchical neural story generation](https://doi.org/10.18653/v1/p18-1082).  In _Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_. Association for Computational Linguistics. \n  * Fei-Fei et al. (2006)â Li Fei-Fei, Rob Fergus, and Pietro Perona. 2006.  [One-shot learning of object categories](https://api.semanticscholar.org/CorpusID:6953475).  _IEEE Transactions on Pattern Analysis and Machine Intelligence_ , 28:594â611. \n  * Feng et al. (2023)â Lincong Feng, Muyu Wang, Maoyu Wang, Kuo Xu, and Xiaoli Liu. 2023.  [Metadreamer: Efficient text-to-3d creation with disentangling geometry and texture](http://arxiv.org/abs/2311.10123). \n  * Fernandes et al. (2023)â Patrick Fernandes, Daniel Deutsch, Mara Finkelstein, Parker Riley, AndrÃ© Martins, Graham Neubig, Ankush Garg, Jonathan Clark, Markus Freitag, and Orhan Firat. 2023.  [The devil is in the errors: Leveraging large language models for fine-grained machine translation evaluation](https://doi.org/10.18653/v1/2023.wmt-1.100).  In _Proceedings of the Eighth Conference on Machine Translation_ , pages 1066â1083, Singapore. Association for Computational Linguistics. \n  * Fu et al. (2023a)â Jinlan Fu, See-Kiong Ng, Zhengbao Jiang, and Pengfei Liu. 2023a.  Gptscore: Evaluate as you desire.  _arXiv preprint arXiv:2302.04166_. \n  * Fu et al. (2022)â Jinlan Fu, See-Kiong Ng, and Pengfei Liu. 2022.  [Polyglot prompt: Multilingual multitask prompt training](https://doi.org/10.18653/v1/2022.emnlp-main.674).  In _Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing_ , pages 9919â9935, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics. \n  * Fu et al. (2023b)â Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and Tushar Khot. 2023b.  [Complexity-based prompting for multi-step reasoning](https://openreview.net/forum?id=yf1icZHC-l9).  In _The Eleventh International Conference on Learning Representations_. \n  * Gabillon et al. (2011)â Victor Gabillon, Mohammad Ghavamzadeh, Alessandro Lazaric, and SÃ©bastien Bubeck. 2011.  [Multi-bandit best arm identification](https://proceedings.neurips.cc/paper_files/paper/2011/file/c4851e8e264415c4094e4e85b0baa7cc-Paper.pdf).  In _Advances in Neural Information Processing Systems_ , volume 24. Curran Associates, Inc. \n  * Ganguli et al. (2023)â Deep Ganguli, Amanda Askell, Nicholas Schiefer, Thomas Liao, KamilÄ LukoÅ¡iÅ«tÄ, Anna Chen, Anna Goldie, Azalia Mirhoseini, Catherine Olsson, Danny Hernandez, et al. 2023.  The capacity for moral self-correction in large language models.  _arXiv preprint arXiv:2302.07459_. \n  * Gao (2023)â Andrew Gao. 2023.  [Prompt engineering for large language models](https://ssrn.com/abstract=4504303).  _SSRN_. \n  * Gao et al. (2023a)â Lingyu Gao, Aditi Chaudhary, Krishna Srinivasan, Kazuma Hashimoto, Karthik Raman, and Michael Bendersky. 2023a.  Ambiguity-aware in-context learning with large language models.  _arXiv preprint arXiv:2309.07900_. \n  * Gao et al. (2023b)â Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and Graham Neubig. 2023b.  Pal: program-aided language models.  In _Proceedings of the 40th International Conference on Machine Learning_ , ICMLâ23. JMLR.org. \n  * Gao et al. (2023c)â Mingqi Gao, Jie Ruan, Renliang Sun, Xunjian Yin, Shiping Yang, and Xiaojun Wan. 2023c.  Human-like summarization evaluation with chatgpt.  _arXiv preprint arXiv:2304.02554_. \n  * Gao et al. (2021)â Tianyu Gao, Adam Fisch, and Danqi Chen. 2021.  [Making pre-trained language models better few-shot learners](https://doi.org/10.18653/v1/2021.acl-long.295).  In _Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)_ , pages 3816â3830, Online. Association for Computational Linguistics. \n  * Garcia (2024)â Marisa Garcia. 2024.  [What air canada lost in âremarkableâ lying ai chatbot case](https://www.forbes.com/sites/marisagarcia/2024/02/19/what-air-canada-lost-in-remarkable-lying-ai-chatbot-case/).  _Forbes_. \n  * Garcia et al. (2023)â Xavier Garcia, Yamini Bansal, Colin Cherry, George Foster, Maxim Krikun, Melvin Johnson, and Orhan Firat. 2023.  The unreasonable effectiveness of few-shot learning for machine translation.  In _Proceedings of the 40th International Conference on Machine Learning_ , ICMLâ23. JMLR.org. \n  * Garnett and Curtin (2023)â MF Garnett and SC Curtin. 2023.  [Suicide mortality in the united states, 2001â2021](https://doi.org/10.15620/cdc:125705).  _NCHS Data Brief_ , 464:1â8. \n  * Gebru et al. (2021)â Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal DaumÃ© III, and Kate Crawford. 2021.  [Datasheets for datasets](https://doi.org/10.1145/3458723).  _Communications of the ACM_ , 64(12):86â92. \n  * Ghazvininejad et al. (2023)â Marjan Ghazvininejad, Hila Gonen, and Luke Zettlemoyer. 2023.  [Dictionary-based phrase-level prompting of large language models for machine translation](http://arxiv.org/abs/2302.07856). \n  * Girdhar et al. (2023)â Rohit Girdhar, Mannat Singh, Andrew Brown, Quentin Duval, Samaneh Azadi, Sai Saketh Rambhatla, Akbar Shah, Xi Yin, Devi Parikh, and Ishan Misra. 2023.  [Emu video: Factorizing text-to-video generation by explicit image conditioning](http://arxiv.org/abs/2311.10709). \n  * Gong et al. (2023)â Yichen Gong, Delong Ran, Jinyuan Liu, Conglei Wang, Tianshuo Cong, Anyu Wang, Sisi Duan, and Xiaoyun Wang. 2023.  [Figstep: Jailbreaking large vision-language models via typographic visual prompts](http://arxiv.org/abs/2311.05608). \n  * Goodside (2022)â Riley Goodside. 2022.  [Exploiting gpt-3 prompts with malicious inputs that order the model to ignore its previous directions](https://twitter.com/goodside/status/1569128808308957185). \n  * Google (2023)â Google. 2023.  [Gemini: A family of highly capable multimodal models](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf). \n  * Gou et al. (2024a)â Zhibin Gou, Zhihong Shao, Yeyun Gong, yelong shen, Yujiu Yang, Nan Duan, and Weizhu Chen. 2024a.  [CRITIC: Large language models can self-correct with tool-interactive critiquing](https://openreview.net/forum?id=Sx038qxjek).  In _The Twelfth International Conference on Learning Representations_. \n  * Gou et al. (2024b)â Zhibin Gou, Zhihong Shao, Yeyun Gong, yelong shen, Yujiu Yang, Minlie Huang, Nan Duan, and Weizhu Chen. 2024b.  [ToRA: A tool-integrated reasoning agent for mathematical problem solving](https://openreview.net/forum?id=Ep0TtjVoap).  In _The Twelfth International Conference on Learning Representations_. \n  * Guo et al. (2017)â Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. 2017.  On calibration of modern neural networks.  In _International conference on machine learning_ , pages 1321â1330. PMLR. \n  * Guo et al. (2022)â Han Guo, Bowen Tan, Zhengzhong Liu, Eric P. Xing, and Zhiting Hu. 2022.  [Efficient (soft) q-learning for text generation with limited good data](http://arxiv.org/abs/2106.07704). \n  * Gupta et al. (2024)â Priyanka Gupta, Bosheng Ding, Chong Guan, and Ding Ding. 2024.  [Generative ai: A systematic review using topic modelling techniques](https://doi.org/https://doi.org/10.1016/j.dim.2024.100066).  _Data and Information Management_ , page 100066. \n  * Hada et al. (2024)â Rishav Hada, Varun Gumma, Adrian Wynter, Harshita Diddee, Mohamed Ahmed, Monojit Choudhury, Kalika Bali, and Sunayana Sitaram. 2024.  [Are large language model-based evaluators the solution to scaling up multilingual evaluation?](https://aclanthology.org/2024.findings-eacl.71) In _Findings of the Association for Computational Linguistics: EACL 2024_ , pages 1051â1070, St. Julianâs, Malta. Association for Computational Linguistics. \n  * Hadi et al. (2023)â Muhammad Usman Hadi, Qasem Al Tashi, Rizwan Qureshi, Abbas Shah, Amgad Muneer, Muhammad Irfan, and et al. 2023.  [Large language models: A comprehensive survey of its applications, challenges, limitations, and future prospects](https://doi.org/10.36227/techrxiv.23589741.v3).  _TechRxiv_. \n  * Hakan Tekgul (2023)â Aparna Dhinakaran Hakan Tekgul. 2023.  [Guardrails: What are they and how can you use nemo and guardrails ai to safeguard llms?](https://arize.com/blog-course/guardrails-what-are-they-and-how-can-you-use-nemo-and-guardrails-ai-to-safeguard-llms/) Online. \n  * Hakimov and Schlangen (2023)â Sherzod Hakimov and David Schlangen. 2023.  [Images in language space: Exploring the suitability of large language models for vision & language tasks](https://doi.org/10.18653/v1/2023.findings-acl.894).  In _Findings of the Association for Computational Linguistics: ACL 2023_ , pages 14196â14210, Toronto, Canada. Association for Computational Linguistics. \n  * Hao et al. (2023)â Shibo Hao, Tianyang Liu, Zhen Wang, and Zhiting Hu. 2023.  [ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via Tool Embeddings](https://api.semanticscholar.org/CorpusID:258823133).  In _NeurIPS_. \n  * He et al. (2023a)â Hangfeng He, Hongming Zhang, and Dan Roth. 2023a.  Socreval: Large language models with the socratic method for reference-free reasoning evaluation.  _arXiv preprint arXiv:2310.00074_. \n  * He et al. (2023b)â Zhiwei He, Tian Liang, Wenxiang Jiao, Zhuosheng Zhang, Yujiu Yang, Rui Wang, Zhaopeng Tu, Shuming Shi, and Xing Wang. 2023b.  [Exploring human-like translation strategy with large language models](http://arxiv.org/abs/2305.04118). \n  * Hendrycks et al. (2021)â Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2021.  Measuring Massive Multitask Language Understanding.  In _ICLR_. \n  * Hendy et al. (2023)â Amr Hendy, Mohamed Gomaa Abdelrehim, Amr Sharaf, Vikas Raunak, Mohamed Gabr, Hitokazu Matsushita, Young Jin Kim, Mohamed Afify, and Hany Hassan Awadalla. 2023.  [How good are gpt models at machine translation? a comprehensive evaluation](https://api.semanticscholar.org/CorpusID:257038384).  _ArXiv_ , abs/2302.09210. \n  * Hertz et al. (2022)â Amir Hertz, Ron Mokady, Jay Tenenbaum, Kfir Aberman, Yael Pritch, and Daniel Cohen-Or. 2022.  [Prompt-to-prompt image editing with cross attention control](http://arxiv.org/abs/2208.01626). \n  * Heston and Khun (2023)â T.F. Heston and C. Khun. 2023.  [Prompt engineering in medical education](https://doi.org/10.3390/ime2030019).  _Int. Med. Educ._ , 2:198â205. \n  * Hinz et al. (2022)â Tobias Hinz, Stefan Heinrich, and Stefan Wermter. 2022.  [Semantic object accuracy for generative text-to-image synthesis](https://doi.org/10.1109/tpami.2020.3021209).  _IEEE Transactions on Pattern Analysis and Machine Intelligence_ , 44(3):1552â1565. \n  * Hou et al. (2023)â Xinyi Hou, Yanjie Zhao, Yue Liu, Zhou Yang, Kailong Wang, Li Li, Xiapu Luo, David Lo, John Grundy, and Haoyu Wang. 2023.  [Large language models for software engineering: A systematic literature review](http://arxiv.org/abs/2308.10620). \n  * Hsu et al. (2023)â Ming-Hao Hsu, Kai-Wei Chang, Shang-Wen Li, and Hung yi Lee. 2023.  [An exploration of in-context learning for speech language model](http://arxiv.org/abs/2310.12477). \n  * Hua et al. (2024)â Yining Hua, Fenglin Liu, Kailai Yang, Zehan Li, Yi han Sheu, Peilin Zhou, Lauren V. Moran, Sophia Ananiadou, and Andrew Beam. 2024.  [Large language models in mental health care: a scoping review](http://arxiv.org/abs/2401.02984). \n  * Huang et al. (2023a)â Haoyang Huang, Tianyi Tang, Dongdong Zhang, Wayne Xin Zhao, Ting Song, Yan Xia, and Furu Wei. 2023a.  [Not all languages are created equal in llms: Improving multilingual capability by cross-lingual-thought prompting](http://arxiv.org/abs/2305.07004). \n  * Huang et al. (2022)â Jiaxin Huang, Shixiang Shane Gu, Le Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu, and Jiawei Han. 2022.  Large language models can self-improve.  _arXiv preprint arXiv:2210.11610_. \n  * Huang et al. (2023b)â Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin Feng, Haotian Wang, Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, and Ting Liu. 2023b.  [A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions](http://arxiv.org/abs/2311.05232). \n  * Huang et al. (2023c)â Shaohan Huang, Li Dong, Wenhui Wang, Yaru Hao, Saksham Singhal, Shuming Ma, Tengchao Lv, Lei Cui, Owais Khan Mohammed, Barun Patra, Qiang Liu, Kriti Aggarwal, Zewen Chi, Johan Bjorck, Vishrav Chaudhary, Subhojit Som, Xia Song, and Furu Wei. 2023c.  [Language is not all you need: Aligning perception with language models](http://arxiv.org/abs/2302.14045). \n  * Inan et al. (2023)â Hakan Inan, Kartikeya Upasani, Jianfeng Chi, Rashi Rungta, Krithika Iyer, Yuning Mao, Michael Tontchev, Qing Hu, Brian Fuller, Davide Testuggine, and Madian Khabsa. 2023.  [Llama guard: Llm-based input-output safeguard for human-ai conversations](http://arxiv.org/abs/2312.06674). \n  * Iyer et al. (2023)â Vivek Iyer, Pinzhen Chen, and Alexandra Birch. 2023.  [Towards effective disambiguation for machine translation with large language models](http://arxiv.org/abs/2309.11668). \n  * Jain et al. (2022)â Ajay Jain, Ben Mildenhall, Jonathan T. Barron, Pieter Abbeel, and Ben Poole. 2022.  [Zero-shot text-guided object generation with dream fields](http://arxiv.org/abs/2112.01455). \n  * Jia et al. (2023)â Qi Jia, Siyu Ren, Yizhu Liu, and Kenny Q Zhu. 2023.  Zero-shot faithfulness evaluation for text summarization with foundation language model.  _arXiv preprint arXiv:2310.11648_. \n  * Jiang et al. (2023)â Zhengbao Jiang, Frank Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, and Graham Neubig. 2023.  [Active retrieval augmented generation](https://doi.org/10.18653/v1/2023.emnlp-main.495).  In _Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing_ , pages 7969â7992, Singapore. Association for Computational Linguistics. \n  * Jiang et al. (2020)â Zhengbao Jiang, Frank F. Xu, Jun Araki, and Graham Neubig. 2020.  [How can we know what language models know?](https://doi.org/10.1162/tacl_a_00324) _Transactions of the Association for Computational Linguistics_ , 8:423â438. \n  * Jiao et al. (2023)â Wenxiang Jiao, Wenxuan Wang, Jen tse Huang, Xing Wang, Shuming Shi, and Zhaopeng Tu. 2023.  [Is chatgpt a good translator? yes with gpt-4 as the engine](http://arxiv.org/abs/2301.08745). \n  * Jin and Lu (2023)â Ziqi Jin and Wei Lu. 2023.  [Tab-cot: Zero-shot tabular chain of thought](http://arxiv.org/abs/2305.17812). \n  * Kadavath et al. (2022)â Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli Tran-Johnson, Scott Johnston, Sheer El-Showk, Andy Jones, Nelson Elhage, Tristan Hume, Anna Chen, Yuntao Bai, Sam Bowman, Stanislav Fort, Deep Ganguli, Danny Hernandez, Josh Jacobson, Jackson Kernion, Shauna Kravec, Liane Lovitt, Kamal Ndousse, Catherine Olsson, Sam Ringer, Dario Amodei, Tom Brown, Jack Clark, Nicholas Joseph, Ben Mann, Sam McCandlish, Chris Olah, and Jared Kaplan. 2022.  [Language models (mostly) know what they know](http://arxiv.org/abs/2207.05221). \n  * Karpas et al. (2022)â Ehud Karpas, Omri Abend, Yonatan Belinkov, Barak Lenz, Opher Lieber, Nir Ratner, Yoav Shoham, Hofit Bata, Yoav Levine, Kevin Leyton-Brown, Dor Muhlgay, Noam Rozen, Erez Schwartz, Gal Shachaf, Shai Shalev-Shwartz, Amnon Shashua, and Moshe Tenenholtz. 2022.  [Mrkl systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning](http://arxiv.org/abs/2205.00445). \n  * Keele et al. (2007)â Staffs Keele et al. 2007.  Guidelines for performing systematic literature reviews in software engineering. \n  * Keskar et al. (2019)â Nitish Shirish Keskar, Bryan McCann, Lav R. Varshney, Caiming Xiong, and Richard Socher. 2019.  [Ctrl: A conditional transformer language model for controllable generation](http://arxiv.org/abs/1909.05858). \n  * Keyvan and Huang (2022)â Kimiya Keyvan and Jimmy Xiangji Huang. 2022.  How to approach ambiguous queries in conversational search: A survey of techniques, approaches, tools, and challenges.  _ACM Computing Surveys_ , 55(6):1â40. \n  * Khalifa et al. (2023)â Muhammad Khalifa, Lajanugen Logeswaran, Moontae Lee, Honglak Lee, and Lu Wang. 2023.  [Exploring demonstration ensembling for in-context learning](http://arxiv.org/abs/2308.08780). \n  * Khalil et al. (2023)â Mahmoud Khalil, Ahmad Khalil, and Alioune Ngom. 2023.  [A comprehensive study of vision transformers in image classification tasks](http://arxiv.org/abs/2312.01232). \n  * Khattab et al. (2022)â Omar Khattab, Keshav Santhanam, Xiang Lisa Li, David Hall, Percy Liang, Christopher Potts, and Matei Zaharia. 2022.  [Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp](http://arxiv.org/abs/2212.14024). \n  * Khattab et al. (2023)â Omar Khattab, Arnav Singhvi, Paridhi Maheshwari, Zhiyuan Zhang, Keshav Santhanam, Sri Vardhamanan, Saiful Haq, Ashutosh Sharma, Thomas T. Joshi, Hanna Moazam, Heather Miller, Matei Zaharia, and Christopher Potts. 2023.  Dspy: Compiling declarative language model calls into self-improving pipelines.  _arXiv preprint arXiv:2310.03714_. \n  * Khot et al. (2022)â Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, and Ashish Sabharwal. 2022.  [Decomposed prompting: A modular approach for solving complex tasks](http://arxiv.org/abs/2210.02406). \n  * Kiesler and Schiffner (2023)â Natalie Kiesler and Daniel Schiffner. 2023.  Large language models in introductory programming education: Chatgptâs performance and implications for assessments.  _arXiv preprint arXiv:2308.08572_. \n  * Kim and Komachi (2023)â Hwichan Kim and Mamoru Komachi. 2023.  [Enhancing few-shot cross-lingual transfer with target language peculiar examples](https://doi.org/10.18653/v1/2023.findings-acl.47).  In _Findings of the Association for Computational Linguistics: ACL 2023_ , pages 747â767, Toronto, Canada. Association for Computational Linguistics. \n  * Kim et al. (2022)â Hyuhng Joon Kim, Hyunsoo Cho, Junyeob Kim, Taeuk Kim, Kang Min Yoo, and Sang goo Lee. 2022.  [Self-generated in-context learning: Leveraging auto-regressive language models as a demonstration generator](http://arxiv.org/abs/2206.08082). \n  * Kim et al. (2023)â Sunkyoung Kim, Dayeon Ki, Yireun Kim, and Jinsik Lee. 2023.  [Boosting cross-lingual transferability in multilingual models via in-context learning](http://arxiv.org/abs/2305.15233). \n  * Ko et al. (2023a)â Dayoon Ko, Sangho Lee, and Gunhee Kim. 2023a.  [Can language models laugh at youtube short-form videos?](http://arxiv.org/abs/2310.14159)\n  * Ko et al. (2023b)â Hyung-Kwon Ko, Gwanmo Park, Hyeon Jeon, Jaemin Jo, Juho Kim, and Jinwook Seo. 2023b.  [Large-scale text-to-image generation models for visual artistsâ creative works](https://doi.org/10.1145/3581641.3584078).  _Proceedings of the 28th International Conference on Intelligent User Interfaces_. \n  * Kocmi and Federmann (2023a)â Tom Kocmi and Christian Federmann. 2023a.  Gemba-mqm: Detecting translation quality error spans with gpt-4.  _arXiv preprint arXiv:2310.13988_. \n  * Kocmi and Federmann (2023b)â Tom Kocmi and Christian Federmann. 2023b.  [Large language models are state-of-the-art evaluators of translation quality](https://aclanthology.org/2023.eamt-1.19).  In _Proceedings of the 24th Annual Conference of the European Association for Machine Translation_ , pages 193â203, Tampere, Finland. European Association for Machine Translation. \n  * Kojima et al. (2022)â Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022.  [Large language models are zero-shot reasoners](http://arxiv.org/abs/2205.11916). \n  * Kumar and Talukdar (2021)â Sawan Kumar and Partha Talukdar. 2021.  [Reordering examples helps during priming-based few-shot learning](http://arxiv.org/abs/2106.01751). \n  * Kwon and Ye (2022)â Gihyun Kwon and Jong Chul Ye. 2022.  [Clipstyler: Image style transfer with a single text condition](http://arxiv.org/abs/2112.00374). \n  * Lakera (2024)â Lakera. 2024.  [Lakera guard](https://www.lakera.ai/lakera-guard). \n  * Lanyado et al. (2023)â Bar Lanyado, Ortal Keizman, and Yair Divinsky. 2023.  [Can you trust chatgptâs package recommendations?](https://vulcan.io/blog/ai-hallucinations-package-risk) Vulcan Cyber Blog. \n  * Le et al. (2023)â Cindy Le, Congrui Hetang, Ang Cao, and Yihui He. 2023.  [Euclidreamer: Fast and high-quality texturing for 3d models with stable diffusion depth](http://arxiv.org/abs/2311.15573). \n  * Lee and Kim (2023)â Soochan Lee and Gunhee Kim. 2023.  [Recursion of thought: A divide-and-conquer approach to multi-context reasoning with language models](http://arxiv.org/abs/2306.06891). \n  * Leidinger et al. (2023)â Alina Leidinger, Robert van Rooij, and Ekaterina Shutova. 2023.  [The language of prompting: What linguistic properties make a prompt successful?](http://arxiv.org/abs/2311.01967)\n  * Lester et al. (2021)â Brian Lester, Rami Al-Rfou, and Noah Constant. 2021.  [The power of scale for parameter-efficient prompt tuning](https://doi.org/10.18653/v1/2021.emnlp-main.243).  In _Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing_. Association for Computational Linguistics. \n  * Lewis et al. (2021)â Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich KÃ¼ttler, Mike Lewis, Wen tau Yih, Tim RocktÃ¤schel, Sebastian Riedel, and Douwe Kiela. 2021.  [Retrieval-augmented generation for knowledge-intensive nlp tasks](http://arxiv.org/abs/2005.11401). \n  * Li et al. (2019a)â Bowen Li, Xiaojuan Qi, Thomas Lukasiewicz, and Philip H. S. Torr. 2019a.  [Controllable text-to-image generation](http://arxiv.org/abs/1909.07083). \n  * Li et al. (2023a)â Cheng Li, Jindong Wang, Yixuan Zhang, Kaijie Zhu, Wenxin Hou, Jianxun Lian, Fang Luo, Qiang Yang, and Xing Xie. 2023a.  [Large language models understand and can be enhanced by emotional stimuli](http://arxiv.org/abs/2307.11760). \n  * Li et al. (2023b)â Chengzhengxu Li, Xiaoming Liu, Yichen Wang, Duyi Li, Yu Lan, and Chao Shen. 2023b.  [Dialogue for prompting: a policy-gradient-based discrete prompt optimization for few-shot learning](http://arxiv.org/abs/2308.07272). \n  * Li et al. (2023c)â Jiahao Li, Hao Tan, Kai Zhang, Zexiang Xu, Fujun Luan, Yinghao Xu, Yicong Hong, Kalyan Sunkavalli, Greg Shakhnarovich, and Sai Bi. 2023c.  [Instant3d: Fast text-to-3d with sparse-view generation and large reconstruction model](http://arxiv.org/abs/2311.06214). \n  * Li et al. (2023d)â Ming Li, Pan Zhou, Jia-Wei Liu, Jussi Keppo, Min Lin, Shuicheng Yan, and Xiangyu Xu. 2023d.  [Instant3d: Instant text-to-3d generation](http://arxiv.org/abs/2311.08403). \n  * Li et al. (2023e)â Ruosen Li, Teerth Patel, and Xinya Du. 2023e.  Prd: Peer rank and discussion improve large language model based evaluations.  _arXiv preprint arXiv:2307.02762_. \n  * Li et al. (2019b)â Wenbo Li, Pengchuan Zhang, Lei Zhang, Qiuyuan Huang, Xiaodong He, Siwei Lyu, and Jianfeng Gao. 2019b.  [Object-driven text-to-image synthesis via adversarial training](http://arxiv.org/abs/1902.10740). \n  * Li et al. (2023f)â Xiaonan Li, Kai Lv, Hang Yan, Tianyang Lin, Wei Zhu, Yuan Ni, Guotong Xie, Xiaoling Wang, and Xipeng Qiu. 2023f.  [Unified demonstration retriever for in-context learning](http://arxiv.org/abs/2305.04320). \n  * Li and Qiu (2023a)â Xiaonan Li and Xipeng Qiu. 2023a.  [Finding support examples for in-context learning](http://arxiv.org/abs/2302.13539). \n  * Li and Qiu (2023b)â Xiaonan Li and Xipeng Qiu. 2023b.  [Mot: Memory-of-thought enables chatgpt to self-improve](http://arxiv.org/abs/2305.05181). \n  * Li et al. (2023g)â Xiaoqian Li, Ercong Nie, and Sheng Liang. 2023g.  [Crosslingual retrieval augmented in-context learning for bangla](http://arxiv.org/abs/2311.00587). \n  * Li et al. (2020)â Xiujun Li, Xi Yin, Chunyuan Li, Pengchuan Zhang, Xiaowei Hu, Lei Zhang, Lijuan Wang, Houdong Hu, Li Dong, Furu Wei, Yejin Choi, and Jianfeng Gao. 2020.  [Oscar: Object-semantics aligned pre-training for vision-language tasks](http://arxiv.org/abs/2004.06165). \n  * Li et al. (2023h)â Yaoyiran Li, Anna Korhonen, and Ivan VuliÄ. 2023h.  [On bilingual lexicon induction with large language models](http://arxiv.org/abs/2310.13995). \n  * Li et al. (2023i)â Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, Jian-Guang Lou, and Weizhu Chen. 2023i.  [Making language models better reasoners with step-aware verifier](https://doi.org/10.18653/v1/2023.acl-long.291).  In _Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_. Association for Computational Linguistics. \n  * Li et al. (2023j)â Yingji Li, Mengnan Du, Rui Song, Xin Wang, and Ying Wang. 2023j.  [A survey on fairness in large language models](http://arxiv.org/abs/2308.10149). \n  * Liang et al. (2023)â Jingyun Liang, Yuchen Fan, Kai Zhang, Radu Timofte, Luc Van Gool, and Rakesh Ranjan. 2023.  [Movideo: Motion-aware video generation with diffusion models](http://arxiv.org/abs/2311.11325). \n  * Lin et al. (2023)â Chen-Hsuan Lin, Jun Gao, Luming Tang, Towaki Takikawa, Xiaohui Zeng, Xun Huang, Karsten Kreis, Sanja Fidler, Ming-Yu Liu, and Tsung-Yi Lin. 2023.  [Magic3d: High-resolution text-to-3d content creation](http://arxiv.org/abs/2211.10440). \n  * Lin et al. (2022)â Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav Chaudhary, Brian OâHoro, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoyanov, and Xian Li. 2022.  [Few-shot learning with multilingual generative language models](https://doi.org/10.18653/v1/2022.emnlp-main.616).  In _Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing_ , pages 9019â9052, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics. \n  * Lin and Chen (2023)â Yen-Ting Lin and Yun-Nung Chen. 2023.  Llm-eval: Unified multi-dimensional automatic evaluation for open-domain conversations with large language models.  _arXiv preprint arXiv:2305.13711_. \n  * Liu (2022)â Jerry Liu. 2022.  [LlamaIndex](https://doi.org/10.5281/zenodo.1234). \n  * Liu et al. (2021)â Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2021.  What makes good in-context examples for GPT-3?  In _Workshop on Knowledge Extraction and Integration for Deep Learning Architectures; Deep Learning Inside Out_. \n  * Liu et al. (2023a)â Nelson F Liu, Tianyi Zhang, and Percy Liang. 2023a.  Evaluating verifiability in generative search engines.  In _Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing_. \n  * Liu et al. (2023b)â Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2023b.  [Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing](https://doi.org/10.1145/3560815).  _ACM Computing Surveys_ , 55(9):1â35. \n  * Liu et al. (2023c)â Weihuang Liu, Xi Shen, Chi-Man Pun, and Xiaodong Cun. 2023c.  [Explicit visual prompting for low-level structure segmentations](https://doi.org/10.1109/cvpr52729.2023.01862).  In _2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)_. IEEE. \n  * Liu et al. (2023d)â Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, and Chenguang Zhu. 2023d.  Gpteval: Nlg evaluation using gpt-4 with better human alignment.  _arXiv preprint arXiv:2303.16634_. \n  * Liu et al. (2023e)â Yihao Liu, Xiangyu Chen, Xianzheng Ma, Xintao Wang, Jiantao Zhou, Yu Qiao, and Chao Dong. 2023e.  [Unifying image processing as visual prompting question answering](http://arxiv.org/abs/2310.10513). \n  * Liu et al. (2023f)â Yongkang Liu, Shi Feng, Daling Wang, Yifei Zhang, and Hinrich SchÃ¼tze. 2023f.  Evaluate what you canât evaluate: Unassessable generated responses quality.  _arXiv preprint arXiv:2305.14658_. \n  * Liu et al. (2023g)â Yuxin Liu, Minshan Xie, Hanyuan Liu, and Tien-Tsin Wong. 2023g.  [Text-guided texturing by synchronized multi-view diffusion](http://arxiv.org/abs/2311.12891). \n  * Liu et al. (2023h)â Yuxuan Liu, Tianchi Yang, Shaohan Huang, Zihan Zhang, Haizhen Huang, Furu Wei, Weiwei Deng, Feng Sun, and Qi Zhang. 2023h.  Calibrating llm-based evaluator.  _arXiv preprint arXiv:2309.13308_. \n  * Long (2023)â Jieyi Long. 2023.  [Large language model guided tree-of-thought](http://arxiv.org/abs/2305.08291). \n  * Lorraine et al. (2023)â Jonathan Lorraine, Kevin Xie, Xiaohui Zeng, Chen-Hsuan Lin, Towaki Takikawa, Nicholas Sharp, Tsung-Yi Lin, Ming-Yu Liu, Sanja Fidler, and James Lucas. 2023.  [Att3d: Amortized text-to-3d object synthesis](http://arxiv.org/abs/2306.07349). \n  * Lu et al. (2023a)â Albert Lu, Hongxin Zhang, Yanzhe Zhang, Xuezhi Wang, and Diyi Yang. 2023a.  [Bounding the capabilities of large language models in open text generation with prompt constraints](http://arxiv.org/abs/2302.09185). \n  * Lu et al. (2023b)â Hongyuan Lu, Haoyang Huang, Dongdong Zhang, Haoran Yang, Wai Lam, and Furu Wei. 2023b.  [Chain-of-dictionary prompting elicits translation in large language models](http://arxiv.org/abs/2305.06575). \n  * Lu et al. (2023c)â Qingyu Lu, Baopu Qiu, Liang Ding, Liping Xie, and Dacheng Tao. 2023c.  Error analysis prompting enables human-like translation evaluation in large language models: A case study on chatgpt.  _arXiv preprint arXiv:2303.13809_. \n  * Lu et al. (2021)â Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. 2021.  [Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity](http://arxiv.org/abs/2104.08786). \n  * Luca Beurer-Kellner (2023)â Charles Duffy Luca Beurer-Kellner, Marc Fischer. 2023.  [lmql](https://github.com/eth-sri/lmql).  GitHub repository. \n  * Luo et al. (2023)â Zheheng Luo, Qianqian Xie, and Sophia Ananiadou. 2023.  Chatgpt as a factual inconsistency evaluator for abstractive text summarization.  _arXiv preprint arXiv:2303.15621_. \n  * Lv et al. (2023)â Jiaxi Lv, Yi Huang, Mingfu Yan, Jiancheng Huang, Jianzhuang Liu, Yifan Liu, Yafei Wen, Xiaoxin Chen, and Shifeng Chen. 2023.  [Gpt4motion: Scripting physical motions in text-to-video generation via blender-oriented gpt planning](http://arxiv.org/abs/2311.12631). \n  * Lyu et al. (2023)â Qing Lyu, Shreya Havaldar, Adam Stein, Li Zhang, Delip Rao, Eric Wong, Marianna Apidianaki, and Chris Callison-Burch. 2023.  [Faithful chain-of-thought reasoning](http://arxiv.org/abs/2301.13379). \n  * Ma et al. (2023)â Huan Ma, Changqing Zhang, Yatao Bian, Lemao Liu, Zhirui Zhang, Peilin Zhao, Shu Zhang, Huazhu Fu, Qinghua Hu, and Bingzhe Wu. 2023.  Fairness-guided few-shot prompting for large language models.  _arXiv preprint arXiv:2303.13217_. \n  * Madaan et al. (2023)â Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Shashank Gupta, Bodhisattwa Prasad Majumder, Katherine Hermann, Sean Welleck, Amir Yazdanbakhsh, and Peter Clark. 2023.  [Self-refine: Iterative refinement with self-feedback](http://arxiv.org/abs/2303.17651). \n  * Mehrabi et al. (2021)â Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan. 2021.  A survey on bias and fairness in machine learning.  _ACM computing surveys (CSUR)_ , 54(6):1â35. \n  * Melzer et al. (2024)â Laura Melzer, Thomas Forkmann, and Tobias Teismann. 2024.  [Suicide crisis syndrome: A systematic review](https://doi.org/10.1111/sltb.13065).  _Suicide and Life-Threatening Behavior_.  February 27, online ahead of print. \n  * Meng et al. (2023)â Fanxu Meng, Haotong Yang, Yiding Wang, and Muhan Zhang. 2023.  [Chain of images for intuitively reasoning](http://arxiv.org/abs/2311.09241). \n  * MeskÃ³ (2023)â B. MeskÃ³. 2023.  [Prompt engineering as an important emerging skill for medical professionals: Tutorial](https://doi.org/10.2196/50638).  _Journal of Medical Internet Research_ , 25(Suppl 1):e50638. \n  * Mi et al. (2023)â Yachun Mi, Yu Li, Yan Shu, Chen Hui, Puchao Zhou, and Shaohui Liu. 2023.  [Clif-vqa: Enhancing video quality assessment by incorporating high-level semantic information related to human feelings](http://arxiv.org/abs/2311.07090). \n  * Mialon et al. (2023)â GrÃ©goire Mialon, Roberto DessÃ¬, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu, Baptiste RoziÃ¨re, Timo Schick, Jane Dwivedi-Yu, Asli Celikyilmaz, Edouard Grave, Yann LeCun, and Thomas Scialom. 2023.  [Augmented language models: a survey](http://arxiv.org/abs/2302.07842). \n  * Min et al. (2022)â Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, and Luke Zettlemoyer. 2022.  [Rethinking the role of demonstrations: What makes in-context learning work?](http://arxiv.org/abs/2202.12837)\n  * Min et al. (2020)â Sewon Min, Julian Michael, Hannaneh Hajishirzi, and Luke Zettlemoyer. 2020.  Ambigqa: Answering ambiguous open-domain questions.  _arXiv preprint arXiv:2004.10645_. \n  * Morelli et al. (1991)â R.A. Morelli, J.D. Bronzino, and J.W. Goethe. 1991.  [A computational speech-act model of human-computer conversations](https://doi.org/10.1109/NEBC.1991.154675).  In _Proceedings of the 1991 IEEE Seventeenth Annual Northeast Bioengineering Conference_ , pages 263â264. \n  * Moslem et al. (2023)â Yasmin Moslem, Rejwanul Haque, John D. Kelleher, and Andy Way. 2023.  [Adaptive machine translation with large language models](https://aclanthology.org/2023.eamt-1.22).  In _Proceedings of the 24th Annual Conference of the European Association for Machine Translation_ , pages 227â237, Tampere, Finland. European Association for Machine Translation. \n  * Mu et al. (2023)â Fangwen Mu, Lin Shi, Song Wang, Zhuohao Yu, Binquan Zhang, Chenxue Wang, Shichao Liu, and Qing Wang. 2023.  [Clarifygpt: Empowering llm-based code generation with intention clarification](http://arxiv.org/abs/2310.10996). \n  * Muennighoff et al. (2023)â Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella Biderman, Teven Le Scao, M Saiful Bari, Sheng Shen, Zheng Xin Yong, Hailey Schoelkopf, Xiangru Tang, Dragomir Radev, Alham Fikri Aji, Khalid Almubarak, Samuel Albanie, Zaid Alyafeai, Albert Webson, Edward Raff, and Colin Raffel. 2023.  [Crosslingual generalization through multitask finetuning](https://doi.org/10.18653/v1/2023.acl-long.891).  In _Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_ , pages 15991â16111, Toronto, Canada. Association for Computational Linguistics. \n  * Nambi et al. (2023)â Akshay Nambi, Vaibhav Balloli, Mercy Ranjit, Tanuja Ganu, Kabir Ahuja, Sunayana Sitaram, and Kalika Bali. 2023.  [Breaking language barriers with a leap: Learning strategies for polyglot llms](http://arxiv.org/abs/2305.17740). \n  * Nasr et al. (2023)â Milad Nasr, Nicholas Carlini, Jonathan Hayase, Matthew Jagielski, A. Feder Cooper, Daphne Ippolito, Christopher A. Choquette-Choo, Eric Wallace, Florian TramÃ¨r, and Katherine Lee. 2023.  [Scalable extraction of training data from (production) language models](http://arxiv.org/abs/2311.17035). \n  * National Center for Health Workforce Analysis (2023)â National Center for Health Workforce Analysis. 2023.  [Behavioral health workforce, 2023](https://bhw.hrsa.gov/sites/default/files/bureau-health-workforce/Behavioral-Health-Workforce-Brief-2023.pdf). \n  * Neagu (2023)â Alexandra Neagu. 2023.  How can large language models and prompt engineering be leveraged in Computer Science education?: Systematic literature review.  Masterâs thesis, Delft University of Technology, 6. \n  * Nie et al. (2023)â Ercong Nie, Sheng Liang, Helmut Schmid, and Hinrich SchÃ¼tze. 2023.  [Cross-lingual retrieval augmented prompt for low-resource languages](https://doi.org/10.18653/v1/2023.findings-acl.528).  In _Findings of the Association for Computational Linguistics: ACL 2023_ , pages 8320â8340, Toronto, Canada. Association for Computational Linguistics. \n  * Ning et al. (2023)â Xuefei Ning, Zinan Lin, Zixuan Zhou, Zifu Wang, Huazhong Yang, and Yu Wang. 2023.  [Skeleton-of-thought: Large language models can do parallel decoding](http://arxiv.org/abs/2307.15337). \n  * OpenAI (2023)â OpenAI. 2023.  [OpenAI Assistants](https://platform.openai.com/docs/assistants/how-it-works). \n  * Oppenlaender (2023)â Jonas Oppenlaender. 2023.  [A taxonomy of prompt modifiers for text-to-image generation](http://arxiv.org/abs/2204.13988). \n  * Osika (2023)â Anton Osika. 2023.  [gpt-engineer](https://github.com/AntonOsika/gpt-engineer). \n  * Page et al. (2021)â Matthew J Page, Joanne E McKenzie, Patrick M Bossuyt, Isabelle Boutron, Tammy C Hoffmann, Cynthia D Mulrow, Larissa Shamseer, Jennifer M Tetzlaff, Elie A Akl, Sue E Brennan, Roger Chou, Julie Glanville, Jeremy M Grimshaw, AsbjÃ¸rn HrÃ³bjartsson, Manoj M Lalu, Tianjing Li, Elizabeth W Loder, Evan Mayo-Wilson, Steve McDonald, Luke A McGuinness, Lesley A Stewart, James Thomas, Andrea C Tricco, Vivian A Welch, Penny Whiting, and David Moher. 2021.  [The prisma 2020 statement: an updated guideline for reporting systematic reviews](https://doi.org/10.1136/bmj.n71).  _BMJ_ , 372. \n  * Pajouheshgar et al. (2023)â Ehsan Pajouheshgar, Yitao Xu, Alexander Mordvintsev, Eyvind Niklasson, Tong Zhang, and Sabine SÃ¼sstrunk. 2023.  [Mesh neural cellular automata](http://arxiv.org/abs/2311.02820). \n  * Patel et al. (2022)â Pruthvi Patel, Swaroop Mishra, Mihir Parmar, and Chitta Baral. 2022.  [Is a question decomposition unit all we need?](http://arxiv.org/abs/2205.12538)\n  * Patil et al. (2023)â Shishir G. Patil, Tianjun Zhang, Xin Wang, and Joseph E. Gonzalez. 2023.  [Gorilla: Large language model connected with massive apis](https://api.semanticscholar.org/CorpusID:258865184).  _ArXiv_ , abs/2305.15334. \n  * Pearce et al. (2021)â Hammond Pearce, Baleegh Ahmad, Benjamin Tan, Brendan Dolan-Gavitt, and Ramesh Karri. 2021.  [Asleep at the keyboard? assessing the security of github copilotâs code contributions](http://arxiv.org/abs/2108.09293). \n  * Pearce et al. (2022)â Hammond Pearce, Benjamin Tan, Baleegh Ahmad, Ramesh Karri, and Brendan Dolan-Gavitt. 2022.  [Examining zero-shot vulnerability repair with large language models](http://arxiv.org/abs/2112.02125). \n  * Peng et al. (2023)â Puyuan Peng, Brian Yan, Shinji Watanabe, and David Harwath. 2023.  [Prompting the hidden talent of web-scale speech models for zero-shot task generalization](http://arxiv.org/abs/2305.11095). \n  * Perez et al. (2022)â Ethan Perez, Saffron Huang, Francis Song, Trevor Cai, Roman Ring, John Aslanides, Amelia Glaese, Nat McAleese, and Geoffrey Irving. 2022.  [Red teaming language models with language models](http://arxiv.org/abs/2202.03286). \n  * Perez and Ribeiro (2022)â FÃ¡bio Perez and Ian Ribeiro. 2022.  [Ignore previous prompt: Attack techniques for language models](https://doi.org/10.48550/ARXIV.2211.09527). \n  * Perry et al. (2022)â Neil Perry, Megha Srivastava, Deepak Kumar, and Dan Boneh. 2022.  [Do users write more insecure code with ai assistants?](http://arxiv.org/abs/2211.03622)\n  * Peskoff and Stewart (2023)â Denis Peskoff and Brandon M Stewart. 2023.  Credible without credit: Domain experts assess generative language models.  In _Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)_ , pages 427â438. \n  * Peskoff et al. (2023)â Denis Peskoff, Adam Visokay, Sander Schulhoff, Benjamin Wachspress, Alan Blinder, and Brandon M Stewart. 2023.  Gpt deciphering fedspeak: Quantifying dissent among hawks and doves.  In _Findings of the Association for Computational Linguistics: EMNLP 2023_ , pages 6529â6539. \n  * Peskov et al. (2021)â Denis Peskov, Viktor Hangya, Jordan Boyd-Graber, and Alexander Fraser. 2021.  Adapting entities across languages and cultures.  _Findings of the Association for Computational Linguistics: EMNLP 2021_. \n  * Petroni et al. (2019)â Fabio Petroni, Tim RocktÃ¤schel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, and Alexander Miller. 2019.  [Language models as knowledge bases?](https://doi.org/10.18653/v1/d19-1250) _Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)_. \n  * Pezeshkpour and Hruschka (2023)â Pouya Pezeshkpour and Estevam Hruschka. 2023.  Large language models sensitivity to the order of options in multiple-choice questions.  _arXiv preprint arXiv:2308.11483_. \n  * Pfaff (1979)â Carol W. Pfaff. 1979.  Constraints on language mixing: Intrasentential code-switching and borrowing in spanish/english.  _Language_ , pages 291â318. \n  * Pilault et al. (2023)â Jonathan Pilault, Xavier Garcia, Arthur BraÅ¾inskas, and Orhan Firat. 2023.  [Interactive-chain-prompting: Ambiguity resolution for crosslingual conditional generation with interaction](http://arxiv.org/abs/2301.10309). \n  * Poole et al. (2022)â Ben Poole, Ajay Jain, Jonathan T. Barron, and Ben Mildenhall. 2022.  [Dreamfusion: Text-to-3d using 2d diffusion](http://arxiv.org/abs/2209.14988). \n  * Poplack (1980)â Shana Poplack. 1980.  Sometimes iâll start a sentence in spanish y termino en espaÃ±ol: Toward a typology of code-switching.  _Linguistics_ , 18(7-8):581â618. \n  * Prasad et al. (2023)â Archiki Prasad, Peter Hase, Xiang Zhou, and Mohit Bansal. 2023.  [GrIPS: Gradient-free, edit-based instruction search for prompting large language models](https://aclanthology.org/2023.eacl-main.277).  In _Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics_ , pages 3845â3864, Dubrovnik, Croatia. Association for Computational Linguistics. \n  * Preamble (2024)â Preamble. 2024.  [Our product](https://www.preamble.com/solution). \n  * Press et al. (2022)â Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A. Smith, and Mike Lewis. 2022.  [Measuring and narrowing the compositionality gap in language models](http://arxiv.org/abs/2210.03350). \n  * Pryzant et al. (2023)â Reid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chenguang Zhu, and Michael Zeng. 2023.  [Automatic prompt optimization with \"gradient descent\" and beam search](http://arxiv.org/abs/2305.03495). \n  * Puduppully et al. (2023)â Ratish Puduppully, Anoop Kunchukuttan, Raj Dabre, Ai Ti Aw, and Nancy F. Chen. 2023.  [Decomposed prompting for machine translation between related languages using large language models](http://arxiv.org/abs/2305.13085). \n  * Qiao et al. (2023)â Bo Qiao, Liqun Li, Xu Zhang, Shilin He, Yu Kang, Chaoyun Zhang, Fangkai Yang, Hang Dong, Jue Zhang, Lu Wang, Ming-Jie Ma, Pu Zhao, Si Qin, Xiaoting Qin, Chao Du, Yong Xu, Qingwei Lin, S. Rajmohan, and Dongmei Zhang. 2023.  [Taskweaver: A code-first agent framework](https://api.semanticscholar.org/CorpusID:265498341).  _ArXiv_ , abs/2311.17541. \n  * Qiao et al. (2022)â Shuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen, Yunzhi Yao, Shumin Deng, Chuanqi Tan, Fei Huang, and Huajun Chen. 2022.  [Reasoning with language model prompting: A survey](http://arxiv.org/abs/2212.09597). \n  * Qin et al. (2023a)â Libo Qin, Qiguang Chen, Fuxuan Wei, Shijue Huang, and Wanxiang Che. 2023a.  [Cross-lingual prompting: Improving zero-shot chain-of-thought reasoning across languages](http://arxiv.org/abs/2310.14799). \n  * Qin et al. (2023b)â Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni Zeng, Yufei Huang, Chaojun Xiao, Chi Han, Yi Ren Fung, Yusheng Su, Huadong Wang, Cheng Qian, Runchu Tian, Kunlun Zhu, Shi Liang, Xingyu Shen, Bokai Xu, Zhen Zhang, Yining Ye, Bo Li, Ziwei Tang, Jing Yi, Yu Zhu, Zhenning Dai, Lan Yan, Xin Cong, Ya-Ting Lu, Weilin Zhao, Yuxiang Huang, Jun-Han Yan, Xu Han, Xian Sun, Dahai Li, Jason Phang, Cheng Yang, Tongshuang Wu, Heng Ji, Zhiyuan Liu, and Maosong Sun. 2023b.  [Tool learning with foundation models](https://api.semanticscholar.org/CorpusID:258179336).  _ArXiv_ , abs/2304.08354. \n  * Radford et al. (2021)â Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. 2021.  Learning transferable visual models from natural language supervision.  In _International conference on machine learning_ , pages 8748â8763. PMLR. \n  * Radford et al. (2019a)â Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019a.  Language models are unsupervised multitask learners.  _OpenAI blog_ , 1(8):9. \n  * Radford et al. (2019b)â Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019b.  Language models are unsupervised multitask learners.  _OpenAI blog_ , 1(8):9. \n  * Rao and DaumÃ© III (2019)â Sudha Rao and Hal DaumÃ© III. 2019.  Answer-based adversarial training for generating clarification questions.  _arXiv preprint arXiv:1904.02281_. \n  * Rebedea et al. (2023)â Traian Rebedea, Razvan Dinu, Makesh Sreedhar, Christopher Parisien, and Jonathan Cohen. 2023.  Nemo guardrails: A toolkit for controllable and safe llm applications with programmable rails.  _arXiv_. \n  * Resnik et al. (2021)â Philip Resnik, April Foreman, Michelle Kuchuk, Katherine Musacchio Schafer, and Beau Pinkham. 2021.  [Naturally occurring language as a source of evidence in suicide prevention](https://doi.org/10.1111/sltb.12674).  _Suicide and Life-Threatening Behavior_ , 51(1):88â96. \n  * Reynolds and McDonell (2021)â Laria Reynolds and Kyle McDonell. 2021.  [Prompt programming for large language models: Beyond the few-shot paradigm](https://doi.org/10.1145/3411763.3451760).  In _Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems_ , CHI â21. ACM. \n  * Rogers et al. (2019)â Megan L Rogers, Carol Chu, and Thomas Joiner. 2019.  The necessity, validity, and clinical utility of a new diagnostic entity: Acute suicidal affective disturbance (asad).  _Journal of Clinical Psychology_ , 75(6):999. \n  * Rombach et al. (2022)â Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and BjÃ¶rn Ommer. 2022.  [High-resolution image synthesis with latent diffusion models](http://arxiv.org/abs/2112.10752). \n  * Rubin et al. (2022)â Ohad Rubin, Jonathan Herzig, and Jonathan Berant. 2022.  [Learning to retrieve prompts for in-context learning](https://doi.org/10.18653/v1/2022.naacl-main.191).  In _Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies_. Association for Computational Linguistics. \n  * Runway (2023)â Runway. 2023.  Gen-2 prompt tips.  <https://help.runwayml.com/hc/en-us/articles/17329337959699-Gen-2-Prompt-Tips>. \n  * Sahoo et al. (2024)â Pranab Sahoo, Ayush Kumar Singh, Sriparna Saha, Vinija Jain, Samrat Mondal, and Aman Chadha. 2024.  [A systematic survey of prompt engineering in large language models: Techniques and applications](http://arxiv.org/abs/2402.07927). \n  * Sandoval et al. (2022)â Gustavo Sandoval, Hammond Pearce, Teo Nys, Ramesh Karri, Siddharth Garg, and Brendan Dolan-Gavitt. 2022.  [Lost at c: A user study on the security implications of large language model code assistants](http://arxiv.org/abs/2208.09727). \n  * Santu and Feng (2023)â Shubhra Kanti Karmaker Santu and Dongji Feng. 2023.  [Teler: A general taxonomy of llm prompts for benchmarking complex tasks](http://arxiv.org/abs/2305.11430). \n  * Schick et al. (2023)â Timo Schick, Jane Dwivedi-Yu, Roberto DessÃ¬, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. 2023.  [Toolformer: Language models can teach themselves to use tools](http://arxiv.org/abs/2302.04761). \n  * Schick and SchÃ¼tze (2020a)â Timo Schick and Hinrich SchÃ¼tze. 2020a.  [Exploiting cloze-questions for few-shot text classification and natural language inference](https://api.semanticscholar.org/CorpusID:210838924).  In _Conference of the European Chapter of the Association for Computational Linguistics_. \n  * Schick and SchÃ¼tze (2020b)â Timo Schick and Hinrich SchÃ¼tze. 2020b.  [Itâs not just size that matters: Small language models are also few-shot learners](https://api.semanticscholar.org/CorpusID:221703107).  _ArXiv_ , abs/2009.07118. \n  * Schick and SchÃ¼tze (2021)â Timo Schick and Hinrich SchÃ¼tze. 2021.  [Exploiting cloze-questions for few-shot text classification and natural language inference](https://doi.org/10.18653/v1/2021.eacl-main.20).  In _Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume_. Association for Computational Linguistics. \n  * Schmidt et al. (2023)â Douglas C. Schmidt, Jesse Spencer-Smith, Quchen Fu, and Jules White. 2023.  Cataloging prompt patterns to enhance the discipline of prompt engineering.  _Dept. of Computer Science, Vanderbilt University_.  Email: douglas.c.schmidt, jesse.spencer-smith, quchen.fu, jules.white@vanderbilt.edu. \n  * Schuck et al. (2019a)â Allison Schuck, Raffaella Calati, Shira Barzilay, Sarah Bloch-Elkouby, and Igor I. Galynker. 2019a.  [Suicide crisis syndrome: A review of supporting evidence for a new suicide-specific diagnosis.](https://api.semanticscholar.org/CorpusID:85449010) _Behavioral sciences & the law_, 37 3:223â239. \n  * Schuck et al. (2019b)â Allison Schuck, Raffaella Calati, Shira Barzilay, Sarah Bloch-Elkouby, and Igor Galynker. 2019b.  Suicide crisis syndrome: A review of supporting evidence for a new suicide-specific diagnosis.  _Behavioral sciences and the law_ , 37(3):223â239. \n  * Schulhoff (2022)â Sander Schulhoff. 2022.  [Learn Prompting](https://github.com/trigaten/Learn_Prompting). \n  * Schulhoff et al. (2023)â Sander Schulhoff, Jeremy Pinto, Anaum Khan, Louis-FranÃ§ois Bouchard, Chenglei Si, Svetlina Anati, Valen Tagliabue, Anson Kost, Christopher Carnahan, and Jordan Boyd-Graber. 2023.  [Ignore this title and HackAPrompt: Exposing systemic vulnerabilities of LLMs through a global prompt hacking competition](https://doi.org/10.18653/v1/2023.emnlp-main.302).  In _Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing_ , pages 4945â4977, Singapore. Association for Computational Linguistics. \n  * Schulhoff (2024)â Sander V Schulhoff. 2024.  [Prompt injection vs jailbreaking: What is the difference?](https://learnprompting.org/blog/2024/2/4/injection_jailbreaking)\n  * Sclar et al. (2023a)â Melanie Sclar, Yejin Choi, Yulia Tsvetkov, and Alane Suhr. 2023a.  Quantifying language modelsâ sensitivity to spurious features in prompt design or: How i learned to start worrying about prompt formatting.  _arXiv preprint arXiv:2310.11324_. \n  * Sclar et al. (2023b)â Melanie Sclar, Yejin Choi, Yulia Tsvetkov, and Alane Suhr. 2023b.  [Quantifying language modelsâ sensitivity to spurious features in prompt design or: How i learned to start worrying about prompt formatting](http://arxiv.org/abs/2310.11324). \n  * Scott Lundberg (2023)â Harsha-Nori Scott Lundberg, Marco Tulio Correia Ribeiro. 2023.  [guidance](https://github.com/guidance-ai/guidance).  GitHub repository. \n  * Searle (1969)â John R. Searle. 1969.  _Speech Acts: An Essay in the Philosophy of Language_.  Cambridge University Press. \n  * Shaikh et al. (2023)â Omar Shaikh, Hongxin Zhang, William Held, Michael Bernstein, and Diyi Yang. 2023.  [On second thought, letâs not think step by step! bias and toxicity in zero-shot reasoning](http://arxiv.org/abs/2212.08061). \n  * Sharma et al. (2023)â Mrinank Sharma, Meg Tong, Tomasz Korbak, David Duvenaud, Amanda Askell, Samuel R Bowman, Newton Cheng, Esin Durmus, Zac Hatfield-Dodds, Scott R Johnston, et al. 2023.  Towards understanding sycophancy in language models.  _arXiv preprint arXiv:2310.13548_. \n  * Shen et al. (2023)â Yongliang Shen, Kaitao Song, Xu Tan, Dong Sheng Li, Weiming Lu, and Yue Ting Zhuang. 2023.  [Hugginggpt: Solving ai tasks with chatgpt and its friends in hugging face](https://api.semanticscholar.org/CorpusID:257833781).  _ArXiv_ , abs/2303.17580. \n  * Shi et al. (2022)â Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, Soroush Vosoughi, Hyung Won Chung, Yi Tay, Sebastian Ruder, Denny Zhou, Dipanjan Das, and Jason Wei. 2022.  [Language models are multilingual chain-of-thought reasoners](http://arxiv.org/abs/2210.03057). \n  * Shin et al. (2020a)â Taylor Shin, Yasaman Razeghi, Robert L Logan IV, Eric Wallace, and Sameer Singh. 2020a.  [Eliciting knowledge from language models using automatically generated prompts](https://api.semanticscholar.org/CorpusID:226222232).  _ArXiv_ , abs/2010.15980. \n  * Shin et al. (2020b)â Taylor Shin, Yasaman Razeghi, Robert L. Logan IV, Eric Wallace, and Sameer Singh. 2020b.  [Autoprompt: Eliciting knowledge from language models with automatically generated prompts](https://doi.org/10.18653/v1/2020.emnlp-main.346).  _Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)_. \n  * Shing et al. (2018)â Han-Chin Shing, Suraj Nair, Ayah Zirikly, Meir Friedenberg, Hal DaumÃ© III, and Philip Resnik. 2018.  [Expert, crowdsourced, and machine assessment of suicide risk via online postings](https://doi.org/10.18653/v1/W18-0603).  In _Proceedings of the Fifth Workshop on Computational Linguistics and Clinical Psychology: From Keyboard to Clinic_ , pages 25â36, New Orleans, LA. Association for Computational Linguistics. \n  * Shinn et al. (2023)â Noah Shinn, Federico Cassano, Edward Berman, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. 2023.  [Reflexion: Language agents with verbal reinforcement learning](http://arxiv.org/abs/2303.11366). \n  * Si et al. (2023a)â Chenglei Si, Dan Friedman, Nitish Joshi, Shi Feng, Danqi Chen, and He He. 2023a.  Measuring inductive biases of in-context learning with underspecified demonstrations.  In _Association for Computational Linguistics (ACL)_. \n  * Si et al. (2023b)â Chenglei Si, Zhe Gan, Zhengyuan Yang, Shuohang Wang, Jianfeng Wang, Jordan Boyd-Graber, and Lijuan Wang. 2023b.  [Prompting gpt-3 to be reliable](https://arxiv.org/abs/2210.09150).  In _International Conference on Learning Representations (ICLR)_. \n  * Si et al. (2023c)â Chenglei Si, Navita Goyal, Sherry Tongshuang Wu, Chen Zhao, Shi Feng, Hal DaumÃ© III, and Jordan Boyd-Graber. 2023c.  Large language models help humans verify truthfulnessâexcept when they are convincingly wrong.  _arXiv preprint arXiv:2310.12558_. \n  * Si et al. (2023d)â Chenglei Si, Weijia Shi, Chen Zhao, Luke Zettlemoyer, and Jordan Lee Boyd-Graber. 2023d.  [Getting MoRE out of Mixture of language model Reasoning Experts](http://umiacs.umd.edu/~jbg//docs/2023_findings_more.pdf).  _Findings of Empirical Methods in Natural Language Processing_. \n  * Sia and Duh (2023)â Suzanna Sia and Kevin Duh. 2023.  [In-context learning as maintaining coherency: A study of on-the-fly machine translation using large language models](http://arxiv.org/abs/2305.03573). \n  * Significant Gravitas (2023)â Significant Gravitas. 2023.  [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT). \n  * Singer et al. (2023)â Uriel Singer, Shelly Sheynin, Adam Polyak, Oron Ashual, Iurii Makarov, Filippos Kokkinos, Naman Goyal, Andrea Vedaldi, Devi Parikh, Justin Johnson, and Yaniv Taigman. 2023.  [Text-to-4d dynamic scene generation](http://arxiv.org/abs/2301.11280). \n  * Sorensen et al. (2022)â Taylor Sorensen, Joshua Robinson, Christopher Rytting, Alexander Shaw, Kyle Rogers, Alexia Delorey, Mahmoud Khalil, Nancy Fulda, and David Wingate. 2022.  [An information-theoretic approach to prompt engineering without ground truth labels](https://doi.org/10.18653/v1/2022.acl-long.60).  In _Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_ , pages 819â862, Dublin, Ireland. Association for Computational Linguistics. \n  * Sottana et al. (2023)â Andrea Sottana, Bin Liang, Kai Zou, and Zheng Yuan. 2023.  Evaluation metrics in the era of gpt-4: Reliably evaluating large language models on sequence to sequence tasks.  _arXiv preprint arXiv:2310.13800_. \n  * Å tefÃ¡nik and KadlÄÃ­k (2023)â Michal Å tefÃ¡nik and Marek KadlÄÃ­k. 2023.  [Can in-context learners learn a reasoning concept from demonstrations?](https://doi.org/10.18653/v1/2023.nlrse-1.8) In _Proceedings of the 1st Workshop on Natural Language Reasoning and Structured Explanations (NLRSE)_ , pages 107â115, Toronto, Canada. Association for Computational Linguistics. \n  * Su et al. (2022)â Hongjin Su, Jungo Kasai, Chen Henry Wu, Weijia Shi, Tianlu Wang, Jiayi Xin, Rui Zhang, Mari Ostendorf, Luke Zettlemoyer, Noah A. Smith, and Tao Yu. 2022.  [Selective annotation makes language models better few-shot learners](http://arxiv.org/abs/2209.01975). \n  * Tang et al. (2023)â Lv Tang, Peng-Tao Jiang, Hao-Ke Xiao, and Bo Li. 2023.  [Towards training-free open-world segmentation via image prompting foundation models](http://arxiv.org/abs/2310.10912). \n  * Tanwar et al. (2023)â Eshaan Tanwar, Subhabrata Dutta, Manish Borthakur, and Tanmoy Chakraborty. 2023.  [Multilingual LLMs are better cross-lingual in-context learners with alignment](https://doi.org/10.18653/v1/2023.acl-long.346).  In _Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_ , pages 6292â6307, Toronto, Canada. Association for Computational Linguistics. \n  * Tao et al. (2022)â Ming Tao, Hao Tang, Fei Wu, Xiao-Yuan Jing, Bing-Kun Bao, and Changsheng Xu. 2022.  [Df-gan: A simple and effective baseline for text-to-image synthesis](http://arxiv.org/abs/2008.05865). \n  * Thompson and Kelly (2023)â Charlotte Thompson and Tiana Kelly. 2023.  [When hallucinations become reality: An exploration of ai package hallucination attacks](https://darktrace.com/blog/when-hallucinations-become-reality-an-exploration-of-ai-package-hallucination-attacks).  Darktrace Blog. \n  * Tian et al. (2023)â Katherine Tian, Eric Mitchell, Allan Zhou, Archit Sharma, Rafael Rafailov, Huaxiu Yao, Chelsea Finn, and Christopher Manning. 2023.  [Just ask for calibration: Strategies for eliciting calibrated confidence scores from language models fine-tuned with human feedback](https://doi.org/10.18653/v1/2023.emnlp-main.330).  In _Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing_ , pages 5433â5442, Singapore. Association for Computational Linguistics. \n  * Towers et al. (2023)â Mark Towers, Jordan K. Terry, Ariel Kwiatkowski, John U. Balis, Gianluca de Cola, Tristan Deleu, Manuel GoulÃ£o, Andreas Kallinteris, Arjun KG, Markus Krimmel, Rodrigo Perez-Vicente, Andrea PierrÃ©, Sander Schulhoff, Jun Jet Tai, Andrew Tan Jin Shen, and Omar G. Younis. 2023.  [Gymnasium](https://doi.org/10.5281/zenodo.8127026). \n  * Trivedi et al. (2023)â Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal. 2023.  [Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions](https://doi.org/10.18653/v1/2023.acl-long.557).  In _Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_ , pages 10014â10037, Toronto, Canada. Association for Computational Linguistics. \n  * Tutunov et al. (2023)â Rasul Tutunov, Antoine Grosnit, Juliusz Ziomek, Jun Wang, and Haitham Bou-Ammar. 2023.  [Why can large language models generate correct chain-of-thoughts?](http://arxiv.org/abs/2310.13571)\n  * Wallace et al. (2019)â Eric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner, and Sameer Singh. 2019.  [Universal adversarial triggers for attacking and analyzing nlp](https://api.semanticscholar.org/CorpusID:201698258).  In _Conference on Empirical Methods in Natural Language Processing_. \n  * Wan et al. (2023a)â Xingchen Wan, Ruoxi Sun, Hanjun Dai, Sercan O. Arik, and Tomas Pfister. 2023a.  [Better zero-shot reasoning with self-adaptive prompting](http://arxiv.org/abs/2305.14106). \n  * Wan et al. (2023b)â Xingchen Wan, Ruoxi Sun, Hootan Nakhost, Hanjun Dai, Julian Martin Eisenschlos, Sercan O. Arik, and Tomas Pfister. 2023b.  [Universal self-adaptive prompting](http://arxiv.org/abs/2305.14926). \n  * Wang et al. (2023a)â Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. 2023a.  [Voyager: An open-ended embodied agent with large language models](http://arxiv.org/abs/2305.16291). \n  * Wang et al. (2023b)â Jiaan Wang, Yunlong Liang, Fandong Meng, Haoxiang Shi, Zhixu Li, Jinan Xu, Jianfeng Qu, and Jie Zhou. 2023b.  Is chatgpt a good nlg evaluator? a preliminary study.  _arXiv preprint arXiv:2303.04048_. \n  * Wang et al. (2023c)â Jiaqi Wang, Zhengliang Liu, Lin Zhao, Zihao Wu, Chong Ma, Sigang Yu, Haixing Dai, Qiushi Yang, Yiheng Liu, Songyao Zhang, Enze Shi, Yi Pan, Tuo Zhang, Dajiang Zhu, Xiang Li, Xi Jiang, Bao Ge, Yixuan Yuan, Dinggang Shen, Tianming Liu, and Shu Zhang. 2023c.  [Review of large vision models and visual prompt engineering](http://arxiv.org/abs/2307.00855). \n  * Wang et al. (2023d)â Jiaqi Wang, Enze Shi, Sigang Yu, Zihao Wu, Chong Ma, Haixing Dai, Qiushi Yang, Yanqing Kang, Jinru Wu, Huawen Hu, Chenxi Yue, Haiyang Zhang, Yiheng Liu, Xiang Li, Bao Ge, Dajiang Zhu, Yixuan Yuan, Dinggang Shen, Tianming Liu, and Shu Zhang. 2023d.  [Prompt engineering for healthcare: Methodologies and applications](http://arxiv.org/abs/2304.14670). \n  * Wang et al. (2023e)â Junjie Wang, Yuchao Huang, Chunyang Chen, Zhe Liu, Song Wang, and Qing Wang. 2023e.  [Software testing with large language model: Survey, landscape, and vision](http://arxiv.org/abs/2307.07221). \n  * Wang et al. (2023f)â Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy Ka-Wei Lee, and Ee-Peng Lim. 2023f.  [Plan-and-solve prompting: Improving zero-shot chain-of-thought reasoning by large language models](http://arxiv.org/abs/2305.04091). \n  * Wang et al. (2023g)â Siyin Wang, Chao-Han Huck Yang, Ji Wu, and Chao Zhang. 2023g.  [Can whisper perform speech-based in-context learning](http://arxiv.org/abs/2309.07081). \n  * Wang et al. (2023h)â Xinyi Wang, Wanrong Zhu, Michael Saxon, Mark Steyvers, and William Yang Wang. 2023h.  [Large language models are latent variable models: Explaining and finding good demonstrations for in-context learning](http://arxiv.org/abs/2301.11916). \n  * Wang et al. (2022)â Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2022.  [Self-consistency improves chain of thought reasoning in language models](http://arxiv.org/abs/2203.11171). \n  * Wang et al. (2023i)â Yaqing Wang, Jiepu Jiang, Mingyang Zhang, Cheng Li, Yi Liang, Qiaozhu Mei, and Michael Bendersky. 2023i.  Automated evaluation of personalized text generation using large language models.  _arXiv preprint arXiv:2310.11593_. \n  * Wang et al. (2019)â Yaqing Wang, Quanming Yao, James Kwok, and Lionel M. Ni. 2019.  [Generalizing from a few examples: A survey on few-shot learning](http://arxiv.org/abs/1904.05046). \n  * Wang et al. (2023j)â Zekun Moore Wang, Zhongyuan Peng, Haoran Que, Jiaheng Liu, Wangchunshu Zhou, Yuhan Wu, Hongcheng Guo, Ruitong Gan, Zehao Ni, Man Zhang, Zhaoxiang Zhang, Wanli Ouyang, Ke Xu, Wenhu Chen, Jie Fu, and Junran Peng. 2023j.  [Rolellm: Benchmarking, eliciting, and enhancing role-playing abilities of large language models](http://arxiv.org/abs/2310.00746). \n  * Wang et al. (2023k)â Zhendong Wang, Yifan Jiang, Yadong Lu, Yelong Shen, Pengcheng He, Weizhu Chen, Zhangyang Wang, and Mingyuan Zhou. 2023k.  [In-context learning unlocked for diffusion models](http://arxiv.org/abs/2305.01115). \n  * Wang et al. (2023l)â Zhenhailong Wang, Shaoguang Mao, Wenshan Wu, Tao Ge, Furu Wei, and Heng Ji. 2023l.  [Unleashing cognitive synergy in large language models: A task-solving agent through multi-persona self-collaboration](http://arxiv.org/abs/2307.05300). \n  * Wei et al. (2022)â Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2022.  [Chain-of-thought prompting elicits reasoning in large language models](http://arxiv.org/abs/2201.11903). \n  * Wei et al. (2023a)â Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2023a.  [Chain-of-thought prompting elicits reasoning in large language models](http://arxiv.org/abs/2201.11903). \n  * Wei et al. (2023b)â Jerry Wei, Da Huang, Yifeng Lu, Denny Zhou, and Quoc V Le. 2023b.  Simple synthetic data reduces sycophancy in large language models.  _arXiv preprint arXiv:2308.03958_. \n  * Wei et al. (2023c)â Jerry Wei, Jason Wei, Yi Tay, Dustin Tran, Albert Webson, Yifeng Lu, Xinyun Chen, Hanxiao Liu, Da Huang, Denny Zhou, et al. 2023c.  Larger language models do in-context learning differently.  _arXiv preprint arXiv:2303.03846_. \n  * Weng et al. (2022)â Yixuan Weng, Minjun Zhu, Fei Xia, Bin Li, Shizhu He, Shengping Liu, Bin Sun, Kang Liu, and Jun Zhao. 2022.  [Large language models are better reasoners with self-verification](http://arxiv.org/abs/2212.09561). \n  * Weston and Sukhbaatar (2023)â Jason Weston and Sainbayar Sukhbaatar. 2023.  [System 2 attention (is something you might need too)](http://arxiv.org/abs/2311.11829). \n  * White et al. (2023)â Jules White, Quchen Fu, Sam Hays, Michael Sandborn, Carlos Olea, Henry Gilbert, Ashraf Elnashar, Jesse Spencer-Smith, and Douglas C. Schmidt. 2023.  [A prompt pattern catalog to enhance prompt engineering with chatgpt](http://arxiv.org/abs/2302.11382). \n  * Wilf et al. (2023)â Alex Wilf, Sihyun Shawn Lee, Paul Pu Liang, and Louis-Philippe Morency. 2023.  [Think twice: Perspective-taking improves large language modelsâ theory-of-mind capabilities](http://arxiv.org/abs/2311.10227). \n  * Willison (2022)â Simon Willison. 2022.  [Prompt injection attacks against gpt-3](https://simonwillison.net/2022/Sep/12/prompt-injection/). \n  * Willison (2024)â Simon Willison. 2024.  [Prompt injection and jailbreaking are not the same thing](https://simonwillison.net/2024/Mar/5/prompt-injection-jailbreaking/). \n  * Winata et al. (2023)â Genta Indra Winata, Liang-Kang Huang, Soumya Vadlamannati, and Yash Chandarana. 2023.  [Multilingual few-shot learning via language model retrieval](http://arxiv.org/abs/2306.10964). \n  * Wu et al. (2023a)â Jay Zhangjie Wu, Yixiao Ge, Xintao Wang, Weixian Lei, Yuchao Gu, Yufei Shi, Wynne Hsu, Ying Shan, Xiaohu Qie, and Mike Zheng Shou. 2023a.  [Tune-a-video: One-shot tuning of image diffusion models for text-to-video generation](http://arxiv.org/abs/2212.11565). \n  * Wu et al. (2023b)â Ning Wu, Ming Gong, Linjun Shou, Shining Liang, and Daxin Jiang. 2023b.  Large language models are diverse role-players for summarization evaluation.  _arXiv preprint arXiv:2303.15078_. \n  * Wu et al. (2022)â Tongshuang Wu, Michael Terry, and Carrie Jun Cai. 2022.  [Ai chains: Transparent and controllable human-ai interaction by chaining large language model prompts](https://doi.org/10.1145/3491102.3517582).  _CHI Conference on Human Factors in Computing Systems_. \n  * Wu et al. (2023c)â Xiaodong Wu, Ran Duan, and Jianbing Ni. 2023c.  [Unveiling security, privacy, and ethical concerns of chatgpt](https://doi.org/https://doi.org/10.1016/j.jiixd.2023.10.007).  _Journal of Information and Intelligence_. \n  * Xia et al. (2024)â Congying Xia, Chen Xing, Jiangshu Du, Xinyi Yang, Yihao Feng, Ran Xu, Wenpeng Yin, and Caiming Xiong. 2024.  [Fofo: A benchmark to evaluate llmsâ format-following capability](http://arxiv.org/abs/2402.18667). \n  * Xiong et al. (2023a)â Miao Xiong, Zhiyuan Hu, Xinyang Lu, Yifei Li, Jie Fu, Junxian He, and Bryan Hooi. 2023a.  Can llms express their uncertainty? an empirical evaluation of confidence elicitation in llms.  _arXiv preprint arXiv:2306.13063_. \n  * Xiong et al. (2023b)â Miao Xiong, Zhiyuan Hu, Xinyang Lu, Yifei Li, Jie Fu, Junxian He, and Bryan Hooi. 2023b.  Can llms express their uncertainty? an empirical evaluation of confidence elicitation in llms.  _arXiv preprint arXiv:2306.13063_. \n  * Xu et al. (2023)â Xiaohan Xu, Chongyang Tao, Tao Shen, Can Xu, Hongbo Xu, Guodong Long, and Jian guang Lou. 2023.  [Re-reading improves reasoning in language models](http://arxiv.org/abs/2309.06275). \n  * Xue et al. (2023)â Tianci Xue, Ziqi Wang, Zhenhailong Wang, Chi Han, Pengfei Yu, and Heng Ji. 2023.  [Rcot: Detecting and rectifying factual inconsistency in reasoning by reversing chain-of-thought](http://arxiv.org/abs/2305.11499). \n  * Yang et al. (2023a)â Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V. Le, Denny Zhou, and Xinyun Chen. 2023a.  [Large language models as optimizers](http://arxiv.org/abs/2309.03409). \n  * Yang et al. (2023b)â Haibo Yang, Yang Chen, Yingwei Pan, Ting Yao, Zhineng Chen, and Tao Mei. 2023b.  [3dstyle-diffusion: Pursuing fine-grained text-driven 3d stylization with 2d diffusion models](http://arxiv.org/abs/2311.05464). \n  * Yang et al. (2023c)â Hui Yang, Sifu Yue, and Yunzhong He. 2023c.  [Auto-gpt for online decision making: Benchmarks and additional opinions](http://arxiv.org/abs/2306.02224). \n  * Yang et al. (2023d)â Xinyi Yang, Runzhe Zhan, Derek F. Wong, Junchao Wu, and Lidia S. Chao. 2023d.  [Human-in-the-loop machine translation with large language model](https://files.sciconf.cn/upload/file/20230827/20230827195133_32318.pdf).  In _Proceedings of Machine Translation Summit XIX Vol. 2: Users Track_ , pages 88â98, Macau SAR, China. Machine Translation Summit. \n  * Yang et al. (2023e)â Zhengyuan Yang, Linjie Li, Kevin Lin, Jianfeng Wang, Chung-Ching Lin, Zicheng Liu, and Lijuan Wang. 2023e.  [The dawn of lmms: Preliminary explorations with gpt-4v(ision)](https://api.semanticscholar.org/CorpusID:263310951).  _ArXiv_ , abs/2309.17421. \n  * Yao et al. (2023a)â Binwei Yao, Ming Jiang, Diyi Yang, and Junjie Hu. 2023a.  [Empowering llm-based machine translation with cultural awareness](http://arxiv.org/abs/2305.14328). \n  * Yao et al. (2023b)â Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, and Karthik Narasimhan. 2023b.  [Tree of thoughts: Deliberate problem solving with large language models](http://arxiv.org/abs/2305.10601). \n  * Yao et al. (2022)â Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2022.  [React: Synergizing reasoning and acting in language models](http://arxiv.org/abs/2210.03629). \n  * Yao et al. (2023c)â Yao Yao, Zuchao Li, and Hai Zhao. 2023c.  [Beyond chain-of-thought, effective graph-of-thought reasoning in large language models](http://arxiv.org/abs/2305.16582). \n  * Yasunaga et al. (2023)â Michihiro Yasunaga, Xinyun Chen, Yujia Li, Panupong Pasupat, Jure Leskovec, Percy Liang, Ed H. Chi, and Denny Zhou. 2023.  [Large language models as analogical reasoners](http://arxiv.org/abs/2310.01714). \n  * Ye et al. (2023)â Qinyuan Ye, Maxamed Axmed, Reid Pryzant, and Fereshte Khani. 2023.  [Prompt engineering a prompt engineer](http://arxiv.org/abs/2311.05661). \n  * Ye and Durrett (2023)â Xi Ye and Greg Durrett. 2023.  [Explanation selection using unlabeled data for chain-of-thought prompting](http://arxiv.org/abs/2302.04813). \n  * Yoo et al. (2022)â Kang Min Yoo, Junyeob Kim, Hyuhng Joon Kim, Hyunsoo Cho, Hwiyeol Jo, Sang-Woo Lee, Sang goo Lee, and Taeuk Kim. 2022.  [Ground-truth labels matter: A deeper look into input-label demonstrations](http://arxiv.org/abs/2205.12685). \n  * Yoran et al. (2023)â Ori Yoran, Tomer Wolfson, Ben Bogin, Uri Katz, Daniel Deutch, and Jonathan Berant. 2023.  [Answering questions by meta-reasoning over multiple chains of thought](http://arxiv.org/abs/2304.13007). \n  * Yousaf et al. (2023)â Adeel Yousaf, Muzammal Naseer, Salman Khan, Fahad Shahbaz Khan, and Mubarak Shah. 2023.  [Videoprompter: an ensemble of foundational models for zero-shot video understanding](http://arxiv.org/abs/2310.15324). \n  * Yu et al. (2023)â Yue Yu, Yuchen Zhuang, Jieyu Zhang, Yu Meng, Alexander Ratner, Ranjay Krishna, Jiaming Shen, and Chao Zhang. 2023.  Large language model as attributed training data generator: A tale of diversity and bias.  _arXiv preprint arXiv:2306.15895_. \n  * Yue et al. (2023)â Xiang Yue, Boshi Wang, Kai Zhang, Ziru Chen, Yu Su, and Huan Sun. 2023.  Automatic evaluation of attribution by large language models.  _arXiv preprint arXiv:2305.06311_. \n  * Zeng et al. (2023)â Zhiyuan Zeng, Jiatong Yu, Tianyu Gao, Yu Meng, Tanya Goyal, and Danqi Chen. 2023.  Evaluating large language models at evaluating instruction following.  _arXiv preprint arXiv:2310.07641_. \n  * Zhang and Choi (2023)â Michael JQ Zhang and Eunsol Choi. 2023.  Clarify when necessary: Resolving ambiguity through interaction with lms.  _arXiv preprint arXiv:2311.09469_. \n  * Zhang et al. (2023a)â Quanjun Zhang, Tongke Zhang, Juan Zhai, Chunrong Fang, Bowen Yu, Weisong Sun, and Zhenyu Chen. 2023a.  [A critical review of large language model on software engineering: An example from chatgpt and automated program repair](http://arxiv.org/abs/2310.08879). \n  * Zhang et al. (2023b)â Yifan Zhang, Jingqin Yang, Yang Yuan, and Andrew Chi-Chih Yao. 2023b.  [Cumulative reasoning with large language models](http://arxiv.org/abs/2308.04371). \n  * Zhang et al. (2022a)â Yiming Zhang, Shi Feng, and Chenhao Tan. 2022a.  [Active example selection for in-context learning](http://arxiv.org/abs/2211.04486). \n  * Zhang et al. (2023c)â Zhuosheng Zhang, Yao Yao, Aston Zhang, Xiangru Tang, Xinbei Ma, Zhiwei He, Yiming Wang, Mark Gerstein, Rui Wang, Gongshen Liu, and Hai Zhao. 2023c.  [Igniting language intelligence: The hitchhikerâs guide from chain-of-thought reasoning to language agents](http://arxiv.org/abs/2311.11797). \n  * Zhang et al. (2022b)â Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola. 2022b.  [Automatic chain of thought prompting in large language models](http://arxiv.org/abs/2210.03493). \n  * Zhang et al. (2023d)â Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. 2023d.  [Multimodal chain-of-thought reasoning in language models](http://arxiv.org/abs/2302.00923). \n  * Zhao et al. (2023a)â Ruochen Zhao, Xingxuan Li, Shafiq Joty, Chengwei Qin, and Lidong Bing. 2023a.  [Verify-and-edit: A knowledge-enhanced chain-of-thought framework](https://doi.org/10.18653/v1/2023.acl-long.320).  In _Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_ , pages 5823â5840, Toronto, Canada. Association for Computational Linguistics. \n  * Zhao et al. (2021a)â Tony Z. Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021a.  [Calibrate before use: Improving few-shot performance of language models](http://arxiv.org/abs/2102.09690). \n  * Zhao et al. (2023b)â Yilun Zhao, Haowei Zhang, Shengyun Si, Linyong Nan, Xiangru Tang, and Arman Cohan. 2023b.  Large language models are effective table-to-text generators, evaluators, and feedback providers.  _arXiv preprint arXiv:2305.14987_. \n  * Zhao et al. (2023c)â Yuyang Zhao, Zhiwen Yan, Enze Xie, Lanqing Hong, Zhenguo Li, and Gim Hee Lee. 2023c.  [Animate124: Animating one image to 4d dynamic scene](http://arxiv.org/abs/2311.14603). \n  * Zhao et al. (2021b)â Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021b.  Calibrate before use: Improving few-shot performance of language models.  In _International Conference on Machine Learning_ , pages 12697â12706. PMLR. \n  * Zheng et al. (2023a)â Chujie Zheng, Hao Zhou, Fandong Meng, Jie Zhou, and Minlie Huang. 2023a.  On large language modelsâ selection bias in multi-choice questions.  _arXiv preprint arXiv:2309.03882_. \n  * Zheng et al. (2023b)â Ge Zheng, Bin Yang, Jiajin Tang, Hong-Yu Zhou, and Sibei Yang. 2023b.  [Ddcot: Duty-distinct chain-of-thought prompting for multimodal reasoning in language models](http://arxiv.org/abs/2310.16436). \n  * Zheng et al. (2023c)â Huaixiu Steven Zheng, Swaroop Mishra, Xinyun Chen, Heng-Tze Cheng, Ed H. Chi, Quoc V Le, and Denny Zhou. 2023c.  [Take a step back: Evoking reasoning via abstraction in large language models](http://arxiv.org/abs/2310.06117). \n  * Zheng et al. (2023d)â Mingqian Zheng, Jiaxin Pei, and David Jurgens. 2023d.  [Is \"a helpful assistant\" the best role for large language models? a systematic evaluation of social roles in system prompts](http://arxiv.org/abs/2311.10054). \n  * Zhou et al. (2022a)â Denny Zhou, Nathanael SchÃ¤rli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, et al. 2022a.  Least-to-most prompting enables complex reasoning in large language models.  _arXiv preprint arXiv:2205.10625_. \n  * Zhou et al. (2022b)â Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. 2022b.  [Large language models are human-level prompt engineers](http://arxiv.org/abs/2211.01910). \n  * Zhou et al. (2023)â Yucheng Zhou, Xiubo Geng, Tao Shen, Chongyang Tao, Guodong Long, Jian-Guang Lou, and Jianbing Shen. 2023.  [Thread of thought unraveling chaotic contexts](http://arxiv.org/abs/2311.08734). \n  * Zhu et al. (2023)â Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su, Chenyu Yang, Gao Huang, Bin Li, Lewei Lu, Xiaogang Wang, Yu Qiao, Zhaoxiang Zhang, and Jifeng Dai. 2023.  [Ghost in the minecraft: Generally capable agents for open-world environments via large language models with text-based knowledge and memory](http://arxiv.org/abs/2305.17144). \n  * Zuo et al. (2023)â Zhichao Zuo, Zhao Zhang, Yan Luo, Yang Zhao, Haijun Zhang, Yi Yang, and Meng Wang. 2023.  [Cut-and-paste: Subject-driven video editing with attention control](http://arxiv.org/abs/2311.11697). \n\n\n##  Appendix A Appendices\nReport issue for preceding element\n###  A.1 Definitions of Prompting\nReport issue for preceding element\n{xltabular}\n|p2cm|X|X| Reference Prompt Prompt Engineering MeskÃ³ ([2023](https://arxiv.org/html/2406.06608v1#bib.bib181)) The practice of designing, refining, and implementing prompts or instructions that guide the output of LLMs to help in various tasks. It is essentially the practice of effectively interacting with AI systems to optimize their benefits. Chen et al. ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib29)) the input of the model the process of structuring input text for LLMs and is a technique integral to optimizing the efficacy of LLMs Santu and Feng ([2023](https://arxiv.org/html/2406.06608v1#bib.bib240)) refers to a textual input provided to the LLMs with the intention of guiding its output toward a specific task involves crafting and revising the query or context in such a way that it elicits the desired response or behavior from LLMs Wang et al. ([2023d](https://arxiv.org/html/2406.06608v1#bib.bib288)) involves designing effective prompts to guide the pre-trained language model in downstream tasks. Wang et al. ([2023c](https://arxiv.org/html/2406.06608v1#bib.bib287)) the process of designing prompts that enable the model to adapt and generalize to different tasks. downstream tasks. Hou et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib94)) manually predefined natural language instructions the careful design of specialized prompts Wang et al. ([2023e](https://arxiv.org/html/2406.06608v1#bib.bib289)) input of the LLMs communicate with LLMs to steer its behavior for desired outcomes \nReport issue for preceding element\nWhite et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib305)) Instructions given to an LLM to enforce rules, automate processes, and ensure specific qualities (and quantities) of generated output. Prompts are also a form of programming that can customize the outputs and interactions with an LLM.\nReport issue for preceding element\nA prompt is a set of instructions provided to an LLM that programs the LLM by customizing it and/or en- hancing or refining its capabilities an increasingly important skill set needed to converse effectively with large language models (LLMs), such as ChatGPT\nReport issue for preceding element\nthe means by which LLMs are programmed via prompts Heston and Khun ([2023](https://arxiv.org/html/2406.06608v1#bib.bib92)) the input structuring the input in a specialized manner \nReport issue for preceding element\nLiu et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib159)) choosing a proper prompt\nReport issue for preceding element\nthe process of creating a prompting function fpâ¢râ¢oâ¢mâ¢pâ¢tâ¢(x)subscriptððððððð¡ð¥f_{prompt}(x)italic_f start_POSTSUBSCRIPT italic_p italic_r italic_o italic_m italic_p italic_t end_POSTSUBSCRIPT ( italic_x ) that results in the most effective performance on the downstream task. Hadi et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib83)) the instructions provided to an LLM to make it follow specified rules, automation of processes and to ensure that the output generated is of a specific quality or quantity refers to the designing and wording of prompts given to LLMs so as to get a desired response from them. \nReport issue for preceding element\nNeagu ([2023](https://arxiv.org/html/2406.06608v1#bib.bib193)) entails various strate- gies, including explicit instruction, and implicit context [21]. Explicit instruction involves providing explicit guidance or constraints to the model through instructions, examples, or specifications. Implicit context leverages the modelâs under- standing of the preceding context to influence its response Dang et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib43)) the systematic practice of constructing prompts to improve the generated output of a generative model Definitions of Prompt and Prompt Engineering from different papers.\nReport issue for preceding element\n###  A.2 Extended Vocabulary\nReport issue for preceding element\n####  A.2.1 Prompting Terms\nReport issue for preceding element\n###### Context Window\nReport issue for preceding element\nThe context window is the space of tokens (for LLMs) which the model can process. It has a maximal length (the context length).\nReport issue for preceding element\n###### Priming\nReport issue for preceding element\nSchulhoff ([2022](https://arxiv.org/html/2406.06608v1#bib.bib248)) refers to giving a model an initial prompt that lays out certain instructions for the rest of a conversation. This priming prompt might contains a role or other instructions on how to interact with the user. Priming can either be done in the system or user prompt (see below).\nReport issue for preceding element\n####  A.2.2 Prompt Engineering Terms\nReport issue for preceding element\n###### Conversational Prompt Engineering\nReport issue for preceding element\nis Prompt Engineering in colloquio. That is, during the course of a conversation with a GenAI, a user may ask the GenAI to refine its output. In contrast, prompt engineering is often done by sending the GenAI a completely new prompt rather than continuing a conversation.\nReport issue for preceding element\n####  A.2.3 Fine-Tuning Terms\nReport issue for preceding element\n###### Prompt-Based Learning\nReport issue for preceding element\nLiu et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib159)), also known as Prompt Learning Liu et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib159)); Wang et al. ([2023d](https://arxiv.org/html/2406.06608v1#bib.bib288)) refers to the process of using prompting-related techniques. It often is used in the context of fine-tuning, especially fine-tuning prompts. Due to conflicting usage, we do not use this term.\nReport issue for preceding element\n###### Prompt Tuning\nReport issue for preceding element\nLester et al. ([2021](https://arxiv.org/html/2406.06608v1#bib.bib135)) refers to directly optimizing the weights of the prompt itself, usually through some form of gradient-based updates. It has also been referred to has Prompt Fine-Tuning. It should not be used to refer to discrete prompt engineering.\nReport issue for preceding element\n####  A.2.4 Orthogonal Prompt Types\nReport issue for preceding element\nWe now discuss terminology for high-level ways of classifying prompts.\nReport issue for preceding element\n#####  A.2.4.1 Originator\nReport issue for preceding element\n###### User Prompt\nReport issue for preceding element\nThis is the type of prompt that comes from the user. This is the most common form of prompting and is how prompts are usually delivered in consumer applications.\nReport issue for preceding element\n###### Assistant Prompt\nReport issue for preceding element\nThis \"prompt\" is simply the output of the LLM itself. It can be considered a prompt (or part of one) when it is fed back into the model, for example as part of a conversation history with a user.\nReport issue for preceding element\n###### System Prompt\nReport issue for preceding element\nThis prompt is used to give LLMs high level instructions for interacting with users. Not all models have this.\nReport issue for preceding element\n#####  A.2.4.2 Hard vs Soft Prompts\nReport issue for preceding element\n###### Hard (discrete) Prompt\nReport issue for preceding element\nThese prompts only contain tokens that directly correspond to words in the LLM vocabulary.\nReport issue for preceding element\n###### Soft (continuous) Prompt\nReport issue for preceding element\nThese prompts contain tokens that may not correspond to any word in the vocabulary Lester et al. ([2021](https://arxiv.org/html/2406.06608v1#bib.bib135)); Wang et al. ([2023c](https://arxiv.org/html/2406.06608v1#bib.bib287)). Soft prompts can be used when fine-tuning is desired, but modifying the weights of the full model is prohibitively expensive. Thus, a frozen model can be used while allowing gradients to flow through the prompt tokens.\nReport issue for preceding element\n| Hard PromptsâSoft PromptsHard PromptsSoft Prompts\\text{Hard Prompts}\\subseteq\\text{Soft Prompts}Hard Prompts â Soft Prompts |   \n---|---|---  \n#####  A.2.4.3 Prediction Styles\nReport issue for preceding element\nIn LLMs, a prediction style is the format in which it predicts the next token. There are two common formats for this in prompting research. We do not discuss non-text prediction styles.\nReport issue for preceding element\n###### Cloze\nReport issue for preceding element\nIn Cloze prompts, the token(s) to be predicted are presented as \"slots to fill\", usually somewhere in the middle of the prompt Liu et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib159)). This is usually the case for earlier transformer models such as BERT Chu and Lin ([2023](https://arxiv.org/html/2406.06608v1#bib.bib38)).\nReport issue for preceding element\n###### Prefix\nReport issue for preceding element\nIn Prefix prompts, the token to be predicted is at the end of the prompt Liu et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib159)). This is usually the case with modern GPT-style models Radford et al. ([2019b](https://arxiv.org/html/2406.06608v1#bib.bib229)).\nReport issue for preceding element\n###  A.3 Datasheet\nReport issue for preceding element\nWe present a datasheet Gebru et al. ([2021](https://arxiv.org/html/2406.06608v1#bib.bib71)) with more information about the associated paper dataset, which is hosted on [HuggingFace](https://huggingface.co/datasets/PromptSystematicReview/Prompt_Systematic_Review_Dataset).\nReport issue for preceding element\n####  A.3.1 Motivation\nReport issue for preceding element\nFor what purpose was the dataset created? Was there a specific task in mind? Was there a specific gap that needed to be filled? Please provide a description. This dataset was created to gather existing literature on prompt engineering in order to analyze all current hard prefix prompting techniques.\nReport issue for preceding element\nWho created the dataset (e.g., which team, research group) and on behalf of which entity (e.g., company, institution, organization)? This research was associated with the University of Maryland, Learn Prompting, and sponsored by OpenAI, but not created on the behalf of any particular organization.\nReport issue for preceding element\nWho funded the creation of the dataset? If there is an associated grant, please provide the name of the grantor and the grant name and number. OpenAI contributed $10,000 in credits for their API.\nReport issue for preceding element\n####  A.3.2 Composition\nReport issue for preceding element\nWhat do the instances that comprise the dataset represent (e.g., documents, photos, people, countries)? Are there multiple types of instances (e.g., movies, users, and ratings; people and interactions between them; nodes and edges)? Please provide a description. The dataset contains 1,565 research papers in PDF format. Any duplicate papers were removed automatically, though some could exist.\nReport issue for preceding element\nWhat data does each instance consist of? âRawâ data (e.g., unprocessed text or images) or features? In either case, please provide a description. Each data instance is a research paper as a PDF.\nReport issue for preceding element\nIs there a label or target associated with each instance? If so, please provide a description. No\nReport issue for preceding element\nIs any information missing from individual instances? If so, please provide a description, explaining why this information is missing (e.g., because it was unavailable). This does not include intentionally removed information, but might include, e.g., redacted text. No.\nReport issue for preceding element\nAre there any errors, sources of noise, or redundancies in the dataset? If so, please provide a description. The papers were gathered in a semi-automated process which introduced the possibility of irrelevant papers being collected and relevant papers not being collected. There were manual reviews done for both possible errors to mitigate these errors.\nReport issue for preceding element\nIs the dataset self-contained, or does it link to or otherwise rely on external resources (e.g., websites, tweets, other datasets)? It is self-contained.\nReport issue for preceding element\nDoes the dataset contain data that might be considered confidential (e.g., data that is protected by legal privilege or by doctorâpatient confidentiality, data that includes the content of individualsâ non-public communications)? If so, please provide a description. No.\nReport issue for preceding element\nDoes the dataset contain data that, if viewed directly, might be offensive, insulting, threatening, or might otherwise cause anxiety? If so, please describe why. The dataset contains some papers on prompt injection. These papers may contain offensive content including racism and sexism.\nReport issue for preceding element\n####  A.3.3 Collection Process\nReport issue for preceding element\nHow was the data associated with each instance acquired? The dataset was compiled from Arxiv, Semantic Scholar, and ACL.\nReport issue for preceding element\nWhat mechanisms or procedures were used to collect the data? We wrote scripts to automatically query the APIs of Arxiv and Semantic Scholar.\nReport issue for preceding element\nOver what timeframe was the data collected? The dataset was curated the duration of the research paper, primarily in February of 2024.\nReport issue for preceding element\nWere any ethical review processes conducted? No.\nReport issue for preceding element\n####  A.3.4 Preprocessing/ Cleaning/ Labeling\nReport issue for preceding element\nWas any preprocessing/cleaning/labeling of the data done? After collecting data from different sources, we removed duplicate papers and did a manual and semi-automated review of papers to ensure they were all relevant.\nReport issue for preceding element\nWas the ârawâ data saved in addition to the preprocessed/cleaned/labeled data? No, we do not anticipate the use of our preprocessed data. However, raw data can be recovered from the links we store.\nReport issue for preceding element\nIs the software that was used to preprocess/clean/label the data available? It is contained within our code repository on [Github](https://github.com/trigaten/Prompt_Systematic_Review/tree/main/src/prompt_systematic_review/get_papers).\nReport issue for preceding element\n####  A.3.5 Uses\nReport issue for preceding element\nHas the dataset been used for any tasks already? No.\nReport issue for preceding element\nIs there a repository that links to any or all papers or systems that use the dataset? [Yes](https://huggingface.co/datasets/PromptSystematicReview/Prompt_Systematic_Review_Dataset).\nReport issue for preceding element\nIs there anything about the composition of the dataset or the way it was collected and preprocessed/cleaned/labeled that might impact future uses? All of the papers we collected were written in English. It is possible some papers were not included due to a translation not being available.\nReport issue for preceding element\nAre there tasks for which the dataset should not be used? No.\nReport issue for preceding element\n####  A.3.6 Distribution\nReport issue for preceding element\nWill the dataset be distributed to third parties outside of the entity on behalf of which the dataset was created? No.\nReport issue for preceding element\n####  A.3.7 Maintenance\nReport issue for preceding element\nWho will be supporting/hosting/maintaining the dataset? Our team will continue maintenance.\nReport issue for preceding element\nHow can the owner/curator/manager of the dataset be contacted? Please email us at sanderschulhoff@gmail.com\nReport issue for preceding element\nIs there an erratum? No.\nReport issue for preceding element\nIf others want to extend/augment/build on/contribute to the dataset, is there a mechanism for them to do so? Yes, anyone is free to use/modify the data.\nReport issue for preceding element\n###  A.4 Keywords\nReport issue for preceding element\nHere are the keywords we used for search.\nReport issue for preceding element\n  * â¢\njailbreak prompt\nReport issue for preceding element\n  * â¢\nprompt an llm\nReport issue for preceding element\n  * â¢\nprompt a large language model\nReport issue for preceding element\n  * â¢\nprompt injection\nReport issue for preceding element\n  * â¢\nprompt optimization\nReport issue for preceding element\n  * â¢\nprompt engineering\nReport issue for preceding element\n  * â¢\nfew-shot learning\nReport issue for preceding element\n  * â¢\nfew shot learning\nReport issue for preceding element\n  * â¢\nprompt-based methods\nReport issue for preceding element\n  * â¢\nprompt based methods\nReport issue for preceding element\n  * â¢\nprompting-based methods\nReport issue for preceding element\n  * â¢\nprompting based methods\nReport issue for preceding element\n  * â¢\nfew-shot prompt\nReport issue for preceding element\n  * â¢\nfew shot prompt\nReport issue for preceding element\n  * â¢\none-shot prompt\nReport issue for preceding element\n  * â¢\none shot prompt\nReport issue for preceding element\n  * â¢\nfew-shot prompting\nReport issue for preceding element\n  * â¢\nfew shot prompting\nReport issue for preceding element\n  * â¢\none-shot prompting\nReport issue for preceding element\n  * â¢\none shot prompting\nReport issue for preceding element\n  * â¢\nprompting techniques\nReport issue for preceding element\n  * â¢\nprompt engineering techniques\nReport issue for preceding element\n  * â¢\nllm prompting\nReport issue for preceding element\n  * â¢\nlarge language model prompting\nReport issue for preceding element\n  * â¢\n0-shot prompt\nReport issue for preceding element\n  * â¢\n0 shot prompt\nReport issue for preceding element\n  * â¢\nzero-shot prompt\nReport issue for preceding element\n  * â¢\nmany-shot prompt\nReport issue for preceding element\n  * â¢\nzero-shot prompting\nReport issue for preceding element\n  * â¢\nmany-shot prompting\nReport issue for preceding element\n  * â¢\nin-context learning\nReport issue for preceding element\n  * â¢\nin context learning\nReport issue for preceding element\n  * â¢\ntransformer model prompts\nReport issue for preceding element\n  * â¢\nprompt-based transfer learning\nReport issue for preceding element\n  * â¢\nnlp prompting strategies\nReport issue for preceding element\n  * â¢\nllm interpretability via prompts\nReport issue for preceding element\n  * â¢\ncurriculum learning with prompts\nReport issue for preceding element\n  * â¢\nfeedback loops in llm prompting\nReport issue for preceding element\n  * â¢\nhuman-in-the-loop prompting\nReport issue for preceding element\n  * â¢\ntoken-efficient prompting\nReport issue for preceding element\n  * â¢\nmultimodal prompting\nReport issue for preceding element\n  * â¢\ninstruction prompting\nReport issue for preceding element\n  * â¢\nprompt templating\nReport issue for preceding element\n  * â¢\nprompt template\nReport issue for preceding element\n\n\n###  A.5 Evaluation Table\nReport issue for preceding element\nID | Model | Prompt | Output Space | Type | Res. | Batch  \n---|---|---|---|---|---|---  \nRoles | CoT | Definition | Few-Shot  \nKocmi and Federmann ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib126)) | GPT-family |  |  |  |  | DA, sMQM, stars, classes | E | S |   \nLu et al. ([2023c](https://arxiv.org/html/2406.06608v1#bib.bib170)) | Dav3, Turbo, GPT-4 |  | â | â | â | Error Span ââ\\rightarrowâ Score | E | S | â  \nFernandes et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib57)) | PaLM |  | â | â | â | Error Span | I | S |   \nKocmi and Federmann ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib125)) | GPT-4 |  | â | â | â | Error Span | I | S | â  \nAraÃºjo and Aguiar ([2023](https://arxiv.org/html/2406.06608v1#bib.bib5)) | ChatGPT |  |  | â |  | Likert [1-5] | E | S | â  \nWang et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib286)) | ChatGPT |  |  | â |  | DA, stars | E | S |   \nLiu et al. ([2023d](https://arxiv.org/html/2406.06608v1#bib.bib161))â â \\daggerâ  | GPT-3.5, GPT-4 |  |  | â |  | Likert [1-10] | I | M |   \nChan et al. ([2024](https://arxiv.org/html/2406.06608v1#bib.bib26)) | ChatGPT, GPT-4 | â | â |  |  | Likert [1-10] | I | M |   \nLuo et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib173)) | ChatGPT |  | â | â |  | yes/no;A/B; Likert [1-10] | E | S |   \nHada et al. ([2024](https://arxiv.org/html/2406.06608v1#bib.bib82)) | GPT4-32K |  |  | â | â | [0,1,2] or binary | E | S | â  \nFu et al. ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib58)) | GPT3, OPT, FLAN-T5, GPT2 |  |  |  |  | Probability | I | S |   \nGao et al. ([2023c](https://arxiv.org/html/2406.06608v1#bib.bib66)) | ChatGPT |  |  | â |  | Likert [1-5], Pairwise, Pyramid, 0/1 | E | S |   \nChen et al. ([2023g](https://arxiv.org/html/2406.06608v1#bib.bib35)) | ChatGPT |  |  |  |  | Likert [1-10]; yes/no; pairwise: A/B/C | E & I | S |   \nHe et al. ([2023a](https://arxiv.org/html/2406.06608v1#bib.bib87)) | GPT-4 |  |  | â |  | Likert [1-5] | E | S |   \nSottana et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib271)) | GPT-4 |  |  | â |  | Likert [1-5] | E | S |   \nChen et al. ([2023c](https://arxiv.org/html/2406.06608v1#bib.bib31)) | GPT, Flan-T5 |  | â |  |  | Yes/No | E | S |   \nZhao et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib346)) | GPT-3.5, GPT-4 |  | â |  | â | true/false | E | S |   \nWu et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib311)) | GPT-3 | â |  |  |  | pairwise voting | E | M | â  \nWang et al. ([2023i](https://arxiv.org/html/2406.06608v1#bib.bib294)) | PaLM 2-IT-L |  |  |  |  | A/B | E | M |   \nJia et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib104)) | LLaMa7b |  |  |  |  | Probability | I | S |   \nYue et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib335)) | ChatGPT, Alpaca, Vicuna, GPT-4 |  |  | â | â | Yes/No | E | S |   \nLi et al. ([2023e](https://arxiv.org/html/2406.06608v1#bib.bib142)) | GPT-3.5, GPT-4, Bard, Vicuna |  | â |  |  | Pairwise | I | M |   \nLiu et al. ([2023f](https://arxiv.org/html/2406.06608v1#bib.bib163)) | ChatGPT, Vicuna, chatGLM, StableLM |  |  | â |  | continuous [0-1] | E | S |   \nBai et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib11)) | GPT-4, Claude, ChatGPT, Bard, Vicuna |  |  | â |  | Likert [1-5] | E | S |   \nDubois et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib51)) | GPT-4, ChatGPT, Dav3 |  |  | â | â | pairwise | E | M | â  \nLiu et al. ([2023h](https://arxiv.org/html/2406.06608v1#bib.bib165))â â \\daggerâ  | GPT-4-32K |  |  | â |  | Likert [1-5] | E | S |   \nWang et al. ([2023h](https://arxiv.org/html/2406.06608v1#bib.bib292)) | Turbo, ChatGPT, GPT-4, Vicuna |  | â |  |  | Likert [1-10] | E | M |   \nZeng et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib336)) | GPT-4, ChatGPT, LLaMA-2-Chat, PaLM2, Falcon | â | â |  | â | Pairwise | E | S |   \nZheng et al. ([2023b](https://arxiv.org/html/2406.06608v1#bib.bib350)) | Claude-v1, GPT-3.5, GPT-4 |  | â |  | â | Pairwise/Likert [1-10] | E | S/M |   \nLin and Chen ([2023](https://arxiv.org/html/2406.06608v1#bib.bib155)) | Claude-v1.3 |  |  |  |  | Likert [0-5], Likert [0-100] | E | S | â  \nTable A.1: Evaluation Paper Summary. E: Explicit (whether the model generates an assessment), I: Implicit (whether an assessment is derived from the model output); Response (Res.) S: Single response, M: Multiple responses; â â \\daggerâ : Model generated instruction;  Report issue for preceding element\n###  A.6 Entrapment Prompting Process\nReport issue for preceding element\nThis section contains the thought process of our prompt engineer as he developed the prompt.\nReport issue for preceding element\n####  A.6.1 Exploration\nReport issue for preceding element\n  * â¢\nFirst did a bit of dataset exploration, looking at length/label distribution, then chose entrapment to start with.\nReport issue for preceding element\n  * â¢\nChecked if gpt-1106-preview understood entrapment, by asking it to define the term WRT SCS. It did not.\nReport issue for preceding element\n\n\n####  A.6.2 Getting a Label\nReport issue for preceding element\n  * â¢\nShowed it the definition of entrapment in the system prompt and asked it to label a data point, but it responded saying I should seek mental health support.\nReport issue for preceding element\n  * â¢\nI put the instructions in the user prompt, but get a similar response.\nReport issue for preceding element\n  * â¢\nAppending \"Is this entrapment? Yes or no\" got it to actually respond with a label.\nReport issue for preceding element\n  * â¢\nI gave it a reject example, but it labeled it as accept, and also sometimes gives emotional responses about getting help.\nReport issue for preceding element\n  * â¢\nUsing 10-shot prompting, it still gives the get help responses.\nReport issue for preceding element\n  * â¢\nI tried removing the definition, got the same problem. It seems that it doesnât like \"accept\"/\"reject\" as labels.\nReport issue for preceding element\n  * â¢\nI added back the definition, changed labels to entrapment/not entrapment, it often says \"not enough info to determine\".\nReport issue for preceding element\n  * â¢\nI switched to GPT-4-32K, which gave one word responses and correctly predicted a reject and an accept datapoint.\nReport issue for preceding element\n\n\n####  A.6.3 Varying Prompting Techniques\nReport issue for preceding element\n  * â¢\nTested 0-shot with context.\nReport issue for preceding element\n  * â¢\n10-shot with context, showed improvement.\nReport issue for preceding element\n  * â¢\nTaking first failing instance into playground. (12th in train file)\nReport issue for preceding element\n  * â¢\nTried doing âA: Letâs go step by step and figure this out: \", output \"A: Yes\"\nReport issue for preceding element\n  * â¢\nDid \"A: Letâs go step by step and figure this out: \", OUTPUT:\nReport issue for preceding element\nThe individual in this post is expressing feelings of hopelessness, loneliness, and despair. They mention a significant loss (their mother) and a subsequent decline in their mental health, turning to alcohol as a coping mechanism. They also mention financial struggles and the possibility of becoming homeless. They express feelings of guilt and shame about their situation and compare themselves negatively to their friends and family. Most concerning is their detailed plan for suicide, involving sleeping pills and alcohol. They also mention considering stepping in front of a car. Given these factors, the label for this post would be \"Yes\" for expressing feelings of entrapment. Report issue for preceding element\n  * â¢\n\"A: Before predicting a label, letâs go step by step and write out your thought process. Use the items in the definition of entrapment to support your conclusion.\", OUTPUT:\nReport issue for preceding element\nBefore predicting a label, letâs go step by step and write out your thought process. Use the items in the definition of entrapment to support your conclusion. Report issue for preceding element\n  * â¢\nBegan discussing with the AI \"they donât ever say they feel trapped or that there is no way out, how did u get that idea?\", OUTPUT:\nReport issue for preceding element\nThe individual doesnât explicitly state that they feel trapped or that there is no way out, but their narrative suggests a sense of entrapment. They mention that they are facing eviction, struggling with debt, and dealing with a decrease in income. They also express a sense of hopelessness and despair, and contemplate suicide as a potential solution to their problems. These elements suggest a feeling of being trapped in their current circumstances with no apparent way out. However, itâs important to note that this interpretation is based on the information provided in the post and the individualâs expressed feelings and thoughts. Report issue for preceding element\n  * â¢\nAsked it to help reformulate instructions to make explicitness more clearly needed, still predicts entrapment.\nReport issue for preceding element\n  * â¢\nAdded \"ENTRAPMENT MUST BE EXPLICIT, NOT IMPLICIT.\" to instruction at top after definitions (no CoT inducer)\nReport issue for preceding element\n  * â¢\nAlso tried with previous CoT inducer, still says entrapment in a hard to parse out way.\nReport issue for preceding element\n  * â¢\nAdded \"If the person does not explicitly say they feel trapped, this doesnât count as entrapment.\" (no CoT), still entrapment.\nReport issue for preceding element\n  * â¢\nTalking to AI, it thinks \"Today I found out I have 10 days to vacate my apartment or Iâll be formally evicted. Iâm 2 months behind on my rent due to a bad time where I got demoted at work and rent from making roughly $1000 ever 2 weeks to around $450. If I get evicted, Iâll probably be homeless\" is feeling trapped/stuck.\nReport issue for preceding element\n  * â¢\nTried \"Before stating a label, write out reasoning using the grid above about why this may/may not be entrapment:\", still thinks entrapment.\nReport issue for preceding element\n  * â¢\npaste in email: [REDACTED] above definition of entrapment\nReport issue for preceding element\n  * â¢\nremove shots, says \"Entrapment\"\nReport issue for preceding element\n  * â¢\nadd this after def: IMPORTANT: Only label the post as entrapment if they explicitly say that they feel trapped., says \"Yes\"\nReport issue for preceding element\n  * â¢\nIn the prompt, gave it CoT reasoning. (18.txt), and tried with the next wrongly labeled one (15), (full prompt, 19.txt)\nReport issue for preceding element\n  * â¢\nTested this on everything except first 20, did pretty well\nReport issue for preceding element\n  * â¢\nTried removing email, performance dropped of a cliff\nReport issue for preceding element\n  * â¢\nAt this point, I am thinking that giving examples with reasoning helps (obviously)\nReport issue for preceding element\n  * â¢\nTried to add 10 shots in for free, before the last one with reasoning, bad results\nReport issue for preceding element\n\n\n#####  A.6.3.1 AutoCoT\nReport issue for preceding element\n  * â¢\nDevelop dataset using this prompt (22.txt). Then ask it \"Why?\". If it disagrees, I say \"It is actually not entrapment, please explain why.\" (accidentally duplicated email 23.txt)\nReport issue for preceding element\n  * â¢\nJust for fun, tried 0 shot full context (had to adjust verbalizer)\nReport issue for preceding element\n  * â¢\ntried this with special verbalizer which catches \"This post does not meet the criteria for Entrapment.\"\nReport issue for preceding element\n  * â¢\nTested my generated data, beat 0.5 F1\nReport issue for preceding element\n  * â¢\nDoing 10 more exemplars w autocot. Sometimes responds immediately with reasoning like \"This post does not meet the criteria for Entrapment as the individual does not explicitly express feelings of being trapped or hopeless.\", so just use that if so. Sometimes get refusal \"Iâm really sorry to hear that youâre feeling this way, but Iâm unable to provide the help that you need. Itâs really important to talk things over with someone who can, though, such as a mental health professional or a trusted person in your life.\", just ask \"Explain why it is not entrapment.\" after if so.\nReport issue for preceding element\n  * â¢\nperformance didnt really improve, realized about 11% are getting -1, meaning not extracted properly. Retrying with full words \"Question\" instead of Q, also for reasoning and answer.\nReport issue for preceding element\n  * â¢\nthis led to higher inability to parse, at about 16%.\nReport issue for preceding element\n\n\n#####  A.6.3.2 Developing Answer Extraction\nReport issue for preceding element\n  * â¢\nput first failing to parse one in (22), and developed a prompt for it.\nReport issue for preceding element\n  * â¢\ndid worse: (0.42857142857142855, 0.5051546391752577, 0.8571428571428571, 0.2857142857142857)\nReport issue for preceding element\n  * â¢\nonly using extracted label if have -1 helps slightly to (0.48, 0.61, 0.8571428571428571, 0.3333333333333333)\nReport issue for preceding element\n  * â¢\ngoing back to best performing promptâ10 QRA shot, and performing extraction with any -1s, doesnt help other than gently boosting accuracy, perhaps when it doesnt answer\nReport issue for preceding element\n\n\n#####  A.6.3.3 Iterating on Email\nReport issue for preceding element\n  * â¢\ntried best perf, with no email\nReport issue for preceding element\n  * â¢\ntried with deduped email, worse results\nReport issue for preceding element\n  * â¢\nnoticed that ones its unsure about often contained 1 labels that should be 0, so trying to \"recover\" these doesnt help\nReport issue for preceding element\n  * â¢\ntry moving around exemplar order, performing extraction, didnt help\nReport issue for preceding element\n  * â¢\ntriplicated email, didnt help\nReport issue for preceding element\n\n\n###  A.7 Formally Defining a Prompt\nReport issue for preceding element\n\"Prompt\" is a widely used term, but uses and definitions differ widely across research. As a result, it is difficult to create a formal, mathematical definition for a prompt. In this section, we outline some formalisms for prompt engineering.\nReport issue for preceding element\n###### As a conditioning Mechanism.\nReport issue for preceding element\nQiao et al. ([2022](https://arxiv.org/html/2406.06608v1#bib.bib224)) present the following definition, which involves the prompt ð¯ð¯\\mathcal{T}caligraphic_T and a question ð¬ð¬\\mathcal{Q}caligraphic_Q as conditioning mechanisms on predicting the next token. Note that they appear to use Brown et al. ([2020](https://arxiv.org/html/2406.06608v1#bib.bib22))âs original definition of prompt, which refers to the non-question part of the prompt (e.g. few-shot exemplars, instructions).\nReport issue for preceding element\n| pâ¢(ðâ£ð¯,ð¬)=âi=1|ð|pLMâ¢(aiâ£ð¯,ð¬,a1:iâ1)ðconditionalðð¯ð¬superscriptsubscriptproductð1ðsubscriptðLMconditionalsubscriptððð¯ð¬subscriptð:1ð1\\displaystyle p(\\mathcal{A}\\mid\\mathcal{T},\\mathcal{Q})=\\prod_{i=1}^{|\\mathcal% {A}|}p_{\\rm LM}\\left(a_{i}\\mid\\mathcal{T},\\mathcal{Q},a_{1:i-1}\\right)italic_p ( caligraphic_A â£ caligraphic_T , caligraphic_Q ) = â start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT | caligraphic_A | end_POSTSUPERSCRIPT italic_p start_POSTSUBSCRIPT roman_LM end_POSTSUBSCRIPT ( italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT â£ caligraphic_T , caligraphic_Q , italic_a start_POSTSUBSCRIPT 1 : italic_i - 1 end_POSTSUBSCRIPT ) |  | (A.1)  \n---|---|---|---  \nHere, the prompt and question condition the pre-trained LLM pLMsubscriptðLMp_{\\rm LM}italic_p start_POSTSUBSCRIPT roman_LM end_POSTSUBSCRIPT. The a1:iâ1subscriptð:1ð1a_{1:i-1}italic_a start_POSTSUBSCRIPT 1 : italic_i - 1 end_POSTSUBSCRIPT are previously generated answer tokens and ðð\\mathcal{A}caligraphic_A a complete answer.\nReport issue for preceding element\n###### Templating.\nReport issue for preceding element\nThe above formalization does not include the notion of maximizing a scoring or utility function (e.g. accuracy on a dataset), which prompts are often designed to do. Additionally, prompt engineers often seek to design prompt template rather than prompts. Here, we reformulate [eq. A.1](https://arxiv.org/html/2406.06608v1#A1.E1 \"In As a conditioning Mechanism. â£ A.7 Formally Defining a Prompt â£ Appendix A Appendices â£ The Prompt Report: A Systematic Survey of Prompting Techniques\") to include the prompt template:\nReport issue for preceding element\n| pâ¢(ðâ£ð¯â¢(xâ))=âi=1|ð|pLMâ¢(aiâ£ð¯â¢(xâ),a1:iâ1)ðconditionalðð¯superscriptð¥superscriptsubscriptproductð1ðsubscriptðLMconditionalsubscriptððð¯superscriptð¥subscriptð:1ð1\\displaystyle p(\\mathcal{A}\\mid\\mathcal{T}(x^{*}))=\\prod_{i=1}^{|\\mathcal{A}|}% p_{\\rm LM}\\left(a_{i}\\mid\\mathcal{T}(x^{*}),a_{1:i-1}\\right)italic_p ( caligraphic_A â£ caligraphic_T ( italic_x start_POSTSUPERSCRIPT â end_POSTSUPERSCRIPT ) ) = â start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT | caligraphic_A | end_POSTSUPERSCRIPT italic_p start_POSTSUBSCRIPT roman_LM end_POSTSUBSCRIPT ( italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT â£ caligraphic_T ( italic_x start_POSTSUPERSCRIPT â end_POSTSUPERSCRIPT ) , italic_a start_POSTSUBSCRIPT 1 : italic_i - 1 end_POSTSUBSCRIPT ) |  | (A.2)  \n---|---|---|---  \nWe replace ð¬ð¬\\mathcal{Q}caligraphic_Q with xââðevalsuperscriptð¥subscriptðevalx^{*}\\in\\mathcal{D}_{\\text{eval}}italic_x start_POSTSUPERSCRIPT â end_POSTSUPERSCRIPT â caligraphic_D start_POSTSUBSCRIPT eval end_POSTSUBSCRIPT, an item from a dataset (e.g., evaluation data). Additionally, we replace ð¬ð¬\\mathcal{Q}caligraphic_Q on the right side with ð¯â¢(x)ð¯ð¥\\mathcal{T}(x)caligraphic_T ( italic_x ). ð¯â¢(â)ð¯â\\mathcal{T}(\\cdot)caligraphic_T ( â ) is a prompt template: a function that accepts some item as input then returns a prompt that is used to condition the model.\nReport issue for preceding element\n###### Few-Shot Prompting.\nReport issue for preceding element\nOften, an important part of the prompting process is the use of few-shot exemplars. ðtâ¢râ¢aâ¢iâ¢nsubscriptðð¡ðððð\\mathcal{D}_{train}caligraphic_D start_POSTSUBSCRIPT italic_t italic_r italic_a italic_i italic_n end_POSTSUBSCRIPT is training data (used to build the prompt) and ð³ð³\\mathcal{X}caligraphic_X is a test set for evaluation.\nReport issue for preceding element\n| ðtrainsubscriptðtrain\\displaystyle\\mathcal{D}_{\\text{train}}caligraphic_D start_POSTSUBSCRIPT train end_POSTSUBSCRIPT | ={(x1,y1),(x2,y2),â¦,(xn,yn)}absentsubscriptð¥1subscriptð¦1subscriptð¥2subscriptð¦2â¦subscriptð¥ðsubscriptð¦ð\\displaystyle=\\\\{(x_{1},y_{1}),(x_{2},y_{2}),...,(x_{n},y_{n})\\\\}= { ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) , ( italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) , â¦ , ( italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) } |  | (A.3)  \n---|---|---|---|---  \n| ð³ð³\\displaystyle\\mathcal{X}caligraphic_X | ={x1â,x2â,â¦,xmâ}absentsubscriptsuperscriptð¥1subscriptsuperscriptð¥2â¦subscriptsuperscriptð¥ð\\displaystyle=\\\\{x^{*}_{1},x^{*}_{2},...,x^{*}_{m}\\\\}= { italic_x start_POSTSUPERSCRIPT â end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUPERSCRIPT â end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , â¦ , italic_x start_POSTSUPERSCRIPT â end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT } |  | (A.4)  \nIn the few-shot setting, the prompt template function ð¯â¢(â)ð¯â\\mathcal{T}(\\cdot)caligraphic_T ( â ) also takes as input one or more training samples ð³={(xi,yi)}1nâðtrainð³superscriptsubscriptsubscriptð¥ðsubscriptð¦ð1ðsubscriptðtrain\\mathcal{X}=\\\\{(x_{i},y_{i})\\\\}_{1}^{n}\\subset\\mathcal{D}_{\\text{train}}caligraphic_X = { ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) } start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT â caligraphic_D start_POSTSUBSCRIPT train end_POSTSUBSCRIPT\nReport issue for preceding element\n| pâ¢(ðâ£ð¯â¢(ð³,xâ))=âi=1|ð|pLMâ¢(aiâ£ð¯â¢(ð³,xâ),a1:iâ1)ðconditionalðð¯ð³superscriptð¥superscriptsubscriptproductð1ðsubscriptðLMconditionalsubscriptððð¯ð³superscriptð¥subscriptð:1ð1\\displaystyle p\\bigl{(}\\mathcal{A}\\mid\\mathcal{T}\\left(\\mathcal{X},\\ x^{*}% \\right)\\bigr{)}=\\prod_{i=1}^{|\\mathcal{A}|}p_{\\rm LM}\\left(a_{i}\\mid\\mathcal{T% }\\left(\\mathcal{X},\\ x^{*}\\right),a_{1:i-1}\\right)italic_p ( caligraphic_A â£ caligraphic_T ( caligraphic_X , italic_x start_POSTSUPERSCRIPT â end_POSTSUPERSCRIPT ) ) = â start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT | caligraphic_A | end_POSTSUPERSCRIPT italic_p start_POSTSUBSCRIPT roman_LM end_POSTSUBSCRIPT ( italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT â£ caligraphic_T ( caligraphic_X , italic_x start_POSTSUPERSCRIPT â end_POSTSUPERSCRIPT ) , italic_a start_POSTSUBSCRIPT 1 : italic_i - 1 end_POSTSUBSCRIPT ) |  | (A.5)  \n---|---|---|---  \n###### Optimization.\nReport issue for preceding element\nAs mentioned, it is often desirable to speak about improving prompts (prompt templates, that is) with respect to a scoring function, usually defined with respect to a dataset.\nReport issue for preceding element\n| ð¯â=argmaxð¯â¢ð¼xi,yiâ¼ðâ¢[Sâ¢(pLMâ¢(ð|ð¯â¢(xi)),yi)]superscriptð¯ð¯argmaxsubscriptð¼similar-tosubscriptð¥ðsubscriptð¦ððdelimited-[]ðsubscriptðLMconditionalðð¯subscriptð¥ðsubscriptð¦ð\\mathcal{T}^{*}=\\underset{\\mathcal{T}}{\\mathrm{argmax}}\\;\\mathbb{E}_{x_{i},y_{% i}\\sim\\mathcal{D}}\\left[S\\left(p_{\\text{LM}}(\\mathcal{A}|\\mathcal{T}(x_{i})),y% _{i}\\right)\\right]caligraphic_T start_POSTSUPERSCRIPT â end_POSTSUPERSCRIPT = undercaligraphic_T start_ARG roman_argmax end_ARG blackboard_E start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT â¼ caligraphic_D end_POSTSUBSCRIPT [ italic_S ( italic_p start_POSTSUBSCRIPT LM end_POSTSUBSCRIPT ( caligraphic_A | caligraphic_T ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ) , italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ] |  | (A.6)  \n---|---|---|---  \nIn this definition, we are evaluating over a dataset ðð\\mathcal{D}caligraphic_D with respect to the scoring function Sâ¢(â)ðâS(\\cdot)italic_S ( â ). Sâ¢(â)ðâS(\\cdot)italic_S ( â ) evaluates the output ðð\\mathcal{A}caligraphic_A, generated by the LLM conditioned on the prompt ð¯â¢(ðð¾)ð¯subscriptðð¾\\mathcal{T(x_{i})}caligraphic_T ( caligraphic_x start_POSTSUBSCRIPT caligraphic_i end_POSTSUBSCRIPT ). yisubscriptð¦ðy_{i}italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT are labeled outputs that can be used by SðSitalic_S.\nReport issue for preceding element\nIn some cases, there may not be any labeled data yisubscriptð¦ðy_{i}italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, and Sâ¢(â)ðâS(\\cdot)italic_S ( â ) may be reference-free.\nReport issue for preceding element\n###### Other considerations.\nReport issue for preceding element\nThese formalisms could be adapted to cater to CoT, retrieval systems, and more. Here we describe a simple setup which is most descriptive of the prompting process without adding too much complexity.\nReport issue for preceding element\nWe also draw attention to the lesser known concept of answer engineering. Eâ¢(ð)ð¸ðE(\\mathcal{A})italic_E ( caligraphic_A ) is a transformation function over the raw LLM output that allows it to be compared to the ground truth.\nReport issue for preceding element\n| ðð\\displaystyle\\mathcal{A}caligraphic_A | â¼pLMâ¢(ðâ£ð¯â¢(xi),yi)similar-toabsentsubscriptðLMconditionalðð¯subscriptð¥ðsubscriptð¦ð\\displaystyle\\sim p_{\\text{LM}}(\\mathcal{A}\\mid\\mathcal{T}(x_{i}),y_{i})â¼ italic_p start_POSTSUBSCRIPT LM end_POSTSUBSCRIPT ( caligraphic_A â£ caligraphic_T ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) |  | (A.7)  \n---|---|---|---|---  \n| ð¯âsuperscriptð¯\\displaystyle\\mathcal{T}^{*}caligraphic_T start_POSTSUPERSCRIPT â end_POSTSUPERSCRIPT | =argmaxð¯,Eâ¢ð¼xi,yiâ¼ðâ¢[Sâ¢(Eâ¢(ð),yi)]absentð¯ð¸argmaxsubscriptð¼similar-tosubscriptð¥ðsubscriptð¦ððdelimited-[]ðð¸ðsubscriptð¦ð\\displaystyle=\\underset{\\mathcal{T},E}{\\mathrm{argmax}}\\;\\mathbb{E}_{x_{i},y_{% i}\\sim\\mathcal{D}}\\left[S\\left(E(\\mathcal{A}),y_{i}\\right)\\right]= start_UNDERACCENT caligraphic_T , italic_E end_UNDERACCENT start_ARG roman_argmax end_ARG blackboard_E start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT â¼ caligraphic_D end_POSTSUBSCRIPT [ italic_S ( italic_E ( caligraphic_A ) , italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ] |  | (A.8)  \n###  A.8 In-Context Learning Definitions Disambiguation\nReport issue for preceding element\nBrown et al. ([2020](https://arxiv.org/html/2406.06608v1#bib.bib22)) seemingly offer two different definitions for ICL. All bolding in this section is our own.\nReport issue for preceding element\n> Recent work [RWC+19] attempts to do this via what we call âin-context learningâ, using the text input of a pretrained language model as a form of task specification: the model is conditioned on a natural language instruction and/or a few demonstrations of the task and is then expected to complete further instances of the task simply by predicting what comes next.\n> Report issue for preceding element\nHowever, they later appear to define it as few-shot only:\nReport issue for preceding element\n> For each task, we evaluate GPT-3 under 3 conditions: (a) âfew-shot learningâ, or in-context learning where we allow as many demonstrations as will fit into the modelâs context window (typically 10 to 100), (b) âone-shot learningâ, where we allow only one demonstration, and (c) âzero-shotâ learning, where no demonstrations are allowed and only an instruction in natural language is given to the model.\n> Report issue for preceding element\nHowever, they include this image that clarifies the matter:\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/5649570/assets/eval_strategies.png) Figure A.1: ICL from Brown et al. ([2020](https://arxiv.org/html/2406.06608v1#bib.bib22)). Report issue for preceding element\nAdditionally, they explicitly state that ICL does not necessarily involve learning new tasks.\nReport issue for preceding element\n> To avoid this confusion, we use the term âmeta-learningâ to capture the inner-loop / outer-loop structure of the general method, and the term âin context-learningâ to refer to the inner loop of meta-learning. We further specialize the description to âzero-shotâ, âone-shotâ, or âfew-shotâ depending on how many demonstrations are provided at inference time. These terms are intended to remain agnostic on the question of whether the model learns new tasks from scratch at inference time or simply recognizes patterns seen during training â this is an important issue which we discuss later in the paper, but âmeta-learningâ is intended to encompass both possibilities, and simply describes the inner-outer loop structure.\n> Report issue for preceding element\nWe use Brown et al. ([2020](https://arxiv.org/html/2406.06608v1#bib.bib22))âs broad definition, though note that practitioners often use ICL to refer to situations in which the model appears to be learning new tasks from the prompt. Our definition differs from Dong et al. ([2023](https://arxiv.org/html/2406.06608v1#bib.bib50))âs formal definition, even though it is also derived from Brown et al. ([2020](https://arxiv.org/html/2406.06608v1#bib.bib22)).\nReport issue for preceding element\n###  A.9 Contributions\nReport issue for preceding element\nThe following are the contributions made by the team members in various sections of this paper. Most authors conducted reviews of other sections as well.\nReport issue for preceding element\n#### Advisors\nReport issue for preceding element\n  * â¢\nDenis Peskoff: Assisted with paper organization and final review.\nReport issue for preceding element\n  * â¢\nAlexander Hoyle: Provided guidance on writing, meta-analysis approach, and ran automated baselines for case study.\nReport issue for preceding element\n  * â¢\nShyamal Anadkat: Assisted with the overall review of the paper and the etymology and definitions.\nReport issue for preceding element\n  * â¢\nJules White: Built trees for technique taxonomies.\nReport issue for preceding element\n  * â¢\nMarine Carpaut: Framed, reviewed and suggested papers for the multilingual section.\nReport issue for preceding element\n  * â¢\nPhillip Resnik: Principal Investigator\nReport issue for preceding element\n\n\n#### SCS Labeling\nReport issue for preceding element\n  * â¢\nMegan L. Rogers, Inna Goncearenco, Giuseppe Sarli, Igor Galynker: reviewed and gave advice for this section.\nReport issue for preceding element\n\n\n#### Benchmarking and Agents\nReport issue for preceding element\n  * â¢\nKonstantine Kahadze: Team leader for the Benchmarking section; managed MMLU benchmarking codebase, contributed to Security and Meta Analysis.\nReport issue for preceding element\n  * â¢\nAshay Srivastava: Team leader for the Agents section, reviewed papers for human review, worked on the tool use agents section. Worked on the compilation of contributions.\nReport issue for preceding element\n  * â¢\nHevander Da Costa: Contributed to the Benchmarking section and Meta Review datasets list, reviewed literature on LLM code generation and prompting techniques. Added literature review content to the Agents section.\nReport issue for preceding element\n  * â¢\nFeileen Li: Worked on the tool use agents section, assisted with the human paper review.\nReport issue for preceding element\n\n\n#### Alignment and Security\nReport issue for preceding element\n  * â¢\nNishant Balepur: Team leader for the alignment section, helped with high-level discussions in benchmarking, and reviewed drafts.\nReport issue for preceding element\n  * â¢\nSevien Schulhoff: Team leader for the security section and contributed to the benchmarking section.\nReport issue for preceding element\n\n\n#### Related Works and Section Contributions\nReport issue for preceding element\n  * â¢\nChenglei Si: Suggested related works and edited section 2.2 and section 7.\nReport issue for preceding element\n  * â¢\nPranav Sandeep Dulepet: Contributed definitions for section 2 and worked on segmentation and object detection in the multimodal section.\nReport issue for preceding element\n  * â¢\nHyoJung Han: Contributed to the Multimodal section, especially the speech+text part, and wrote the audio prompting section.\nReport issue for preceding element\n  * â¢\nHudson Tao: Authored sections on image, video, and 3D within multimodal, reviewed papers for human review; maintained GitHub codebase, and built the project website.\nReport issue for preceding element\n  * â¢\nAmanda Liu: Authored taxonomic ontology sections, conducted background research for introduction and related work, developed code pipelines for meta-analysis graphs\nReport issue for preceding element\n  * â¢\nSweta Agrawal: Team lead for evaluation section.\nReport issue for preceding element\n  * â¢\nSaurav Vidyadhara: Assisted with general review and revising taxonomy trees.\nReport issue for preceding element\n  * â¢\nChau Pham: Assisted with meta review, including automated analysis of topics.\nReport issue for preceding element\n\n\n#### Multilingual Prompting and Meta Analysis\nReport issue for preceding element\n  * â¢\nZoey Ki: Led the Multilingual prompting section, conducted review on related papers, and wrote Section 3.1.\nReport issue for preceding element\n  * â¢\nYinheng Li: Worked on section 2.2 text-based techniques, reviewed techniques, and contributed to drafting figure 2.2.\nReport issue for preceding element\n  * â¢\nSaloni Gupta: Wrote tests for paper compilation, helped set up paper pipeline, and worked on the code diagram and grammar for the paper.\nReport issue for preceding element\n  * â¢\nGerson Kroiz: Involved with section 1.1 and defining a prompt.\nReport issue for preceding element\n  * â¢\nAayush Gupta: Contributed to the Meta Analysis, compiling papers, and generating visualization graphs.\nReport issue for preceding element\n  * â¢\nMichael Ilie: Co-Lead Author, managed codebase, ran experiments, collected data, and helped with various sections including the PRISMA review figure and the SCS prompting case study.\nReport issue for preceding element\n  * â¢\nSander Schulhoff: Lead Author\nReport issue for preceding element\n\n\nReport Issue\n##### Report Github Issue\nTitle:Content selection saved. Describe the issue below:Description:\nSubmit without GithubSubmit in Github\nReport Issue for Selection\nGenerated by [ L A T E xml ![\\[LOGO\\]](https://arxiv.org/html/2406.06608v1) ](https://math.nist.gov/~BMiller/LaTeXML/)\n## Instructions for reporting errors\nWe are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:\n  * Click the \"Report Issue\" button.\n  * Open a report feedback form via keyboard, use \"**Ctrl + ?** \".\n  * Make a text selection and click the \"Report Issue for Selection\" button near your cursor.\n  * You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.\n\n\nOur team has already identified [the following issues](https://github.com/arXiv/html_feedback/issues). We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.\nHave a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a [list of packages that need conversion](https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML), and welcome [developer contributions](https://github.com/brucemiller/LaTeXML/issues).\n"
  },
  {
    "link": "https://arxiv.org/html/2404.09554v1",
    "raw_content": "[ ![logo](https://services.dev.arxiv.org/html/static/arxiv-logomark-small-white.svg) Back to arXiv ](https://arxiv.org/)\n[ ](https://arxiv.org/abs/2404.09554v1) [ ](javascript:toggleColorScheme\\(\\) \"Toggle dark/light mode\")\n[ ![logo](https://services.dev.arxiv.org/html/static/arxiv-logo-one-color-white.svg) Back to arXiv ](https://arxiv.org/)\nThis is **experimental HTML** to improve accessibility. We invite you to report rendering errors. Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off. Learn more [about this project](https://info.arxiv.org/about/accessible_HTML.html) and [help improve conversions](https://info.arxiv.org/help/submit_latex_best_practices.html). \n[Why HTML?](https://info.arxiv.org/about/accessible_HTML.html) [Report Issue](https://arxiv.org/html/2404.09554v1#myForm) [Back to Abstract](https://arxiv.org/abs/2404.09554v1) [Download PDF](https://arxiv.org/pdf/2404.09554v1) [ ](javascript:toggleColorScheme\\(\\) \"Toggle dark/light mode\")\n## Table of Contents\n  1. [ Abstract  ](https://arxiv.org/html/2404.09554v1#abstract \"Abstract\")\n  2. [1 Introduction](https://arxiv.org/html/2404.09554v1#S1 \"In Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n  3. [2 Technical Background](https://arxiv.org/html/2404.09554v1#S2 \"In Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n    1. [2.1 System Architectures](https://arxiv.org/html/2404.09554v1#S2.SS1 \"In 2 Technical Background â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n    2. [2.2 GenAI Model Architectures](https://arxiv.org/html/2404.09554v1#S2.SS2 \"In 2 Technical Background â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n      1. [2.2.1 Transformers](https://arxiv.org/html/2404.09554v1#S2.SS2.SSS1 \"In 2.2 GenAI Model Architectures â£ 2 Technical Background â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n      2. [2.2.2 Diffusion Models](https://arxiv.org/html/2404.09554v1#S2.SS2.SSS2 \"In 2.2 GenAI Model Architectures â£ 2 Technical Background â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n    3. [2.3 Other Generative Models: VAEs, GANs](https://arxiv.org/html/2404.09554v1#S2.SS3 \"In 2 Technical Background â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n    4. [2.4 Controlling Outputs](https://arxiv.org/html/2404.09554v1#S2.SS4 \"In 2 Technical Background â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n    5. [2.5 LLM Training](https://arxiv.org/html/2404.09554v1#S2.SS5 \"In 2 Technical Background â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n  4. [3 The importance, challenges and desiderata of GenXAI](https://arxiv.org/html/2404.09554v1#S3 \"In Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n    1. [3.1 Importance of XAI for GenAI](https://arxiv.org/html/2404.09554v1#S3.SS1 \"In 3 The importance, challenges and desiderata of GenXAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n    2. [3.2 Why is XAI more challenging for GenAI?](https://arxiv.org/html/2404.09554v1#S3.SS2 \"In 3 The importance, challenges and desiderata of GenXAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n    3. [3.3 Desiderata of Explanations for GenAI](https://arxiv.org/html/2404.09554v1#S3.SS3 \"In 3 The importance, challenges and desiderata of GenXAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n  5. [4 Taxonomy of XAI techniques for GenAI](https://arxiv.org/html/2404.09554v1#S4 \"In Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n    1. [4.1 Dimensions of taxonomy](https://arxiv.org/html/2404.09554v1#S4.SS1 \"In 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n      1. [4.1.1 Output, Interaction and Input Scope](https://arxiv.org/html/2404.09554v1#S4.SS1.SSS1 \"In 4.1 Dimensions of taxonomy â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n      2. [4.1.2 Explanation Modality](https://arxiv.org/html/2404.09554v1#S4.SS1.SSS2 \"In 4.1 Dimensions of taxonomy â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n      3. [4.1.3 Dynamics](https://arxiv.org/html/2404.09554v1#S4.SS1.SSS3 \"In 4.1 Dimensions of taxonomy â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n      4. [4.1.4 Foundational Source for XAI techniques](https://arxiv.org/html/2404.09554v1#S4.SS1.SSS4 \"In 4.1 Dimensions of taxonomy â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n      5. [4.1.5 Required Model Access by XAI Method](https://arxiv.org/html/2404.09554v1#S4.SS1.SSS5 \"In 4.1 Dimensions of taxonomy â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n      6. [4.1.6 Model (Self-)Explainers](https://arxiv.org/html/2404.09554v1#S4.SS1.SSS6 \"In 4.1 Dimensions of taxonomy â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n      7. [4.1.7 Explanation Sample Difficulty](https://arxiv.org/html/2404.09554v1#S4.SS1.SSS7 \"In 4.1 Dimensions of taxonomy â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n      8. [4.1.8 Dimensions of Pre-GenAI](https://arxiv.org/html/2404.09554v1#S4.SS1.SSS8 \"In 4.1 Dimensions of taxonomy â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n    2. [4.2 Classification of Techniques](https://arxiv.org/html/2404.09554v1#S4.SS2 \"In 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n      1. [4.2.1 Feature Attribution](https://arxiv.org/html/2404.09554v1#S4.SS2.SSS1 \"In 4.2 Classification of Techniques â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n      2. [4.2.2 Sample-based](https://arxiv.org/html/2404.09554v1#S4.SS2.SSS2 \"In 4.2 Classification of Techniques â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n      3. [4.2.3 Probing-based](https://arxiv.org/html/2404.09554v1#S4.SS2.SSS3 \"In 4.2 Classification of Techniques â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n      4. [4.2.4 Mechanistic interpretability](https://arxiv.org/html/2404.09554v1#S4.SS2.SSS4 \"In 4.2 Classification of Techniques â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n      5. [4.2.5 Structuring based on novel dimensions](https://arxiv.org/html/2404.09554v1#S4.SS2.SSS5 \"In 4.2 Classification of Techniques â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n  6. [5 Research Agenda of XAI for GenAI, Discussion and Conclusions](https://arxiv.org/html/2404.09554v1#S5 \"In Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n  7. [6 Acknowledgments](https://arxiv.org/html/2404.09554v1#S6 \"In Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n  8. [7 Appendix](https://arxiv.org/html/2404.09554v1#S7 \"In Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n    1. [7.1 Research Methodology](https://arxiv.org/html/2404.09554v1#S7.SS1 \"In 7 Appendix â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")\n  9. [ References  ](https://arxiv.org/html/2404.09554v1#bib \"References\")\n\n\nHTML conversions [sometimes display errors](https://info.dev.arxiv.org/about/accessibility_html_error_messages.html) due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.\n  * failed: manyfoot\n\n\nAuthors: achieve the best HTML results from your LaTeX submissions by following these [best practices](https://info.arxiv.org/help/submit_latex_best_practices.html).\n[License: CC BY 4.0](https://info.arxiv.org/help/license/index.html#licenses-available)\narXiv:2404.09554v1 [cs.AI] 15 Apr 2024\n# Explainable Generative AI (GenXAI): A Survey, Conceptualization, and Research Agenda\nReport issue for preceding element\n\\fnmJohannes \\surSchneider  johannes.schneider@uni.li \\orgnameUniversity of Liechtenstein, \\cityVaduz, \\countryLiechtenstein \nReport issue for preceding element\n###### Abstract\nReport issue for preceding element\nGenerative AI (GenAI) marked a shift from AI being able to ârecognizeâ to AI being able to âgenerateâ solutions for a wide variety of tasks. As the generated solutions and applications become increasingly more complex and multi-faceted, novel needs, objectives, and possibilities have emerged for explainability (XAI). In this work, we elaborate on why XAI has gained importance with the rise of GenAI and its challenges for explainability research. We also unveil novel and emerging desiderata that explanations should fulfill, covering, for instance, verifiability, interactivity, security, and cost aspects. To this end, we focus on surveying existing works. Furthermore, we provide a taxonomy of relevant dimensions that allows us to better characterize existing XAI mechanisms and methods for GenAI. We discuss different avenues to ensure XAI, from training data to prompting. Our paper offers a short but concise technical background of GenAI for non-technical readers, focusing on text and images to better understand novel or adapted XAI techniques for GenAI. However, due to the vast array of works on GenAI, we decided to forego detailed aspects of XAI related to evaluation and usage of explanations. As such, the manuscript interests both technically oriented people and other disciplines, such as social scientists and information systems researchers. Our research roadmap provides more than ten directions for future investigation. \nReport issue for preceding element\n###### keywords: \nReport issue for preceding elementGenerative Artificial Intelligence, Explainability, Conceptualization, Survey, Explainable Artificial Intelligence, Research agenda. \n##  1 Introduction\nReport issue for preceding element\nGenerative AI (GenAI) has shown remarkable capabilities that have shaken up the world on a broad basis â ranging from regulators [[36](https://arxiv.org/html/2404.09554v1#bib.bib36)], educators [[8](https://arxiv.org/html/2404.09554v1#bib.bib8)], programmers [[161](https://arxiv.org/html/2404.09554v1#bib.bib161)] onto medical staff [[173](https://arxiv.org/html/2404.09554v1#bib.bib173)]. For businesses [[120](https://arxiv.org/html/2404.09554v1#bib.bib120)], GenAI has the potential to unlock trillions of dollars annually [[96](https://arxiv.org/html/2404.09554v1#bib.bib96)]. At the same time, it is said to threaten mankind [[170](https://arxiv.org/html/2404.09554v1#bib.bib170)]. These opposing views are a key drive for understanding and explaining GenAI. Generative AI constitutes the next level of AI driven by foundation models [[146](https://arxiv.org/html/2404.09554v1#bib.bib146)], where AI can create text, images, audio, 3D solutions, and videos [[47](https://arxiv.org/html/2404.09554v1#bib.bib47), [14](https://arxiv.org/html/2404.09554v1#bib.bib14)] controllable by humans, specifically via textual prompts [[186](https://arxiv.org/html/2404.09554v1#bib.bib186)] â see also Table [1](https://arxiv.org/html/2404.09554v1#S1.T1 \"Table 1 â£ 1 Introduction â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\") for examples of public GenAI systems. This is a major step forward from AI that was primarily able to ârecognizeâ to AI that âgeneratesâ. GenAI has shown unprecedented capabilities like passing university-level exams [[22](https://arxiv.org/html/2404.09554v1#bib.bib22), [65](https://arxiv.org/html/2404.09554v1#bib.bib65)]. It also achieves remarkable results even in areas deemed non-suitable for machines, such as creativity [[17](https://arxiv.org/html/2404.09554v1#bib.bib17)]. It is accessible to everyone, as witnessed by commercial systems like ChatGPT [[1](https://arxiv.org/html/2404.09554v1#bib.bib1)] and Dall-E [[11](https://arxiv.org/html/2404.09554v1#bib.bib11), [124](https://arxiv.org/html/2404.09554v1#bib.bib124)]. Early generative AI methods, such as Generative Adversarial networks (GANs), can also generate artifacts but are typically more difficult to control than modern models such as transformers and diffusion architectures.\nReport issue for preceding element\nExplainable AI for GenAI (GenXAI) techniques produce explanations that help comprehend AI, for example, outputs for individual inputs or the model as a whole. Traditionally, explanations have served many purposes due to multiple needs; for instance, they can increase trust and support the debugging of models [[100](https://arxiv.org/html/2404.09554v1#bib.bib100)]. The need for understanding AI is even larger than in pre-GenAI eras. For example, explanations can support the verifiability of generated content and, thereby, contribute to combatting one of the major problems of GenAI: hallucinations (as argued in Section [3.1](https://arxiv.org/html/2404.09554v1#S3.SS1 \"3.1 Importance of XAI for GenAI â£ 3 The importance, challenges and desiderata of GenXAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")). Unfortunately, Explainable AI (even for pre-GenAI models) is characterized by several open problems despite many attempts to design solutions to address them over the last few years [[84](https://arxiv.org/html/2404.09554v1#bib.bib84), [100](https://arxiv.org/html/2404.09554v1#bib.bib100)]. For example, a recent comparison [[155](https://arxiv.org/html/2404.09554v1#bib.bib155)] among methods on the impact of XAI on human-agent interaction found that the difference in scores between the best (counterfactuals) and worst method (using simply probability scores) was only 20%, hinting that complex existing methods yield limited benefits over more complex ones. Thus, XAI techniques are still far from being optimal. Other works have even openly called the âstatus quo in interpretability research largely unproductiveâ [[125](https://arxiv.org/html/2404.09554v1#bib.bib125)]. As such, there is much to be done, and it is essential to understand current efforts to learn and improve on them â especially to mitigate high risks [[170](https://arxiv.org/html/2404.09554v1#bib.bib170)] while leveraging opportunities [[146](https://arxiv.org/html/2404.09554v1#bib.bib146)].\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/2404.09554v1/img/outline.png) Figure 1: Article outline. Following important factors and challenges of XAI for GenAI, desiderata and, in turn, a taxonomy is derived. All three together inform our research agenda. Report issue for preceding element\nThis research manuscript is a genuine attempt to progress in this direction. Our goal is not to (only) list and structure existing XAI techniques, as in the current stage of the field, more basic questions need to be addressed, such as identifying key challenges and desiderata for GenXAI. To this end, we, therefore, opted for a more narrative review methodology [[69](https://arxiv.org/html/2404.09554v1#bib.bib69)] accompanied by a taxonomy development approach from the field of information systems [[110](https://arxiv.org/html/2404.09554v1#bib.bib110)].111Details on the methodology are given in the Appendix (Section [7.1](https://arxiv.org/html/2404.09554v1#S7.SS1 \"7.1 Research Methodology â£ 7 Appendix â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")).\nReport issue for preceding element\nThere are several surveys on XAI focusing on the pre-GenAI era with primary technical focus [[2](https://arxiv.org/html/2404.09554v1#bib.bib2), [209](https://arxiv.org/html/2404.09554v1#bib.bib209), [31](https://arxiv.org/html/2404.09554v1#bib.bib31), [148](https://arxiv.org/html/2404.09554v1#bib.bib148), [125](https://arxiv.org/html/2404.09554v1#bib.bib125), [131](https://arxiv.org/html/2404.09554v1#bib.bib131), [163](https://arxiv.org/html/2404.09554v1#bib.bib163), [102](https://arxiv.org/html/2404.09554v1#bib.bib102), [12](https://arxiv.org/html/2404.09554v1#bib.bib12), [172](https://arxiv.org/html/2404.09554v1#bib.bib172), [52](https://arxiv.org/html/2404.09554v1#bib.bib52), [51](https://arxiv.org/html/2404.09554v1#bib.bib51)] and an interdisciplinary or social science focus [[101](https://arxiv.org/html/2404.09554v1#bib.bib101), [100](https://arxiv.org/html/2404.09554v1#bib.bib100), [84](https://arxiv.org/html/2404.09554v1#bib.bib84)]. In particular, by building upon them, we perform a meta-survey to structure our methods leveraging also knowledge from pre-GenAI. However, we also uncover novel aspects that have not yet been covered related to GenAI. Many works surveyed various aspects of GenAI (not including XAI) [[191](https://arxiv.org/html/2404.09554v1#bib.bib191), [80](https://arxiv.org/html/2404.09554v1#bib.bib80), [190](https://arxiv.org/html/2404.09554v1#bib.bib190), [193](https://arxiv.org/html/2404.09554v1#bib.bib193), [200](https://arxiv.org/html/2404.09554v1#bib.bib200), [203](https://arxiv.org/html/2404.09554v1#bib.bib203), [117](https://arxiv.org/html/2404.09554v1#bib.bib117)]. We leverage such surveys for our technical background. Some sub-areas of GenAI, e.g., on knowledge identification and editing [[202](https://arxiv.org/html/2404.09554v1#bib.bib202)], use isolated XAI techniques as a tool, but do not aim at elaborating on it generally. While we could not identify any review discussing XAI for GenAI, some research manuscripts take more of a holistic, partially opinionated view on XAI for large language models (LLMs) [[158](https://arxiv.org/html/2404.09554v1#bib.bib158), [78](https://arxiv.org/html/2404.09554v1#bib.bib78)] or explicitly survey XAI for LLMs [[204](https://arxiv.org/html/2404.09554v1#bib.bib204), [89](https://arxiv.org/html/2404.09554v1#bib.bib89)]. None of the prior work has provided a comprehensive list of desiderata, motivation, and challenges for XAI for GenAI, and taxonomy. In particular, many of our novel aspects cannot be found in prior works. Aside from that, even when focusing on LLMs only, we differ considerably from prior works. \nReport issue for preceding element\nWe begin by providing a technical background. To derive the contributions, we proceed as outlined in Figure [1](https://arxiv.org/html/2404.09554v1#S1.F1 \"Figure 1 â£ 1 Introduction â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\"): Then, we provide motivation and challenges for XAI for GenAI, especially pointing towards novel aspects that emerge with GenAI, such as the increased reach of GenAI throughout society and the need for interactive adjustment of often complex, difficult to evaluate outputs by users. Based on this, we derive desiderata, i.e., requirements that explanations should ideally fulfill, such as the support of interactivity and verification of outputs. Then, we derive a taxonomy for existing and future XAI techniques for GenAI. To categorize XAI we use dimensions related to the in-, the outputs, and internal properties of GenXAI techniques that distinguish them from pre-GenAI such as self-explanation as well as different sources and drivers for XAI such as prompts and training data.\nReport issue for preceding element\nUsing the identified challenges and desiderata, the remainder of this manuscript focuses on discussing novel dimensions for GenXAI and the resulting taxonomy, discussing XAI methods in conjunction with GenAI. Finally, we provide future directions Our key contributions include describing the need for XAI for GenAI, desiderata for explanations, and a taxonomy for mechanisms and algorithms including novel dimensions for categorization.\nReport issue for preceding element\nTable 1: Examples of In-/Outputs for GenAI. For more examples, see [[47](https://arxiv.org/html/2404.09554v1#bib.bib47)]. Input/Output |  Description |  Example  \n---|---|---  \n_Text to Text_ |  Input: Raw text. Output: Processed or generated text. |  ChatGPT 3.5 [[1](https://arxiv.org/html/2404.09554v1#bib.bib1)]  \n_Text to Image/video_ |  Input: Descriptive text or prompt. Output: Generated image/text. |  DALL-E[[11](https://arxiv.org/html/2404.09554v1#bib.bib11)], Sora[[13](https://arxiv.org/html/2404.09554v1#bib.bib13)]  \n_Image/video to Text_ |  Input: Image/video and text. Output: Textual interpretation and answer. |  GPT 4 with Dall-E [[1](https://arxiv.org/html/2404.09554v1#bib.bib1)], Gemini [[127](https://arxiv.org/html/2404.09554v1#bib.bib127)]  \n_Images, Actions to Actions_ |  Input: Images depicting actions. Output: Generated action sequences. |  Gato [[126](https://arxiv.org/html/2404.09554v1#bib.bib126)]  \n_Text to 3D_ |  Input: Text describing object Output: 3D representation of object. |  Magic3d [[79](https://arxiv.org/html/2404.09554v1#bib.bib79)]  \nReport issue for preceding element\n##  2 Technical Background\nReport issue for preceding element\nHere, we provide a short technical introduction to generative AI, covering key ideas on system and model architectures and training procedures. We restrict ourselves to text and image data to illustrate multi-modality. For video and audio, please refer to other surveys (for example [[149](https://arxiv.org/html/2404.09554v1#bib.bib149), [201](https://arxiv.org/html/2404.09554v1#bib.bib201)]).\nReport issue for preceding element\n###  2.1 System Architectures\nReport issue for preceding element\nGenAI models can be used as stand-alone applications accessible through a simple user interface, essentially allowing textual inputs or uploads as for OpenAIâs ChatGPT[[1](https://arxiv.org/html/2404.09554v1#bib.bib1)] and displaying responses. Thus, a system might be essentially one large model, where a model is almost exclusively based on deep learning taking an input processed by a neural network yielding an output. For multi-modal applications, systems that consist of an LLM and other generative models, such as diffusion models, are typically employed. However, GenAI-powered systems might involve external data sources and external applications that interact in complex patterns, as illustrated in Figure [2](https://arxiv.org/html/2404.09554v1#S2.F2 \"Figure 2 â£ 2.1 System Architectures â£ 2 Technical Background â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\"). An orchestration application might decide what actions to take based on GenAI outputs or user inputs. For example, in ChatGPT-4 a user can include a term like âsearch the internetâ in the prompt, which implies that first an Internet search is conducted, and retrieved content from the web is then fed into the GenAI model. The orchestration application is responsible for actually performing the web search and modifying the prompt to the GenAI model, e.g., enhancing it with an instruction like âAnswer based on the following content:â followed by the retrieved information from the web.\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/2404.09554v1/img/models.png) Figure 2: Overview of GenAI system architectures comprising a single or combined model (with a GUI) as well as GenAI systems interacting with other applications Report issue for preceding element\n###  2.2 GenAI Model Architectures\nReport issue for preceding element\nWe discuss key aspects of the transformer architecture and diffusion models and briefly elaborate on other generative models.\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/2404.09554v1/img/transf.png) Figure 3: Transformer architecture [[176](https://arxiv.org/html/2404.09554v1#bib.bib176)] Report issue for preceding element\n####  2.2.1 Transformers\nReport issue for preceding element\nTransformers are the de-facto standard for LLMs, while GenAI models involving images might also encompass other models such as diffusion models, variational autoencoders (VAEs), and generative adversarial networks (GANs). The transformer model makes little assumption upon the input data, which makes it a very flexible model. Assumptions on the data (priors) also help to reduce the amount of data needed to train a model. Thus, transformers often require more data than other models to reach the same performance though simpler models might never reach the same top-level performance. The transformer architecture [[176](https://arxiv.org/html/2404.09554v1#bib.bib176)] (Figure [3](https://arxiv.org/html/2404.09554v1#S2.F3 \"Figure 3 â£ 2.2 GenAI Model Architectures â£ 2 Technical Background â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")) comes with many variations [[80](https://arxiv.org/html/2404.09554v1#bib.bib80)] mostly by using different implementations of individual elements, for example, using different types of positional embeddings [[30](https://arxiv.org/html/2404.09554v1#bib.bib30)] or different types of attention [[134](https://arxiv.org/html/2404.09554v1#bib.bib134)] or even replacing some components, for instance, Hyena [[119](https://arxiv.org/html/2404.09554v1#bib.bib119)] provides a drop-in replacement for attention based on convolutions. Commonly, the objectives of these adjustments are better performance and faster computation; for example, the original transformer requires quadratic run-time in the number of inputs, which makes it prohibitive for very long inputs. The vanilla transformer architecture (Figure [3](https://arxiv.org/html/2404.09554v1#S2.F3 \"Figure 3 â£ 2.2 GenAI Model Architectures â£ 2 Technical Background â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")) consists of an encoder and a decoder, where the decoder processes the outputs of the encoder and (shifted) targets. One might think of a translation scenario, where the encoder takes a sentence expressed in the source language and the decoder generates one output word after the other in the desired language. Each generated word also becomes an input to the decoder when the next word is generated. Decoder-only architectures (such as the GPT-series [[121](https://arxiv.org/html/2404.09554v1#bib.bib121), [1](https://arxiv.org/html/2404.09554v1#bib.bib1)]) do not have an encoder. In contrast, encoder-only architectures do not have a decoder and typically produce contextualized embeddings of single words or text fragments (for example, BERT [[29](https://arxiv.org/html/2404.09554v1#bib.bib29)]).\nReport issue for preceding element\nBoth the encoder and the decoder take tokens as input. The embeddings are vectors in a latent space. While raw tokens can only be compared for equality, vectors in a latent space allow a more nuanced similarity computation and, potentially, the extraction of specific token attributes such as sentiment. Thus, many current GenAI systems leverage encoders to obtain vector embeddings and use them to retrieve relevant information to enhance prompts by searching in a vector database [[73](https://arxiv.org/html/2404.09554v1#bib.bib73)]. A positional encoding is added to the (text) embedding, so the network has information about where a word occurred. After that, inputs are processed through multi-head attention. A single-head attention provides a mechanism to focus (and select) a specific aspect of the input (for instance, syntax or sentiment), which is then further processed through a Feed Forward Network (FFN). Attention can be masked for the decoder so that it cannot access the actual or future targets it wants to predict; for example, for the common task of next-word prediction, the triangular matrix constituting the mask prevents the network has access to the next word to predict as well as words following the next word.\nReport issue for preceding element\n####  2.2.2 Diffusion Models\nReport issue for preceding element\nDiffusion models learn to reconstruct noisy data. They first distort inputs by repeatedly adding small amounts of noise until the image appears to be noise following, e.g., a Gaussian distribution one can sample from to generate images. They reverse the process for sample generation by taking ânoiseâ as input and reconstructing samples. There are multiple rather mathematical intricate methods for diffusion models [[193](https://arxiv.org/html/2404.09554v1#bib.bib193)]. Here, we discuss key steps of a prominent technique highly relevant for text-to-image generation, i.e. Denoising Diffusion Probabilistic Model (DDPM) [[57](https://arxiv.org/html/2404.09554v1#bib.bib57)]. In the forward pass (input distortion) DDPM acts as a Markov chain, meaning that only the current state (or input) is relevant for the next output, i.e., for a given data distribution x0â¼qâ¢(x0)similar-tosubscriptð¥0ðsubscriptð¥0x_{0}\\sim q(x_{0})italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT â¼ italic_q ( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ), DDPM yields output xTsubscriptð¥ðx_{T}italic_x start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT in a sequence of TðTitalic_T sequential steps by computing in step tð¡titalic_t: qâ¢(xt|xtâ1)=Nâ¢(xt;1âÎ²tâ¢xtâ1,Î²tâ¢I)ðconditionalsubscriptð¥ð¡subscriptð¥ð¡1ðsubscriptð¥ð¡1subscriptð½ð¡subscriptð¥ð¡1subscriptð½ð¡ð¼q(x_{t}|x_{t-1})=N(x_{t};\\sqrt{1-\\beta_{t}}x_{t-1},\\beta_{t}I)italic_q ( italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_x start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT ) = italic_N ( italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ; square-root start_ARG 1 - italic_Î² start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG italic_x start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT , italic_Î² start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT italic_I ). Thus, the overall output becomes qâ¢(xT|x0)=ât=1Tqâ¢(xt|xtâ1)ðconditionalsubscriptð¥ðsubscriptð¥0superscriptsubscriptproductð¡1ððconditionalsubscriptð¥ð¡subscriptð¥ð¡1q(x_{T}|x_{0})=\\prod_{t=1}^{T}q(x_{t}|x_{t-1})italic_q ( italic_x start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT | italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) = â start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_q ( italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_x start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT ). Here NðNitalic_N is the Gaussian distribution and Î²tsubscriptð½ð¡\\beta_{t}italic_Î² start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is a hyperparameter. The reverse pass for generation starts from pÎ¸â¢(xT)subscriptððsubscriptð¥ðp_{\\theta}(x_{T})italic_p start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ) and yields pÎ¸â¢(x0)subscriptððsubscriptð¥0p_{\\theta}(x_{0})italic_p start_POSTSUBSCRIPT italic_Î¸ end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ), which is supposed to follow the true data distribution qx0subscriptðsubscriptð¥0q_{x_{0}}italic_q start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT. Thus, outputs of diffusion models are not easily controllable, i.e., additional input must be provided to the reconstruction process to guide the generation process towards user-desired images as discussed in Section [2.4](https://arxiv.org/html/2404.09554v1#S2.SS4 \"2.4 Controlling Outputs â£ 2 Technical Background â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\").\nReport issue for preceding element\n###  2.3 Other Generative Models: VAEs, GANs\nReport issue for preceding element\nWe also discuss generative models aside from diffusion models but refer to [[193](https://arxiv.org/html/2404.09554v1#bib.bib193)] that performs a detailed comparison for in-depth elaboration. Generative Adversarial Networks (GAN) [[45](https://arxiv.org/html/2404.09554v1#bib.bib45)] are trained using a generator that constructs an output from a random vector and a discriminator that aims to distinguish generated outputs x^^ð¥\\hat{x}over^ start_ARG italic_x end_ARG from actual samples of the true data distribution xâ¼qxsimilar-toð¥subscriptðð¥x\\sim q_{x}italic_x â¼ italic_q start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT. An autoencoder [[77](https://arxiv.org/html/2404.09554v1#bib.bib77)] comprises an encoder and a decoder that learns to output a given input that is compressed by the encoder into a latent space before being attempted to be reconstructed by the decoder. A Variational Autoencoder (VAE) constrains the latent space towards a given prior distribution through a regularization term as part of the optimization objective. If the latent space follows a known distribution, sampling, i.e., sample generation is facilitated.\nReport issue for preceding element\n###  2.4 Controlling Outputs\nReport issue for preceding element\nDiffusion and generative models like VAEs and GANs yield high-quality outputs by providing random inputs. Controlling outputs is not easily possible and requires additional effort. Early techniques on controllable image synthesis generated outputs conditioned on class labels or by disentangling dimensions of the latent space so that altering a dimension corresponds to a human interpretable operation [[19](https://arxiv.org/html/2404.09554v1#bib.bib19)]. However, these approaches provide only very limited ways to customize outputs. Text-to-image models are more versatile. They commonly encode text and use it as input for generation. Text encoding might be done using a frozen encoder [[133](https://arxiv.org/html/2404.09554v1#bib.bib133)] or by altering the text encoder as part of the training process (GLIDE [[109](https://arxiv.org/html/2404.09554v1#bib.bib109)]). Text-to-image models require (image, text) pairs for training, in turn, the textual encoder can stem from the text of the (text-image) pairs only or from a broader corpus and larger models. Text-to-image models can either start generation from a low-dimensional space such as Dall-E [[124](https://arxiv.org/html/2404.09554v1#bib.bib124), [11](https://arxiv.org/html/2404.09554v1#bib.bib11)] or aim to construct directly from pixel space such as GLIDE [[109](https://arxiv.org/html/2404.09554v1#bib.bib109)]. For illustration, we briefly discuss Dall-E [[124](https://arxiv.org/html/2404.09554v1#bib.bib124), [11](https://arxiv.org/html/2404.09554v1#bib.bib11)]. It uses a multimodal contrastive model where image and text embeddings are matched. It also contains a text-to-image generator before closing the gap between CLIP text and image latent space, which can be learned using a diffusion prior.\nReport issue for preceding element\n###  2.5 LLM Training\nReport issue for preceding element\nLLM training consists of at least one and up to three phases. The phases differ in the training methodology, goal, and amount of data.\nReport issue for preceding element\nSelf-supervised pre-training: The raw model is trained on very large amounts of data using self-supervised pre-training, for instance, next word prediction (GPT-2) or tasks such as predicting masked words and sentence order (BERT). The goal is to learn a flexible and broad representation of all forms of text that can set the foundation for many different tasks. The data can be a composition of many different kinds of text data as described for LLama-2 [[174](https://arxiv.org/html/2404.09554v1#bib.bib174)], e.g., covering code, Wikipedia articles, or a dump of parts of the internet [[24](https://arxiv.org/html/2404.09554v1#bib.bib24)].\nReport issue for preceding element\nInstruction tuning adapts a pre-trained LLM through supervised fine-tuning [[86](https://arxiv.org/html/2404.09554v1#bib.bib86), [203](https://arxiv.org/html/2404.09554v1#bib.bib203)]. The term âinstructionâ is often used interchangeably with prompt. Instructions tend to be more explicit and directive with more precise guidance. The goal of instruction tuning is to improve performance on the most common use cases for LLMs: to follow (short) instructions. Though multiple variations exist, the training data can consist of task instructions, input (task instance), and desired outputs. Instruction tuning helps performance on both seen and unseen tasks and across architectures of different scales [[85](https://arxiv.org/html/2404.09554v1#bib.bib85)]. It can go beyond mere adaption of an LLM and also provide a means to encode additional knowledge for domain specialization, such as medical knowledge [[159](https://arxiv.org/html/2404.09554v1#bib.bib159)].\nReport issue for preceding element\nAlignment Tuning: LLMs might not incorporate human values and preferences, i.e., they can produce harmful, misleading, and biased outputs [[153](https://arxiv.org/html/2404.09554v1#bib.bib153), [185](https://arxiv.org/html/2404.09554v1#bib.bib185)]. Alignment criteria can be diverse, covering helpfulness, honesty, and harmlessness [[116](https://arxiv.org/html/2404.09554v1#bib.bib116)]. Training data typically stems from humans, for instance, by ranking LLM-generated answers or producing their own answers. Occasionally, also (more powerful) and already aligned LLMs produce training data[[167](https://arxiv.org/html/2404.09554v1#bib.bib167)]. Training can take place by fine-tuning the LLM using supervised learning and the alignment dataset. Training can also be indirect in the sense that human feedback is used to learn a reward model serving as a human critic, i.e., predicting the human scoring of an output. The resulting reward model can be used to adjust the LLM using reinforcement learning. The LLM generates outputs and receives feedback from the reward model.\nReport issue for preceding element\n##  3 The importance, challenges and desiderata of GenXAI\nReport issue for preceding element\nThis section motivates the need to use eXplainable Artificial Intelligence for GenAI and its challenges, followed by describing important desiderata that explanations should fulfill.\nReport issue for preceding element\n###  3.1 Importance of XAI for GenAI\nReport issue for preceding element\nNeed to adjust outputs -  A larger need for explainability for GenAI emerges as humans effectively control and tailor the generated outputs. Generative AI blurs the boundary between users and developers. It can be instructed to solve tasks based on auxiliary knowledge [[73](https://arxiv.org/html/2404.09554v1#bib.bib73)] as witnessed by OpenAIâs GPT-4 store [[114](https://arxiv.org/html/2404.09554v1#bib.bib114)], which allows ordinary users without programming skills to build and offer applications leveraging uploaded knowledge and GPT-4. A new skill of prompt engineering has emerged that users need to master [[199](https://arxiv.org/html/2404.09554v1#bib.bib199)]. XAI has also been identified as a key requirement to support prompt engineering by experts [[103](https://arxiv.org/html/2404.09554v1#bib.bib103)]. Users need to understand better how to control outputs, handle limitations, and mitigate risks [[185](https://arxiv.org/html/2404.09554v1#bib.bib185)]. Thus, the stakeholders must understand GenAI to create solutions aligned with their preferences.\nReport issue for preceding element\nNeed of output verification -  GenAI, in particular LLMs, are known for many shortcomings, ranging from generating harmful, toxic responses to misleading, incorrect content [[185](https://arxiv.org/html/2404.09554v1#bib.bib185)]. LLMs can be said to be âfluent but non-factual,â which makes their verification even harder. Their outputs are generally non-trustworthy and need some form of verification or validation (as also acknowledged by regulators [[36](https://arxiv.org/html/2404.09554v1#bib.bib36)]). An explanation provides a mechanism to identify errors such as hallucinations in outputs.\nReport issue for preceding element\nIncreased reach -  GenAI is easy to access and use through an ordinary browser with a web interface facilitating widespread adoption. ChatGPT was also the fastest product to reach 100 million users and still rapidly grows [[120](https://arxiv.org/html/2404.09554v1#bib.bib120)]. It is used throughout society, including vulnerable groups such as schoolchildren, the elderly with limited IT knowledge, and corporate employees.\nReport issue for preceding element\nHigh impact applications -  GenAI is a general-purpose technology with applications that might have severe immediate and long-term impacts. Users might seek advice for pressing personal problems [[152](https://arxiv.org/html/2404.09554v1#bib.bib152)] or turn to GenAI for educational purposes. In an educational context, using ChatGPT once and receiving a slightly biased response (towards gender, race, or minority) might have limited impact, but receiving such responses over a prolonged time might profoundly impact future generations. Aside from such a long-term view, users might turn to GenAI like ChatGPT while being in psychological distress and seeking immediate advice. ChatGPT is even known to outperform humans on emotional awareness [[33](https://arxiv.org/html/2404.09554v1#bib.bib33)]. Given such high-stake applications, understanding GenAI becomes crucial.\nReport issue for preceding element\nUnknown Applications -  As generative AI can process any text, image, and other medium as input and output, it is hard to anticipate all possible applications. As such, the need to understand the models more holistically to ensure they align with higher-level principles becomes relevant.\nReport issue for preceding element\nDifficult to evaluate automatically -  Simple strategies, which means counting the number of correct and incorrect answers (accuracy), provide only a very limited picture of GenAIâs behavior, as many tasks yield responses that are difficult to score. For example, for summarization, human ratings of gold standards are worse than those of benchmarks, hinting at the challenge in designing benchmarks [[162](https://arxiv.org/html/2404.09554v1#bib.bib162)]. Thus, a thorough systematic quantitative evaluation using classical input and output test datasets is difficult, resulting in an increased demand for better model understanding to anticipate potential shortcomings, as automated tests are difficult and possibly insufficient.\nReport issue for preceding element\nSecurity and safety concerns -  Various problems exist related to the safety and security of GenAI-based technologies, such as witnessed by adversarial examples [[45](https://arxiv.org/html/2404.09554v1#bib.bib45)]. However, GenAI allows for novel forms of attacks and abuse [[53](https://arxiv.org/html/2404.09554v1#bib.bib53)] targeting a vast number of people through social engineering at a large scale to manipulate elections. Also, individuals might leverage GenAI for malicious activities, such as receiving detailed instructions on performing terrorist attacks.\nReport issue for preceding element\nAccountability and legal concerns -  The need for accountability arises due to multiple questions, often driven by legal concerns. GenAI exhibits a complex supply chain of data providers and developers, which means data might stem from many sources, and multiple companies might be involved in building a GenAI system. These include those that make a foundation model [[146](https://arxiv.org/html/2404.09554v1#bib.bib146)], those that fine-tune it to a task, and ultimately, a user who adjusts it through prompting. This makes accountability a challenging task that is needed as GenAI systems have the potential to cause harm. Thus, the question of who is responsible and what causes harm becomes more relevant. This can lead to forensic questions like âWhy did an AI trigger a certain action [[138](https://arxiv.org/html/2404.09554v1#bib.bib138)]? Was it the training, data, or model?â And even if it can be tied to one aspect, for example, data, further questions come up such as âWas it the data from a third-party provider, public data, or data from users?â. The need for accountability arises due to the use of copyrighted material or, potentially, patented material. In lawsuits, a key question is if a patent is valid because it is highly original. If GenAI can explain that the solution is not âa copy from an existing patentâ but emerges through basic reasoning given âprior art,â the judge might be more inclined to rule the patent invalid.\nReport issue for preceding element\nTable 2: Why is explainability important for GenAI? Reason |  Description  \n---|---  \n_Need to adjust_ |  Users want to create artifacts aligned with their preferences  \n_Need to verify_ |  Ensure correctness or identify errors in outputs, for example, due to hallucinations  \n_Increased reach_ |  Growth in the number and diversity of people, including vulnerable groups exposed to GenAI  \n_High impact applications_ |  GenAI is used for applications with profound impact on individuals and society, for instance, in the medical domain and education  \n_Unknown Applications_ |  GenAI can be used for many tasks in ways that are hard to anticipate  \n_Difficult to evaluate_ |  Many applications of GenAI are hard to evaluate using conventional train/test set approaches, as the quality of outputs is hard to quantify  \n_Security and safety_ |  GenAI suffers from novel vulnerabilities (such as prompt hacks), and it has the potential to cause harm at a large scale  \n_Accountability and legal concerns_ |  GenAI involve more actors (data provider, foundation model creator, fine-tuner, end-user), making accountability more challenging while at the same time being subject to legal risks  \nReport issue for preceding element Table 3: Why is XAI more challenging for GenAI? Reason |  Description  \n---|---  \n_Lack of access_ |  _No access to inner workings_  \n_Interactivity_ |  Outputs are due to multiple rounds of interaction, necessitating understanding humans and AI and their mutual understanding.  \n_Complex systems, models, data, and training_ |  Understanding gets more difficult as complexity increases, e.g., due to network and training data size, the diversity of data, and the combination of multiple training procedures. GenAI models might also be part of a complex system with multiple closely interacting non-AI components such as code interpreters and search engines.  \n_Complex outputs_ |  Generated artifacts can comprise millions of bits.  \n_Hard to evaluate explanations_ |  As automatic evaluation of outputs is hard, so is (function-grounded) evaluation of XAI  \n_Diverse users_ |  More varied user base  \n_Risk of ethical violations_ |  As GenAI suffers from biases and offensiveness, so might its explanations  \n_Technical shortcomings_ |  GenAI models hallucinate and exhibit reasoning errors. In particular, also self-explanations by LLMs are subject to known shortcomings such as hallucinations and limited reasoning  \nReport issue for preceding element\n###  3.2 Why is XAI more challenging for GenAI?\nReport issue for preceding element\nLack of access: Commercial GenAI models from large corporations such as OpenAI and Google are among the most widely used systems. However, users, researchers, and other organizations interested in understanding the generative process of specific artifacts or models cannot access model internals and training data of these models. This rules out many XAI approaches.\nReport issue for preceding element\nInteractivity: Some tasks involving humans and GenAI are inherently interactive, including negotiations that can be conducted between GenAI and humans [[143](https://arxiv.org/html/2404.09554v1#bib.bib143)]. Thus, explanations need to focus not just on the model, but also on how the model impacts humans and vice versa over the course of an interaction.\nReport issue for preceding element\nComplex systems, models, data, and training: Understanding AI gets increasingly difficult as models grow and digest more training data. GenAI based on very large foundation models constitutes the largest AI models today with hundreds of billions of parameters [[146](https://arxiv.org/html/2404.09554v1#bib.bib146)]. They also lead to novel, more complex supply chains of AI. Pre-GenAI models were often built based on company-internal data, possibly by fine-tuning a model trained on a moderate-sized public dataset such as ImageNet. GenAI systems are built using much larger data from many sources, including public and third-party providers. Often, a foundation model is further adjusted through fine-tuning or retrieving information from external data sources [[73](https://arxiv.org/html/2404.09554v1#bib.bib73)] to yield a GenAI system. Thus, the final output of a GenAI system might be generated not only through a deep learning model but also by engaging with other tools such as code interpreters [[135](https://arxiv.org/html/2404.09554v1#bib.bib135)].\nReport issue for preceding element\nComplex outputs: Generated artifacts are complex, i.e. typically consisting of thousands up to millions of bits in an information-theoretic sense. Classical supervised learning yielding classes often produce just a single bit in case of binary decisions and at most a few dozen bits, i.e., mostly less than a few million classes. In some sense, before GenAI a label of a classifier constitutes a single decision, while GenAI makes a multitude of decisions â one for each aspect of the artifact. Thus, textual outputs and images naturally lead to investigations of several aspects of the output, such as tone, style, or semantics of texts [[196](https://arxiv.org/html/2404.09554v1#bib.bib196)]. There are many possible questions about why an artifact exhibits a certain property.\nReport issue for preceding element\nIt is hard to evaluate explanations, especially for function-grounded approaches, where GenAI itself is hard to evaluate. Function-grounded evaluation focuses on assessing an XAI method based on predefined benchmarks, for example, to use an explanation to classify an object and see whether the explanation is equal to the output of the model used to create the explanation. As such benchmarks might not exist and are difficult to create for certain GenAI tasks, evaluation of explanations also becomes more challenging. \nReport issue for preceding element\nDiverse users: A model might be utilized by a diverse set of users across all age and knowledge groups covering many needs â similar to a search engine. In contrast, pre-GenAI systems are more often tailored to a specific user group and task.\nReport issue for preceding element\nRisk of ethical violations: Even commercial GenAI models are known for producing potentially offensive, harmful, and biased content [[1](https://arxiv.org/html/2404.09554v1#bib.bib1)]. GenAI models also commonly self-explain, and, in turn, the possibility arises that while the outputs might be ethical, the explanations are offensive, for example, due to inadequate phrasing or visual depictions.\nReport issue for preceding element\nTechnical shortcomings: GenAI suffers from hallucinations and limited reasoning capability. In turn, if GenAI models self-explain, such explanations are subject to the same shortcomings.\nReport issue for preceding element\n###  3.3 Desiderata of Explanations for GenAI\nReport issue for preceding element Novel Desiderata |  Description  \n---|---  \n_Verifiability_ |  Explanation should support verification of AI outputs.  \n_Lineage_ |  Explanations might include information on tracking and documenting data, algorithms, and processes in AI models to aid accountability, transparency, and reproducibility.  \n_Interactivity and personalization_ |  With complex AI systems, explanations must be customizable by users and their preferences.  \n_Dynamic explanations_ |  Explanations might differ in content and structure depending on the sample and specified objectives (e.g., max. plausibility, explain surprising aspects) as it is impossible to explain all details of complex artifacts.  \n_Costs_ |  Economics of XAI include costs associated with risks of value leakage and the costs for implementing XAI.  \n_Alignment criteria_ |  Explanations should align with criteria like helpfulness, honesty, and harmlessness, crucial for trust and ethical AI.  \n_Security_ |  Providing explanations should not compromise security, as insights on GenAI models might facilitate attacks or exploit vulnerabilities.  \n_Uncertainty_ |  Understanding and conveying the confidence and uncertainty of AI outputs is vital for decision-making and trust.  \nTable 4: Overview of novel and emerging desiderata for GenXAI Report issue for preceding element\nThere are also several novel and emerging aspects as well as a big change in the relevance of desiderata:\nReport issue for preceding element\n  * â¢\nVerifiability has been recently discussed as an important aspect of explanations [[38](https://arxiv.org/html/2404.09554v1#bib.bib38)]. But the problem that outputs of LLMs cannot be verified (due to hallucinations) has been discussed years earlier [[95](https://arxiv.org/html/2404.09554v1#bib.bib95)]. Suppose explanations cannot be verified, and an explainee must trust the explanation. In that case, the consequence can be the rejection of a correct answer due to an incorrect explanation or failure to detect incorrect outputs. A key concern concerning verification is the effort to verify. Efforts to understand and tailor explanations have been discussed for XAI in general, for example, for time efficiency see [[148](https://arxiv.org/html/2404.09554v1#bib.bib148)].\nReport issue for preceding element\n  * â¢\nLineage ensures that model decisions can be tracked to their origins. It refers to tracking and documenting data, algorithms, and processes throughout the lifecycle of an AI model. It is highly relevant for accountability, transparency, reproducibility, and, in turn, governance of artificial intelligence [[142](https://arxiv.org/html/2404.09554v1#bib.bib142)]. It concerns the âwhoâ and the âwhatâ, for example, âWho provided the data or made the model?â or âWhat data or aspects thereof caused a decision?â. While the latter is a well-known aspect of XAI, as witnessed by sample-based XAI techniques, the former has not been emphasized significantly in the context of XAI. [[37](https://arxiv.org/html/2404.09554v1#bib.bib37)] set forth data traceability as a requirement in the context of Machine Learning Operations (MLOPs) for XAI in industrial applications. The need for lineage emerges as GenAI supply chains get more complex often involving multiple companies [[146](https://arxiv.org/html/2404.09554v1#bib.bib146)] rather than just a single one. Furthermore, multiple lawsuits have been undertaken in the context of generative AI, for example, related to copyright issues [[50](https://arxiv.org/html/2404.09554v1#bib.bib50)]. Regulators have also set stringent demands on AI providers [[36](https://arxiv.org/html/2404.09554v1#bib.bib36)]. Thus, employing GenAI poses legal risks to organizations. In turn, ensuring lineage-supported accountability can serve as a risk mitigation.\nReport issue for preceding element\n  * â¢\nInteractivity and personalization have been discussed previously in XAI [[148](https://arxiv.org/html/2404.09554v1#bib.bib148), [139](https://arxiv.org/html/2404.09554v1#bib.bib139)]. However, as GenAI outputs and systems are more complex, the number of options for how and what to explain has increased drastically. While there is only one bit to explain in a binary classification system, it amounts to millions for a generative AI system generating images. That is, it is nearly impossible for a user to understand the reasons behind all possible details of an output. Thus, depending on user preferences and the purpose of the explanation, some aspects might be more relevant to understand than others, necessitating the need for a user to engage with the system to obtain explanations and for the system to provide adequate explanations tailored to the userâs demand. As discussed in Section [4.1.3](https://arxiv.org/html/2404.09554v1#S4.SS1.SSS3 \"4.1.3 Dynamics â£ 4.1 Dimensions of taxonomy â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\"), systems supporting interactive XAI are increasingly emerging.\nReport issue for preceding element\n  * â¢\nDynamic explanations aim at choosing the explanation qualities and content (e.g., What output properties are explained?) automatically depending on the sample, explanation objective and possibly other information. For example, an explanation might elaborate on why a positive or negative tone for a generated text is chosen. Tonality might only be discussed for some samples and not for others. When to include it, should be aligned with a specified objective, e.g., the explanation should satisfy the explainee (plausibility) or to explain the most surprising aspects of the generated artifacts or to explain the most impactful properties of the artifact on its consumers. The goal of dynamic explanations is to maximize the specified objectives while being free to choose the explanation content, including meta-characteristics such as what aspects are included in the explanation, its structure, etc.\nReport issue for preceding element\n  * â¢\nCosts related to XAI might also become an emerging area. Economics of XAI has been elaborated in [[10](https://arxiv.org/html/2404.09554v1#bib.bib10)], where concerns related to the costs of implementing XAI (and transparency) are mentioned. For cooperations, GenXAI adds the risk of leaking value. That is, competitors (or academics) might prompt a model to save on the costs of training data. For example, the Alpaca model [[167](https://arxiv.org/html/2404.09554v1#bib.bib167)] was trained on data extracted from one of OpenAIâs models, allowing them to forego the costly and time-consuming task of collecting data from humans. Using explanations, for instance, as part of chain-of-thought (CoT) [[184](https://arxiv.org/html/2404.09554v1#bib.bib184)], can further enhance performance and is thus of value.\nReport issue for preceding element\n  * â¢\nAlignment criteria such as helpfulness, honesty, and harmlessness [[6](https://arxiv.org/html/2404.09554v1#bib.bib6)] that are relevant for GenAI in general also play a role for XAI. Some of these criteria partially overlap with existing ones, such as plausibility (with helpfulness) and faithfulness (with honesty, for instance, explanations should not be deceptive [[144](https://arxiv.org/html/2404.09554v1#bib.bib144)]). Aspects such as harmlessness have received less attention, as explanations were commonly simpler (for example, attribution-based). Harmlessness implies that explanations do not contain offensive information or information concerning potentially dangerous activities [[6](https://arxiv.org/html/2404.09554v1#bib.bib6)]. It also relates to security, discussed next:\nReport issue for preceding element\n  * â¢\nSecurity increasingly evolves as a desideratum. Explanations should not jeopardize the security of the user and the organizations operating the GenAI model. Providing insights into the reasoning process might facilitate attacks or might be leveraged in competitive situations, leading to poorer outcomes of GenAI. For example, in a recent study on price negotiations of humans against LLMs [[143](https://arxiv.org/html/2404.09554v1#bib.bib143)], humans asked an LLM what decision criteria it used for its decisions and, in turn, systematically exploited this knowledge to obtain better outcomes against the LLM. A human negotiator might not disclose such information. Thus, openness can also be abused. âSecurity through obscurityâ is one protection mechanism against attacks. Cooperation might also aim to protect their intellectual property. For example, customer support employees (and GenAI models) might have access to some relevant information on a product to help customers. Still, they might not be allowed to obtain explanations on how exactly the product is manufactured as this might constitute a valuable secret for the company.\nReport issue for preceding element\n  * â¢\nUncertainty: Understanding the confidence of outputs is an important desideratum of XAI. While most works aim to explain a decision, explaining the uncertainty of a prediction has also attracted some attention [[106](https://arxiv.org/html/2404.09554v1#bib.bib106), [41](https://arxiv.org/html/2404.09554v1#bib.bib41)]. Deep learning models such as image classifiers are known to be overconfident, with multiple attempts to address the issue [[99](https://arxiv.org/html/2404.09554v1#bib.bib99), [41](https://arxiv.org/html/2404.09554v1#bib.bib41)]. LLMs arguably take this a step further, as they commonly generate answers eloquently even if they are wrong, i.e., they are âfluent but non-factualâ. Still, LLMs have some (though not perfect) understanding of whether they can answer a question [[64](https://arxiv.org/html/2404.09554v1#bib.bib64)] or not. They can also be enhanced with uncertainty estimation techniques [[60](https://arxiv.org/html/2404.09554v1#bib.bib60)].\nReport issue for preceding element\n\n\nPrior research has extensively discussed principles and desiderata of explanations. Here, we briefly summarize key characteristics explanations should exhibit drawing on prior surveys [[90](https://arxiv.org/html/2404.09554v1#bib.bib90), [139](https://arxiv.org/html/2404.09554v1#bib.bib139), [148](https://arxiv.org/html/2404.09554v1#bib.bib148), [12](https://arxiv.org/html/2404.09554v1#bib.bib12), [51](https://arxiv.org/html/2404.09554v1#bib.bib51)] and briefly discuss based on novel characteristics of GenAI. Among the most important, well-known desiderata are:\nReport issue for preceding element\n  * â¢\nFaithfulness (= fidelity = reliability): An explanation should precisely reflect the reasoning process of a model. Due to the complexity of GenAI (models), a higher level of abstraction seems necessary to keep explanations comprehensible in a limited amount of time.\nReport issue for preceding element\n  * â¢\nPlausibility (= persuasiveness = understandability): An explanation should be understandable and compelling to the target audience. Textual explanations (especially, self-explanations) are often easy to understand (e.g., compared to classical explanations such as SHAP values).\nReport issue for preceding element\n  * â¢\nCompleteness (= coverage) and minimality: An explanation should contain all relevant factors for a prediction (completeness) but no more (minimality). Asking for complete coverage becomes less feasible with the growth of output, data, and model sizes. Personalized, interactive explanations allowing a user to control explanations as well as XAI techniques automatically selecting only interesting properties to be explained could be the way forward.\nReport issue for preceding element\n  * â¢\nComplexity: Total amount of conveyed information in an explanation, typically measured relative to an explainerâs knowledge, i.e., subjectively. This aspect gains in importance as stakeholders become more diverse.\nReport issue for preceding element\n  * â¢\nInput and model sensitivity and robustness: Changes in the input (or model) that impact model outputs should also lead to changes of explanations (sensitivity), but if changes (of inputs) do not alter model behavior or changes in the model do not alter processing and outputs significantly then explanations should not change disproportionately (robustness). This still holds for GenAI.\nReport issue for preceding element\n\n\nTable 5: Dimensions of our taxonomy for GenXAI algorithms Dimension  \n---  \n_Explanation (=Output) properties:_  \nâ·â·\\trianglerightâ· Scope  \nâ\\circâ Explaining single vs. all attributes of the output â\\circâ Explaining single input-output vs. entire interaction  \nâ·â·\\trianglerightâ· Modality  \nâ\\circâ Unimodal vs. multi-modal explanations  \nâ·â·\\trianglerightâ· Dynamics  \nâ\\circâ Interactive vs. non-interactive explanations â\\circâ Static (sample-independent) vs. dynamic (sample-dependent) explanation qualities and content  \n_Input and internal properties:_  \nâ·â·\\trianglerightâ· Foundational source for XAI  \nâ\\circâ Model â\\circâ Optimization â\\circâ Training data â\\circâ Prompt  \nâ·â·\\trianglerightâ· Required access by XAI Method  \nâ\\circâ Black-box vs. white-box  \nâ·â·\\trianglerightâ· Model (self-)explainers  \nâ\\circâ Self- vs. explanations by other models/algorithms  \nâ·â·\\trianglerightâ· Sample difficulty  \nâ\\circâ Explaining simple vs. difficult samples  \nâ·â·\\trianglerightâ· Dimensions of pre-GenAI  \nReport issue for preceding element\n##  4 Taxonomy of XAI techniques for GenAI\nReport issue for preceding element\nOur taxonomy provides a scheme for the classification of XAI mechanisms and algorithms supporting the understanding of GenAI (Section [4.1](https://arxiv.org/html/2404.09554v1#S4.SS1 \"4.1 Dimensions of taxonomy â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")), which we utilize to classify existing techniques (Section [4.2](https://arxiv.org/html/2404.09554v1#S4.SS2 \"4.2 Classification of Techniques â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")).\nReport issue for preceding element\n###  4.1 Dimensions of taxonomy\nReport issue for preceding element\nThe key characteristics of our taxonomy are summarized in Table [5](https://arxiv.org/html/2404.09554v1#S3.T5 \"Table 5 â£ 3.3 Desiderata of Explanations for GenAI â£ 3 The importance, challenges and desiderata of GenXAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\"). We distinguish between GenXAI algorithmsâ output (= explanation) properties, input, and internal properties. Explanation properties characterize the XAI algorithms outputs, i.e., the explanations, in terms of scope, i.e., what (fraction of) samples, attributes and part of the interaction they explain, modality, that means, unimodal or multi-modal, and interactivity, i.e., can user engage in obtaining additional explanations or tailor explanations. Input and internal properties relate to what the XAI algorithms require producing explanations and how they are obtained. While many ideas on structuring XAI are still valid in the context of GenAI, we focus primarily on novel dimensions such as the foundational source for XAI, which is one of data, model, training, and prompt. The source forms the key mechanism or artifact leveraged by XAI techniques to generate explanations, as elaborated in Section [4.1.4](https://arxiv.org/html/2404.09554v1#S4.SS1.SSS4 \"4.1.4 Foundational Source for XAI techniques â£ 4.1 Dimensions of taxonomy â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\"). One might classify the first three (data, model, and training) under the category of intrinsic methods as they impact the resulting model. However, data can also be extrinsic, particularly for Retrieval-Augmented Generation (RAG). Similarly, for prompts, Chain-of-Thought (CoT) encourages and guides XAI, but it also relies to some extent on training. That is, if training data lacks any form of explanation, CoT prompting will not work. This can be most easily seen in an extreme case, where words like âbecauseâ are removed from the training data, implying that they will never be generated.\nReport issue for preceding element\n####  4.1.1 Output, Interaction and Input Scope\nReport issue for preceding element\nOften, scope [[148](https://arxiv.org/html/2404.09554v1#bib.bib148)] only refers to what inputs are explained by a method, i.e., a single sample (local) versus all samples (global), which means the model behavior in general [[52](https://arxiv.org/html/2404.09554v1#bib.bib52), [12](https://arxiv.org/html/2404.09554v1#bib.bib12)]. Thus, the scope states the quantity of the input samples, which are explained. We call it _input scope_. For GenAI, we say that scope also refers to the quantity of the output that is explained, i.e., a single attribute of the output (focused) vs. all attributes (holistic). We call this _output scope_. This is illustrated with an example in Figure [4](https://arxiv.org/html/2404.09554v1#S4.F4 \"Figure 4 â£ 4.1.1 Output, Interaction and Input Scope â£ 4.1 Dimensions of taxonomy â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\"). As outputs are significantly more complex for GenAI, they raise more options for questions. For example, why did the response contain some information and not another? Why was the sentiment of a generated sentence positive, neutral, or negative? While some of our methods touch on these questions, overall, there is limited work in this direction. Similarly, there is limited understanding of how to relate training data to predictions beyond classical approaches such as influence functions, i.e., how did a specific piece of knowledge in the training data impact the generation process?\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/2404.09554v1/img/inout.png) Figure 4: Illustration of input and output scope, where we use âtonalityâ as an example of a text-related attribute. Traditionally, scope only referred to output scope. Report issue for preceding element\n_Interaction scope_ : For GenAI, interactions are no longer commonly in the form of dialogues, and understanding both sides of the system becomes much more relevant. As such, we distinguish two goals:\nReport issue for preceding element\n  * â¢\nExplaining (single) input-output relations: This is the classical notion, where an AI system processes one input to produce one output. The goal can be to understand a particular instance (local explanation) or the model as a whole. While explanations might consider user-specific aspects and personalize explanations [[139](https://arxiv.org/html/2404.09554v1#bib.bib139)], such personalization is typically independent of the interaction.\nReport issue for preceding element\n  * â¢\nExplaining the entire interaction: It focuses on human-AI interaction and its dynamics, for example, the communication and actions between an AI and a human when a human solves a task using an AI. Interactions are characterized by multiple rounds of outputs generated by both sides conditioned on prior outputs. In this case, the goal is to more holistically explain (i) the dynamics of the interaction, i.e., not just one single input-output but the entire sequence of in- and outputs and (ii) the outcome of the interaction, which could be why a particular artifact such as an image was generated in a certain way, but also why a user did not complete a task, for example, abandoned it prematurely or achieved an unsatisfactory output. Interaction dynamics are influenced by a series of technical (such as model behavior including classical performance measures but also latency, user interface, etc.) and non-technical factors (such as human attitudes and policies). As such, human-AI interaction cannot easily be associated with one scientific field but is inherently interdisciplinary. Explainability, which aims at understanding AI technology, should focus on how technical factors related to model behavior impact the interaction. While many existing works touch on the subject, the change in interactivity brought along by prompting due to GenAI is not well understood. A study that investigated interactivity in negotiations was [[143](https://arxiv.org/html/2404.09554v1#bib.bib143)]. However, the explanations for outcomes of negotiations and interaction behavior are not through algorithms but rather through a manual, qualitative investigation of interaction â a common technique in social sciences but less prevalent in computer science.\nReport issue for preceding element\n\n\nThe two goals are illustrated with an example in Figure [5](https://arxiv.org/html/2404.09554v1#S4.F5 \"Figure 5 â£ 4.1.1 Output, Interaction and Input Scope â£ 4.1 Dimensions of taxonomy â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\").\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/2404.09554v1/img/interScope.png) Figure 5: Illustration of input and interaction scope, where we use âtonalityâ as an example of a text-related attribute. Traditionally, scope only referred to output scope. Report issue for preceding element\nThe field of human-computer interaction has aimed at explaining human interactions for a significant amount of time [[92](https://arxiv.org/html/2404.09554v1#bib.bib92), [15](https://arxiv.org/html/2404.09554v1#bib.bib15)] with some effort also on discussing human-AI interaction. For example, guidelines for human-AI interaction (before GenAI) are well-studied [[5](https://arxiv.org/html/2404.09554v1#bib.bib5)], also the topic of explanation in collaborative human-AI systems [[171](https://arxiv.org/html/2404.09554v1#bib.bib171)]. Furthermore, explanations in human-AI systems typically encompass objectives that are driven by non-technical concerns [[101](https://arxiv.org/html/2404.09554v1#bib.bib101), [108](https://arxiv.org/html/2404.09554v1#bib.bib108)] but there is less work on explaining human-AI interactions themselves [[164](https://arxiv.org/html/2404.09554v1#bib.bib164)], in particular, targeted towards GenAI. To provide two examples from the pre-GenAI area spanning from in-depth technical study to broader organizational studies: [[136](https://arxiv.org/html/2404.09554v1#bib.bib136)] discussed how human-AI interaction could be optimized, accounting for long-term goals such as preserving human diversity. The work would explain how the user can improve her interaction to reduce error rates and become more efficient. [[48](https://arxiv.org/html/2404.09554v1#bib.bib48)] investigated the dynamics of AI adoption within an organization, explaining how error rates and learning behavior of an AI impact the complexity of processes. Explanations in interactive systems in pre-GenAI [[122](https://arxiv.org/html/2404.09554v1#bib.bib122)] and GenAI (see Section [4.1.3](https://arxiv.org/html/2404.09554v1#S4.SS1.SSS3 \"4.1.3 Dynamics â£ 4.1 Dimensions of taxonomy â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")) are typically more concerned about supporting interactive explorations of a decision, for instance, querying a system to better understand it rather than obtaining explanations on how a sequence of inputs and outputs emerged.\nReport issue for preceding element\n####  4.1.2 Explanation Modality\nReport issue for preceding element\nCommonly, explanations are unimodal, for example, textual, visual, or numeric. However, also multi-modal explanations have been investigated [[118](https://arxiv.org/html/2404.09554v1#bib.bib118)] by collecting a dataset containing textual and visual justifications. They show that multi-modal explanations yield favorable outcomes, for instance, each modality improves due to the presence of the other.\nReport issue for preceding element\n####  4.1.3 Dynamics\nReport issue for preceding element\n_Interactivity:_ In a classical setting, XAI is often non-interactive, meaning an explainee has limited options to control explanations or request additional information. However, the idea of interactivity has existed in XAI for some time, as shown in prior taxonomies [[148](https://arxiv.org/html/2404.09554v1#bib.bib148)]. One idea is to rethink XAI as a dialogue [[158](https://arxiv.org/html/2404.09554v1#bib.bib158)]. [[160](https://arxiv.org/html/2404.09554v1#bib.bib160)] supports the explainability of a machine learning model by using an LLM to translate natural language queries into a pre-defined set of operations related to explainability, for example, getting the most important features, changing a feature, etc.. [[40](https://arxiv.org/html/2404.09554v1#bib.bib40)] uses LLMs to create an interactive and explainable recommender system. In terms of classical metrics such as recall and precision, the system is not outperforming. Improving models due to human explanations in an interactive setting has also been studied for image recognition [[147](https://arxiv.org/html/2404.09554v1#bib.bib147)]. While LLMs are known for their superior performance in many Natural Language Processing (NLP) tasks, they might also be employed without improving classical metrics such as accuracy or precision and recall but rather to yield other benefits such as explainable, interactive systems requiring less (training) data [[40](https://arxiv.org/html/2404.09554v1#bib.bib40), [28](https://arxiv.org/html/2404.09554v1#bib.bib28)]. [[28](https://arxiv.org/html/2404.09554v1#bib.bib28)] showed that binary risk classification can be done with 40x fewer data to roughly match the performance of a classical machine learning system through explainable-guided prompts. _Static vs. dynamic explanation qualities and content_ relates to how the structure and content of explanation vary based on the sample due to the algorithm. That is, which and how properties of the generated artifact are explained. This choice can be independent of the sample(static), i.e., identical for each sample, or it can be dependent on the sample itself(dynamic). For example, classical methods like attribution maps are static, as they only explain relevance and they always assign a relevance value for each input pixel. In contrast, textual self-explanations can be dynamic. The explained properties can be selective, e.g., for a generated image an explanation like âA moving, red car was shown to make the image more vivid and engage viewerâ only describes one part of the image and one property of that part. Explanations are dynamic if the structure and content of the explanation varied with the sample. Say the XAI technique yielded a generated image of a mountain landscape âA snowy landscape was chosen as the prompt contained the word âbrightâ. Explanations were dynamic as the two exemplary explanations refer to a different object (car vs landscape), differ in explained properties (explaining emotional intention vs. not discussing it), and differ in causal factors discussed (mentioning what inputs caused output properties, i.e., âbrightâ in prompt vs. not doing so).\nReport issue for preceding element\n####  4.1.4 Foundational Source for XAI techniques\nReport issue for preceding element\nWe consider the data, model, and optimization (training) and prompt the foundational sources for XAI methods. That is, each source can be modified or tailored to improve XAI.\nReport issue for preceding element\nModel induced XAI refers to intrinsic XAI methods (also named model-specific XAI [[52](https://arxiv.org/html/2404.09554v1#bib.bib52)]), where the design of the model is altered to foster explainability. With GenAI, novel intrinsic methods have emerged. _Using interpretable components_ : Deep learning is a composition of multiple layers and components, such as activation functions and attention mechanisms. These components can be more or less complex, limiting the overall explainability of the model.For example, interpretable activation functions might substitute conventional less interpretable functions, for instance, SoLU [[32](https://arxiv.org/html/2404.09554v1#bib.bib32)] is said to enhance interpretability. These functions are built on the idea that there are more features than neurons (per layer), and, in turn, superposition yields additional features [[112](https://arxiv.org/html/2404.09554v1#bib.bib112)]. The paper also provides evidence for this hypothesis. The interpretability makes some neurons more interpretable but hides others. Thus, while the method overall claims to provide a net benefit, it is not without costs. Classical attention layers are also commonly used, though their value for XAI is debated (see Sec. [4.2.1](https://arxiv.org/html/2404.09554v1#S4.SS2.SSS1 \"4.2.1 Feature Attribution â£ 4.2 Classification of Techniques â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")).\nReport issue for preceding element\n_Interpretable GenAI models through additional models_ : Model interpretability can be achieved by combining LLMs with other models and often external knowledge. For example, in [[21](https://arxiv.org/html/2404.09554v1#bib.bib21)] an LLM is enhanced with a GNN and external knowledge that generates an explanation and prediction jointly. [[26](https://arxiv.org/html/2404.09554v1#bib.bib26)] fostered explicit multistep reasoning by chaining responses of two fine-tuned LLMs; one performs selection, the other inference. [[180](https://arxiv.org/html/2404.09554v1#bib.bib180)] uses the idea to incorporate external knowledge using classical internet search (as is done in commercial products such as Bing Chat). In addition, it also uses first-order logic; for example, it creates easier-to-verify subclaims (that jointly lead to the overall claim). It also generates explanations simply by querying the LLM. [[177](https://arxiv.org/html/2404.09554v1#bib.bib177)] developed and trained a decoder for faithful and explainable online shopping product comparisons.\nReport issue for preceding element\nOptimization: Adjusting the optimization objective is a common technique to foster explainability. Common strategies involve disentanglement of latent dimensions [[129](https://arxiv.org/html/2404.09554v1#bib.bib129)] as well as training also for XAI relevant criteria, such as citing evidence [[98](https://arxiv.org/html/2404.09554v1#bib.bib98)]. In the context of GANs, [[19](https://arxiv.org/html/2404.09554v1#bib.bib19)] trained explicitly disentangled representations by maximizing the mutual information between a small subset of the latent variables and the sample. This allowed the so-called InfoGAN to separate writing styles from digit shapes on the MNIST dataset. Furthermore, in [[129](https://arxiv.org/html/2404.09554v1#bib.bib129)], explanations have been used to constrain training, such as âto be right for the right reasonsâ. Note that while disentanglement is commonly achieved through training objectives and regularization, special network architectures like capsule networks [[130](https://arxiv.org/html/2404.09554v1#bib.bib130)] and others (see Section on Disentanglement in [[148](https://arxiv.org/html/2404.09554v1#bib.bib148)]) can also support disentanglement. Diffusion models already have a semantic latent space [[72](https://arxiv.org/html/2404.09554v1#bib.bib72)]. A special reverse process can leverage it for image editing using CLIP [[124](https://arxiv.org/html/2404.09554v1#bib.bib124)], which iteratively improves reconstructed images. [[98](https://arxiv.org/html/2404.09554v1#bib.bib98)] trains (more than one) model to cite evidence for claims, facilitating answer understanding and, especially, fact-checking.\nReport issue for preceding element\nTraining data can support XAI in multiple ways. While the exact impact of training data and dynamics is not yet fully explored [[168](https://arxiv.org/html/2404.09554v1#bib.bib168)], current findings indicate that training data is an important factor to support explainability â particularly for textual data. _Training data composition:_ GenAI training data is usually complex â even for a single modality. For example, text data might consist of programming code, books, dialogues, etc. The composition of the training data can impact reasoning, i.e., code can improve certain reasoning task [[91](https://arxiv.org/html/2404.09554v1#bib.bib91)]. While less explicit statements are known for explanations, the overall data composition is also likely impacting XAI. _Explanation quality and quantity_ : Aside from the overall composition of training data, the presence and absence of explanations in the training data also impacts XAI. While it is well-known that the quality of training data has a strong impact on the performance of a model, the impact on XAI has received less attention. However, as GenAI can self-explain as witnessed by CoT [[184](https://arxiv.org/html/2404.09554v1#bib.bib184)], i.e., generate explanations as part of outputs, training data strongly impacts performance. For illustration, assume that a model is trained with erroneous explanations though potentially correct results, it could in principle perform well on tasks but provide poor explanations. Also, if the training data does not contain any data explaining the reasoning, the model might perform worse at explanations. In an extreme case, if the training data does not contain explanations including explanatory words such as âdue toâ, âfor that reasonâ and âbecauseâ the model will also never generate such words (and the corresponding explanations). _Domain specialization_ [[81](https://arxiv.org/html/2404.09554v1#bib.bib81)] can tailor the model more towards a specific domain, potentially at the cost of abilities in other domains [[18](https://arxiv.org/html/2404.09554v1#bib.bib18)]. It can also contribute towards explainability, as a narrower model focus implies fewer potential options for explanations and, thus, a lower risk of errors and easier verifiability. \nReport issue for preceding element\nPrompts can also induce explanations: LLMs can be prompted (i) to provide explanations in a preferred manner or (ii) be constrained to rely on a limited set of given facts to create responses, which facilitates verification. The idea of ârationalizationâ dates back to the early 2000s [[198](https://arxiv.org/html/2404.09554v1#bib.bib198)]. One type of explainability is âjustifying a modelâs output by providing a natural language explanationâ [[54](https://arxiv.org/html/2404.09554v1#bib.bib54)]. Commonly, explanations clarifying the reasoning process are elicited through the use of chain-of-thought(CoT) prompting [[184](https://arxiv.org/html/2404.09554v1#bib.bib184)]. Such prompting allows the structure of the reasoning process, implicitly shaping explanations and utilizing external knowledge for each reasoning step to yield more faithful explanations [[184](https://arxiv.org/html/2404.09554v1#bib.bib184), [55](https://arxiv.org/html/2404.09554v1#bib.bib55)]. However, explanations can also contain hallucinations, as shown in the context of few-shot prompting [[195](https://arxiv.org/html/2404.09554v1#bib.bib195)] and sensitivity to inputs for CoT prompting [[175](https://arxiv.org/html/2404.09554v1#bib.bib175)]. Despite their unreliability (to explain the true inner workings due to lack of faithfulness), they might still be of value to verify output correctness or, in the training of (smaller) models [[207](https://arxiv.org/html/2404.09554v1#bib.bib207)]. Additionally, LLMs can be constrained to rely on information, which is part of the user-given prompt or extracted from an external database or the internet, known as Retrieval-Augmented Generation (RAG) [[73](https://arxiv.org/html/2404.09554v1#bib.bib73)]. RAG facilitates understanding the response of an LLM and, especially, verifying it, as the source of information for the answer is known and typically very small compared to the entire training data of a GenAI model. To facilitate explainability for recommender systems, personalized prompt learning, for example, soft-prompt tuning to yield vector IDs, has been conducted [[75](https://arxiv.org/html/2404.09554v1#bib.bib75)].\nReport issue for preceding element\n####  4.1.5 Required Model Access by XAI Method\nReport issue for preceding element\nDepending on what is to be explained and the XAI method, different information is needed to obtain explanations [[148](https://arxiv.org/html/2404.09554v1#bib.bib148)]. Black-box access does not provide information on likelihoods other than the predicted output, and potentially even such probabilities might not be given. That is, internal access, e.g., to activations and gradients, is commonly unavailable. White-box access refers to having complete access to the model, its training data, and its training procedure. In between, there is a wide range of grey-box access [[138](https://arxiv.org/html/2404.09554v1#bib.bib138)]. An important restriction for XAI techniques investigating commercial models is that models are typically only accessible as a black box, such as GPT-4 through an API. Similarly, commercial vendors do not share their training data and often do not even disclose a coarse summary of the training dataset. Thus, also XAI techniques leveraging training data are not easily employable.\nReport issue for preceding element\n####  4.1.6 Model (Self-)Explainers\nReport issue for preceding element\nGenAI, in particular, LLMs provide explanations for their own decisions (self-explain) or serve as explainers in general. That is, the model itself provides explanations rather than a dedicated XAI technique. This contrasts the classical notion of intrinsic XAI that often denotes understandable, simple models such as decision trees and linear regression. While self-explanations are not necessarily faithful [[175](https://arxiv.org/html/2404.09554v1#bib.bib175)], attempts have been made to improve them. For example, [[23](https://arxiv.org/html/2404.09554v1#bib.bib23)] proposed to use an evaluator to quantify faithfulness and optimizing faithfulness scores iteratively. Though self-explanations are not necessarily accurate or faithful, they can be helpful, as demonstrated in a complex environment, where agents performed multistep planning and improved through self-explanation [[182](https://arxiv.org/html/2404.09554v1#bib.bib182)].\nReport issue for preceding element\nLLMs can serve themselves as explainers by providing explanations for essentially anything, for instance, they can self-explain by generating explanations tailored to their outputs [[184](https://arxiv.org/html/2404.09554v1#bib.bib184), [175](https://arxiv.org/html/2404.09554v1#bib.bib175)] or support explaining other machine learning models [[115](https://arxiv.org/html/2404.09554v1#bib.bib115), [160](https://arxiv.org/html/2404.09554v1#bib.bib160), [157](https://arxiv.org/html/2404.09554v1#bib.bib157)], provide explanations by analyzing data, for example, pattern in data through autoprompting [[156](https://arxiv.org/html/2404.09554v1#bib.bib156)], support people in self-diagnosis [[152](https://arxiv.org/html/2404.09554v1#bib.bib152)], or yield interpretable autonomous driving systems [[93](https://arxiv.org/html/2404.09554v1#bib.bib93)]. In fact, on free-form coding tasks (generation), LLMs produce explanations that often exceed the quality of crowd workersâ gold references [[208](https://arxiv.org/html/2404.09554v1#bib.bib208)]. For mental health analysis, explanations of LLMs approach those of humans in quality [[192](https://arxiv.org/html/2404.09554v1#bib.bib192)].\nReport issue for preceding element\n####  4.1.7 Explanation Sample Difficulty\nReport issue for preceding element\nNot all input samples are equivalently challenging to explain [[132](https://arxiv.org/html/2404.09554v1#bib.bib132)]. The idea that some samples and interactions are easier to explain than others gains in relevance, as there is a larger variance in possible inputs and outputs. For example, LLMs allow us to ask the most simple to the most complex questions from a human perspective. LLM-generated texts might be a âlookupâ of a fact learned from the training data onto long stories or solutions to complex tasks. Explanations (as judged by humans) might be worse for difficult samples than for simple ones. More precisely, this has been observed in explaining data labels with GPT-3, where GPT-3 explanations degraded much more with example hardness than human explanations [[132](https://arxiv.org/html/2404.09554v1#bib.bib132)]. Generally, the idea of distinguishing XAI tasks based on their difficulty has received little attention so far. From a computational perspective, current explanation algorithms require an identical amount of computation independent of the difficulty. Also, forward computations typically proceed identically independent of sample difficulty, though the notion of reflection (and thinking fast and slow) has been mentioned in the literature [[141](https://arxiv.org/html/2404.09554v1#bib.bib141)]. LLMs can benefit from ensemble methods, for example, by combining multiple outputs into a single output [[59](https://arxiv.org/html/2404.09554v1#bib.bib59)]. There are numerous works on self-correction [[117](https://arxiv.org/html/2404.09554v1#bib.bib117)]. For example, self-debugging using self-generated explanations as feedback has been associated with reducing coding errors by LLMs [[20](https://arxiv.org/html/2404.09554v1#bib.bib20)]. However, the ability of LLMs to self-correct reasoning by âreflectingâ on their responses without additional information has also been questioned [[58](https://arxiv.org/html/2404.09554v1#bib.bib58)]. While state-of-the-art systems like GPT-4 improve scores on causal reasoning benchmarks, which can serve as explanations, they also exhibit unpredictable failure modes [[67](https://arxiv.org/html/2404.09554v1#bib.bib67)].\nReport issue for preceding element\n####  4.1.8 Dimensions of Pre-GenAI\nReport issue for preceding element\nThere is also a long list of concepts relevant to our taxonomy that originate from pre-GenAI [[2](https://arxiv.org/html/2404.09554v1#bib.bib2), [209](https://arxiv.org/html/2404.09554v1#bib.bib209), [31](https://arxiv.org/html/2404.09554v1#bib.bib31), [148](https://arxiv.org/html/2404.09554v1#bib.bib148), [125](https://arxiv.org/html/2404.09554v1#bib.bib125), [131](https://arxiv.org/html/2404.09554v1#bib.bib131), [163](https://arxiv.org/html/2404.09554v1#bib.bib163), [102](https://arxiv.org/html/2404.09554v1#bib.bib102)], which we do not elaborate on in detail. For example, XAI methods can also be classified according to what to understand, which includes the system, model-related information such as representations (layers, vectors, embeddings) and outputs, training dynamics, and (impact) of data. This distinction has already been made before GenAI [[148](https://arxiv.org/html/2404.09554v1#bib.bib148)]. The most common ways to structure XAI techniques in prior works are, unfortunately, not conceptually clean; for example, a common distinction is between mechanistic and feature attribution-based techniques. But conceptually, feature attribution relates to how the explanation looks (i.e., relevance scores for output). At the same time, mechanistic interpretability aims more at what is being investigated (i.e., neurons and interactions) and how the techniques work (through reverse engineering). As the names of the existing categories are well-established and, thus, easy to comprehend for a reader, we shall also use them in our classification of techniques shown in the next section, but also discuss classification based on our novel dimensions shown in Table [5](https://arxiv.org/html/2404.09554v1#S3.T5 \"Table 5 â£ 3.3 Desiderata of Explanations for GenAI â£ 3 The importance, challenges and desiderata of GenXAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\").\nReport issue for preceding element\n###  4.2 Classification of Techniques\nReport issue for preceding element\nWe place XAI techniques into four categories commonly found in existing literature (see prior surveys in Section [1](https://arxiv.org/html/2404.09554v1#S1 \"1 Introduction â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")). Figure [6](https://arxiv.org/html/2404.09554v1#S4.F6 \"Figure 6 â£ 4.2 Classification of Techniques â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\") shows an overview of techniques. Our focus lies on techniques that have been developed particularly for GenAI models or constitute classical techniques that have been adjusted towards GenAI (mostly by addressing computational issues) or could be employed without much change. We also structure existing techniques in terms of our novel dimensions (Section [4.2.5](https://arxiv.org/html/2404.09554v1#S4.SS2.SSS5 \"4.2.5 Structuring based on novel dimensions â£ 4.2 Classification of Techniques â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")).\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/2404.09554v1/img/techniquesOver.png) Figure 6: Overview of categories of techniques with illustrative examples (Figures are from cited references) Report issue for preceding element\n####  4.2.1 Feature Attribution\nReport issue for preceding element\nFeature attribution provides a relevance score for each input feature, such as a word or pixel. Perturbation-based techniques alter inputs partially, for example, by removing or changing features and investigating output (changes). In the context of NLP, alterations such as removing tokens have been investigated [[188](https://arxiv.org/html/2404.09554v1#bib.bib188)] as well as negating and intensifying statements [[74](https://arxiv.org/html/2404.09554v1#bib.bib74)]. Gradient-based methods require a backward pass from outputs to inputs to obtain derivatives. While not all gradient-based techniques are said to work reliably [[3](https://arxiv.org/html/2404.09554v1#bib.bib3), [44](https://arxiv.org/html/2404.09554v1#bib.bib44)], some techniques like Grad-CAM [[150](https://arxiv.org/html/2404.09554v1#bib.bib150)] that compute a function of gradients and activations have shown to be valuable on a pixel level in images but also to compute token-level attribution [[105](https://arxiv.org/html/2404.09554v1#bib.bib105)]. Directional gradients have also been used in NLP models [[154](https://arxiv.org/html/2404.09554v1#bib.bib154), [34](https://arxiv.org/html/2404.09554v1#bib.bib34)]. Integrated gradients have been used to attribute knowledge to internal neurons [[88](https://arxiv.org/html/2404.09554v1#bib.bib88), [27](https://arxiv.org/html/2404.09554v1#bib.bib27)] as discussed under âNeuron activation explanationâ. Simple first derivatives concerning embedding dimensions are shown in [[74](https://arxiv.org/html/2404.09554v1#bib.bib74)]. Surrogate models approximate large models using much simpler models - often to understand individual predictions. Classical methods are LIME [[128](https://arxiv.org/html/2404.09554v1#bib.bib128)] and SHAP [[87](https://arxiv.org/html/2404.09554v1#bib.bib87)], which have been ported for transformers, that means, for SHAP, see [[71](https://arxiv.org/html/2404.09554v1#bib.bib71)]. Furthermore, attention flows in NLP models have been shown to be related to SHAP values [[35](https://arxiv.org/html/2404.09554v1#bib.bib35)]. Explain Any Concept (EAC) [[166](https://arxiv.org/html/2404.09554v1#bib.bib166)] presents an approach for concept explanation, utilizing Segment Anything Model (SAM) [[70](https://arxiv.org/html/2404.09554v1#bib.bib70)] for initial segmentation and introducing a surrogate model to enhance the efficiency of the explanation process. SAM excels at producing object masks from input prompts like partial masks, points, or boxes. It can generate masks for all objects in an image. SAM is trained on a vast dataset that includes 11 million images and 1.1 billion masks. Decomposition-based methods: Decomposition traditionally refers to attributing relevance from outputs towards inputs or decomposing vectors, but in the context of GenAI, it can also refer to decomposing the reasoning process and attributing outputs to specific reasons. [[83](https://arxiv.org/html/2404.09554v1#bib.bib83)] aims at explaining the reasoning process for question answers using entailment trees constructed using reinforcement learning. An entailment tree has a hypothesis as its root, reasoning steps as intermediate nodes, and facts as leaves.\nReport issue for preceding element\nCommon decomposition techniques compute relevance scores on a layer-by-layer level so that contributions of upper layers emerge as a combination of lower-level contributions. A classic example is Layer-wise relevance propagation (LRP) [[107](https://arxiv.org/html/2404.09554v1#bib.bib107)]. Decomposition-based methods have also been applied to transformers[[4](https://arxiv.org/html/2404.09554v1#bib.bib4)]. [[4](https://arxiv.org/html/2404.09554v1#bib.bib4)] claimed that their adaptation of LRP mitigates shortcomings of gradient methods, which are said to arise due to layernorm and attention layers. Linear decomposition has also been suggested for local interpretation for transformers [[194](https://arxiv.org/html/2404.09554v1#bib.bib194)], where a decomposition is considered interpretable if it is orthogonal and linear. Decompositions are often vector-based [[89](https://arxiv.org/html/2404.09554v1#bib.bib89)]. They express a vector (such as a token embedding) in terms of more elementary vectors. For example, [[104](https://arxiv.org/html/2404.09554v1#bib.bib104)] decomposed (token) vectors and propagated them through the network while maintaining accurate attribution. [[209](https://arxiv.org/html/2404.09554v1#bib.bib209)] surveyed XAI methods for (word) embeddings. One idea is to express embedding vectors in terms of an (orthogonal) basis of interpretable basis (concept) vectors; another technique employs external knowledge and sparsification of (dense) vectors. Attention-based: Attention is a key element within neural networks. It provides an importance score for inputs, where inputs are not necessarily inputs to the network but those of a prior layer. For LLMs, attention scores are commonly obtained between all input token pairs for a single attention layer, which can be visualized using a heatmap or bipartite graph [[178](https://arxiv.org/html/2404.09554v1#bib.bib178)]. Relevance scores have also been computed by combining attention information and gradients [[9](https://arxiv.org/html/2404.09554v1#bib.bib9)]. Attention-based methods have been scrutinized, as they might not identify the most relevant features for predictions [[151](https://arxiv.org/html/2404.09554v1#bib.bib151), [61](https://arxiv.org/html/2404.09554v1#bib.bib61)]. However, the debate has not yet been settled. [[165](https://arxiv.org/html/2404.09554v1#bib.bib165)] focus on explaining language models for long texts leveraging sparse attention by developing a masked sampling procedure to identify text blocks contributing to a prediction. Some listed techniques leverage several ideas, for instance, [[104](https://arxiv.org/html/2404.09554v1#bib.bib104)] can be considered a vector-based and decomposition-based method.\nReport issue for preceding element\n####  4.2.2 Sample-based\nReport issue for preceding element\nSample-based techniques investigate output changes for different inputs. In contrast to perturbation-based methods that change more selectively individual features to investigate their impact, sample-based techniques focus more on the sample in its entirety to understand the relationship between various inputs and their corresponding outputs rather than attributing the output to specific features within a single input. âTraining data influenceâ measures the impact of a specific training sample on the model, typically on the output for a particular input to investigate. [[49](https://arxiv.org/html/2404.09554v1#bib.bib49)] addressed computational issues to employ influence functions for LLMs. Explainability has been transferred from a large natural language inference dataset to other tasks [[197](https://arxiv.org/html/2404.09554v1#bib.bib197)]. Adversarial samples are input alterations due to small, hard-to-perceive changes for humans that lead to a change in outputs. They are typically discussed in the context of cybersecurity, where an attacker aims to alter model outputs, while a human should not notice the input change. However, also schemes that aim to âtrickâ humans and classifiers alike have been proposed [[137](https://arxiv.org/html/2404.09554v1#bib.bib137)]. For example, SemAttack [[179](https://arxiv.org/html/2404.09554v1#bib.bib179)] perturbs embeddings of (tokens) of BERT, while other attacks exchange words [[63](https://arxiv.org/html/2404.09554v1#bib.bib63)]. Parts of inputs can also be occluded to understand model behavior better [[140](https://arxiv.org/html/2404.09554v1#bib.bib140)]. Counterfactual explanations seek to identify minimal changes to an input so that the output changes from a class yð¦yitalic_y to a specific class yâ²superscriptð¦â²y^{\\prime}italic_y start_POSTSUPERSCRIPT â² end_POSTSUPERSCRIPT. In contrast to adversarial samples, changes can be noticed by humans. For example, GPT-2 has been fine-tuned to provide counterfactuals based on pairs of original and perturbed input sentences[[187](https://arxiv.org/html/2404.09554v1#bib.bib187)]. Exploring LLM capabilities through counterfactual task variations, [[189](https://arxiv.org/html/2404.09554v1#bib.bib189)] has shown that LLMs commonly rely on narrow, context-specific procedures that do not transfer well across tasks. [[7](https://arxiv.org/html/2404.09554v1#bib.bib7), [62](https://arxiv.org/html/2404.09554v1#bib.bib62)] use diffusion model guided by classifiers to create counterfactual explanations. Contrastive explanations explain why a model predicted yð¦yitalic_y rather than yâ²superscriptð¦â²y^{\\prime}italic_y start_POSTSUPERSCRIPT â² end_POSTSUPERSCRIPT. Contrastive explanations are said to better disentangle different aspects (such as part of speech, tense, semantics) by analyzing why a model outputs one token instead of another [[196](https://arxiv.org/html/2404.09554v1#bib.bib196)]. \nReport issue for preceding element\n####  4.2.3 Probing-based\nReport issue for preceding element\nProbing-based methods aim at understanding what knowledge an LLM has captured through âqueriesâ (probes). A classifier(probe) is commonly trained on a modelâs activations to distinguish different types of in- and outputs. Knowledge-based: For example, encoders such as BERT, MiniXX, and T5 that produce vectors can be probed by training a classifier on their outputs that aims to identify the presence of properties of outputs or abilities that emerge from the inputs, such as syntax knowledge [[16](https://arxiv.org/html/2404.09554v1#bib.bib16)] and semantic knowledge [[169](https://arxiv.org/html/2404.09554v1#bib.bib169)]. Alternatively to using classifiers, datasets focusing on specific aspects such as grammar [[94](https://arxiv.org/html/2404.09554v1#bib.bib94)] can be created. The modelâs performance on the dataset indicates the ability to capture the property. The design of datasets requires care as regularities might provide an opportunity for shortcut learning [[206](https://arxiv.org/html/2404.09554v1#bib.bib206)] that foregoes learning the properties in favor of identifying such dataset-specific regularities. [[56](https://arxiv.org/html/2404.09554v1#bib.bib56)] learns how to map statements in natural language to fact encodings (in an LLMs representation). In turn, they allow a new way to detect (and explain) when LLMs fail to integrate information from context. The research argues that untruthful texts result from not integrating textual information into specific internal representations. For example, [[82](https://arxiv.org/html/2404.09554v1#bib.bib82)] investigated the training of RoBERTa over time through probing. They found that local information, such as parts of speech, is acquired before long-distance dependencies such as topics. [[46](https://arxiv.org/html/2404.09554v1#bib.bib46)] analyzes the learning of text summarization capability of a large language model by obtaining summaries and output probabilities for a fixed set of articles at different points during training. They show n-gram overlap between generated summaries and original articles over time, concluding, for example, that models learn to copy early during training (leading to high overlap), which gets smaller over time (decrease in overlap). Concept-based explanation: Typically, given a set of concepts, concept-based explanations provide relevance scores of these concepts within inputs [[68](https://arxiv.org/html/2404.09554v1#bib.bib68)]. More recently, it has also been proposed to uncover concepts based on what input information is still present at specific layers (or embeddings) [[140](https://arxiv.org/html/2404.09554v1#bib.bib140)]. While the latter investigates images, high-impact concepts as a source of explanation have also been used for LLMs [[205](https://arxiv.org/html/2404.09554v1#bib.bib205)]. [[39](https://arxiv.org/html/2404.09554v1#bib.bib39)] allows to interpret a large set of individual neurons by constructing a visualizable graph using the training data and truncation and saliency methods. However, concept-based methods must be designed carefully, as merely investigating interactions among input variables might be insufficient to show that symbolic concepts are learnt [[76](https://arxiv.org/html/2404.09554v1#bib.bib76)]. Neuron activation explanation: Individual neurons can also be understood using their activations for inputs. Recently, GPT-4 has been used to generate textual explanations for individual neuron activations of GPT-2 [[115](https://arxiv.org/html/2404.09554v1#bib.bib115)]. For example, GPT-4 summarizes the text triggering large activations for a neuron. [[27](https://arxiv.org/html/2404.09554v1#bib.bib27)] uncovered âknowledge neuronsâ that store particular facts, i.e., they performed knowledge attribution by setting neuron weights to 0 and increasing it to its original value, while summing up the gradient. If the neuron is relevant for a particular fact, the sum should be large.\nReport issue for preceding element\n####  4.2.4 Mechanistic interpretability\nReport issue for preceding element\nMechanistic interpretability investigates neurons and their interconnections. It aims at reverse-engineering model components into human-understandable algorithms [[111](https://arxiv.org/html/2404.09554v1#bib.bib111)]. To this end, models can be viewed as graphs [[42](https://arxiv.org/html/2404.09554v1#bib.bib42)]. Circuits, i.e., subgraphs, can be identified that yield certain functionality [[181](https://arxiv.org/html/2404.09554v1#bib.bib181)]. Common approaches fall into three categories [[89](https://arxiv.org/html/2404.09554v1#bib.bib89)], i.e., circuit discovery, causal tracing, and vocabulary lens. The typical workflow to discover a circuit is often manual and involves [[25](https://arxiv.org/html/2404.09554v1#bib.bib25)]: (i) Observing a behavior (or task) of a model, creating a dataset to reproduce it, and choosing a metric to measure the extent to which the model performs the task. (ii) Define the scope of interpretation (for example the layers of the model), and (iii) perform experiments to prune connections and components from the model. Circuit-based analysis can, thus, also focus on specific architectural elements; for instance, feedforward layers have been assessed and associated with human-understandable concepts [[43](https://arxiv.org/html/2404.09554v1#bib.bib43)]. Also, two-layer attention-only has been investigated, leading to conjectures about how in-context learning might work [[113](https://arxiv.org/html/2404.09554v1#bib.bib113)]. Recent work has automated finding connections between (abstract) neural network units that constitute a circuit [[25](https://arxiv.org/html/2404.09554v1#bib.bib25)].\nReport issue for preceding element\n(Modern) causal tracing commonly estimates the impact of intermediate activation on their output [[97](https://arxiv.org/html/2404.09554v1#bib.bib97)]. While causal tracing moves from activation toward outputs, the vocabulary lens focuses on establishing relations to the vocabulary space. For example, [[43](https://arxiv.org/html/2404.09554v1#bib.bib43)] projects weights and hidden states to the vocabulary space. Individual tokens have also been assessed [[123](https://arxiv.org/html/2404.09554v1#bib.bib123), [66](https://arxiv.org/html/2404.09554v1#bib.bib66)]. [[66](https://arxiv.org/html/2404.09554v1#bib.bib66)] create information flow graphs showing (human-readable) tokens based on processed vectors within attention heads and memory values. That is, these vectors are mapped to tokens.\nReport issue for preceding element\n####  4.2.5 Structuring based on novel dimensions\nReport issue for preceding element\nWe also classify existing techniques based on uncovered characteristics, shown in Table [5](https://arxiv.org/html/2404.09554v1#S3.T5 \"Table 5 â£ 3.3 Desiderata of Explanations for GenAI â£ 3 The importance, challenges and desiderata of GenXAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\"). Concerning scope, no existing technique explicitly focuses on the entire interaction. However, LLMs providing self-explanations could be used for that purpose. When it comes to explaining one, multiple or all properties of the output, a feature attribution map explains typically at most one attribute of the output, e.g., by highlighting positive and negative words or phrases sentiment might be explained. Sample-based techniques can potentially explain multiple attributes, e.g., if the chosen samples share different characteristics, e.g., for classification if the most similar images show the same object but within a different pose and of different color, it can be concluded that the latter two attributes are irrelevant. Mechanistic interpretability and probing often aim at isolating a single concept, but this is not a must.\nReport issue for preceding element\nExisting XAI techniques are typically non-dynamics. Explanations from LLMs can be interactive, personalized and are often also sample-dependent.\nReport issue for preceding element\nFigure [6](https://arxiv.org/html/2404.09554v1#S4.T6 \"Table 6 â£ 4.2.5 Structuring based on novel dimensions â£ 4.2 Classification of Techniques â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\") shows a concept matrix linking the foundational source to XAI methods. Feature attribution techniques are typically posthoc methods that leverage the model to generate explanations. However, LLMs could also be prompted to generate feature attribution techniques. Sample-based techniques commonly rely on the training data and the model, for example, to determine which samples most strongly activate a particular neuron. While mechanistic approaches commonly rely on a dataset, it does not have to be data from the training. Probing can be performed naturally through prompts and other forms of providing inputs (and analyzing corresponding outputs).\nReport issue for preceding element\n| Existing Categories | Selected GenAI Techniques  \n---|---|---  \n| Feat. Att. | Sample | Mechan. | Prob. | CoT | RAG  \nTraining data |  | x | (x) |  | (x) | (x)  \nModel | x | x | x | x |  |   \nOptimization |  |  |  | x |  |   \nPrompts | (x) |  |  | x | x | x  \nTable 6: Mapping of XAI categories and selected techniques to foundational sources for XAI Report issue for preceding element\nMost existing techniques require white-box access [7](https://arxiv.org/html/2404.09554v1#S4.T7 \"Table 7 â£ 4.2.5 Structuring based on novel dimensions â£ 4.2 Classification of Techniques â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\"). It might be possible to gain limited insights using black-box access only, for example, using occlusion (or masking) for feature attribution techniques. It might be investigated if predictions change, but such an approach typically yields coarser and less accurate explanations compared to having access to the output probabilities.\nReport issue for preceding element\n| Existing Categories | Selected GenAI Techniques  \n---|---|---  \n| Feat. Att. | Sample | Mechan. | Prob. | Self-explain |   \nRequired Access |  |   \nBlack-Box | (x) |  |  |  | x |   \nWhite-Box | x | x | x | x |  |   \nTable 7: Mapping of XAI categories and selected techniques to required access by XAI techniques Report issue for preceding element\n##  5 Research Agenda of XAI for GenAI, Discussion and Conclusions\nReport issue for preceding element\nAs the field of XAI for GenAI is quickly emerging, there are many opportunities for research covering more technical algorithmic avenues onto economic and psychological aspects. Bridging the gap between AI research and other disciplines, such as cognitive science, psychology, and humanities, is likely the way forward for many topics.\nReport issue for preceding element\n  1. 1.\nExplaining interactions rather than single input-outputs is particularly interesting for interdisciplinary research such as conducted in the field of information systems and human-computer interaction as it requires both understanding of humans, the model, and the system (See âInteraction Scopeâ in Section [4.1.1](https://arxiv.org/html/2404.09554v1#S4.SS1.SSS1 \"4.1.1 Output, Interaction and Input Scope â£ 4.1 Dimensions of taxonomy â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")).\nReport issue for preceding element\n  2. 2.\nReal-time and interactive explanation based on user queries and feedback could be further explored, necessitating also insights from multiple disciplines (Section [4.1.3](https://arxiv.org/html/2404.09554v1#S4.SS1.SSS3 \"4.1.3 Dynamics â£ 4.1 Dimensions of taxonomy â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")).\nReport issue for preceding element\n  3. 3.\nMultimodal GenXAI: Today, most explanations are of a single modality, i.e., commonly either text or visual. There is a lack of techniques providing explanations using more than one modality (Section [4.1.2](https://arxiv.org/html/2404.09554v1#S4.SS1.SSS2 \"4.1.2 Explanation Modality â£ 4.1 Dimensions of taxonomy â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")).\nReport issue for preceding element\n  4. 4.\nAdding XAI to novel directions of GenAI, for instance, GenXAI for video, 3D content generation, and actions (see Table [1](https://arxiv.org/html/2404.09554v1#S1.T1 \"Table 1 â£ 1 Introduction â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")) is urgently needed.\nReport issue for preceding element\n  5. 5.\nDeriving novel XAI techniques. In particular, the field of mechanistic interpretability (Section [4.2.4](https://arxiv.org/html/2404.09554v1#S4.SS2.SSS4 \"4.2.4 Mechanistic interpretability â£ 4.2 Classification of Techniques â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")) investigating the inner workings of GenAI models is a promising yet challenging frontier.\nReport issue for preceding element\n  6. 6.\nAddressing verifiability and hallucinations using AI. Hallucinations are arguably one of the biggest challenges of GenAI. GenXAI can support to mitigate them as seen through techniques such as Chain-of-thought, explaining the reasoning process, but more techniques are needed.\nReport issue for preceding element\n  7. 7.\nPorting of pre-GenAI XAI techniques by addressing computational concerns of classical techniques to apply them to large models, as was done for techniques like SHAP (see Section [4.2.1](https://arxiv.org/html/2404.09554v1#S4.SS2.SSS1 \"4.2.1 Feature Attribution â£ 4.2 Classification of Techniques â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")).\nReport issue for preceding element\n  8. 8.\nPersonalization of explanations: Recognizing the diversity in usersâ backgrounds, expertise, and needs, future research should focus on personalizing explanations as an important desideratum (see Section [3.3](https://arxiv.org/html/2404.09554v1#S3.SS3 \"3.3 Desiderata of Explanations for GenAI â£ 3 The importance, challenges and desiderata of GenXAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")).\nReport issue for preceding element\n  9. 9.\nExplanation difficulty has received little attention. A more thorough understanding in the context of GenAI, quantifying the phenomenon and potentially even leading to techniques accounting for such difficulty, is another future avenue (see Section [4.1.7](https://arxiv.org/html/2404.09554v1#S4.SS1.SSS7 \"4.1.7 Explanation Sample Difficulty â£ 4.1 Dimensions of taxonomy â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")).\nReport issue for preceding element\n  10. 10.\nDealing with the complex nature of outputs of GenAI (compared to simple classification in the context of pre-GenAI) remains under-explored. While interactive, user-driven investigation is one avenue in this regard (Section [4.1.3](https://arxiv.org/html/2404.09554v1#S4.SS1.SSS3 \"4.1.3 Dynamics â£ 4.1 Dimensions of taxonomy â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")) as well as isolating particular facets using mechanistic interpretability techniques focusing on circuits (Section [4.2.4](https://arxiv.org/html/2404.09554v1#S4.SS2.SSS4 \"4.2.4 Mechanistic interpretability â£ 4.2 Classification of Techniques â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")), in general, little is known as of today. For example, it is not clear what facets should be explained for text or images (see âOutput Scopeâ in Section [4.1.1](https://arxiv.org/html/2404.09554v1#S4.SS1.SSS1 \"4.1.1 Output, Interaction and Input Scope â£ 4.1 Dimensions of taxonomy â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")) and how to relate actual explanations to high-level objectives such as maximizing plausbability, e.g., âWhat attributes should be explained so that an explanation appears plausible?â (Section [4.1.3](https://arxiv.org/html/2404.09554v1#S4.SS1.SSS3 \"4.1.3 Dynamics â£ 4.1 Dimensions of taxonomy â£ 4 Taxonomy of XAI techniques for GenAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")).\nReport issue for preceding element\n  11. 11.\nBuilding GenXAI to target ethical, societal, and regulatory concerns, including contributing to the mitigation of biases and enhancing fairness by identifying and quantifying them through XAI techniques (see second last paragraph in this section).\nReport issue for preceding element\n  12. 12.\nGenXAI itself raises a number of critical issues with respect to ethical concerns. For example, in legal cases an explanation why someone performed an action can decide over life and death. As such explanation themselves need to carefully assessed with respect to alignment criteria(Section [3.1](https://arxiv.org/html/2404.09554v1#S3.SS1 \"3.1 Importance of XAI for GenAI â£ 3 The importance, challenges and desiderata of GenXAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\")).\nReport issue for preceding element\n\n\nAs with any other work, this paper employs a particular perspective on the matter of study, foregoing some aspects, and emphasizing others. More concretely, we did not aim to be comprehensive in all regards. Due to the vast array of works on GenAI and XAI, we decided to forego detailed aspects of XAI related to evaluation and usage of explanations. Furthermore, we did not reiterate all existing XAI techniques before GenAI; rather, we focused on novel aspects and methods for GenAI and referred to other surveys for this purpose. Concerning modalities, our core focus was on images and text, driven by the fact that these are (as of now) the two most prevalent modalities. However, others, like video and 3D content generation, are quickly emerging, and audio-to-text (and vice versa) has already been established for some time. We conceptualized existing techniques and discussed some technical aspects, but a more mathematical treatment could be undertaken. As AI quickly evolves, our work can only be seen as a snapshot in time. Our conceptualization is subject to further evolution, though we believe the uncovered dimensions will pass the test of time, albeit with some enhancements and modifications. Furthermore, GenAI (in combination with XAI) touches on many ethical and societal implications, which we partially touched upon in Sections [3.2](https://arxiv.org/html/2404.09554v1#S3.SS2 \"3.2 Why is XAI more challenging for GenAI? â£ 3 The importance, challenges and desiderata of GenXAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\") and [3.1](https://arxiv.org/html/2404.09554v1#S3.SS1 \"3.1 Importance of XAI for GenAI â£ 3 The importance, challenges and desiderata of GenXAI â£ Explainable Generative AI \\(GenXAI\\): A Survey, Conceptualization, and Research Agenda\"). However, we refrained from a detailed discussion. We opted to provide a more neutral stance pointing towards concerns rather than being prescriptive and elaborating on actions to be taken to address ethical issues. For example, the lack of access to (commercial) models hinders transparency on the one hand but protects company know-how on the other hand. As such, one might advocate for demanding regulation to increase transparency or double down on allowing companies to be secretive about details regarding their models to protect their intellectual property. From an organizational perspective, more transparency might also support user trust. Thus, the preferred governance of GenAI concerning transparency by companies or from a societal level is debatable [[145](https://arxiv.org/html/2404.09554v1#bib.bib145)]. We do not take any particular stance in such debates. \nReport issue for preceding element\nTo conclude, GenXAI is an important area for AI in general. Given the rapid advancement of GenAI and its widespread implications on individuals, society, and economics, more work should be dedicated to this area â especially given the many research gaps highlighted in our research roadmap elaborating on aspects such as interactivity and scope of explanations. Our work contributes in this direction by providing a thorough motivation for the study of XAI for GenAI, structuring existing knowledge through an enhanced conceptualization of XAI, uncovering novel dimensions, and setting forth a research agenda calling for a joint effort of the research community to address open issues that hopefully contribute to the well-being of all of us. \nReport issue for preceding element\n##  6 Acknowledgments\nReport issue for preceding element\nTwo very humble and reputable researchers also contributed to this manuscript but still felt that their contribution did not deserve co-authorship or even be mentioned explicitly in the acknowledgments, which is remarkable in the competitive field of research. Both of whom I want to thank cordially.\nReport issue for preceding element\n##  7 Appendix\nReport issue for preceding element\n###  7.1 Research Methodology\nReport issue for preceding element\nOur approach combines aspects of a systematic and a narrative review. However, as explained, XAI for GenAI is rather novel, with a relatively limited number of technical works available. A more qualitative approach was our main focus, for example, a narrative literature review [[69](https://arxiv.org/html/2404.09554v1#bib.bib69)]. While we describe our search process below, our goal was not to quantitatively assess peer-reviewed works by showing the evolution and counts of publications over the last years. Currently, works on XAI for GenAI lack a comprehensive conceptualization of important aspects that inform technical works, such as challenges and desiderata for explanations for GenAI. Therefore, the importance and challenges we identified are a synthesis of existing works and a creative combination taking essential properties of GenAI and prior XAI desiderata into account. Our taxonomy is based on (i) a meta-survey of (pre-)GenAI taxonomies and surveys, as many concepts and characteristics are still relevant for GenAI, as well as (ii) novel works contributing towards XAI for GenAI. We searched for several terms on Google Scholar between the 15th of February 2024 and the 15th of March 2024 using either âsurveyâ or âreviewâ in âSurvey explainabilityâ, âSurvey XAI for generative AIâ, âSurvey explainability for large language modelsâ, âexplainability large language modelsâ, âexplainability transformerâ, âexplainability diffusion modelâ. This was followed by forward and backward search [[183](https://arxiv.org/html/2404.09554v1#bib.bib183)]. We filtered results based on title, abstract, and full-text as follows: We preferred peer-reviewed works but also commonly included articles from arxiv.org after performing our quality assessment as reviewers. We were stricter in inclusion with older works (on pre-GenAI) and more open to works on XAI for GenAI containing novel aspects as there are fewer works, and we deem it important to include ideas that are still in the making. Our taxonomy development process followed that of [[110](https://arxiv.org/html/2404.09554v1#bib.bib110)] that is we alternated between looking at concepts (mostly synthesized in earlier surveys) and empirical data (primary research papers on XAI for GenAI) to derive our dimensions iteratively and, ultimately, our taxonomy.\nReport issue for preceding element\n## References\nReport issue for preceding element\n  * \\bibcommenthead\n  * Achiam et al [2023]â Achiam J, Adler S, Agarwal S, et al (2023) Gpt-4 technical report. arXiv preprint arXiv:230308774 \n  * Adadi and Berrada [2018]â Adadi A, Berrada M (2018) Peeking inside the black-box: a survey on explainable artificial intelligence (xai). IEEE Access \n  * Adebayo et al [2018]â Adebayo J, Gilmer J, Muelly M, et al (2018) Sanity checks for saliency maps. Advances in Neural Information Processing Systems \n  * Ali et al [2022]â Ali A, Schnake T, Eberle O, et al (2022) XAI for transformers: Better explanations through conservative propagation. In: International Conference on Machine Learning \n  * Amershi et al [2019]â Amershi S, Weld D, Vorvoreanu M, et al (2019) Guidelines for human-ai interaction. In: Proceedings of the CHI conference on human factors in computing systems \n  * Askell et al [2021]â Askell A, Bai Y, Chen A, et al (2021) A general language assistant as a laboratory for alignment. arXiv preprint arXiv:211200861 \n  * Augustin et al [2022]â Augustin M, Boreiko V, Croce F, et al (2022) Diffusion visual counterfactual explanations. Advances in Neural Information Processing Systems \n  * Baidoo-Anu and Ansah [2023]â Baidoo-Anu D, Ansah LO (2023) Education in the era of generative artificial intelligence (AI): Understanding the potential benefits of ChatGPT in promoting teaching and learning. Journal of AI \n  * Barkan et al [2021]â Barkan O, Hauon E, Caciularu A, et al (2021) Grad-sam: Explaining transformers via gradient self-attention maps. In: Proceedings of the ACM International Conference on Information & Knowledge Management \n  * Beaudouin et al [2020]â Beaudouin V, Bloch I, Bounie D, et al (2020) Flexible and context-specific AI explainability: a multidisciplinary approach. arXiv preprint arXiv:200307703 \n  * Betker et al [2023]â Betker J, Goh G, Jing L, et al (2023) Improving image generation with better captions. Computer Science URL <https://cdn.openai.com/papers/dall-e-3.pdf>\n  * Bodria et al [2023]â Bodria F, Giannotti F, Guidotti R, et al (2023) Benchmarking and survey of explanation methods for black box models. Data Mining Knowledge Discovery \n  * Brooks et al [2024]â Brooks T, Peebles B, Holmes C, et al (2024) Video generation models as world simulators. URL <https://openai.com/research/video-generation-models-as-world-simulators>, accessed on 2024-03-15 \n  * Cao et al [2023]â Cao Y, Li S, Liu Y, et al (2023) A comprehensive survey of ai-generated content (aigc): A history of generative ai from gan to chatgpt. arXiv preprint arXiv:230304226 \n  * Carroll and Olson [1988]â Carroll JM, Olson JR (1988) Mental models in human-computer interaction. Handbook of human-computer interaction \n  * Chen et al [2021]â Chen B, Fu Y, Xu G, et al (2021) Probing BERT in hyperbolic spaces. arXiv preprint arXiv:210403869 \n  * Chen et al [2023a]â Chen L, Sun L, Han J (2023a) A comparison study of human and machine generated creativity. Journal of Computing and Information Science in Engineering \n  * Chen et al [2020]â Chen S, Hou Y, Cui Y, et al (2020) Recall and learn: Fine-tuning deep pretrained language models with less forgetting. In: Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP) \n  * Chen et al [2016]â Chen X, Duan Y, Houthooft R, et al (2016) Infogan: Interpretable representation learning by information maximizing generative adversarial nets. Advances in neural information processing systems \n  * Chen et al [2023b]â Chen X, Lin M, SchÃ¤rli N, et al (2023b) Teaching large language models to self-debug. arXiv preprint arXiv:230405128 \n  * Chen et al [2023c]â Chen Z, Singh AK, Sra M (2023c) LMExplainer: a Knowledge-Enhanced Explainer for Language Models. arXiv preprint arXiv:230316537 \n  * Choi et al [2021]â Choi JH, Hickman KE, Monahan AB, et al (2021) Chatgpt goes to law school. Journal of Legal Educaction \n  * Chuang et al [2024]â Chuang YN, Wang G, Chang CY, et al (2024) Large Language Models As Faithful Explainers. arXiv preprint arXiv:240204678 \n  * Common Crawl Foundation [2024]â Common Crawl Foundation (2024) Common Crawl. <https://commoncrawl.org/>, accessed: 2024-02-20 \n  * Conmy et al [2024]â Conmy A, Mavor-Parker A, Lynch A, et al (2024) Towards automated circuit discovery for mechanistic interpretability. Advances in Neural Information Processing Systems \n  * Creswell and Shanahan [2022]â Creswell A, Shanahan M (2022) Faithful reasoning using large language models. arXiv preprint arXiv:220814271 \n  * Dai et al [2022]â Dai D, Dong L, Hao Y, et al (2022) Knowledge neurons in pretrained transformers. In: Proceedings of the Annual Meeting of the Association for Computational Linguistics \n  * Deldjoo [2023]â Deldjoo Y (2023) Fairness of chatgpt and the role of explainable-guided prompts. arXiv preprint arXiv:230711761 \n  * Devlin et al [2019]â Devlin J, Chang MW, Lee K, et al (2019) Bert: Pre-training of deep bidirectional transformers for language understanding. In: Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics \n  * Dufter et al [2022]â Dufter P, Schmitt M, SchÃ¼tze H (2022) Position information in transformers: An overview. Computational Linguistics \n  * Dwivedi et al [2023]â Dwivedi R, Dave D, Naik H, et al (2023) Explainable AI (XAI): Core ideas, techniques, and solutions. ACM Computing Surveys \n  * Elhage et al [2022]â Elhage N, Hume T, Olsson C, et al (2022) Softmax linear units. Transformer Circuits Thread, URL [{https://transformer-circuits.pub/2022/solu/index.html}](https://arxiv.org/html/%7Bhttps:/transformer-circuits.pub/2022/solu/index.html%7D)\n  * Elyoseph et al [2023]â Elyoseph Z, Hadar-Shoval D, Asraf K, et al (2023) Chatgpt outperforms humans in emotional awareness evaluations. Frontiers in Psychology \n  * Enguehard [2023]â Enguehard J (2023) Sequential Integrated Gradients: a simple but effective method for explaining language models. arXiv preprint arXiv:230515853 \n  * Ethayarajh and Jurafsky [2021]â Ethayarajh K, Jurafsky D (2021) Attention flows are shapley value explanations. arXiv preprint arXiv:210514652 \n  * European Union [2023]â European Union (2023) Eu ai act. <https://artificialintelligenceact.eu/>, accessed: 2024-15-02 \n  * Faubel et al [2023]â Faubel L, Woudsma T, Methnani L, et al (2023) Towards an MLOps Architecture for XAI in Industrial Applications. arXiv preprint arXiv:230912756 \n  * Fok and Weld [2023]â Fok R, Weld DS (2023) In search of verifiability: Explanations rarely enable complementary performance in ai-advised decision making. arXiv preprint arXiv:230507722 \n  * Foote et al [2023]â Foote A, Nanda N, Kran E, et al (2023) Neuron to graph: Interpreting language model neurons at scale. arXiv preprint arXiv:230519911 \n  * Gao et al [2023]â Gao Y, Sheng T, Xiang Y, et al (2023) Chat-rec: Towards interactive and explainable llms-augmented recommender system. arXiv preprint arXiv:230314524 \n  * Gawlikowski et al [2023]â Gawlikowski J, Tassi CRN, Ali M, et al (2023) A survey of uncertainty in deep neural networks. Artificial Intelligence Review \n  * Geiger et al [2021]â Geiger A, Lu H, Icard T, et al (2021) Causal abstractions of neural networks. Advances in Neural Information Processing Systems \n  * Geva et al [2022]â Geva M, Caciularu A, Wang KR, et al (2022) Transformer feed-forward layers build predictions by promoting concepts in the vocabulary space. arXiv preprint arXiv:220314680 \n  * Ghorbani et al [2019]â Ghorbani A, Abid A, Zou J (2019) Interpretation of neural networks is fragile. In: Proceedings of the AAAI conference on artificial intelligence \n  * Goodfellow et al [2015]â Goodfellow IJ, Shlens J, Szegedy C (2015) Explaining and harnessing adversarial examples. In: International Conference on Learning Representations (ICLR) \n  * Goyal et al [2022]â Goyal T, Xu J, Li JJ, et al (2022) Training dynamics for text summarization models. In: Findings of the Association for Computational Linguistics \n  * Gozalo-Brizuela and Garrido-Merchan [2023]â Gozalo-Brizuela R, Garrido-Merchan EC (2023) ChatGPT is not all you need. A State of the Art Review of large Generative AI models. arXiv preprint arXiv:230104655 \n  * Grisold and Schneider [2023]â Grisold T, Schneider J (2023) Dynamics of human-ai delegation in organizational routines. In: Proceedings of the International Conference on Information Systems \n  * Grosse et al [2023]â Grosse R, Bae J, Anil C, et al (2023) Studying large language model generalization with influence functions. arXiv preprint arXiv:230803296 \n  * Grynbaum and Mac [2023]â Grynbaum MM, Mac R (2023) The times sues openai and microsoft over a.i. use of copyrighted work. <https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html>, accessed: 2024-02-15 \n  * Guidotti [2022]â Guidotti R (2022) Counterfactual explanations and how to find them: literature review and benchmarking. Data Mining and Knowledge Discovery \n  * Guidotti et al [2019]â Guidotti R, Monreale A, Ruggieri S, et al (2019) A survey of methods for explaining black box models. ACM Computer Surveys \n  * Gupta et al [2023]â Gupta M, Akiri C, Aryal K, et al (2023) From chatgpt to threatgpt: Impact of generative ai in cybersecurity and privacy. IEEE Access \n  * Gurrapu et al [2023]â Gurrapu S, Kulkarni A, Huang L, et al (2023) Rationalization for explainable nlp: A survey. Frontiers in Artificial Intelligence \n  * He et al [2022]â He H, Zhang H, Roth D (2022) Rethinking with retrieval: Faithful large language model inference. arXiv preprint arXiv:230100303 \n  * Hernandez et al [2023]â Hernandez E, Li BZ, Andreas J (2023) Inspecting and editing knowledge representations in language models. arXiv preprint arXiv:230400740 \n  * Ho et al [2020]â Ho J, Jain A, Abbeel P (2020) Denoising diffusion probabilistic models. Advances in neural information processing systems \n  * Huang et al [2023a]â Huang J, Chen X, Mishra S, et al (2023a) Large language models cannot self-correct reasoning yet. arXiv preprint arXiv:231001798 \n  * Huang et al [2023b]â Huang J, Gu SS, Hou L, et al (2023b) Large language models can self-improve. In: Proceedings of the Conference on Empirical Methods in Natural Language Processing \n  * Huang et al [2023c]â Huang Y, Song J, Wang Z, et al (2023c) Look before you leap: An exploratory study of uncertainty measurement for large language models. arXiv preprint arXiv:230710236 \n  * Jain and Wallace [2019]â Jain S, Wallace BC (2019) Attention is not Explanation. In: Proceedings of NAACL-HLT \n  * Jeanneret et al [2022]â Jeanneret G, Simon L, Jurie F (2022) Diffusion models for counterfactual explanations. In: Proceedings of the Asian Conference on Computer Vision \n  * Jin et al [2020]â Jin D, Jin Z, Zhou JT, et al (2020) Is bert really robust? a strong baseline for natural language attack on text classification and entailment. In: Proceedings of the AAAI conference on artificial intelligence \n  * Kadavath et al [2022]â Kadavath S, Conerly T, Askell A, et al (2022) Language models (mostly) know what they know. arXiv preprint arXiv:220705221 \n  * Katz et al [2024]â Katz DM, Bommarito MJ, Gao S, et al (2024) Gpt-4 passes the bar exam. Philosophical Transactions of the Royal Society A \n  * Katz and Belinkov [2023]â Katz S, Belinkov Y (2023) Interpreting Transformerâs Attention Dynamic Memory and Visualizing the Semantic Information Flow of GPT. arXiv preprint arXiv:230513417 \n  * KÄ±cÄ±man et al [2023]â KÄ±cÄ±man E, Ness R, Sharma A, et al (2023) Causal reasoning and large language models: Opening a new frontier for causality. arXiv preprint arXiv:230500050 \n  * Kim et al [2018]â Kim B, Wattenberg M, Gilmer J, et al (2018) Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav). In: International conference on machine learning \n  * King and He [2005]â King WR, He J (2005) Understanding the role and methods of meta-analysis in is research. Communications of the Association for Information Systems \n  * Kirillov et al [2023]â Kirillov A, Mintun E, Ravi N, et al (2023) Segment anything. arXiv preprint arXiv:230402643 \n  * Kokalj et al [2021]â Kokalj E, Å krlj B, LavraÄ N, et al (2021) BERT meets shapley: Extending SHAP explanations to transformer-based classifiers. In: Proceedings of the EACL Hackashop on News Media Content Analysis and Automated Report Generation \n  * Kwon et al [2022]â Kwon M, Jeong J, Uh Y (2022) Diffusion models already have a semantic latent space. arXiv preprint arXiv:221010960 \n  * Lewis et al [2020]â Lewis P, Perez E, Piktus A, et al (2020) Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems \n  * Li et al [2016]â Li J, Chen X, Hovy E, et al (2016) Visualizing and understanding neural models in NLP. In: Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics, San Diego, California, pp 681â691, [10.18653/v1/N16-1082](https://arxiv.org/doi.org/10.18653/v1/N16-1082), URL <https://aclanthology.org/N16-1082>\n  * Li et al [2023a]â Li L, Zhang Y, Chen L (2023a) Personalized prompt learning for explainable recommendation. ACM Transactions on Information Systems \n  * Li and Zhang [2023]â Li M, Zhang Q (2023) Does a neural network really encode symbolic concepts? In: International Conference on Machine Learning, PMLR, pp 20452â20469 \n  * Li et al [2023b]â Li P, Pei Y, Li J (2023b) A comprehensive survey on design and application of autoencoder in deep learning. Applied Soft Computing \n  * Liao and Vaughan [2023]â Liao QV, Vaughan JW (2023) AI Transparency in the Age of LLMs: A Human-Centered Research Roadmap. arXiv preprint arXiv:230601941 \n  * Lin et al [2023]â Lin CH, Gao J, Tang L, et al (2023) Magic3d: High-resolution text-to-3d content creation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition \n  * Lin et al [2022]â Lin T, Wang Y, Liu X, et al (2022) A survey of transformers. AI Open \n  * Ling et al [2023]â Ling C, Zhao X, Lu J, et al (2023) Domain specialization as the key to make large language models disruptive: A comprehensive survey. arXiv preprint arXiv:230518703 \n  * Liu et al [2021]â Liu LZ, Wang Y, Kasai J, et al (2021) Probing across time: What does RoBERTa know and when? In: Findings of the Association for Computational Linguistics: EMNLP 2021 \n  * Liu et al [2022]â Liu T, Guo Q, Hu X, et al (2022) RLET: A reinforcement learning based approach for explainable QA with entailment trees. arXiv preprint arXiv:221017095 \n  * Longo et al [2024]â Longo L, Brcic M, Cabitza F, et al (2024) Explainable artificial intelligence (xai) 2.0: A manifesto of open challenges and interdisciplinary research directions. Information Fusion \n  * Longpre et al [2023]â Longpre S, Hou L, Vu T, et al (2023) The flan collection: Designing data and methods for effective instruction tuning. In: International Conference on Machine Learning \n  * Lou et al [2023]â Lou R, Zhang K, Yin W (2023) Is prompt all you need? no. A comprehensive and broader view of instruction learning. arXiv preprint arXiv:230310475 \n  * Lundberg and Lee [2017]â Lundberg SM, Lee SI (2017) A unified approach to interpreting model predictions. Advances in neural information processing systems \n  * Lundstrom et al [2022]â Lundstrom DD, Huang T, Razaviyayn M (2022) A rigorous study of integrated gradients method and extensions to internal neuron attributions. In: International Conference on Machine Learning \n  * Luo and Specia [2024]â Luo H, Specia L (2024) From Understanding to Utilization: A Survey on Explainability for Large Language Models. arXiv preprint arXiv:240112874 \n  * Lyu et al [2024]â Lyu Q, Apidianaki M, Callison-Burch C (2024) Towards faithful model explanation in nlp: A survey. Computational Linguistics \n  * Ma et al [2023]â Ma Y, Liu Y, Yu Y, et al (2023) At which training stage does code data help llms reasoning? arXiv preprint arXiv:230916298 \n  * MacKenzie [2024]â MacKenzie IS (2024) Human-computer interaction: An empirical research perspective, 2nd edn. Morgan Kaufmann \n  * Mao et al [2023]â Mao J, Ye J, Qian Y, et al (2023) A language agent for autonomous driving. arXiv preprint arXiv:231110813 \n  * Marvin and Linzen [2018]â Marvin R, Linzen T (2018) Targeted syntactic evaluation of language models. arXiv preprint arXiv:180809031 \n  * Maynez et al [2020]â Maynez J, Narayan S, Bohnet B, et al (2020) On faithfulness and factuality in abstractive summarization. In: Proceedings of the Annual Meeting of the Association for Computational Linguistics \n  * McKinsey & Company [2023]â McKinsey & Company (2023) The economic potential of generative ai: The next productivity frontier. <https://www.mckinsey.com/featured-insights/mckinsey-live/webinars/the-economic-potential-of-generative-ai-the-next-productivity-frontier>, accessed: 2024-02-13 \n  * Meng et al [2022]â Meng K, Bau D, Andonian A, et al (2022) Locating and editing factual associations in GPT. Advances in Neural Information Processing Systems \n  * Menick et al [2022]â Menick J, Trebacz M, Mikulik V, et al (2022) Teaching language models to support answers with verified quotes. arXiv preprint arXiv:220311147 \n  * Meronen et al [2024]â Meronen L, Trapp M, Pilzer A, et al (2024) Fixing overconfidence in dynamic neural networks. In: Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision \n  * Meske et al [2022]â Meske C, Bunde E, Schneider J, et al (2022) Explainable artificial intelligence: objectives, stakeholders, and future research opportunities. Information Systems Management \n  * Miller [2019]â Miller T (2019) Explanation in artificial intelligence: Insights from the social sciences. Artificial Intelligence \n  * Minh et al [2022]â Minh D, Wang HX, Li YF, et al (2022) Explainable artificial intelligence: a comprehensive review. Artificial Intelligence Review \n  * Mishra et al [2023]â Mishra A, Soni U, Arunkumar A, et al (2023) PromptAid: Prompt Exploration, Perturbation, Testing and Iteration using Visual Analytics for Large Language Models. arXiv preprint arXiv:230401964 \n  * Modarressi et al [2023]â Modarressi A, Fayyaz M, Aghazadeh E, et al (2023) DecompX: Explaining Transformers Decisions by Propagating Token Decomposition. arXiv preprint arXiv:230602873 \n  * Mohebbi et al [2021]â Mohebbi H, Modarressi A, Pilehvar MT (2021) Exploring the role of BERT token representations to explain sentence probing results. arXiv preprint arXiv:210401477 \n  * Molnar [2020]â Molnar C (2020) Interpretable Machine Learning. URL <https://christophm.github.io/interpretable-ml-book/>\n  * Montavon et al [2019]â Montavon G, Binder A, Lapuschkin S, et al (2019) Layer-wise relevance propagation: an overview. Explainable AI: interpreting, explaining and visualizing deep learning \n  * Mueller et al [2021]â Mueller ST, Veinott ES, Hoffman RR, et al (2021) Principles of explanation in human-ai systems. arXiv preprint arXiv:210204972 \n  * Nichol et al [2022]â Nichol AQ, Dhariwal P, Ramesh A, et al (2022) Glide: Towards photorealistic image generation and editing with text-guided diffusion models. In: Proceedings of the International Conference on Machine Learning \n  * Nickerson et al [2013]â Nickerson RC, Varshney U, Muntermann J (2013) A method for taxonomy development and its application in information systems. European Journal of Information Systems \n  * Olah [2022]â Olah C (2022) Mechanistic interpretability, variables, and the importance of interpretable bases. URL <https://www.transformer-circuits.pub/2022/mech-interp-essay>, accessed: 2024-02-15 \n  * Olah et al [2020]â Olah C, Cammarata N, Schubert L, et al (2020) Zoom in: An introduction to circuits. Distill (3) \n  * Olsson et al [2022]â Olsson C, Elhage N, Nanda N, et al (2022) In-context learning and induction heads. arXiv preprint arXiv:220911895 \n  * OpenAI [2023a]â OpenAI (2023a) Introducing the gpt store. <https://openai.com/blog/introducing-the-gpt-store>, accessed: 2024-15-02 \n  * OpenAI [2023b]â OpenAI (2023b) Language models can explain neurons in language models. <https://openai.com/research/language-models-can-explain-neurons-in-language-models?s=09>, accessed: 2024-15-02 \n  * Ouyang et al [2022]â Ouyang L, Wu J, Jiang X, et al (2022) Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems \n  * Pan et al [2023]â Pan L, Saxon M, Xu W, et al (2023) Automatically correcting large language models: Surveying the landscape of diverse self-correction strategies. arXiv preprint arXiv:230803188 \n  * Park et al [2018]â Park DH, Hendricks LA, Akata Z, et al (2018) Multimodal explanations: Justifying decisions and pointing to the evidence. In: Proceedings of the IEEE conference on computer vision and pattern recognition \n  * Poli et al [2023]â Poli M, Massaroli S, Nguyen E, et al (2023) Hyena hierarchy: Towards larger convolutional language models. arXiv preprint arXiv:230210866 \n  * Porter [2023]â Porter J (2023) Chatgpt continues to be one of the fastest-growing services ever. <https://www.theverge.com/2023/11/6/23948386/chatgpt-active-user-count-openai-developer-conference>, accessed: 2024-02-19 \n  * Radford et al [2019]â Radford A, Wu J, Child R, et al (2019) Language models are unsupervised multitask learners. OpenAI blog \n  * Rago et al [2021]â Rago A, Cocarascu O, Bechlivanidis C, et al (2021) Argumentative explanations for interactive recommendations. Artificial Intelligence \n  * Ram et al [2022]â Ram O, Bezalel L, Zicher A, et al (2022) What are you token about? dense retrieval as distributions over the vocabulary. arXiv preprint arXiv:221210380 \n  * Ramesh et al [2022]â Ramesh A, Dhariwal P, Nichol A, et al (2022) Hierarchical text-conditional image generation with clip latents. arXiv preprint arXiv:220406125 \n  * RÃ¤uker et al [2023]â RÃ¤uker T, Ho A, Casper S, et al (2023) Toward transparent ai: A survey on interpreting the inner structures of deep neural networks. In: IEEE Conference on Secure and Trustworthy Machine Learning (SaTML) \n  * Reed et al [2022]â Reed S, Zolna K, Parisotto E, et al (2022) A generalist agent. arXiv preprint arXiv:220506175 \n  * Reid et al [2024]â Reid M, Savinov N, Teplyashin D, et al (2024) Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context. arXiv preprint arXiv:240305530 \n  * Ribeiro et al [2016]â Ribeiro MT, Singh S, Guestrin C (2016) âWhy should i trust you?â Explaining the predictions of any classifier. In: Proceedings of the ACM SIGKDD international conference on knowledge discovery and data mining \n  * Ross et al [2017]â Ross AS, Hughes MC, Doshi-Velez F (2017) Right for the right reasons: Training differentiable models by constraining their explanations. arXiv preprint arXiv:170303717 \n  * Sabour et al [2017]â Sabour S, Frosst N, Hinton GE (2017) Dynamic routing between capsules. Advances in neural information processing systems 30 \n  * Saeed and Omlin [2023]â Saeed W, Omlin C (2023) Explainable ai (xai): A systematic meta-survey of current challenges and future opportunities. Knowledge-Based Systems \n  * Saha et al [2022]â Saha S, Hase P, Rajani N, et al (2022) Are Hard Examples also Harder to Explain? A Study with Human and Model-Generated Explanations. In: Proceedings of the Conference on Empirical Methods in Natural Language Processing \n  * Saharia et al [2022]â Saharia C, Chan W, Saxena S, et al (2022) Photorealistic text-to-image diffusion models with deep language understanding. Advances in Neural Information Processing Systems \n  * de Santana Correia and Colombini [2022]â de Santana Correia A, Colombini EL (2022) Attention, please! a survey of neural attention models in deep learning. Artificial Intelligence Review \n  * Schick et al [2024]â Schick T, Dwivedi-Yu J, DessÃ¬ R, et al (2024) Toolformer: Language models can teach themselves to use tools. Advances in Neural Information Processing Systems \n  * Schneider [2022]â Schneider J (2022) Optimizing human hand gestures for ai-systems. AI Communications \n  * Schneider and Apruzzese [2023]â Schneider J, Apruzzese G (2023) Dual adversarial attacks: Fooling humans and classifiers. Journal of Information Security and Applications \n  * Schneider and Breitinger [2023]â Schneider J, Breitinger F (2023) Towards ai forensics: Did the artificial intelligence system do it? Journal of Information Security and Applications \n  * Schneider and Handali [2019]â Schneider J, Handali J (2019) Personalized explanation in machine learning: A conceptualization. In: Proceedings of the European Conference on Information Systems (ECIS) \n  * Schneider and Vlachos [2023a]â Schneider J, Vlachos M (2023a) Explaining classifiers by constructing familiar concepts. Machine Learning \n  * Schneider and Vlachos [2023b]â Schneider J, Vlachos M (2023b) Reflective-net: Learning from explanations. Data Mining and Knowledge Discovery \n  * Schneider et al [2023a]â Schneider J, Abraham R, Meske C, et al (2023a) Artificial intelligence governance for businesses. Information Systems Management 40(3) \n  * Schneider et al [2023b]â Schneider J, Haag S, Kruse LC (2023b) Negotiating with llms: Prompt hacks, skill gaps, and reasoning deficits. arXiv preprint arXiv:231203720 \n  * Schneider et al [2023c]â Schneider J, Meske C, Vlachos M (2023c) Deceptive xai: Typology, creation and detection. SN Computer Science \n  * Schneider et al [2024a]â Schneider J, Abraham R, Meske C (2024a) Governance of generative artificial intelligence for companies. arXiv preprint arXiv:240308802 \n  * Schneider et al [2024b]â Schneider J, Meske C, Kuss P (2024b) Foundation models: A new paradigm for artificial intelligence. Business & Information Systems Engineering \n  * Schramowski et al [2020]â Schramowski P, Stammer W, Teso S, et al (2020) Making deep neural networks right for the right scientific reasons by interacting with their explanations. Nature Machine Intelligence \n  * Schwalbe and Finzel [2023]â Schwalbe G, Finzel B (2023) A comprehensive taxonomy for explainable artificial intelligence: a systematic survey of surveys on methods and concepts. Data Mining and Knowledge Discovery \n  * Selva et al [2023]â Selva J, Johansen AS, Escalera S, et al (2023) Video transformers: A survey. IEEE Transactions on Pattern Analysis and Machine Intelligence \n  * Selvaraju et al [2017]â Selvaraju RR, Cogswell M, Das A, et al (2017) Grad-cam: Visual explanations from deep networks via gradient-based localization. In: Proceedings of the IEEE International Conference on Computer Vision \n  * Serrano and Smith [2019]â Serrano S, Smith NA (2019) Is Attention Interpretable? In: Proceedings of the Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics \n  * Shahsavar and Choudhury [2023]â Shahsavar Y, Choudhury A (2023) User intentions to use chatgpt for self-diagnosis and health-related purposes: Cross-sectional survey study. JMIR Human Factors \n  * Shen et al [2023]â Shen T, Jin R, Huang Y, et al (2023) Large language model alignment: A survey. arXiv preprint arXiv:230915025 \n  * Sikdar et al [2021]â Sikdar S, Bhattacharya P, Heese K (2021) Integrated directional gradients: Feature interaction attribution for neural NLP models. In: Proceedings of the Annual Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language Processing \n  * Silva et al [2023]â Silva A, Schrum M, Hedlund-Botti E, et al (2023) Explainable artificial intelligence: Evaluating the objective and subjective impacts of xai on human-agent interaction. International Journal of HumanâComputer Interaction \n  * Singh et al [2022]â Singh C, Morris JX, Aneja J, et al (2022) Explaining patterns in data with language models via interpretable autoprompting. arXiv preprint arXiv:221001848 \n  * Singh et al [2023]â Singh C, Hsu AR, Antonello R, et al (2023) Explaining black box text modules in natural language with language models. arXiv preprint arXiv:230509863 \n  * Singh et al [2024]â Singh C, Inala JP, Galley M, et al (2024) Rethinking Interpretability in the Era of Large Language Models. arXiv preprint arXiv:240201761 \n  * Singhal et al [2023]â Singhal K, Azizi S, Tu T, et al (2023) Large language models encode clinical knowledge. Nature \n  * Slack et al [2023]â Slack D, Krishna S, Lakkaraju H, et al (2023) Explaining machine learning models with interactive natural language conversations using TalkToModel. Nature Machine Intelligence \n  * Sobania et al [2023]â Sobania D, Briesch M, Hanna C, et al (2023) An analysis of the automatic bug fixing performance of chatgpt. arXiv preprint arXiv:230108653 \n  * Sottana et al [2023]â Sottana A, Liang B, Zou K, et al (2023) Evaluation metrics in the era of gpt-4: Reliably evaluating large language models on sequence to sequence tasks. In: Proceedings of the Conference on Empirical Methods in Natural Language Processing \n  * Speith [2022]â Speith T (2022) A review of taxonomies of explainable artificial intelligence (XAI) methods. In: Proceedings of the ACM Conference on Fairness, Accountability, and Transparency \n  * Sreedharan et al [2022]â Sreedharan S, Kulkarni A, Kambhampati S (2022) Explainable Human-AI Interaction: A Planning Perspective. Springer Nature \n  * Stremmel et al [2022]â Stremmel J, Hill BL, Hertzberg J, et al (2022) Extend and explain: Interpreting very long language models. In: Machine Learning for Health \n  * Sun et al [2024]â Sun A, Ma P, Yuan Y, et al (2024) Explain any concept: Segment anything meets concept-based explanation. Advances in Neural Information Processing Systems \n  * Taori et al [2023]â Taori R, Gulrajani I, Zhang T, et al (2023) Stanford alpaca: An instruction-following llama model. <https://github.com/tatsu-lab/stanford_alpaca>\n  * Teehan et al [2022]â Teehan R, Clinciu M, Serikov O, et al (2022) Emergent structures and training dynamics in large language models. In: Proceedings of BigScience Episode# 5âWorkshop on Challenges & Perspectives in Creating Large Language Models \n  * Tenney et al [2019]â Tenney I, Xia P, Chen B, et al (2019) What do you learn from context? probing for sentence structure in contextualized word representations. arXiv preprint arXiv:190506316 \n  * The Guardian [2023]â The Guardian (2023) Elon musk calls ai one of the biggest threats to humanity at summit. <https://www.theguardian.com/technology/2023/nov/01/elon-musk-calls-ai-one-of-the-biggest-threats-to-humanity-at-summit>, accessed: 2024-02-26 \n  * Theis et al [2023]â Theis S, Jentzsch S, Deligiannaki F, et al (2023) Requirements for explainability and acceptance of artificial intelligence in collaborative work. In: International Conference on Human-Computer Interaction \n  * Theissler et al [2022]â Theissler A, Spinnato F, Schlegel U, et al (2022) Explainable AI for time series classification: A review, taxonomy and research directions. IEEE Access \n  * Thirunavukarasu et al [2023]â Thirunavukarasu AJ, Ting DSJ, Elangovan K, et al (2023) Large language models in medicine. Nature Medicine \n  * Touvron et al [2023]â Touvron H, Martin L, Stone K, et al (2023) Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:230709288 \n  * Turpin et al [2024]â Turpin M, Michael J, Perez E, et al (2024) Language models donât always say what they think: unfaithful explanations in chain-of-thought prompting. Advances in Neural Information Processing Systems \n  * Vaswani et al [2017]â Vaswani A, Shazeer N, Parmar N, et al (2017) Attention is all you need. In: Advances in neural information processing systems \n  * Vedula et al [2023]â Vedula N, Collins M, Agichtein E, et al (2023) Generating explainable product comparisons for online shopping. In: Proceedings of the ACM International Conference on Web Search and Data Mining \n  * Vig [2019]â Vig J (2019) A Multiscale Visualization of Attention in the Transformer Model. In: Proceedings of the Annual Meeting of the Association for Computational Linguistics: System Demonstrations \n  * Wang et al [2022a]â Wang B, Xu C, Liu X, et al (2022a) Semattack: natural textual attacks via different semantic spaces. arXiv preprint arXiv:220501287 \n  * Wang and Shu [2023]â Wang H, Shu K (2023) Explainable claim verification via knowledge-grounded reasoning with large language models. arXiv preprint arXiv:231005253 \n  * Wang et al [2022b]â Wang K, Variengien A, Conmy A, et al (2022b) Interpretability in the wild: a circuit for indirect object identification in gpt-2 small. arXiv preprint arXiv:221100593 \n  * Wang et al [2023]â Wang Z, Cai S, Chen G, et al (2023) Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents. arXiv preprint arXiv:230201560 \n  * Webster and Watson [2002]â Webster J, Watson RT (2002) Analyzing the past to prepare for the future: Writing a literature review. MIS quarterly \n  * Wei et al [2022]â Wei J, Wang X, Schuurmans D, et al (2022) Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems \n  * Weidinger et al [2022]â Weidinger L, Uesato J, Rauh M, et al (2022) Taxonomy of risks posed by language models. In: Proceedings of the ACM Conference on Fairness, Accountability, and Transparency \n  * White et al [2023]â White J, Fu Q, Hays S, et al (2023) A prompt pattern catalog to enhance prompt engineering with chatgpt. arXiv preprint arXiv:230211382 \n  * Wu et al [2021]â Wu T, Ribeiro MT, Heer J, et al (2021) Polyjuice: Generating counterfactuals for explaining, evaluating, and improving models. arXiv preprint arXiv:210100288 \n  * Wu et al [2020]â Wu Z, Chen Y, Kao B, et al (2020) Perturbed masking: Parameter-free probing for analyzing and interpreting bert. arXiv preprint arXiv:200414786 \n  * Wu et al [2023]â Wu Z, Qiu L, Ross A, et al (2023) Reasoning or reciting? exploring the capabilities and limitations of language models through counterfactual tasks. arXiv preprint arXiv:230702477 \n  * Xing et al [2023]â Xing Z, Feng Q, Chen H, et al (2023) A survey on video diffusion models. arXiv preprint arXiv:231010647 \n  * Xu et al [2023]â Xu P, Zhu X, Clifton DA (2023) Multimodal learning with transformers: A survey. IEEE Transactions on Pattern Analysis and Machine Intelligence \n  * Yang et al [2023a]â Yang K, Ji S, Zhang T, et al (2023a) Towards interpretable mental health analysis with large language models. In: Proceedings of the Conference on Empirical Methods in Natural Language Processing \n  * Yang et al [2023b]â Yang L, Zhang Z, Song Y, et al (2023b) Diffusion models: A comprehensive survey of methods and applications. ACM Computing Surveys \n  * Yang et al [2023c]â Yang S, Huang S, Zou W, et al (2023c) Local interpretation of transformer based on linear decomposition. In: Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics \n  * Ye and Durrett [2022]â Ye X, Durrett G (2022) The unreliability of explanations in few-shot prompting for textual reasoning. Advances in neural information processing systems \n  * Yin and Neubig [2022]â Yin K, Neubig G (2022) Interpreting language models with contrastive explanations. arXiv preprint arXiv:220210419 \n  * Yordanov et al [2021]â Yordanov Y, Kocijan V, Lukasiewicz T, et al (2021) Few-Shot Out-of-Domain Transfer Learning of Natural Language Explanations in a Label-Abundant Setup. arXiv preprint arXiv:211206204 \n  * Zaidan et al [2007]â Zaidan O, Eisner J, Piatko C (2007) Using âannotator rationalesâ to improve machine learning for text categorization. In: Human language technologies 2007: The conference of the North American chapter of the association for computational linguistics; proceedings of the main conference \n  * Zamfirescu-Pereira et al [2023]â Zamfirescu-Pereira J, Wong RY, Hartmann B, et al (2023) Why Johnny canât prompt: how non-AI experts try (and fail) to design LLM prompts. In: Proceedings of the CHI Conference on Human Factors in Computing Systems \n  * Zhang et al [2023a]â Zhang C, Zhang C, Zhang M, et al (2023a) Text-to-image diffusion model in generative ai: A survey. arXiv preprint arXiv:230307909 \n  * Zhang et al [2023b]â Zhang C, Zhang C, Zheng S, et al (2023b) A survey on audio diffusion models: Text to speech synthesis and enhancement in generative ai. arXiv preprint arXiv:230313336 \n  * Zhang et al [2024]â Zhang N, Yao Y, Tian B, et al (2024) A comprehensive study of knowledge editing for large language models. arXiv preprint arXiv:240101286 \n  * Zhang et al [2023c]â Zhang S, Dong L, Li X, et al (2023c) Instruction tuning for large language models: A survey. arXiv preprint arXiv:230810792 \n  * Zhao et al [2023a]â Zhao H, Chen H, Yang F, et al (2023a) Explainability for large language models: A survey. ACM Transactions on Intelligent Systems and Technology \n  * Zhao et al [2023b]â Zhao R, Joty S, Wang Y, et al (2023b) Explaining Language Modelsâ Predictions with High-Impact Concepts. arXiv preprint arXiv:230502160 \n  * Zhong et al [2021]â Zhong Z, Friedman D, Chen D (2021) Factual probing is [mask]: Learning vs. learning to recall. arXiv preprint arXiv:210405240 \n  * Zhou et al [2023]â Zhou Y, Zhang Y, Tan C (2023) FLamE: Few-shot Learning from Natural Language Explanations. arXiv preprint arXiv:230608042 \n  * Ziems et al [2023]â Ziems C, Held W, Shaikh O, et al (2023) Can Large Language Models Transform Computational Social Science? arXiv preprint arXiv:230503514 \n  * Zini and Awad [2022]â Zini JE, Awad M (2022) On the explainability of natural language processing deep models. ACM Computing Surveys \n\n\nReport Issue\n##### Report Github Issue\nTitle:Content selection saved. Describe the issue below:Description:\nSubmit without GithubSubmit in Github\nReport Issue for Selection\nGenerated by [ L A T E xml ![\\[LOGO\\]](https://arxiv.org/html/2404.09554v1) ](https://math.nist.gov/~BMiller/LaTeXML/)\n## Instructions for reporting errors\nWe are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:\n  * Click the \"Report Issue\" button.\n  * Open a report feedback form via keyboard, use \"**Ctrl + ?** \".\n  * Make a text selection and click the \"Report Issue for Selection\" button near your cursor.\n  * You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.\n\n\nOur team has already identified [the following issues](https://github.com/arXiv/html_feedback/issues). We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.\nHave a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a [list of packages that need conversion](https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML), and welcome [developer contributions](https://github.com/brucemiller/LaTeXML/issues).\n"
  },
  {
    "link": "https://arxiv.org/html/2502.17440v1",
    "raw_content": "[ ![logo](https://services.dev.arxiv.org/html/static/arxiv-logomark-small-white.svg) Back to arXiv ](https://arxiv.org/)\n[ ](https://arxiv.org/abs/2502.17440v1) [ ](javascript:toggleColorScheme\\(\\) \"Toggle dark/light mode\")\n[ ![logo](https://services.dev.arxiv.org/html/static/arxiv-logo-one-color-white.svg) Back to arXiv ](https://arxiv.org/)\nThis is **experimental HTML** to improve accessibility. We invite you to report rendering errors. Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off. Learn more [about this project](https://info.arxiv.org/about/accessible_HTML.html) and [help improve conversions](https://info.arxiv.org/help/submit_latex_best_practices.html). \n[Why HTML?](https://info.arxiv.org/about/accessible_HTML.html) [Report Issue](https://arxiv.org/html/2502.17440v1#myForm) [Back to Abstract](https://arxiv.org/abs/2502.17440v1) [Download PDF](https://arxiv.org/pdf/2502.17440v1) [ ](javascript:toggleColorScheme\\(\\) \"Toggle dark/light mode\")\n## Table of Contents\n  1. [ Abstract  ](https://arxiv.org/html/2502.17440v1#abstract \"Abstract\")\n  2. [1 Introduction](https://arxiv.org/html/2502.17440v1#S1 \"In GenAIOps for GenAI Model-Agility\")\n  3. [2 GenAIOps](https://arxiv.org/html/2502.17440v1#S2 \"In GenAIOps for GenAI Model-Agility\")\n    1. [2.1 New App Development](https://arxiv.org/html/2502.17440v1#S2.SS1 \"In 2 GenAIOps â£ GenAIOps for GenAI Model-Agility\")\n    2. [2.2 App Maintenance](https://arxiv.org/html/2502.17440v1#S2.SS2 \"In 2 GenAIOps â£ GenAIOps for GenAI Model-Agility\")\n    3. [2.3 Regression Test](https://arxiv.org/html/2502.17440v1#S2.SS3 \"In 2 GenAIOps â£ GenAIOps for GenAI Model-Agility\")\n    4. [2.4 Auto prompt-engineering](https://arxiv.org/html/2502.17440v1#S2.SS4 \"In 2 GenAIOps â£ GenAIOps for GenAI Model-Agility\")\n  4. [3 Evaluation Framework](https://arxiv.org/html/2502.17440v1#S3 \"In GenAIOps for GenAI Model-Agility\")\n  5. [4 Justification of Various Optimization Methods](https://arxiv.org/html/2502.17440v1#S4 \"In GenAIOps for GenAI Model-Agility\")\n    1. [4.1 Prompt Tuning](https://arxiv.org/html/2502.17440v1#S4.SS1 \"In 4 Justification of Various Optimization Methods â£ GenAIOps for GenAI Model-Agility\")\n    2. [4.2 Auto Prompt-Engineering](https://arxiv.org/html/2502.17440v1#S4.SS2 \"In 4 Justification of Various Optimization Methods â£ GenAIOps for GenAI Model-Agility\")\n    3. [4.3 Few-shot Learning](https://arxiv.org/html/2502.17440v1#S4.SS3 \"In 4 Justification of Various Optimization Methods â£ GenAIOps for GenAI Model-Agility\")\n    4. [4.4 Pitfalls](https://arxiv.org/html/2502.17440v1#S4.SS4 \"In 4 Justification of Various Optimization Methods â£ GenAIOps for GenAI Model-Agility\")\n  6. [5 Concluding Remarks](https://arxiv.org/html/2502.17440v1#S5 \"In GenAIOps for GenAI Model-Agility\")\n  7. [ References  ](https://arxiv.org/html/2502.17440v1#bib \"References\")\n\n\n[License: CC BY 4.0](https://info.arxiv.org/help/license/index.html#licenses-available)\narXiv:2502.17440v1 [cs.SE] 19 Dec 2024\n# GenAIOps for GenAI Model-Agility\nReport issue for preceding element\nKen Ueno, Makoto Kogo, Hiromi Kawatsu, Yohsuke Uchiumi, and Michiaki Tatsubori IBM Japan \nReport issue for preceding element\n###### Abstract\nReport issue for preceding element\nAI-agility, with which an organization can be quickly adapted to its business priorities, is desired even for the development and operations of generative AI (GenAI) applications. Especially in this paper, we discuss so-called GenAI Model-agility, which we define as the readiness to be flexibly adapted to base foundation models as diverse as the model providers and versions. First, for handling issues specific to generative AI, we first define a methodology of GenAI application development and operations, as GenAIOps, to identify the problem of application quality degradation caused by changes to the underlying foundation models. We study prompt tuning technologies, which look promising to address this problem, and discuss their effectiveness and limitations through case studies using existing tools.\nReport issue for preceding element\nKeywords: generative AI, MLOps, AI agility , Hybrid by Design, CI/CD\nReport issue for preceding element\n##  1 Introduction\nReport issue for preceding element\nCompanies want AI agility so they can gather the necessary resources to build AI capabilities in line with business priorities, and generative AI is no exception. In recent years, the use of generative AI has accelerated among individuals and companies, and the direction of development of foundational models, including large-scale language models (LLMs), is expected to be between general-purpose proprietary models and open models specialized for individual use cases, with these two types of models being used interchangeably. Individual users often use general-purpose models as is, while corporate users are likely to incorporate use-case-specific models into their business applications.\nReport issue for preceding element\nWhen using multiple models for each function, application development will require tuning and management of prompts for each model, comparative evaluation testing between models, and regression testing when changing models. Development and testing processes and tools are required that enable the agility of generative AI to quickly and efficiently switch models in response to rapid changes in customers, markets, and business. For the development and operation of machine learning models and generative AI platform models, MLOps [[7](https://arxiv.org/html/2502.17440v1#bib.bib7)] and LLMOps [[5](https://arxiv.org/html/2502.17440v1#bib.bib5)] have been advocated and various tools are available, but there is no established framework or tool for a business application development process that can switch between multiple models in an agile manner.\nReport issue for preceding element\nIn this paper, we define a comprehensive framework for an agile generative AI development process in Chapter 2. In Chapter 3, we summarize the issues with model switching that we call âgenerative AI model agility.â In Chapter 4, we survey existing research and tools and discuss solutions to the problem. In Chapter 5, we verify model switching using actual tools and data. Finally, we present solutions to the problem and their limitations.\nReport issue for preceding element\n##  2 GenAIOps\nReport issue for preceding element\nIn this section, we define the generative AI development and operation process, which is a prerequisite for discussing AI agility.[14] Although there is no standardized process for machine learning such as CRISP-DM, proposals such as MLOps [[8](https://arxiv.org/html/2502.17440v1#bib.bib8)] and CRISP-ML(Q) [[12](https://arxiv.org/html/2502.17440v1#bib.bib12)] have been made that follow CRISP-DM[15] but add machine learning-specific steps [[1](https://arxiv.org/html/2502.17440v1#bib.bib1), [2](https://arxiv.org/html/2502.17440v1#bib.bib2)]. Furthermore, in recent years, LLMOps, a process for developing and operating generative AI models and applications, has also been discussed.\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/x1.png) Figure 1: Steps in GenAI application development and operations. Report issue for preceding element\nBased on this series of proposals, the authors have defined the flow of LLM application development and operation as shown in Figure 1. Our definition simplifies the definition by integrating multiple steps of the MLOps process so that it is sufficient for discussing the agility of generative AI models, which is our main focus, and then details the aspects specific to generative AI development to highlight problems. Broadly speaking, as shown in Figure 1, we will divide the development lifecycle of an application that includes generative AI into the initial version development phase (blue) and the new version development phase (green).\nReport issue for preceding element\n###  2.1 New App Development\nReport issue for preceding element\nFirst, let us look at the flow of development of the initial version. We have broadly categorized the flow of development of a new LLM app (blue part in Figure 1) into five steps.\nReport issue for preceding element \n\nPlan\n    \nThe first step (Step 0 in Figure 1) is planning. For example, âLetâs develop an app using generative AI!â This is the stage where you decide to âdevelop a generative AI application using RAG (e.g., AI Chatbot).â\nReport issue for preceding element \n\nApplication Development\n    \nThe next step (Step 1 in Figure 1) is to develop the app (write the code). Here, we will develop the app (write the code), including selecting the LLM model to be used in the application (in this example, an AI Chatbot).\nReport issue for preceding element \n\nTest\n    \nThe next step after coding (Step 2 in Figure 1) is the testing phase. In LLM app development, prompt engineering is carried out during the testing phase. In this example, prompt engineering is repeated until the AI Chatbot gives the expected answer (within an acceptable range). In traditional terms, this is equivalent to repeating tests. At the same time, model parameter tuning will also be performed. If this is your first experience with LLM application development, it is difficult to estimate how much time will be required for prompt engineering and model parameter tuning.\nReport issue for preceding element \n\nRelease\n    \nAfter testing is complete, the app is released (Step 3 in Figure 1). This is the stage where testing, including prompt engineering and parameter tuning, is completed and the AI Chatbot is released (end users can start using it).\nReport issue for preceding element \n\nObservation\n    \nAfter successfully releasing the first LLM app (AI Chatbot), we enter the observation phase (Step 4 in Figure 1). This is also called the maintenance phase, where we can receive feedback from AI Chatbot users and use it to improve the app. This stage is the final step of the first cycle of the life cycle of developing a new LLM app (the final step in blue in Figure 1).\nReport issue for preceding element\n###  2.2 App Maintenance\nReport issue for preceding element\nNext, the application enters maintenance (the green phase in Figure 1). In this phase, the initial version of the AI Chatbot is released, feedback is received from many users, and then the next version is considered based on that feedback.\nReport issue for preceding element \n\nPlan\n    \nThe AI Chatbot development team begins to consider the next version (Step 5 in Figure 1). This includes discussions on changing to a new model. For example, several months after the service release, new models appear one after another, touting improved performance (improved accuracy), and in order to expand the number of AI Chatbot users and increase user satisfaction, they begin to consider changing the model. This is the story of how the AI Chatbot development team decides to change to the latest and most popular model (replace the model used in the initial release of AI Chatbot with the new model).\nReport issue for preceding element \n\nDevelopment\n    \nThe AI Chatbot development team will identify areas that need to be modified in the app and confirm that the model can be modified without changing the application logic, by simply changing the way the API is called to use the model (e.g., changing the API URL) (Steps 6 and 7 in Figure 1). In this example, the story is about improving the app by replacing the model without making major changes to the application logic.\nReport issue for preceding element \n\nTest\n    \nTo use the newly adopted model, a simple call test is performed to confirm that the model can be replaced simply by changing the method of calling the API (e.g., changing the API URL) (Step 8 in Figure 1). After that, we conduct a test (regression test) to confirm that the response returned is the same as that of the initial release of the app. The test cases are defined and created when developing a new app, and are reused (Step 9 in Figure 1). The important point here is to implement prompt engineering. Due to differences in the models (the model has been replaced), it becomes necessary to modify the prompts (prompt engineering). In other words, prompt engineering that is appropriate for the new model must be implemented. In reality, it is difficult to predict how much work this will entail. It is expected that prompt engineering work equivalent to that required for new development will be carried out for the new model.\nReport issue for preceding element \n\nRelease\n    \nOnce the prompts have been revised (prompt engineering work equivalent to that required for new development), and testing is completed (work equivalent to that required for new development), the AI Chatbot Release 2 adopting the new model is complete (Step 11 in Figure 1).\nReport issue for preceding element \n\nObservation\n    \nAfter the release of the version adopting the new model, feedback from end users was positive and we entered the operation phase (Step 12 in Figure 1).\nReport issue for preceding element\n###  2.3 Regression Test\nReport issue for preceding element\nIn this paper, we consider the automation of prompt engineering to reduce the need for prompt modification when changing models used in LLM applications. In order to optimize prompt modification, some kind of training data is required, but in this paper we assume that the contents of regression testing will be used and discuss what kind of testing needs to be performed.\nReport issue for preceding element\nCheck whether the application behaves the same (behaves the same from the userâs perspective and returns the same answer) before and after the model is changed. This corresponds to the so-called âregression testâ. How should regression test cases for LLM applications be created and prepared appropriately?\nReport issue for preceding element\nIn web application development, particularly in user interface testing, there are test automation frameworks that emulate web browsers and test whether the same user experience is being provided from the perspective of the website user as before (Selenium is a representative tool used in many development sites), making it easy to detect differences in the appearance of a website depending on the version.\nReport issue for preceding element\nHowever, in LLM, even if the same prompt is given, the answer is never exactly the same as the previous time, so is traditional regression testing using the tools mentioned above appropriate?\nReport issue for preceding element\n###  2.4 Auto prompt-engineering\nReport issue for preceding element\nSoft prompt tuning technology has been put to practical use to automate prompt engineering. Prompt tuning, as adopted in Watsonx Tuning Studio, etc., performs tuning by adjusting the prompt vectors that are tokenized and vectorized from user input.\nReport issue for preceding element\nMeanwhile, various methods known as automatic prompt engineering [[14](https://arxiv.org/html/2502.17440v1#bib.bib14)] have been proposed in recent years. Automatic prompt engineering is an optimization technique that aims to have the LLM itself generate prompts that were previously created by humans. For example, the following papers and services have been published:\nReport issue for preceding element\n  * â¢\nAutomatic Prompt Engineer [[14](https://arxiv.org/html/2502.17440v1#bib.bib14)]\nReport issue for preceding element\n  * â¢\nOPRO [[13](https://arxiv.org/html/2502.17440v1#bib.bib13)]\nReport issue for preceding element\n  * â¢\nEvoPrompt [[3](https://arxiv.org/html/2502.17440v1#bib.bib3)]\nReport issue for preceding element\n  * â¢\nProTeGi [[10](https://arxiv.org/html/2502.17440v1#bib.bib10)]\nReport issue for preceding element\n  * â¢\nSAMMO [[11](https://arxiv.org/html/2502.17440v1#bib.bib11)]\nReport issue for preceding element\n\n\nMany of these methods have been proposed for the purpose of publishing academic papers, and have only been verified for specific models. In addition, many of them are not sufficiently maintained as reusable libraries, and only a limited number of them are available for continuous use. Furthermore, there remains the challenge that advanced machine learning expertise is still required to effectively optimize these methods.\nReport issue for preceding element\n##  3 Evaluation Framework\nReport issue for preceding element\nWe developed an evaluation framework for the LLM application, which consists of the following three items:\nReport issue for preceding element \n\nFunctionality\n    \n- We evaluate the accuracy of the LLM by measuring whether the output is performed with the accuracy expected by the developer and how well the AI service executes the task. Here, we also check whether the output is in line with the developerâs intention, even for unexpected input.\nReport issue for preceding element \n\nSafety and trustworthiness\n    \n- Evaluate whether there is any input or output that could identify an individual, or any output that could potentially harm a person. Also evaluate whether the AI complies with various guidelines.\nReport issue for preceding element \n\nFairness\n    \n- We evaluate whether the algorithms and data are unbiased, are socially acceptable from the perspective of diversity, and produce fair output for everyone.\nReport issue for preceding element\nTable 1: Available evaluation metrics Evaluation Metric | Summary | Applicable Tasks  \n---|---|---  \n|  |  SummarizationReport issue for preceding element |  Content GenerationReport issue for preceding element |  Question AnsweringReport issue for preceding element |  Entity ExtractionReport issue for preceding element  \nROUGE |  Indicates the degree to which a summary or generated text reproduces the original data; recall. | â | â | â | â  \nSARI |  Summarization accuracy; indicates the degree of agreement with the original text; agreement rate. | â |  |  |   \nMETEOR |  Average of recall and precision. |  | â | â |   \nText Quality |  Measures F1 score, precision, and recall against model predictions and ground truth data. | â | â |  |   \nBLEU |  Indicates the degree of similarity between the generated text and the evaluation target. | â | â | â |   \nSentence Similarity |  Converts input text to a vector and calculates its similarity. | â |  |  |   \nReadability |  Grades the readability of the generated text on a 7-point scale.. | â | â |  |   \nExact Match |  Indicates the degree of matching to the reference. |  |  | â | â  \nMulti-Label/Class Metrics |  Measures the performance of a multi-label/class prediction model. |  |  |  | â  \nReport issue for preceding element\nTo evaluate the output accuracy of the LLM application, different metrics from watsonx.governance are used depending on the task. For example, in the question answering task, metrics that evaluate recall, similarity, and agreement, such as ROUGE, BLEU, and Exact Match, are used. Table [1](https://arxiv.org/html/2502.17440v1#S3.T1 \"Table 1 â£ 3 Evaluation Framework â£ GenAIOps for GenAI Model-Agility\") summarizes the evaluation metrics that can be used for each LLM task.\nReport issue for preceding element\nTo assess whether both the input and output data contain personal information, we use the PII (Personally Identifiable Information) index from watsonx.governance. In addition, to assess whether both the input and output data contain violent or inappropriate language, we use the HAP (Hate, Abuse, and Profanity) index. In addition, assessment templates on watsonx.governance will be used to evaluate compliance with various guidelines.\nReport issue for preceding element\nPossible causes of bias include bias in the data or samples, and learning bias. To create an AI that produces fair output, various tools can be used in the pre-processing, learning, and post-processing stages of building an LLM. Since this paper does not focus on tuning the LLM itself, it uses a post-processing tool that can evaluate unfairness between segments for the output of an existing AI model. Specifically, we use AI Fairness 360âs Reject Option Classification [[6](https://arxiv.org/html/2502.17440v1#bib.bib6)], Equalized Odds Postprocessing [[4](https://arxiv.org/html/2502.17440v1#bib.bib4)], and Calibrated Equalized Odds Postprocessing [[9](https://arxiv.org/html/2502.17440v1#bib.bib9)] as evaluation indicators.\nReport issue for preceding element\n##  4 Justification of Various Optimization Methods\nReport issue for preceding element\nAmong the various optimization methods that can be applied to LLM, we have actually verified representative methods. In this chapter, we describe the verification results.\nReport issue for preceding element\n###  4.1 Prompt Tuning\nReport issue for preceding element\nTuning Studio (IBM watsonx) allows for fine tuning of existing models using additional training data, prompt tuning, and other tuning methods. Here, we describe the results of prompt tu[5]ning using the dialogue summary dataset DialogSum.\nReport issue for preceding element\nTable 2: Parameters for prompt tuning. Parameter | Value  \n---|---  \nTask | Generation  \nGradient accumulation steps | 16  \nBatch Size | 16  \nInitialization method | random  \nInitialization text | (blank)  \nLearning rate | 0.3  \nMax input tokens | 256  \nMax output tokens | 128  \nNumber of epochs | 20  \nNumber of virtual tokens | 100  \nReport issue for preceding element\nThe model was ibm/granite-13b-chat-v2, and two types of training data, 250 and 9950 cases, were prepared, and the changes in optimization step and loss were compared. The main parameters used in the validation are shown in Table [2](https://arxiv.org/html/2502.17440v1#S4.T2 \"Table 2 â£ 4.1 Prompt Tuning â£ 4 Justification of Various Optimization Methods â£ GenAIOps for GenAI Model-Agility\").\nReport issue for preceding element\n![Refer to caption](https://arxiv.org/html/extracted/6081088/images/tuningresult-250.png) Figure 2: Prompt tuning results (size = 250). Report issue for preceding element ![Refer to caption](https://arxiv.org/html/extracted/6081088/images/tuningresult-250.png) Figure 3: Prompt tuning results (size = 9950). Report issue for preceding element\nAs shown in Figure [2](https://arxiv.org/html/2502.17440v1#S4.F2 \"Figure 2 â£ 4.1 Prompt Tuning â£ 4 Justification of Various Optimization Methods â£ GenAIOps for GenAI Model-Agility\"), when there is little training data, the loss decreases slowly, but when a sufficient amount of training data is used, the loss decreases quickly, as shown in Figure [3](https://arxiv.org/html/2502.17440v1#S4.F3 \"Figure 3 â£ 4.1 Prompt Tuning â£ 4 Justification of Various Optimization Methods â£ GenAIOps for GenAI Model-Agility\"). This shows that this is an effective optimization method in an environment where there is sufficient learning data in advance and prompt tuning such as Tuning Studio can be applied.\nReport issue for preceding element\n###  4.2 Auto Prompt-Engineering\nReport issue for preceding element\nWe implemented a mechanism based on Automatic Prompt Engineer [[14](https://arxiv.org/html/2502.17440v1#bib.bib14)] and confirmed that it is possible to generate prompts using LLM. However, in this verification, we were unable to generate prompts that were significantly better than those generated by humans. This may be because prompt optimization is required to generate prompts, and the optimization method depends on each model.\nReport issue for preceding element\nIn order to utilize automatic prompt engineering in business, it is necessary to develop a more versatile and maintainable solution. In short, it would be sufficient to fix the LLM for generating prompts and perform meta-prompt engineering, but this is only applicable in limited cases. In a more general sense, a mechanism is needed that allows prompt tuning of meta-prompts.\nReport issue for preceding element\n###  4.3 Few-shot Learning\nReport issue for preceding element\nNext, we verified few-shot learning, which allows for efficient tuning with a small amount of training data. The data injected into the prompts was the same as the dataset used for prompt tuning, and example sentences were randomly selected from that dataset, and the change in loss due to the number of injections was compared. The results are shown in Figure 4. The target models for comparison were ibm/granite-13b-chat-v2, as well as two models that had been subjected to prompt tuning.\nReport issue for preceding element\nFor models that have not undergone prompt tuning, it has been confirmed that loss is reduced when few-shot learning is applied to zero-shot. However, when the number of injected samples exceeds a certain level, loss tends to increase, and it is necessary to set an optimal number of injected samples.\nReport issue for preceding element\nIn contrast, the same model with prompt tuning showed lower loss than the model without prompt tuning at the zero-shot point, but when the sample was injected at the few-shot point, the loss tended to increase. This phenomenon will be discussed in the next chapter.\nReport issue for preceding element\n###  4.4 Pitfalls\nReport issue for preceding element\nAs in the example of Few Shot Learning in the previous chapter, when prompt tuning and other tuning methods were applied to LLM, cases were confirmed in which the effects were negated depending on the combination and order. This is because additional optimization inputs prompts with different patterns from the learning data used in prompt tuning, which is thought to be a phenomenon similar to overfitting in machine learning.\nReport issue for preceding element\nTo deal with such cases, it is necessary to carefully select the appropriate combination of tuning methods and the order in which they are applied. For example, in manual and automatic prompt engineering and few shot learning, it is expected that both tuning methods will be effective if prompt tuning is performed after determining the base prompt.\nReport issue for preceding element\nIn addition, prompt tuning is not a very effective tuning method when combined with methods that dynamically change prompts, such as RAG (Retrieval-Augmented Generation), and it is considered preferable to use these methods exclusively.\nReport issue for preceding element\n##  5 Concluding Remarks\nReport issue for preceding element\nIn this paper, we presented the problem of LLM changes in the development and operation of generative AI applications as generative AI model agility, and discussed solutions. We defined GenAIOps, a generative AI application development and operation process that extends MLOps, and clarified the issues and related matters within each step. We took up prompt tuning as a solution direction and investigated existing tools and research. In particular, we discussed the effectiveness and limitations from a case study that utilized existing soft prompt tuning tools.\nReport issue for preceding element\nThere are many directions for future research, but from the perspective of generative AI model agility, we would like to clarify the compatibility between existing LLMs. We also want to develop practical tools for advanced prompt tuning, which will be essential for CI/CD of GenAIOps.\nReport issue for preceding element\n## References\nReport issue for preceding element\n  * [1]â Saleema Amershi, Andrew Begel, Christian Bird, Robert DeLine, Harald C. Gall, Ece Kamar, Nachiappan Nagappan, Besmira Nushi, and Thomas Zimmermann.  Software engineering for machine learning: a case study.  In Helen Sharp and Mike Whalen, editors, Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Practice, ICSE (SEIP) 2019, Montreal, QC, Canada, May 25-31, 2019, pages 291â300. IEEE / ACM, 2019. \n  * [2]â Eric Breck, Shanqing Cai, Eric Nielsen, Michael Salib, and D. Sculley.  The ML test score: A rubric for ML production readiness and technical debt reduction.  In Jian-Yun Nie, Zoran Obradovic, Toyotaro Suzumura, Rumi Ghosh, Raghunath Nambiar, Chonggang Wang, Hui Zang, Ricardo Baeza-Yates, Xiaohua Hu, Jeremy Kepner, Alfredo Cuzzocrea, Jian Tang, and Masashi Toyoda, editors, 2017 IEEE International Conference on Big Data (IEEE BigData 2017), Boston, MA, USA, December 11-14, 2017, pages 1123â1132. IEEE Computer Society, 2017. \n  * [3]â Qingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao Song, Xu Tan, Guoqing Liu, Jiang Bian, and Yujiu Yang.  Connecting large language models with evolutionary algorithms yields powerful prompt optimizers.  In The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024. OpenReview.net, 2024. \n  * [4]â Moritz Hardt, Eric Price, and Nathan Srebro.  Equality of opportunity in supervised learning.  In Proceedings of the 30th International Conference on Neural Information Processing Systems, NIPSâ16, pages 3323â3331, Red Hook, NY, USA, 2016. Curran Associates Inc. \n  * [5]â Ken Huang, Vishwas Manral, and Wickey Wang.  From LLMOps to DevSecOps for GenAI.  Generative AI Security: Theories and Practices, pages 241â269, 2024. \n  * [6]â Faisal Kamiran and Toon Calders.  Data preprocessing techniques for classification without discrimination.  In Proceedings of the 3rd International Conference on Knowledge Management and Information Sharing, KMISâ11, pages 344â349, SetÃºbal, Portugal, 2012. SciTePress. \n  * [7]â Sasu MÃ¤kinen, Henrik SkogstrÃ¶m, Eero Laaksonen, and Tommi Mikkonen.  Who needs mlops: What data scientists seek to accomplish and how can mlops help?  In 1st IEEE/ACM Workshop on AI Engineering - Software Engineering for AI, WAIN@ICSE 2021, Madrid, Spain, May 30-31, 2021, pages 109â112. IEEE, 2021. \n  * [8]â Fernando MartÃ­nez-Plumed, Lidia Contreras Ochando, CÃ¨sar Ferri, JosÃ© HernÃ¡ndez-Orallo, Meelis Kull, Nicolas Lachiche, MarÃ­a JosÃ© RamÃ­rez-Quintana, and Peter A. Flach.  CRISP-DM twenty years later: From data mining processes to data science trajectories.  IEEE Trans. Knowl. Data Eng., 33(8):3048â3061, 2021. \n  * [9]â Geoff Pleiss, Manish Raghavan, Felix Wu, Jon Kleinberg, and Kilian Q. Weinberger.  On fairness and calibration.  In Proceedings of the 31st International Conference on Neural Information Processing Systems, NIPSâ17, pages 5684â5694, Red Hook, NY, USA, 2017. Curran Associates Inc. \n  * [10]â Reid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chenguang Zhu, and Michael Zeng.  Automatic prompt optimization with âgradient descentâ and beam search.  In Houda Bouamor, Juan Pino, and Kalika Bali, editors, Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023, pages 7957â7968. Association for Computational Linguistics, 2023. \n  * [11]â Tobias Schnabel and Jennifer Neville.  Symbolic prompt program search: A structure-aware approach to efficient compile-time prompt optimization.  In Yaser Al-Onaizan, Mohit Bansal, and Yun-Nung Chen, editors, Findings of the Association for Computational Linguistics: EMNLP 2024, Miami, Florida, USA, November 12-16, 2024, pages 670â686. Association for Computational Linguistics, 2024. \n  * [12]â Stefan Studer, Thanh Binh Bui, Christian Drescher, Alexander Hanuschkin, Ludwig Winkler, Steven Peters, and Klaus-Robert MÃ¼ller.  Towards CRISP-ML(Q): A machine learning process model with quality assurance methodology.  Mach. Learn. Knowl. Extr., 3(2):392â413, 2021. \n  * [13]â Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V. Le, Denny Zhou, and Xinyun Chen.  Large language models as optimizers.  In The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024. OpenReview.net, 2024. \n  * [14]â Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba.  Large language models are human-level prompt engineers.  In The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net, 2023. \n\n\nReport Issue\n##### Report Github Issue\nTitle:Content selection saved. Describe the issue below:Description:\nSubmit without GithubSubmit in Github\nReport Issue for Selection\nGenerated by [ L A T E xml ![\\[LOGO\\]](https://arxiv.org/html/2502.17440v1) ](https://math.nist.gov/~BMiller/LaTeXML/)\n## Instructions for reporting errors\nWe are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:\n  * Click the \"Report Issue\" button.\n  * Open a report feedback form via keyboard, use \"**Ctrl + ?** \".\n  * Make a text selection and click the \"Report Issue for Selection\" button near your cursor.\n  * You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.\n\n\nOur team has already identified [the following issues](https://github.com/arXiv/html_feedback/issues). We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.\nHave a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a [list of packages that need conversion](https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML), and welcome [developer contributions](https://github.com/brucemiller/LaTeXML/issues).\n"
  },
  {
    "link": "https://arxiv.org/abs/2312.10997",
    "raw_content": "[![close this message](https://arxiv.org/static/browse/0.3.4/images/icons/close-slider.png)](https://arxiv.org/abs/2312.10997)\n![arXiv smileybones](https://arxiv.org/static/browse/0.3.4/images/icons/smileybones-pixel.png)\n## arXiv Is Hiring a DevOps Engineer\nWork on one of the world's most important websites and make an impact on open science.\n[**View Jobs**](https://info.arxiv.org/hiring/index.html)\n[Skip to main content](https://arxiv.org/abs/2312.10997#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\narXiv Is Hiring a DevOps Engineer\n[View Jobs](https://info.arxiv.org/hiring/index.html)\nWe gratefully acknowledge support from the Simons Foundation, [member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors. [Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/) > [cs](https://arxiv.org/list/cs/recent) > arXiv:2312.10997 \n[Help](https://info.arxiv.org/help) | [Advanced Search](https://arxiv.org/search/advanced)\nAll fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[ ![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg) ](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n## quick links\n  * [Login](https://arxiv.org/login)\n  * [Help Pages](https://info.arxiv.org/help)\n  * [About](https://info.arxiv.org/about)\n\n\n# Computer Science > Computation and Language\n**arXiv:2312.10997** (cs) \n[Submitted on 18 Dec 2023 ([v1](https://arxiv.org/abs/2312.10997v1)), last revised 27 Mar 2024 (this version, v5)]\n# Title:Retrieval-Augmented Generation for Large Language Models: A Survey\nAuthors:[Yunfan Gao](https://arxiv.org/search/cs?searchtype=author&query=Gao,+Y), [Yun Xiong](https://arxiv.org/search/cs?searchtype=author&query=Xiong,+Y), [Xinyu Gao](https://arxiv.org/search/cs?searchtype=author&query=Gao,+X), [Kangxiang Jia](https://arxiv.org/search/cs?searchtype=author&query=Jia,+K), [Jinliu Pan](https://arxiv.org/search/cs?searchtype=author&query=Pan,+J), [Yuxi Bi](https://arxiv.org/search/cs?searchtype=author&query=Bi,+Y), [Yi Dai](https://arxiv.org/search/cs?searchtype=author&query=Dai,+Y), [Jiawei Sun](https://arxiv.org/search/cs?searchtype=author&query=Sun,+J), [Meng Wang](https://arxiv.org/search/cs?searchtype=author&query=Wang,+M), [Haofen Wang](https://arxiv.org/search/cs?searchtype=author&query=Wang,+H)\nView a PDF of the paper titled Retrieval-Augmented Generation for Large Language Models: A Survey, by Yunfan Gao and 8 other authors\n[View PDF](https://arxiv.org/pdf/2312.10997) [HTML (experimental)](https://arxiv.org/html/2312.10997v5)\n> Abstract:Large Language Models (LLMs) showcase impressive capabilities but encounter challenges like hallucination, outdated knowledge, and non-transparent, untraceable reasoning processes. Retrieval-Augmented Generation (RAG) has emerged as a promising solution by incorporating knowledge from external databases. This enhances the accuracy and credibility of the generation, particularly for knowledge-intensive tasks, and allows for continuous knowledge updates and integration of domain-specific information. RAG synergistically merges LLMs' intrinsic knowledge with the vast, dynamic repositories of external databases. This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the Modular RAG. It meticulously scrutinizes the tripartite foundation of RAG frameworks, which includes the retrieval, the generation and the augmentation techniques. The paper highlights the state-of-the-art technologies embedded in each of these critical components, providing a profound understanding of the advancements in RAG systems. Furthermore, this paper introduces up-to-date evaluation framework and benchmark. At the end, this article delineates the challenges currently faced and points out prospective avenues for research and development. \nComments: | Ongoing Work  \n---|---  \nSubjects: |  Computation and Language (cs.CL); Artificial Intelligence (cs.AI)  \nCite as: | [arXiv:2312.10997](https://arxiv.org/abs/2312.10997) [cs.CL]  \n| (or  [arXiv:2312.10997v5](https://arxiv.org/abs/2312.10997v5) [cs.CL] for this version)   \n|  <https://doi.org/10.48550/arXiv.2312.10997> Focus to learn more arXiv-issued DOI via DataCite  \n## Submission history\nFrom: Yunfan Gao [[view email](https://arxiv.org/show-email/c3ea0ed7/2312.10997)] **[[v1]](https://arxiv.org/abs/2312.10997v1)** Mon, 18 Dec 2023 07:47:33 UTC (7,541 KB) **[[v2]](https://arxiv.org/abs/2312.10997v2)** Fri, 29 Dec 2023 18:25:00 UTC (6,421 KB) **[[v3]](https://arxiv.org/abs/2312.10997v3)** Wed, 3 Jan 2024 17:04:40 UTC (7,508 KB) **[[v4]](https://arxiv.org/abs/2312.10997v4)** Fri, 5 Jan 2024 01:18:27 UTC (7,508 KB) **[v5]** Wed, 27 Mar 2024 09:16:57 UTC (1,955 KB) \nFull-text links:\n## Access Paper:\nView a PDF of the paper titled Retrieval-Augmented Generation for Large Language Models: A Survey, by Yunfan Gao and 8 other authors\n  * [View PDF](https://arxiv.org/pdf/2312.10997)\n  * [HTML (experimental)](https://arxiv.org/html/2312.10997v5)\n  * [TeX Source](https://arxiv.org/src/2312.10997)\n  * [Other Formats](https://arxiv.org/format/2312.10997)\n\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/ \"Rights to this article\")\nCurrent browse context: \ncs.CL\n[< prev](https://arxiv.org/prevnext?id=2312.10997&function=prev&context=cs.CL \"previous in cs.CL \\(accesskey p\\)\") |  [next >](https://arxiv.org/prevnext?id=2312.10997&function=next&context=cs.CL \"next in cs.CL \\(accesskey n\\)\")\n[new](https://arxiv.org/list/cs.CL/new) |  [recent](https://arxiv.org/list/cs.CL/recent) | [2023-12](https://arxiv.org/list/cs.CL/2023-12)\nChange to browse by: \n[cs](https://arxiv.org/abs/2312.10997?context=cs) [cs.AI](https://arxiv.org/abs/2312.10997?context=cs.AI)\n### References & Citations\n  * [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2312.10997)\n  * [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2312.10997)\n  * [Semantic Scholar](https://api.semanticscholar.org/arXiv:2312.10997)\n\n\n### [ 4 blog links](https://arxiv.org/tb/2312.10997)\n([what is this?](https://info.arxiv.org/help/trackback.html)) \n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citation Loading...\n## BibTeX formatted citation\nÃ\nloading...\nData provided by: \n### Bookmark\n[ ![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png) ](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2312.10997&description=Retrieval-Augmented Generation for Large Language Models: A Survey \"Bookmark on BibSonomy\") [ ![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png) ](https://reddit.com/submit?url=https://arxiv.org/abs/2312.10997&title=Retrieval-Augmented Generation for Large Language Models: A Survey \"Bookmark on Reddit\")\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer _([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\nConnected Papers Toggle\nConnected Papers _([What is Connected Papers?](https://www.connectedpapers.com/about))_\nLitmaps Toggle\nLitmaps _([What is Litmaps?](https://www.litmaps.co/))_\nscite.ai Toggle\nscite Smart Citations _([What are Smart Citations?](https://www.scite.ai/))_\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv _([What is alphaXiv?](https://alphaxiv.org/))_\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers _([What is CatalyzeX?](https://www.catalyzex.com))_\nDagsHub Toggle\nDagsHub _([What is DagsHub?](https://dagshub.com/))_\nGotitPub Toggle\nGotit.pub _([What is GotitPub?](http://gotit.pub/faq))_\nHuggingface Toggle\nHugging Face _([What is Huggingface?](https://huggingface.co/huggingface))_\nLinks to Code Toggle\nPapers with Code _([What is Papers with Code?](https://paperswithcode.com/))_\nScienceCast Toggle\nScienceCast _([What is ScienceCast?](https://sciencecast.org/welcome))_\nDemos\n# Demos\nReplicate Toggle\nReplicate _([What is Replicate?](https://replicate.com/docs/arxiv/about))_\nSpaces Toggle\nHugging Face Spaces _([What is Spaces?](https://huggingface.co/docs/hub/spaces))_\nSpaces Toggle\nTXYZ.AI _([What is TXYZ.AI?](https://txyz.ai))_\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower _([What are Influence Flowers?](https://influencemap.cmlab.dev/))_\nCore recommender toggle\nCORE Recommender _([What is CORE?](https://core.ac.uk/services/recommender))_\n  * Author\n  * Venue\n  * Institution\n  * Topic\n\n\nAbout arXivLabs \n# arXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2312.10997) | [Disable MathJax](javascript:setMathjaxCookie\\(\\)) ([What is MathJax?](https://info.arxiv.org/help/mathjax.html)) \n  * [About](https://info.arxiv.org/about)\n  * [Help](https://info.arxiv.org/help)\n\n\n  * contact arXivClick here to contact arXiv [ Contact](https://info.arxiv.org/help/contact.html)\n  * subscribe to arXiv mailingsClick here to subscribe [ Subscribe](https://info.arxiv.org/help/subscribe)\n\n\n  * [Copyright](https://info.arxiv.org/help/license/index.html)\n  * [Privacy Policy](https://info.arxiv.org/help/policies/privacy_policy.html)\n\n\n  * [Web Accessibility Assistance](https://info.arxiv.org/help/web_accessibility.html)\n  * [arXiv Operational Status ](https://status.arxiv.org) Get status notifications via [email](https://subscribe.sorryapp.com/24846f03/email/new) or [slack](https://subscribe.sorryapp.com/24846f03/slack/new)\n\n\n"
  }
]